{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "if 'Imports':\n",
    "    # from Scripts.DataManager.DabasePreparations.AmazonReviewSentiGraph import AmazonReviewSentiGraph\n",
    "    from Scripts.Models.ModelsManager.SimpleGraphClassifierModelManager import SimpleGraphClassifierModelManager\n",
    "    from Scripts.Configs.ConfigClass import Config\n",
    "    config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence')\n",
    "    from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.CoOccurrenceGraphConstructor import CoOccurrenceGraphConstructor\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import GraphConstructor, TextGraphType\n",
    "from Scripts.DataManager.GraphLoader.GraphLoader import GraphLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch\n",
    "from Scripts.DataManager.Datasets.GraphConstructorDataset import GraphConstructorDataset\n",
    "\n",
    "class AmazonReviewGraphLoader(GraphLoader):\n",
    "\n",
    "    def __init__(self, config: Config, has_val: bool, has_test: bool, test_size=0.2, val_size=0.2, num_workers=2,\n",
    "                 drop_last=True, train_data_path='', test_data_path='', graphs_path='', batch_size = 32,\n",
    "                 device='cpu', shuffle = False, num_data_load=-1,\n",
    "                 graph_type: TextGraphType = TextGraphType.CO_OCCURRENCE, *args, **kwargs):\n",
    "        kwargs['num_workers'] = num_workers\n",
    "        kwargs['batch_size'] = batch_size\n",
    "        kwargs['num_workers'] = num_workers\n",
    "        kwargs['shuffle'] = shuffle\n",
    "        super(AmazonReviewGraphLoader, self)\\\n",
    "            .__init__(config, device, has_val, has_test, test_size, val_size, *args, **kwargs)\n",
    "\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.drop_last = drop_last\n",
    "        self.graph_type = graph_type\n",
    "        self.train_data_path = 'data/Amazon-Review/train_sm.csv' if train_data_path == '' else train_data_path\n",
    "        self.test_data_path = 'data/Amazon-Review/test_sm.csv' if test_data_path == '' else test_data_path\n",
    "        self.train_df: pd.DataFrame = pd.DataFrame()\n",
    "        self.test_df: pd.DataFrame = pd.DataFrame()\n",
    "        self.labels = None\n",
    "        self.dataset = None\n",
    "        self.shuffle = shuffle\n",
    "        self.num_node_features = 0\n",
    "        self.num_classes = 0\n",
    "        self.df: pd.DataFrame = pd.DataFrame()\n",
    "        self.__train_dataset, self.__val_dataset, self.__test_dataset = None, None, None\n",
    "        self.num_data_load = num_data_load\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        pass\n",
    "    def setup2(self):\n",
    "        self.train_df = pd.read_csv(path.join(self.config.root, self.train_data_path))\n",
    "        self.test_df = pd.read_csv(path.join(self.config.root, self.test_data_path))\n",
    "        self.train_df.columns = ['Polarity', 'Title', 'Review']\n",
    "        self.test_df.columns = ['Polarity', 'Title', 'Review']\n",
    "        self.train_df = self.train_df[['Polarity', 'Review']]\n",
    "        self.test_df = self.test_df[['Polarity', 'Review']]\n",
    "        self.df = pd.concat([self.train_df, self.test_df])\n",
    "        labels = self.df['Polarity']\n",
    "        self.num_data_load = self.num_data_load if self.num_data_load>0 else self.df.shape[0]\n",
    "        labels = labels.apply(lambda p: 0 if p == 1 else 1).to_numpy()[:self.num_data_load]\n",
    "        labels = torch.from_numpy(labels)\n",
    "        self.labels = labels.to(torch.float32).view(-1, 1)\n",
    "        graph_constructor = self.__get_co_occurrence_graph()\n",
    "        self.dataset = GraphConstructorDataset(graph_constructor, self.labels)\n",
    "        sample_graph = graph_constructor.get_first()\n",
    "        self.num_node_features = sample_graph.num_features\n",
    "        self.num_classes = len(torch.unique(self.labels))\n",
    "        self.__train_dataset, self.__val_dataset, self.__test_dataset =\\\n",
    "            random_split(self.dataset, [1-self.val_size-self.test_size, self.val_size, self.test_size])\n",
    "\n",
    "    def teardown(self, stage: str) -> None:\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(self.__train_dataset)\n",
    "        print(self.batch_size)\n",
    "        print(self.drop_last)\n",
    "        print(self.shuffle)\n",
    "        print(self.num_workers)\n",
    "        return DataLoader(self.__train_dataset, batch_size=self.batch_size, drop_last=self.drop_last,\n",
    "                          shuffle=self.shuffle, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.__test_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.__val_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def __set_graph_constructors(self, graph_type: TextGraphType):\n",
    "        graph_constructors = {}\n",
    "        if TextGraphType.CO_OCCURRENCE in graph_type:\n",
    "            graph_constructors[TextGraphType.CO_OCCURRENCE] = self.__get_co_occurrence_graph()\n",
    "        if TextGraphType.DEPENDENCY in graph_type:\n",
    "            pass\n",
    "        if TextGraphType.SEQUENTIAL in graph_type:\n",
    "            pass\n",
    "        if TextGraphType.TAGS in graph_type:\n",
    "            pass\n",
    "        return graph_constructors\n",
    "\n",
    "    def __get_co_occurrence_graph(self):\n",
    "        return CoOccurrenceGraphConstructor(self.train_df['Review'][:self.num_data_load], 'data/GraphData/AmazonReview', self.config,\n",
    "                                         lazy_construction=False,\n",
    "                                         load_preprocessed_data=False, naming_prepend='graph')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from Scripts.DataManager.GraphLoader.AmazonReviewGraphLoader import AmazonReviewGraphLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\lightning\\datamodule.py:49: The 'shuffle=True' option is ignored in 'AmazonReviewGraphLoader'. Remove it from the argument list to disable this warning\n"
     ]
    }
   ],
   "source": [
    "if 'Load and Prepare data':\n",
    "    data_manager = AmazonReviewGraphLoader(config, True, True, num_workers=2, batch_size=8, shuffle=True, num_data_load = -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 100\n",
      "i: 200\n",
      "i: 300\n",
      "i: 400\n",
      "i: 500\n",
      "i: 600\n",
      "i: 700\n",
      "i: 800\n",
      "i: 900\n",
      "i: 1000\n",
      "i: 1100\n",
      "i: 1200\n",
      "i: 1300\n",
      "i: 1400\n",
      "i: 1500\n",
      "i: 1600\n",
      "i: 1700\n",
      "i: 1800\n",
      "i: 1900\n",
      "i: 2000\n",
      "i: 2100\n",
      "i: 2200\n",
      "i: 2300\n",
      "i: 2400\n",
      "i: 2500\n",
      "i: 2600\n",
      "i: 2700\n",
      "i: 2800\n",
      "i: 2900\n",
      "i: 3000\n",
      "i: 3100\n",
      "i: 3200\n",
      "i: 3300\n",
      "i: 3400\n",
      "i: 3500\n",
      "i: 3600\n",
      "i: 3700\n",
      "i: 3800\n",
      "i: 3900\n",
      "i: 4000\n",
      "i: 4100\n",
      "i: 4200\n",
      "i: 4300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdata_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m data_manager\u001B[38;5;241m.\u001B[39mtrain_dataloader()\n",
      "Cell \u001B[1;32mIn[3], line 64\u001B[0m, in \u001B[0;36mAmazonReviewGraphLoader.setup2\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     62\u001B[0m labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(labels)\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 64\u001B[0m graph_constructor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_co_occurrence_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m GraphConstructorDataset(graph_constructor, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels)\n\u001B[0;32m     66\u001B[0m sample_graph \u001B[38;5;241m=\u001B[39m graph_constructor\u001B[38;5;241m.\u001B[39mget_first()\n",
      "Cell \u001B[1;32mIn[3], line 105\u001B[0m, in \u001B[0;36mAmazonReviewGraphLoader.__get_co_occurrence_graph\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__get_co_occurrence_graph\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mCoOccurrenceGraphConstructor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mReview\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_data_load\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/GraphData/AmazonReview\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mlazy_construction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mload_preprocessed_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnaming_prepend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgraph\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\CoOccurrenceGraphConstructor.py:46\u001B[0m, in \u001B[0;36mCoOccurrenceGraphConstructor.__init__\u001B[1;34m(self, texts, save_path, config, lazy_construction, load_preprocessed_data, naming_prepend)\u001B[0m\n\u001B[0;32m     44\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     45\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mi: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 46\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graphs[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvar\u001B[38;5;241m.\u001B[39mgraphs_name[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnaming_prepend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_all_data()\n",
      "File \u001B[1;32m~\\Projects\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\CoOccurrenceGraphConstructor.py:56\u001B[0m, in \u001B[0;36mCoOccurrenceGraphConstructor.to_graph\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     55\u001B[0m unique_word_vectors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_unique_words_vector(unique_words)\n\u001B[1;32m---> 56\u001B[0m co_occurrence_matrix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_co_occurrence_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munique_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munique_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__create_graph(unique_word_vectors, co_occurrence_matrix)\n",
      "File \u001B[1;32m~\\Projects\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\CoOccurrenceGraphConstructor.py:85\u001B[0m, in \u001B[0;36mCoOccurrenceGraphConstructor.__get_co_occurrence_matrix\u001B[1;34m(doc, unique_words, unique_map)\u001B[0m\n\u001B[0;32m     83\u001B[0m     grid_ids \u001B[38;5;241m=\u001B[39m [(x, y) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m n_gram_ids \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m n_gram_ids \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m!=\u001B[39m y]\n\u001B[0;32m     84\u001B[0m     grid_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(grid_ids, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint)\n\u001B[1;32m---> 85\u001B[0m     dense_mat[grid_ids[:, \u001B[38;5;241m0\u001B[39m], grid_ids[:, \u001B[38;5;241m1\u001B[39m]] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     86\u001B[0m dense_mat \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mnormalize(dense_mat)\n\u001B[0;32m     87\u001B[0m sparse_mat \u001B[38;5;241m=\u001B[39m dense_mat\u001B[38;5;241m.\u001B[39mto_sparse_coo()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data_manager.setup2()\n",
    "data_loader = data_manager.train_dataloader()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.dataset.__len__())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import time\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8, exectime: 37.84641790390015\n",
      "8, exectime: 0.3111612796783447\n",
      "8, exectime: 0.0010538101196289062\n",
      "8, exectime: 0.0029754638671875\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "for X,y in data_loader:\n",
    "    print(f'{len(X)}, exectime: {time.time()-begin}')\n",
    "    begin = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from Scripts.Models.BaseModels.GcnGatModel1 import GcnGatModel1\n",
    "from Scripts.Models.LightningModels.LightningModels import BinaryLightningModel\n",
    "import torch\n",
    "import lightning as L"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "torch_model = GcnGatModel1(300, 1)\n",
    "lightning_model = BinaryLightningModel(torch_model,\n",
    "                                 torch.optim.Adam(torch_model.parameters(), lr=0.001, weight_decay=0.005),\n",
    "                                       torch.nn.BCEWithLogitsLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(data_manager, L.LightningDataModule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | GcnGatModel1      | 245 K \n",
      "1 | loss_func | BCEWithLogitsLoss | 0     \n",
      "2 | train_acc | BinaryAccuracy    | 0     \n",
      "3 | val_acc   | BinaryAccuracy    | 0     \n",
      "4 | test_acc  | BinaryAccuracy    | 0     \n",
      "------------------------------------------------\n",
      "245 K     Trainable params\n",
      "0         Non-trainable params\n",
      "245 K     Total params\n",
      "0.983     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x00000173AE39AF80>\n",
      "8\n",
      "True\n",
      "True\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535f4c72b5f74cf6a8566b2784772c4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd7cc20d8cbf41ed832109fbdd476cdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 449. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 266. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "251f7f8e4cef4b72bf695756a6e462dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aaf62a440b6a4a40b19c90c369708416"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5d844eb6c6e4819b9928559ece90a81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c06c2f5207904c85904a4b50552d0d96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66c4b135949844fd9c009eb38361b287"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59a83113d6bf4d2c9793c3da595a4236"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb3165872d984c69b7c8f1de88e917c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d218c894741a444e860d2521c30e077c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2ccb7ac6c1549359167a1f81826423b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, num_sanity_val_steps=0)\n",
    "# trainer.fit(lightning_model, datamodule=data_manager)\n",
    "trainer.fit(lightning_model,\n",
    "            train_dataloaders=data_manager.train_dataloader(),\n",
    "            val_dataloaders=data_manager.val_dataloader())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import summary\n",
    "from tqdm import tqdm\n",
    "from Scripts.Models.LightningModels.LightningModels import BaseLightningModel\n",
    "from Scripts.Models.ModelsManager.ModelManager import ModelManager\n",
    "from Scripts.Models.BaseModels.GATGCNClassifierSimple import GNNClassifier\n",
    "from Scripts.DataManager.GraphLoader.NLabeledGraphLoader import NLabeledGraphLoader\n",
    "from Scripts.Utils.enums import Optimizer, LossType\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "class SimpleNodeClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self, graph_handler: NLabeledGraphLoader, device=torch.device('cpu'),\n",
    "                 lr=0.01, weight_decay=0.001, optimizer_type: Optimizer = Optimizer.ADAM,\n",
    "                 loss_type: LossType = LossType.CROSS_ENTROPY):\n",
    "        super(SimpleNodeClassifierModelManager, self).__init__(lr, weight_decay, device)\n",
    "        self.graph_handler = graph_handler\n",
    "        self.num_output_classes = self.graph_handler.num_classes\n",
    "        self.num_input_features = self.graph_handler.num_features\n",
    "        self.loss_type = loss_type\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.model, self.optimizer, self.loss_func = self._create_model(lr, weight_decay, optimizer_type, loss_type)\n",
    "        self.lightning_model = BaseLightningModel(self.model, self.optimizer, self.loss_func)\n",
    "\n",
    "    def train(self, epoch_num: int = 100, lr: float = None, l2_norm: float = None, optimizer: Optimizer = None):\n",
    "\n",
    "        trainer = L.Trainer(max_epochs=100, accelerator='gpu', devices=1)\n",
    "        trainer.fit(self.lightning_model,\n",
    "                    train_dataloaders=self.graph_handler.get_train_data(),\n",
    "                    val_dataloaders=self.graph_handler.get_val_data()\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "        if lr or l2_norm or optimizer:\n",
    "            self.set_optimizer(lr, l2_norm, optimizer)\n",
    "\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "\n",
    "        train_node_x, train_node_y, train_edges = self.graph_handler.get_train_data()\n",
    "        test_node_x, test_node_y, test_edges = self.graph_handler.get_test_data()\n",
    "        for i in tqdm(range(epoch_num)):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            my_node, my_label, my_edges = self.graph_handler.extract_random_sub_edges_graph()\n",
    "            y_hat: torch.Tensor = self.model(my_node, my_edges)\n",
    "            loss = self.loss_func(F.one_hot(my_label, self.num_output_classes).float(), y_hat)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "            train_losses.append(loss_value)\n",
    "            accuracy = (torch.sum((y_hat.argmax(dim=1) == my_label).float()) / len(my_label)).cpu().numpy()\n",
    "            train_accuracies.append(accuracy)\n",
    "\n",
    "            my_node, my_label, my_edges = self.graph_handler.extract_random_sub_edges_graph()\n",
    "            y_hat: torch.Tensor = self.model(my_node, my_edges)\n",
    "            loss = self.loss_func(F.one_hot(my_label, self.graph_handler.num_classes).float(), y_hat)\n",
    "            loss_value = loss.item()\n",
    "            test_losses.append(loss_value)\n",
    "            accuracy = (torch.sum((y_hat.argmax(dim=1) == my_label).float()) / len(my_label)).cpu().numpy()\n",
    "            test_accuracies.append(accuracy)\n",
    "        self.history['train_losses'] = train_losses\n",
    "        self.history['train_accuracies'] = train_accuracies\n",
    "        self.history['test_losses'] = test_losses\n",
    "        self.history['test_accuracies'] = test_accuracies\n",
    "        return self.history\n",
    "\n",
    "    def evaluate(self):\n",
    "        node_x, node_y, edges = self.graph_handler.get_val_data()\n",
    "        self.model.eval()\n",
    "        y_hat: torch.Tensor = self.model(node_x, edges)\n",
    "        loss = self.loss_func(F.one_hot(node_y, self.num_output_classes).float(), y_hat)\n",
    "        return y_hat, loss\n",
    "\n",
    "    def predict(self, node_x, edge_index):\n",
    "        self.model.eval()\n",
    "        y_hat: torch.Tensor = self.model(node_x, edge_index)\n",
    "        return y_hat\n",
    "\n",
    "    def draw_summary(self):\n",
    "        nodes_x, nodes_y, edge_indices_test = self.graph_handler.get_test_data()\n",
    "        nodes_x, nodes_y, edge_indices_test = self.graph_handler.extract_random_sub_edges_graph(2)\n",
    "        print(summary(self.model, nodes_x, edge_indices_test))\n",
    "\n",
    "    def _create_model(self, lr, l2_norm, optimizer_type, loss_type):\n",
    "        model = GNNClassifier(input_feature=self.num_input_features, class_counts=self.num_output_classes)\n",
    "        optimizer = ModelManager._create_optimizer(model, lr, l2_norm, optimizer_type)\n",
    "        loss_func = ModelManager._create_loss_func(loss_type)\n",
    "        model.to(self.device)\n",
    "        return model, optimizer, loss_func\n",
    "\n",
    "    def set_optimizer(self, lr, l2_norm, optimizer=Optimizer.ADAM):\n",
    "        if lr:\n",
    "            self.lr = lr\n",
    "        if l2_norm:\n",
    "            self.l2_norm = l2_norm\n",
    "        if optimizer:\n",
    "            self.optimizer_type = optimizer\n",
    "        self.optimizer = ModelManager._create_optimizer(self.model, self.lr, self.l2_norm, self.optimizer_type)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from Scripts.Models.ModelsManager.SimpleGraphClassifierModelManager import SimpleGraphClassifierModelManager\n",
    "\n",
    "if 'Train Data':\n",
    "    model_manager = SimpleGraphClassifierModelManager(\n",
    "        data_manager.graph_constructors[TextGraphType.CO_OCCURRENCE])\n",
    "    model_manager.draw_summary()\n",
    "    model_manager.train()\n",
    "    model_manager.draw_training_results()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Draw Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Scripts.Models.BaseModels.GcnGatModel1 import GcnGatModel1\n",
    "from transformers.models.longformer.convert_longformer_original_pytorch_lightning_to_pytorch import LightningModel\n",
    "mymodel = GcnGatModel1(100, 10, config)\n",
    "print(type(mymodel))\n",
    "model = LightningModel(mymodel)\n",
    "print(type(model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def sample_func() -> Tuple[int, float]:\n",
    "    return 1, 2.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "targets = sample_func"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Scripts.Utils.enums import Optimizer\n",
    "\n",
    "type(Optimizer.ADAM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_func():\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aa: Callable = None\n",
    "type(aa)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}