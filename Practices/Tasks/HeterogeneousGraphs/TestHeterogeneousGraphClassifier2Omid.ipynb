{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.AmazonReviewGraphDataModule import AmazonReviewGraphDataModule\n",
    "from Scripts.DataManager.GraphLoader.TwitterGraphDataModule import TwitterGraphDataModule\n",
    "import time\n",
    "\n",
    "config = Config(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.end_data_load: 3000\n",
      "filename: E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\data/GraphData/Sentiment140\\140_sentiment\\graph_var.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Loding Graphs From File : 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "tag_dep_seq_sent = TextGraphType.SENTIMENT\n",
    "data_manager = TwitterGraphDataModule(config, True, True, shuffle=False,start_data_load=0, end_data_load = 3000, device='cpu', batch_size=batch_size, graph_type=tag_dep_seq_sent, load_preprocessed_data = True)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  dep={\n",
       "    length=45,\n",
       "    x=[45],\n",
       "  },\n",
       "  tag={\n",
       "    length=50,\n",
       "    x=[50],\n",
       "  },\n",
       "  word={ x=[24, 300] },\n",
       "  sentence={ x=[1, 300] },\n",
       "  general={ x=[1, 300] },\n",
       "  sentiment={ x=[2, 300] },\n",
       "  (dep, dep_word, word)={\n",
       "    edge_index=[2, 23],\n",
       "    edge_attr=[23],\n",
       "  },\n",
       "  (word, word_dep, dep)={\n",
       "    edge_index=[2, 23],\n",
       "    edge_attr=[23],\n",
       "  },\n",
       "  (tag, tag_word, word)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, word_tag, tag)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, seq, word)={\n",
       "    edge_index=[2, 46],\n",
       "    edge_attr=[46],\n",
       "  },\n",
       "  (general, general_sentence, sentence)={\n",
       "    edge_index=[2, 1],\n",
       "    edge_attr=[1],\n",
       "  },\n",
       "  (sentence, sentence_general, general)={\n",
       "    edge_index=[2, 1],\n",
       "    edge_attr=[1],\n",
       "  },\n",
       "  (word, word_sentence, sentence)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (sentence, sentence_word, word)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, word_sentiment, sentiment)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2],\n",
       "  },\n",
       "  (sentiment, sentiment_word, word)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the huge size of sentiment files\n",
    "# data_manager.graph_constructors[tag_dep_seq_sent].get_first()['sentiment'].x.shape\n",
    "# data_manager.graph_constructors[tag_dep_seq_sent].get_graph(30)['sentiment' , 'sentiment_word' , 'word'].edge_index\n",
    "data_manager.graph_constructors[tag_dep_seq_sent].get_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  1,  1],\n",
       "        [18, 19, 25, 29]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.graph_constructors[TextGraphType.SENTIMENT].get_graph(20)['sentiment' , 'sentiment_word' , 'word'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))\n",
    "# X1.metadata()\n",
    "len(t_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, BatchNorm, SAGEConv, PairNorm\n",
    "from torch_geometric.utils import to_dense_adj, dropout_path\n",
    "class HeteroGCNConv(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2, num_heads: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_feature, int(out_feature/num_heads), heads=num_heads, edge_dim=1, add_self_loops=False)\n",
    "        self.batch_norm = BatchNorm(out_feature)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        # self.dropout_rate = dropout\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weights: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weights)\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # dropout_path(edge_index, self.dropout_rate)\n",
    "        return x\n",
    "\n",
    "class HeteroLinear(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_feature, out_feature)\n",
    "        self.batch_norm = BatchNorm(out_feature)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        # self.dropout_rate = dropout\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # dropout_path(edge_index, self.dropout_rate)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import to_hetero\n",
    "# hetero_model = to_hetero(HeteroGCNConv(300, 1024, 0.2), X2.metadata())\n",
    "# pre = hetero_model(X2.x_dict, X2.edge_index_dict, X2.edge_attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from typing import Dict\n",
    "import torch_geometric\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv, GCN2Conv, DenseGCNConv, dense_diff_pool, BatchNorm, global_mean_pool, global_add_pool, global_max_pool, MemPooling, SAGEConv, to_hetero, HeteroBatchNorm, MeanSubtractionNorm, PairNorm, HeteroConv\n",
    "from torch_geometric.nn import Sequential as GSequential\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "class HeteroGcnGatModel1(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_feature: int, out_features: int,\n",
    "                 metadata,\n",
    "                 hidden_feature: int=256,\n",
    "                 device = 'cpu',\n",
    "                 dropout=0.1):\n",
    "\n",
    "        super(HeteroGcnGatModel1, self).__init__()\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.bsh: int = hidden_feature\n",
    "        bsh2: int = int(self.bsh/2)\n",
    "        bsh4: int = int(self.bsh/4)\n",
    "        bsh8: int = int(self.bsh/8)\n",
    "\n",
    "        self.part_weight_norm = torch.nn.LayerNorm((11,))\n",
    "        self.norm = PairNorm()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        self.lin1 = to_hetero(HeteroLinear(input_feature, self.bsh, dropout), X2.metadata())\n",
    "        \n",
    "        self.conv1 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        self.conv2 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        self.conv3 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        \n",
    "        self.lin2 = to_hetero(HeteroLinear(self.bsh, input_feature, dropout), X2.metadata())\n",
    "        \n",
    "        self.mem_pool = MemPooling(self.bsh, self.bsh, 2, 1)\n",
    "        \n",
    "        \n",
    "        self.fn1 = Linear(self.bsh, 64)\n",
    "        self.fn2 = Linear(64, 64)\n",
    "        self.fn3 = Linear(64, 64)\n",
    "        \n",
    "        self.output_layer = Linear(64, self.num_out_features)\n",
    "\n",
    "        self.dep_embedding = torch.nn.Embedding(45, 300)\n",
    "        self.tag_embedding = torch.nn.Embedding(50, 300)\n",
    "        self.dep_unembedding = torch.nn.Linear(300, 45)\n",
    "        self.tag_unembedding = torch.nn.Linear(300, 50)\n",
    "        \n",
    "        self.pw1 = torch.nn.Parameter(torch.randn([11,], dtype=torch.float32), requires_grad=True)\n",
    "        self.pw2 = torch.nn.Parameter(torch.randn([11,], dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: HeteroData) -> Tensor:\n",
    "        x_dict, edge_attr_dict, edge_index_dict = self.preprocess_data(x)\n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw1)\n",
    "        \n",
    "        x_dict = self.lin1(x_dict)\n",
    "        \n",
    "        x_dict = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "        \n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw2)\n",
    "        \n",
    "        x_dict = self.conv2(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "\n",
    "        x_dict = self.conv3(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        \n",
    "        x_pooled, S = self.mem_pool(x_dict['word'], x['word'].batch)\n",
    "        \n",
    "        x_pooled = x_pooled.view(x_pooled.shape[0], -1)\n",
    "        x_pooled = self.fn1(x_pooled)\n",
    "        x_pooled = self.fn2(x_pooled)\n",
    "        x_pooled = self.fn3(x_pooled)\n",
    "        out = self.output_layer(x_pooled)\n",
    "        x_dict = self.lin2(x_dict)\n",
    "        x_dict['dep'] = self.dep_unembedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_unembedding(x_dict['tag'])\n",
    "        return out, x_dict\n",
    "\n",
    "    def preprocess_data(self, x):\n",
    "        x_dict = {key: x.x_dict[key] for key in x.x_dict}\n",
    "        x_dict['dep'] = self.dep_embedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_embedding(x_dict['tag'])\n",
    "\n",
    "        edge_attr_dict = x.edge_attr_dict\n",
    "        edge_index_dict = x.edge_index_dict\n",
    "        # shape1 = edge_index_dict[('sentence', 'sentence_word', 'word')].shape[1]\n",
    "        # shape2 = edge_attr_dict[('word', 'word_sentence', 'sentence')].shape[0]\n",
    "        # if shape1 != shape2:\n",
    "        #     edge_attr_dict[('sentence', 'sentence_word', 'word')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][shape1:shape2]\n",
    "        #     edge_attr_dict[('word', 'word_sentence', 'sentence')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][:shape1]\n",
    "\n",
    "        for key in x.edge_attr_dict:\n",
    "            edge_attr_dict[key] = self.get_scale_same(1.0, edge_attr_dict[key])\n",
    "\n",
    "        return x_dict, edge_attr_dict, edge_index_dict\n",
    "\n",
    "    def normalize(self, x_dict, x):\n",
    "        # for key in x_dict:\n",
    "        #     x_dict[key] = self.norm(x_dict[key], x[key].batch)\n",
    "        return x_dict\n",
    "\n",
    "    def update_weights(self, edge_attr_dict, part_weights):\n",
    "        self.part_weight_norm(part_weights)\n",
    "        part_weights = F.relu(part_weights)\n",
    "        for i, key in enumerate(edge_attr_dict):\n",
    "            edge_attr = edge_attr_dict[key]\n",
    "            if edge_attr == None or edge_attr == ('word', 'seq', 'word'):\n",
    "                continue\n",
    "            edge_attr_dict[key]= edge_attr * part_weights[i]\n",
    "        return edge_attr_dict\n",
    "\n",
    "\n",
    "    def get_scale_same(self, scale:float, attributes: Tensor):\n",
    "        if attributes == None or len(attributes) == 0:\n",
    "            return\n",
    "        attributes = scale * torch.ones_like(attributes)\n",
    "        return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'], [('dep', 'dep_word', 'word'), ('word', 'word_dep', 'dep'), ('tag', 'tag_word', 'word'), ('word', 'word_tag', 'tag'), ('word', 'seq', 'word'), ('general', 'general_sentence', 'sentence'), ('sentence', 'sentence_general', 'general'), ('word', 'word_sentence', 'sentence'), ('sentence', 'sentence_word', 'word'), ('word', 'word_sentiment', 'sentiment'), ('sentiment', 'sentiment_word', 'word')])\n"
     ]
    }
   ],
   "source": [
    "print(X1.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\TestHeterogeneousGraphClassifier2Omid.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch_model \u001b[39m=\u001b[39m torch_model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(torch_model\u001b[39m.\u001b[39mparameters()))\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(torch_geometric\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49msummary(torch_model, X1\u001b[39m.\u001b[39;49mto(device)))\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\summary.py:117\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, max_depth, leaf_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 117\u001b[0m     model(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    119\u001b[0m model\u001b[39m.\u001b[39mtrain(training)\n\u001b[0;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks\u001b[39m.\u001b[39mvalues():  \u001b[39m# Remove hooks.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[0;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1573\u001b[0m     ):\n\u001b[0;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\TestHeterogeneousGraphClassifier2Omid.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: HeteroData) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     x_dict, edge_attr_dict, edge_index_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess_data(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     edge_attr_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_weights(edge_attr_dict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpw1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     x_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin1(x_dict)\n",
      "\u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\TestHeterogeneousGraphClassifier2Omid.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_data\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     x_dict \u001b[39m=\u001b[39m {key: x\u001b[39m.\u001b[39mx_dict[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mx_dict}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     x_dict[\u001b[39m'\u001b[39m\u001b[39mdep\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdep_embedding(x_dict[\u001b[39m'\u001b[39;49m\u001b[39mdep\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     x_dict[\u001b[39m'\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtag_embedding(x_dict[\u001b[39m'\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Darsi/Payan%20Name%20Arshad/Second%20Work/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2Omid.ipynb#X11sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     edge_attr_dict \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39medge_attr_dict\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[0;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1573\u001b[0m     ):\n\u001b[0;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.2)\n",
    "torch_model = torch_model.to(device)\n",
    "print(next(iter(torch_model.parameters())).device)\n",
    "print(torch_geometric.nn.summary(torch_model, X1.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import HeteroBinaryLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import HeteroLossArgs, HeteroLoss1\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict_keys = X1.x_dict.keys()\n",
    "print(len(list(X1.edge_attr_dict.keys())))\n",
    "x_dict_keys-'word'\n",
    "print(X1['word' , 'word_sentiment' , 'sentiment'].edge_index.shape)\n",
    "print(X1['word' , 'word_sentiment' , 'sentiment'].edge_attr.shape)\n",
    "print(X1['word'].x.shape)\n",
    "print(X1['sentiment'].x.shape)\n",
    "print(X1['word'].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_size = 5000\n",
    "# for i in range(0, 110000, step_size):\n",
    "#     print(f'{i}, {i+step_size}')\n",
    "#     data_manager.create_sub_data_loader(i, i+step_size)\n",
    "#     # t_dataloader = data_manager2.train_dataloader()\n",
    "#     # v_dataloader = data_manager2.val_dataloader()\n",
    "#     # X1, y1 = next(iter(t_dataloader))\n",
    "#     # X2, y2 = next(iter(v_dataloader))\n",
    "    \n",
    "#     callbacks = [\n",
    "#         ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "#         # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "#     ]\n",
    "#     torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.3)\n",
    "#     torch_model = torch_model.to(device)\n",
    "#     lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "#                                                  torch.optim.Adam(torch_model.parameters(), lr=0.0046, weight_decay=0.001),\n",
    "#                                         loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.005),\n",
    "#                                         learning_rate=0.0046,\n",
    "#                                         batch_size=batch_size,\n",
    "#                                         user_lr_scheduler=False,\n",
    "#                                         min_lr=0.0001\n",
    "#                                         ).to(device)\n",
    "#     model_manager = ClassifierModelManager(torch_model, lightning_model, model_save_dir=r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs', log_name='test_data_1', device=device, num_train_epoch=10)\n",
    "#     model_manager.fit(datamodule=data_manager)\n",
    "#     model_manager.save_plot_csv_logger(name_prepend=f'{i}, {i+step_size}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])\n",
    "#     # X1.metadata()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "    # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "]\n",
    "lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "                                 torch.optim.Adam(torch_model.parameters(), lr=0.0046, weight_decay=0.001),\n",
    "                                       loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.05),\n",
    "                                       learning_rate=0.0046,\n",
    "                                       batch_size=batch_size,\n",
    "                                       user_lr_scheduler=False,\n",
    "                                       min_lr=0.0001\n",
    "                                       ).to(device)\n",
    "model_manager = ClassifierModelManager(torch_model, lightning_model, model_save_dir=r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs', log_name='hetero_model_2', device=device, num_train_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.2)\n",
    "# torch_model = torch_model.to(device)\n",
    "# print(next(iter(torch_model.parameters())).device)\n",
    "# print(torch_geometric.nn.summary(torch_model, X1.to(device)))\n",
    "# y_a, x_dict_a = lightning_model(X1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1.x_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = X1.to(device)\n",
    "# y1 = y1.to(device)\n",
    "# hetero_out = lightning_model(X1)\n",
    "# pred_args = HeteroLossArgs(hetero_out[0], hetero_out[1])\n",
    "# main_args = HeteroLossArgs(y1.view(hetero_out[0].shape), X1.x_dict)\n",
    "# hetero_loss_func = HeteroLoss1(exception_keys=['word'])\n",
    "# hetero_loss_func(pred_args, main_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager.tune(data_manager=data_manager, min_lr=1e-5, max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.loss_func = HeteroLoss1(exception_keys=['word'], enc_factor=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.update_learning_rate(0.0012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0.3\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0.1\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def find_best_settings(lrs: List[float]=[0.001], dropouts: List[float]=[0.2], weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], log_name='find_best_settings'):\n",
    "    for lr in lrs:\n",
    "        for dropout in dropouts:\n",
    "            for wd in weight_decays:\n",
    "                for emb_factor in emb_factors:\n",
    "                    torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=dropout)\n",
    "                    lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "                                    torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "                                        loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "                                        learning_rate=lr,\n",
    "                                        batch_size=batch_size,\n",
    "                                        user_lr_scheduler=True\n",
    "                                        ).to(device)\n",
    "                    model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "                    print(model_manager.lightning_model.optimizer.)\n",
    "                    model_manager.fit(datamodule=data_manager)\n",
    "                    model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.001]#np.logspace(-5,-2,10)\n",
    "dropouts =  np.linspace(0.2, 0.6, 5)\n",
    "weight_decays = [0.001]# np.logspace(-5,-2,10)\n",
    "emb_factors = [0.185]#np.linspace(0.07, 0.3, 3)\n",
    "find_best_settings(lrs, dropouts, weight_decays, emb_factors, log_name='find_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.tune(data_manager=data_manager, min_lr=1e-10, max_lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(model_manager.lightning_model.optimizer.param_groups))['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(model_manager.lightning_model.optimizer.param_groups))['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.update_learning_rate(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model_manager.lightning_model.model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(model_manager.lightning_model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=500,\n",
    "            accelerator='gpu',\n",
    "            logger=CSVLogger(save_dir='logs/', name='hetero_gnn_1'),\n",
    "            num_sanity_val_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer)\n",
    "results = tuner.lr_find(lightning_model, datamodule=data_manager, min_lr=0.0000001,max_lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = results.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(trainer.model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=lightning_model, datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os import path\n",
    "def plot_csv_logger(csv_path, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "    metrics = pd.read_csv(csv_path)\n",
    "\n",
    "    aggregation_metrics = []\n",
    "    agg_col = 'epoch'\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggregation_metrics.append(agg)\n",
    "\n",
    "    df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "    df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "    df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_csv_logger(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\logs\\hetero_model_2\\version_47\\metrics.csv', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
