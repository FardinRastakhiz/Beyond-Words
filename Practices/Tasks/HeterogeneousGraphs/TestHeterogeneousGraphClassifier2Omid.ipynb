{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.AmazonReviewGraphDataModule import AmazonReviewGraphDataModule\n",
    "from Scripts.DataManager.GraphLoader.TwitterGraphDataModule import TwitterGraphDataModule\n",
    "import time\n",
    "\n",
    "config = Config(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\data/GraphData/Sentiment140\\140_sentiment\\graph_var.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Loding Graphs From File : 100%|██████████| 5/5 [00:11<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "tag_dep_seq_sent = TextGraphType.SENTIMENT\n",
    "data_manager = TwitterGraphDataModule(config, True, True, shuffle=False,start_data_load=0, end_data_load = 5000, device='cpu', batch_size=batch_size, graph_type=tag_dep_seq_sent, load_preprocessed_data = True)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  dep={\n",
       "    length=45,\n",
       "    x=[45],\n",
       "  },\n",
       "  tag={\n",
       "    length=50,\n",
       "    x=[50],\n",
       "  },\n",
       "  word={ x=[24, 300] },\n",
       "  sentence={ x=[1, 300] },\n",
       "  general={ x=[1, 300] },\n",
       "  sentiment={ x=[2, 300] },\n",
       "  (dep, dep_word, word)={\n",
       "    edge_index=[2, 23],\n",
       "    edge_attr=[23],\n",
       "  },\n",
       "  (word, word_dep, dep)={\n",
       "    edge_index=[2, 23],\n",
       "    edge_attr=[23],\n",
       "  },\n",
       "  (tag, tag_word, word)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, word_tag, tag)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, seq, word)={\n",
       "    edge_index=[2, 46],\n",
       "    edge_attr=[46],\n",
       "  },\n",
       "  (general, general_sentence, sentence)={\n",
       "    edge_index=[2, 1],\n",
       "    edge_attr=[1],\n",
       "  },\n",
       "  (sentence, sentence_general, general)={\n",
       "    edge_index=[2, 1],\n",
       "    edge_attr=[1],\n",
       "  },\n",
       "  (word, word_sentence, sentence)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (sentence, sentence_word, word)={\n",
       "    edge_index=[2, 24],\n",
       "    edge_attr=[24],\n",
       "  },\n",
       "  (word, word_sentiment, sentiment)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2],\n",
       "  },\n",
       "  (sentiment, sentiment_word, word)={\n",
       "    edge_index=[2, 2],\n",
       "    edge_attr=[2],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the huge size of sentiment files\n",
    "# data_manager.graph_constructors[tag_dep_seq_sent].get_first()['sentiment'].x.shape\n",
    "# data_manager.graph_constructors[tag_dep_seq_sent].get_graph(30)['sentiment' , 'sentiment_word' , 'word'].edge_index\n",
    "data_manager.graph_constructors[tag_dep_seq_sent].get_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  1,  1],\n",
       "        [18, 19, 25, 29]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.graph_constructors[TextGraphType.SENTIMENT].get_graph(20)['sentiment' , 'sentiment_word' , 'word'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))\n",
    "# X1.metadata()\n",
    "len(t_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, BatchNorm, SAGEConv, PairNorm\n",
    "from torch_geometric.utils import to_dense_adj, dropout_path\n",
    "class HeteroGCNConv(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2, num_heads: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_feature, int(out_feature/num_heads), heads=num_heads, edge_dim=1, add_self_loops=False)\n",
    "        self.batch_norm = BatchNorm(out_feature)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        # self.dropout_rate = dropout\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weights: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weights)\n",
    "        x = self.batch_norm(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # dropout_path(edge_index, self.dropout_rate)\n",
    "        return x\n",
    "\n",
    "class HeteroLinear(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_feature, out_feature)\n",
    "        self.batch_norm = BatchNorm(out_feature)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        # self.dropout_rate = dropout\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # dropout_path(edge_index, self.dropout_rate)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import to_hetero\n",
    "# hetero_model = to_hetero(HeteroGCNConv(300, 1024, 0.2), X2.metadata())\n",
    "# pre = hetero_model(X2.x_dict, X2.edge_index_dict, X2.edge_attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from typing import Dict\n",
    "import torch_geometric\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv, GCN2Conv, DenseGCNConv, dense_diff_pool, BatchNorm, global_mean_pool, global_add_pool, global_max_pool, MemPooling, SAGEConv, to_hetero, HeteroBatchNorm, MeanSubtractionNorm, PairNorm, HeteroConv\n",
    "from torch_geometric.nn import Sequential as GSequential\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "class HeteroGcnGatModel1(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_feature: int, out_features: int,\n",
    "                 metadata,\n",
    "                 hidden_feature: int=256,\n",
    "                 device = 'cpu',\n",
    "                 dropout=0.1):\n",
    "\n",
    "        super(HeteroGcnGatModel1, self).__init__()\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.bsh: int = hidden_feature\n",
    "        bsh2: int = int(self.bsh/2)\n",
    "        bsh4: int = int(self.bsh/4)\n",
    "        bsh8: int = int(self.bsh/8)\n",
    "\n",
    "        self.part_weight_norm = torch.nn.LayerNorm((11,))\n",
    "        self.norm = PairNorm()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        self.lin1 = to_hetero(HeteroLinear(input_feature, self.bsh, dropout), X2.metadata())\n",
    "        \n",
    "        self.conv1 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        self.conv2 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        self.conv3 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout, num_heads=2), metadata)\n",
    "        \n",
    "        self.lin2 = to_hetero(HeteroLinear(self.bsh, input_feature, dropout), X2.metadata())\n",
    "        \n",
    "        self.mem_pool = MemPooling(self.bsh, self.bsh, 2, 1)\n",
    "        \n",
    "        \n",
    "        self.fn1 = Linear(self.bsh, 64)\n",
    "        self.fn2 = Linear(64, 64)\n",
    "        self.fn3 = Linear(64, 64)\n",
    "        \n",
    "        self.output_layer = Linear(64, self.num_out_features)\n",
    "\n",
    "        self.dep_embedding = torch.nn.Embedding(45, 300)\n",
    "        self.tag_embedding = torch.nn.Embedding(50, 300)\n",
    "        self.dep_unembedding = torch.nn.Linear(300, 45)\n",
    "        self.tag_unembedding = torch.nn.Linear(300, 50)\n",
    "        \n",
    "        self.pw1 = torch.nn.Parameter(torch.randn([11,], dtype=torch.float32), requires_grad=True)\n",
    "        self.pw2 = torch.nn.Parameter(torch.randn([11,], dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: HeteroData) -> Tensor:\n",
    "        x_dict, edge_attr_dict, edge_index_dict = self.preprocess_data(x)\n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw1)\n",
    "        \n",
    "        x_dict = self.lin1(x_dict)\n",
    "        \n",
    "        x_dict = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "        \n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw2)\n",
    "        \n",
    "        x_dict = self.conv2(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "\n",
    "        x_dict = self.conv3(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        \n",
    "        x_pooled, S = self.mem_pool(x_dict['word'], x['word'].batch)\n",
    "        \n",
    "        x_pooled = x_pooled.view(x_pooled.shape[0], -1)\n",
    "        x_pooled = self.fn1(x_pooled)\n",
    "        x_pooled = self.fn2(x_pooled)\n",
    "        x_pooled = self.fn3(x_pooled)\n",
    "        out = self.output_layer(x_pooled)\n",
    "        x_dict = self.lin2(x_dict)\n",
    "        x_dict['dep'] = self.dep_unembedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_unembedding(x_dict['tag'])\n",
    "        return out, x_dict\n",
    "\n",
    "    def preprocess_data(self, x):\n",
    "        x_dict = {key: x.x_dict[key] for key in x.x_dict}\n",
    "        x_dict['dep'] = self.dep_embedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_embedding(x_dict['tag'])\n",
    "\n",
    "        edge_attr_dict = x.edge_attr_dict\n",
    "        edge_index_dict = x.edge_index_dict\n",
    "        # shape1 = edge_index_dict[('sentence', 'sentence_word', 'word')].shape[1]\n",
    "        # shape2 = edge_attr_dict[('word', 'word_sentence', 'sentence')].shape[0]\n",
    "        # if shape1 != shape2:\n",
    "        #     edge_attr_dict[('sentence', 'sentence_word', 'word')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][shape1:shape2]\n",
    "        #     edge_attr_dict[('word', 'word_sentence', 'sentence')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][:shape1]\n",
    "\n",
    "        for key in x.edge_attr_dict:\n",
    "            edge_attr_dict[key] = self.get_scale_same(1.0, edge_attr_dict[key])\n",
    "\n",
    "        return x_dict, edge_attr_dict, edge_index_dict\n",
    "\n",
    "    def normalize(self, x_dict, x):\n",
    "        # for key in x_dict:\n",
    "        #     x_dict[key] = self.norm(x_dict[key], x[key].batch)\n",
    "        return x_dict\n",
    "\n",
    "    def update_weights(self, edge_attr_dict, part_weights):\n",
    "        self.part_weight_norm(part_weights)\n",
    "        part_weights = F.relu(part_weights)\n",
    "        for i, key in enumerate(edge_attr_dict):\n",
    "            edge_attr = edge_attr_dict[key]\n",
    "            if edge_attr == None or edge_attr == ('word', 'seq', 'word'):\n",
    "                continue\n",
    "            edge_attr_dict[key]= edge_attr * part_weights[i]\n",
    "        return edge_attr_dict\n",
    "\n",
    "\n",
    "    def get_scale_same(self, scale:float, attributes: Tensor):\n",
    "        if attributes == None or len(attributes) == 0:\n",
    "            return\n",
    "        attributes = scale * torch.ones_like(attributes)\n",
    "        return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'], [('dep', 'dep_word', 'word'), ('word', 'word_dep', 'dep'), ('tag', 'tag_word', 'word'), ('word', 'word_tag', 'tag'), ('word', 'seq', 'word'), ('general', 'general_sentence', 'sentence'), ('sentence', 'sentence_general', 'general'), ('word', 'word_sentence', 'sentence'), ('sentence', 'sentence_word', 'word'), ('word', 'word_sentiment', 'sentiment'), ('sentiment', 'sentiment_word', 'word')])\n"
     ]
    }
   ],
   "source": [
    "print(X1.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "+------------------------------------------------------------+-------------------------------+----------------------------+----------+\n",
      "| Layer                                                      | Input Shape                   | Output Shape               | #Param   |\n",
      "|------------------------------------------------------------+-------------------------------+----------------------------+----------|\n",
      "| HeteroGcnGatModel1                                         | [14879, 14879]                | [128, 1]                   | 590,422  |\n",
      "| ├─(part_weight_norm)LayerNorm                              | [11]                          | [11]                       | 22       |\n",
      "| ├─(norm)PairNorm                                           | --                            | --                         | --       |\n",
      "| ├─(drop)Dropout                                            | --                            | --                         | --       |\n",
      "| ├─(lin1)GraphModule                                        |                               |                            | 115,712  |\n",
      "| │    └─(linear)ModuleDict                                  | --                            | --                         | 115,584  |\n",
      "| │    │    └─(dep)Linear                                    | [5760, 300]                   | [5760, 64]                 | 19,264   |\n",
      "| │    │    └─(tag)Linear                                    | [6400, 300]                   | [6400, 64]                 | 19,264   |\n",
      "| │    │    └─(word)Linear                                   | [2096, 300]                   | [2096, 64]                 | 19,264   |\n",
      "| │    │    └─(sentence)Linear                               | [239, 300]                    | [239, 64]                  | 19,264   |\n",
      "| │    │    └─(general)Linear                                | [128, 300]                    | [128, 64]                  | 19,264   |\n",
      "| │    │    └─(sentiment)Linear                              | [256, 300]                    | [256, 64]                  | 19,264   |\n",
      "| │    └─(dropout)ModuleDict                                 | --                            | --                         | --       |\n",
      "| │    │    └─(dep)Dropout                                   | [5760, 64]                    | [5760, 64]                 | --       |\n",
      "| │    │    └─(tag)Dropout                                   | [6400, 64]                    | [6400, 64]                 | --       |\n",
      "| │    │    └─(word)Dropout                                  | [2096, 64]                    | [2096, 64]                 | --       |\n",
      "| │    │    └─(sentence)Dropout                              | [239, 64]                     | [239, 64]                  | --       |\n",
      "| │    │    └─(general)Dropout                               | [128, 64]                     | [128, 64]                  | --       |\n",
      "| │    │    └─(sentiment)Dropout                             | [256, 64]                     | [256, 64]                  | --       |\n",
      "| │    └─(batch_norm)BatchNorm                               | --                            | --                         | 128      |\n",
      "| │    │    └─(module)BatchNorm1d                            | --                            | --                         | 128      |\n",
      "| ├─(conv1)GraphModule                                       |                               |                            | 94,400   |\n",
      "| │    └─(conv1)ModuleDict                                   | --                            | --                         | 93,632   |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 1858], [1858]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 1858], [1858]             | [5760, 64]                 | 8,512    |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 2096], [2096]             | [6400, 64]                 | 8,512    |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [2096, 64], [2, 3936], [3936] | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 239], [239]               | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 239], [239]               | [128, 64]                  | 8,512    |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 2096], [2096]             | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_sentiment__sentiment)GATv2Conv     | [2, 160], [160]               | [256, 64]                  | 8,512    |\n",
      "| │    │    └─(sentiment__sentiment_word__word)GATv2Conv     | [2, 160], [160]               | [2096, 64]                 | 8,512    |\n",
      "| │    └─(batch_norm)ModuleDict                              | --                            | --                         | 768      |\n",
      "| │    │    └─(dep)BatchNorm                                 | [5760, 64]                    | [5760, 64]                 | 128      |\n",
      "| │    │    └─(tag)BatchNorm                                 | [6400, 64]                    | [6400, 64]                 | 128      |\n",
      "| │    │    └─(word)BatchNorm                                | [2096, 64]                    | [2096, 64]                 | 128      |\n",
      "| │    │    └─(sentence)BatchNorm                            | [239, 64]                     | [239, 64]                  | 128      |\n",
      "| │    │    └─(general)BatchNorm                             | [128, 64]                     | [128, 64]                  | 128      |\n",
      "| │    │    └─(sentiment)BatchNorm                           | [256, 64]                     | [256, 64]                  | 128      |\n",
      "| │    └─(dropout)ModuleDict                                 | --                            | --                         | --       |\n",
      "| │    │    └─(dep)Dropout                                   | [5760, 64]                    | [5760, 64]                 | --       |\n",
      "| │    │    └─(tag)Dropout                                   | [6400, 64]                    | [6400, 64]                 | --       |\n",
      "| │    │    └─(word)Dropout                                  | [2096, 64]                    | [2096, 64]                 | --       |\n",
      "| │    │    └─(sentence)Dropout                              | [239, 64]                     | [239, 64]                  | --       |\n",
      "| │    │    └─(general)Dropout                               | [128, 64]                     | [128, 64]                  | --       |\n",
      "| │    │    └─(sentiment)Dropout                             | [256, 64]                     | [256, 64]                  | --       |\n",
      "| ├─(conv2)GraphModule                                       |                               |                            | 94,400   |\n",
      "| │    └─(conv1)ModuleDict                                   | --                            | --                         | 93,632   |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 1858], [1858]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 1858], [1858]             | [5760, 64]                 | 8,512    |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 2096], [2096]             | [6400, 64]                 | 8,512    |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [2096, 64], [2, 3936], [3936] | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 239], [239]               | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 239], [239]               | [128, 64]                  | 8,512    |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 2096], [2096]             | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_sentiment__sentiment)GATv2Conv     | [2, 160], [160]               | [256, 64]                  | 8,512    |\n",
      "| │    │    └─(sentiment__sentiment_word__word)GATv2Conv     | [2, 160], [160]               | [2096, 64]                 | 8,512    |\n",
      "| │    └─(batch_norm)ModuleDict                              | --                            | --                         | 768      |\n",
      "| │    │    └─(dep)BatchNorm                                 | [5760, 64]                    | [5760, 64]                 | 128      |\n",
      "| │    │    └─(tag)BatchNorm                                 | [6400, 64]                    | [6400, 64]                 | 128      |\n",
      "| │    │    └─(word)BatchNorm                                | [2096, 64]                    | [2096, 64]                 | 128      |\n",
      "| │    │    └─(sentence)BatchNorm                            | [239, 64]                     | [239, 64]                  | 128      |\n",
      "| │    │    └─(general)BatchNorm                             | [128, 64]                     | [128, 64]                  | 128      |\n",
      "| │    │    └─(sentiment)BatchNorm                           | [256, 64]                     | [256, 64]                  | 128      |\n",
      "| │    └─(dropout)ModuleDict                                 | --                            | --                         | --       |\n",
      "| │    │    └─(dep)Dropout                                   | [5760, 64]                    | [5760, 64]                 | --       |\n",
      "| │    │    └─(tag)Dropout                                   | [6400, 64]                    | [6400, 64]                 | --       |\n",
      "| │    │    └─(word)Dropout                                  | [2096, 64]                    | [2096, 64]                 | --       |\n",
      "| │    │    └─(sentence)Dropout                              | [239, 64]                     | [239, 64]                  | --       |\n",
      "| │    │    └─(general)Dropout                               | [128, 64]                     | [128, 64]                  | --       |\n",
      "| │    │    └─(sentiment)Dropout                             | [256, 64]                     | [256, 64]                  | --       |\n",
      "| ├─(conv3)GraphModule                                       |                               |                            | 94,400   |\n",
      "| │    └─(conv1)ModuleDict                                   | --                            | --                         | 93,632   |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 1858], [1858]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 1858], [1858]             | [5760, 64]                 | 8,512    |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 2096], [2096]             | [6400, 64]                 | 8,512    |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [2096, 64], [2, 3936], [3936] | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 239], [239]               | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 239], [239]               | [128, 64]                  | 8,512    |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 2096], [2096]             | [239, 64]                  | 8,512    |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 2096], [2096]             | [2096, 64]                 | 8,512    |\n",
      "| │    │    └─(word__word_sentiment__sentiment)GATv2Conv     | [2, 160], [160]               | [256, 64]                  | 8,512    |\n",
      "| │    │    └─(sentiment__sentiment_word__word)GATv2Conv     | [2, 160], [160]               | [2096, 64]                 | 8,512    |\n",
      "| │    └─(batch_norm)ModuleDict                              | --                            | --                         | 768      |\n",
      "| │    │    └─(dep)BatchNorm                                 | [5760, 64]                    | [5760, 64]                 | 128      |\n",
      "| │    │    └─(tag)BatchNorm                                 | [6400, 64]                    | [6400, 64]                 | 128      |\n",
      "| │    │    └─(word)BatchNorm                                | [2096, 64]                    | [2096, 64]                 | 128      |\n",
      "| │    │    └─(sentence)BatchNorm                            | [239, 64]                     | [239, 64]                  | 128      |\n",
      "| │    │    └─(general)BatchNorm                             | [128, 64]                     | [128, 64]                  | 128      |\n",
      "| │    │    └─(sentiment)BatchNorm                           | [256, 64]                     | [256, 64]                  | 128      |\n",
      "| │    └─(dropout)ModuleDict                                 | --                            | --                         | --       |\n",
      "| │    │    └─(dep)Dropout                                   | [5760, 64]                    | [5760, 64]                 | --       |\n",
      "| │    │    └─(tag)Dropout                                   | [6400, 64]                    | [6400, 64]                 | --       |\n",
      "| │    │    └─(word)Dropout                                  | [2096, 64]                    | [2096, 64]                 | --       |\n",
      "| │    │    └─(sentence)Dropout                              | [239, 64]                     | [239, 64]                  | --       |\n",
      "| │    │    └─(general)Dropout                               | [128, 64]                     | [128, 64]                  | --       |\n",
      "| │    │    └─(sentiment)Dropout                             | [256, 64]                     | [256, 64]                  | --       |\n",
      "| ├─(lin2)GraphModule                                        |                               |                            | 117,600  |\n",
      "| │    └─(linear)ModuleDict                                  | --                            | --                         | 117,000  |\n",
      "| │    │    └─(dep)Linear                                    | [5760, 64]                    | [5760, 300]                | 19,500   |\n",
      "| │    │    └─(tag)Linear                                    | [6400, 64]                    | [6400, 300]                | 19,500   |\n",
      "| │    │    └─(word)Linear                                   | [2096, 64]                    | [2096, 300]                | 19,500   |\n",
      "| │    │    └─(sentence)Linear                               | [239, 64]                     | [239, 300]                 | 19,500   |\n",
      "| │    │    └─(general)Linear                                | [128, 64]                     | [128, 300]                 | 19,500   |\n",
      "| │    │    └─(sentiment)Linear                              | [256, 64]                     | [256, 300]                 | 19,500   |\n",
      "| │    └─(dropout)ModuleDict                                 | --                            | --                         | --       |\n",
      "| │    │    └─(dep)Dropout                                   | [5760, 300]                   | [5760, 300]                | --       |\n",
      "| │    │    └─(tag)Dropout                                   | [6400, 300]                   | [6400, 300]                | --       |\n",
      "| │    │    └─(word)Dropout                                  | [2096, 300]                   | [2096, 300]                | --       |\n",
      "| │    │    └─(sentence)Dropout                              | [239, 300]                    | [239, 300]                 | --       |\n",
      "| │    │    └─(general)Dropout                               | [128, 300]                    | [128, 300]                 | --       |\n",
      "| │    │    └─(sentiment)Dropout                             | [256, 300]                    | [256, 300]                 | --       |\n",
      "| │    └─(batch_norm)BatchNorm                               | --                            | --                         | 600      |\n",
      "| │    │    └─(module)BatchNorm1d                            | --                            | --                         | 600      |\n",
      "| ├─(mem_pool)MemPooling                                     | [2096, 64], [2096]            | [128, 1, 64], [128, 36, 1] | 4,226    |\n",
      "| │    └─(conv)Conv2d                                        | [128, 2, 36, 1]               | [128, 1, 36, 1]            | 2        |\n",
      "| │    └─(lin)Linear                                         | [128, 1, 64]                  | [128, 1, 64]               | 4,096    |\n",
      "| ├─(fn1)Linear                                              | [128, 64]                     | [128, 64]                  | 4,160    |\n",
      "| ├─(fn2)Linear                                              | [128, 64]                     | [128, 64]                  | 4,160    |\n",
      "| ├─(fn3)Linear                                              | [128, 64]                     | [128, 64]                  | 4,160    |\n",
      "| ├─(output_layer)Linear                                     | [128, 64]                     | [128, 1]                   | 65       |\n",
      "| ├─(dep_embedding)Embedding                                 | [5760]                        | [5760, 300]                | 13,500   |\n",
      "| ├─(tag_embedding)Embedding                                 | [6400]                        | [6400, 300]                | 15,000   |\n",
      "| ├─(dep_unembedding)Linear                                  | [5760, 300]                   | [5760, 45]                 | 13,545   |\n",
      "| ├─(tag_unembedding)Linear                                  | [6400, 300]                   | [6400, 50]                 | 15,050   |\n",
      "+------------------------------------------------------------+-------------------------------+----------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.2)\n",
    "torch_model = torch_model.to(device)\n",
    "print(next(iter(torch_model.parameters())).device)\n",
    "print(torch_geometric.nn.summary(torch_model, X1.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import HeteroBinaryLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import HeteroLossArgs, HeteroLoss1\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "torch.Size([2, 160])\n",
      "torch.Size([160])\n",
      "torch.Size([2096, 300])\n",
      "torch.Size([256, 300])\n",
      "torch.Size([2096, 300])\n"
     ]
    }
   ],
   "source": [
    "x_dict_keys = X1.x_dict.keys()\n",
    "print(len(list(X1.edge_attr_dict.keys())))\n",
    "x_dict_keys-'word'\n",
    "print(X1['word' , 'word_sentiment' , 'sentiment'].edge_index.shape)\n",
    "print(X1['word' , 'word_sentiment' , 'sentiment'].edge_attr.shape)\n",
    "print(X1['word'].x.shape)\n",
    "print(X1['sentiment'].x.shape)\n",
    "print(X1['word'].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_size = 5000\n",
    "# for i in range(0, 110000, step_size):\n",
    "#     print(f'{i}, {i+step_size}')\n",
    "#     data_manager.create_sub_data_loader(i, i+step_size)\n",
    "#     # t_dataloader = data_manager2.train_dataloader()\n",
    "#     # v_dataloader = data_manager2.val_dataloader()\n",
    "#     # X1, y1 = next(iter(t_dataloader))\n",
    "#     # X2, y2 = next(iter(v_dataloader))\n",
    "    \n",
    "#     callbacks = [\n",
    "#         ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "#         # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "#     ]\n",
    "#     torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.3)\n",
    "#     torch_model = torch_model.to(device)\n",
    "#     lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "#                                                  torch.optim.Adam(torch_model.parameters(), lr=0.0046, weight_decay=0.001),\n",
    "#                                         loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.005),\n",
    "#                                         learning_rate=0.0046,\n",
    "#                                         batch_size=batch_size,\n",
    "#                                         user_lr_scheduler=False,\n",
    "#                                         min_lr=0.0001\n",
    "#                                         ).to(device)\n",
    "#     model_manager = ClassifierModelManager(torch_model, lightning_model, model_save_dir=r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs', log_name='test_data_1', device=device, num_train_epoch=10)\n",
    "#     model_manager.fit(datamodule=data_manager)\n",
    "#     model_manager.save_plot_csv_logger(name_prepend=f'{i}, {i+step_size}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])\n",
    "#     # X1.metadata()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "    # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "]\n",
    "lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "                                 torch.optim.Adam(torch_model.parameters(), lr=0.0046, weight_decay=0.001),\n",
    "                                       loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.05),\n",
    "                                       learning_rate=0.0046,\n",
    "                                       batch_size=batch_size,\n",
    "                                       user_lr_scheduler=False,\n",
    "                                       min_lr=0.0001\n",
    "                                       ).to(device)\n",
    "model_manager = ClassifierModelManager(torch_model, lightning_model, model_save_dir=r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs', log_name='hetero_model_2', device=device, num_train_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=0.2)\n",
    "# torch_model = torch_model.to(device)\n",
    "# print(next(iter(torch_model.parameters())).device)\n",
    "# print(torch_geometric.nn.summary(torch_model, X1.to(device)))\n",
    "# y_a, x_dict_a = lightning_model(X1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1.x_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = X1.to(device)\n",
    "# y1 = y1.to(device)\n",
    "# hetero_out = lightning_model(X1)\n",
    "# pred_args = HeteroLossArgs(hetero_out[0], hetero_out[1])\n",
    "# main_args = HeteroLossArgs(y1.view(hetero_out[0].shape), X1.x_dict)\n",
    "# hetero_loss_func = HeteroLoss1(exception_keys=['word'])\n",
    "# hetero_loss_func(pred_args, main_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager.tune(data_manager=data_manager, min_lr=1e-5, max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | HeteroGcnGatModel1 | 590 K \n",
      "1 | loss_func | HeteroLoss1        | 0     \n",
      "2 | train_acc | BinaryAccuracy     | 0     \n",
      "3 | val_acc   | BinaryAccuracy     | 0     \n",
      "4 | test_acc  | BinaryAccuracy     | 0     \n",
      "-------------------------------------------------\n",
      "590 K     Trainable params\n",
      "0         Non-trainable params\n",
      "590 K     Total params\n",
      "2.362     Total estimated model params size (MB)\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  17%|█▋        | 4/23 [00:01<00:06,  2.78it/s, v_num=12, train_acc_step=0.805, val_acc_step=0.615, val_acc_epoch=0.687, train_acc_epoch=0.818] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.loss_func = HeteroLoss1(exception_keys=['word'], enc_factor=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.update_learning_rate(0.0012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0.3\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_factor = 0.1\n",
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def find_best_settings(lrs: List[float]=[0.001], dropouts: List[float]=[0.2], weight_decays: List[float]=[0.00055], emb_factors: List[float]=[0.1], log_name='find_best_settings'):\n",
    "    for lr in lrs:\n",
    "        for dropout in dropouts:\n",
    "            for wd in weight_decays:\n",
    "                for emb_factor in emb_factors:\n",
    "                    torch_model = HeteroGcnGatModel1(300, 1, X1.metadata(), 64, dropout=dropout)\n",
    "                    lightning_model = HeteroBinaryLightningModel(torch_model,\n",
    "                                    torch.optim.Adam(torch_model.parameters(), lr=lr, weight_decay=wd),\n",
    "                                        loss_func=HeteroLoss1(exception_keys='word', enc_factor=emb_factor),\n",
    "                                        learning_rate=lr,\n",
    "                                        batch_size=batch_size,\n",
    "                                        user_lr_scheduler=True\n",
    "                                        ).to(device)\n",
    "                    model_manager = ClassifierModelManager(torch_model, lightning_model, log_name=log_name, device=device, num_train_epoch=10)\n",
    "                    print(model_manager.lightning_model.optimizer.)\n",
    "                    model_manager.fit(datamodule=data_manager)\n",
    "                    model_manager.save_plot_csv_logger(name_prepend=f'{lr}_{dropout}_{wd}_{emb_factor}', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.001]#np.logspace(-5,-2,10)\n",
    "dropouts =  np.linspace(0.2, 0.6, 5)\n",
    "weight_decays = [0.001]# np.logspace(-5,-2,10)\n",
    "emb_factors = [0.185]#np.linspace(0.07, 0.3, 3)\n",
    "find_best_settings(lrs, dropouts, weight_decays, emb_factors, log_name='find_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.tune(data_manager=data_manager, min_lr=1e-10, max_lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(model_manager.lightning_model.optimizer.param_groups))['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(model_manager.lightning_model.optimizer.param_groups))['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.update_learning_rate(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.lightning_model.optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model_manager.lightning_model.model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(model_manager.lightning_model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=500,\n",
    "            accelerator='gpu',\n",
    "            logger=CSVLogger(save_dir='logs/', name='hetero_gnn_1'),\n",
    "            num_sanity_val_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(trainer)\n",
    "results = tuner.lr_find(lightning_model, datamodule=data_manager, min_lr=0.0000001,max_lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = results.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(trainer.model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=lightning_model, datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os import path\n",
    "def plot_csv_logger(csv_path, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "    metrics = pd.read_csv(csv_path)\n",
    "\n",
    "    aggregation_metrics = []\n",
    "    agg_col = 'epoch'\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggregation_metrics.append(agg)\n",
    "\n",
    "    df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "    df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "    df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_csv_logger(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\logs\\hetero_model_2\\version_47\\metrics.csv', loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
