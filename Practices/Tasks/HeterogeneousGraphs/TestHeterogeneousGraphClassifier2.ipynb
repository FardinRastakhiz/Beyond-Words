{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.AmazonReviewGraphDataModule import AmazonReviewGraphDataModule\n",
    "import time\n",
    "\n",
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.num_data_load: 55000\n",
      "filename: C:\\Users\\fardin\\Projects\\ColorIntelligence\\data/GraphData/AmazonReview\\full\\graph_var.txt\n",
      " 0 graph loaded\n",
      " 100 graph loaded\n",
      " 200 graph loaded\n",
      " 300 graph loaded\n",
      " 400 graph loaded\n",
      " 500 graph loaded\n",
      " 600 graph loaded\n",
      " 700 graph loaded\n",
      " 800 graph loaded\n",
      " 900 graph loaded\n",
      " 1000 graph loaded\n",
      " 1100 graph loaded\n",
      " 1200 graph loaded\n",
      " 1300 graph loaded\n",
      " 1400 graph loaded\n",
      " 1500 graph loaded\n",
      " 1600 graph loaded\n",
      " 1700 graph loaded\n",
      " 1800 graph loaded\n",
      " 1900 graph loaded\n",
      " 2000 graph loaded\n",
      " 2100 graph loaded\n",
      " 2200 graph loaded\n",
      " 2300 graph loaded\n",
      " 2400 graph loaded\n",
      " 2500 graph loaded\n",
      " 2600 graph loaded\n",
      " 2700 graph loaded\n",
      " 2800 graph loaded\n",
      " 2900 graph loaded\n",
      " 3000 graph loaded\n",
      " 3100 graph loaded\n",
      " 3200 graph loaded\n",
      " 3300 graph loaded\n",
      " 3400 graph loaded\n",
      " 3500 graph loaded\n",
      " 3600 graph loaded\n",
      " 3700 graph loaded\n",
      " 3800 graph loaded\n",
      " 3900 graph loaded\n",
      " 4000 graph loaded\n",
      " 4100 graph loaded\n",
      " 4200 graph loaded\n",
      " 4300 graph loaded\n",
      " 4400 graph loaded\n",
      " 4500 graph loaded\n",
      " 4600 graph loaded\n",
      " 4700 graph loaded\n",
      " 4800 graph loaded\n",
      " 4900 graph loaded\n",
      " 5000 graph loaded\n",
      " 5100 graph loaded\n",
      " 5200 graph loaded\n",
      " 5300 graph loaded\n",
      " 5400 graph loaded\n",
      " 5500 graph loaded\n",
      " 5600 graph loaded\n",
      " 5700 graph loaded\n",
      " 5800 graph loaded\n",
      " 5900 graph loaded\n",
      " 6000 graph loaded\n",
      " 6100 graph loaded\n",
      " 6200 graph loaded\n",
      " 6300 graph loaded\n",
      " 6400 graph loaded\n",
      " 6500 graph loaded\n",
      " 6600 graph loaded\n",
      " 6700 graph loaded\n",
      " 6800 graph loaded\n",
      " 6900 graph loaded\n",
      " 7000 graph loaded\n",
      " 7100 graph loaded\n",
      " 7200 graph loaded\n",
      " 7300 graph loaded\n",
      " 7400 graph loaded\n",
      " 7500 graph loaded\n",
      " 7600 graph loaded\n",
      " 7700 graph loaded\n",
      " 7800 graph loaded\n",
      " 7900 graph loaded\n",
      " 8000 graph loaded\n",
      " 8100 graph loaded\n",
      " 8200 graph loaded\n",
      " 8300 graph loaded\n"
     ]
    }
   ],
   "source": [
    "tag_dep_seq_sent = TextGraphType.DEPENDENCY | TextGraphType.TAGS | TextGraphType.SEQUENTIAL | TextGraphType.SENTENCE\n",
    "data_manager = AmazonReviewGraphDataModule(config, True, True, shuffle=True, num_data_load = 55000, device='cpu', batch_size=batch_size, graph_type=tag_dep_seq_sent, load_preprocessed_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'word', 'tag', 'sentence', 'general'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1[0].x_dict['sentence'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1[0].edge_index_dict[('word', 'word_sentence', 'sentence')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "def get_min_max_scaled(scale:float, attributes: Tensor):\n",
    "    if attributes == None or len(attributes) == 0:\n",
    "        return\n",
    "    min_max = (torch.min(attributes), torch.max(attributes))\n",
    "    if min_max[0] == min_max[1]:\n",
    "        attributes = scale * torch.ones_like(attributes)\n",
    "    else:\n",
    "        attributes = scale * (attributes - min_max[0]) / (min_max[1] - min_max[0])\n",
    "    print(torch.max(attributes))\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1.edge_attr_dict[('sentence', 'sentence_word', 'word')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "edge_attr_dict = X1.edge_attr_dict\n",
    "for key in X1.edge_attr_dict:\n",
    "    edge_attr_dict[key] = get_min_max_scaled(1.0, X1.edge_attr_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.edge_attr_dict = edge_attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(X1.edge_attr_dict[('dep', 'dep_word', 'word')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5760])\n",
      "torch.Size([11002, 300])\n",
      "torch.Size([6400])\n",
      "torch.Size([668, 300])\n",
      "torch.Size([128, 300])\n"
     ]
    }
   ],
   "source": [
    "for key in X1.x_dict:\n",
    "    print(X1.x_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, BatchNorm, SAGEConv\n",
    "from torch_geometric.utils import to_dense_adj, dropout_path\n",
    "class HeteroGCNConv(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2, num_heads: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_feature, int(out_feature/num_heads), heads=num_heads, edge_dim=1, add_self_loops=False)\n",
    "        # self.batch_norm = BatchNorm(out_feature)\n",
    "        # self.dropout= nn.Dropout(dropout)\n",
    "        # self.dropout_rate = dropout\n",
    "        \n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weights: Tensor) -> Tensor:\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = self.batch_norm(x)\n",
    "        # x = F.leaky_relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        # dropout_path(edge_index, self.dropout_rate)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import to_hetero\n",
    "# hetero_model = to_hetero(HeteroGCNConv(300, 1024, 0.2), X2.metadata())\n",
    "# pre = hetero_model(X2.x_dict, X2.edge_index_dict, X2.edge_attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_nums = torch.randn((9,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3762,  0.4653,  1.5296, -0.3035, -0.7276,  1.0449, -0.1632,  0.6929,\n",
       "        -1.3023])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, key in enumerate(X1.edge_attr_dict):\n",
    "#     print(f'{i}: {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'word', 'tag', 'sentence', 'general'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from typing import Dict\n",
    "import torch_geometric\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv, GCN2Conv, DenseGCNConv, dense_diff_pool, BatchNorm, global_mean_pool, global_add_pool, global_max_pool, MemPooling, SAGEConv, to_hetero, HeteroBatchNorm, MeanSubtractionNorm, PairNorm\n",
    "from torch_geometric.nn import Sequential as GSequential\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "class HeteroGcnGatModel1(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_feature: int, out_features: int,\n",
    "                 metadata,\n",
    "                 base_hidden_feature: int=256,\n",
    "                 device = 'cpu',\n",
    "                 dropout=0.1):\n",
    "        \n",
    "        super(HeteroGcnGatModel1, self).__init__()\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.bsh: int = base_hidden_feature\n",
    "        bsh2: int = int(self.bsh/2)\n",
    "        bsh4: int = int(self.bsh/4)\n",
    "        bsh8: int = int(self.bsh/8)\n",
    "        \n",
    "        self.norm = PairNorm()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        self.conv1 = to_hetero(HeteroGCNConv(input_feature, self.bsh, dropout), metadata)\n",
    "\n",
    "        self.conv2 = to_hetero(HeteroGCNConv(self.bsh, bsh2, dropout, num_heads=4), metadata)\n",
    "        self.conv3 = to_hetero(HeteroGCNConv(bsh2, bsh4, dropout, num_heads=2), metadata)\n",
    "        self.conv4 = to_hetero(HeteroGCNConv(bsh4, bsh4, dropout, num_heads=2), metadata)\n",
    "        self.conv5 = to_hetero(HeteroGCNConv(bsh4, bsh8, dropout), metadata)\n",
    "        self.conv6 = to_hetero(HeteroGCNConv(bsh8, bsh8, dropout), metadata)\n",
    "        self.conv7 = to_hetero(HeteroGCNConv(bsh8, bsh8, dropout), metadata)\n",
    "        \n",
    "        \n",
    "        # self.conv4 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout), metadata)\n",
    "        # self.conv5 = to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout), metadata)\n",
    "            \n",
    "        # self.encoder = GSequential('x_dict, edge_index_dict, edge_weights_dict', [\n",
    "        #     (to_hetero(HeteroGCNConv(input_feature, self.bsh, dropout), metadata), 'x_dict, edge_index_dict, edge_weights_dict ->x1'),\n",
    "        #     (to_hetero(HeteroGCNConv(self.bsh, self.bsh, dropout), metadata), 'x1, edge_index_dict, edge_weights_dict ->x1'),\n",
    "        #     (to_hetero(HeteroGCNConv(self.bsh, bsh2, dropout), metadata), 'x1, edge_index_dict, edge_weights_dict -> x2'),\n",
    "        #     (to_hetero(HeteroGCNConv(bsh2, bsh2, dropout), metadata), 'x2, edge_index_dict, edge_weights_dict -> x2'),\n",
    "        #     (to_hetero(HeteroGCNConv(bsh2, bsh2, dropout), metadata), 'x2, edge_index_dict, edge_weights_dict -> x2'),\n",
    "        #     (lambda x1, x2: (x1, x2), 'x1, x2 -> x1, x2')\n",
    "            \n",
    "            # (to_hetero(HeteroGCNConv(bsh2, bsh4, dropout), metadata), 'x2, edge_index_dict, edge_weights_dict -> x3'),\n",
    "            # (to_hetero(HeteroGCNConv(bsh4, bsh4, dropout), metadata), 'x3, edge_index_dict, edge_weights_dict -> x3'),\n",
    "            # (to_hetero(HeteroGCNConv(bsh4, bsh4, dropout), metadata), 'x3, edge_index_dict, edge_weights_dict -> x3'),\n",
    "            # (to_hetero(HeteroGCNConv(bsh4, bsh8, dropout), metadata), 'x3, edge_index_dict, edge_weights_dict -> x4'),\n",
    "            # (to_hetero(HeteroGCNConv(bsh8, bsh8, dropout), metadata), 'x4, edge_index_dict, edge_weights_dict -> x4'),\n",
    "            # (to_hetero(HeteroGCNConv(bsh8, bsh8, dropout), metadata), 'x4, edge_index_dict, edge_weights_dict -> x4'),\n",
    "            # (lambda x1, x2, x3, x4: (x1, x2, x3, x4), 'x1, x2, x3, x4 -> x1, x2, x3, x4')\n",
    "        # ])\n",
    "        \n",
    "        # print(f'bsh8: {bsh8}')\n",
    "        # self.attention = GSequential('x3, x4, edge_index, edge_weights', [\n",
    "        #     (GATv2Conv(bsh8, bsh8, 2, edge_dim=1, dropout=dropout), 'x4, edge_index, edge_weights ->x4'),\n",
    "        #     (BatchNorm(bsh4), 'x4->x4'),\n",
    "        #     (nn.ReLU(), 'x4->x4'),\n",
    "            \n",
    "        #     (GCN2Conv(bsh4, 0.5, 0.1, 2), 'x4, x3, edge_index, edge_weights->x3'),\n",
    "        #     (BatchNorm(bsh4), 'x3->x3'),\n",
    "        #     (nn.ReLU(), 'x3->x3'),\n",
    "        #     (GCNConv(bsh4, bsh4), 'x3, edge_index, edge_weights -> x3'),\n",
    "        #     (BatchNorm(bsh4), 'x3->x3'),\n",
    "        #     (nn.ReLU(), 'x3->x3'),\n",
    "            \n",
    "        #     (GATv2Conv(bsh4, bsh4, 2, edge_dim=1, dropout=dropout), 'x3, edge_index, edge_weights ->x3'),\n",
    "        #     (BatchNorm(bsh2), 'x3->x3'),\n",
    "        #     (nn.ReLU(), 'x3->x3'),\n",
    "        #     (lambda x3, x4: (x3, x4), 'x3, x4 -> x3, x4')\n",
    "        # ])\n",
    "        \n",
    "        # self.decoder = GSequential('x1, x2, x3, edge_index, edge_weights', [\n",
    "            \n",
    "        #     (GCN2Conv(bsh2, 0.5, 0.1, 2), 'x3, x2, edge_index, edge_weights->x2'),\n",
    "        #     (BatchNorm(bsh2), 'x2->x2'),\n",
    "        #     (nn.ReLU(), 'x2->x2'),\n",
    "        #     (nn.Dropout(dropout), 'x2->x2'),\n",
    "        # self.decoder = GSequential('x1, x2, edge_index, edge_weights', [\n",
    "        #     (GCNConv(bsh2, bsh2), 'x2, edge_index, edge_weights -> x2'),\n",
    "        #     (BatchNorm(bsh2), 'x2->x2'),\n",
    "        #     (nn.ReLU(), 'x2->x2'),\n",
    "        #     (nn.Dropout(dropout), 'x2->x2'),\n",
    "        #     (GCNConv(bsh2, self.bsh), 'x2, edge_index->x2'),\n",
    "        #     (BatchNorm(self.bsh), 'x2->x2'),\n",
    "        #     (nn.ReLU(), 'x2->x2'),\n",
    "        #     (nn.Dropout(dropout), 'x2->x2'),\n",
    "            \n",
    "        #     (GCN2Conv(self.bsh, 0.5, 0.1, 2), 'x2, x1, edge_index, edge_weights->x1'),\n",
    "        #     (BatchNorm(self.bsh), 'x1->x1'),\n",
    "        #     (nn.ReLU(), 'x1->x1'),\n",
    "        #     (nn.Dropout(dropout), 'x1->x1'),\n",
    "        #     (GCNConv(self.bsh, self.bsh), 'x1, edge_index, edge_weights ->x1'),\n",
    "        #     (BatchNorm(self.bsh), 'x1->x1'),\n",
    "        #     (nn.ReLU(), 'x1->x1'),\n",
    "        #     (nn.Dropout(dropout), 'x1->x1'),\n",
    "        #     (GCNConv(self.bsh, self.bsh), 'x1, edge_index, edge_weights ->x1'),\n",
    "        #     (BatchNorm(self.bsh), 'x1->x1'),\n",
    "        #     (nn.ReLU(), 'x1->x1'),\n",
    "        #     (nn.Dropout(dropout), 'x1->x1')\n",
    "        # ])\n",
    "        self.mem_pool = MemPooling(bsh8, bsh8, 2, 8)\n",
    "        self.output_layer = Linear(self.bsh, self.num_out_features)\n",
    "        \n",
    "        self.dep_embedding = torch.nn.Embedding(45, 300)\n",
    "        self.tag_embedding = torch.nn.Embedding(50, 300)\n",
    "        self.pw1 = torch.nn.Parameter(torch.randn([9,], dtype=torch.float32), requires_grad=True)\n",
    "        self.pw2 = torch.nn.Parameter(torch.randn([9,], dtype=torch.float32), requires_grad=True)\n",
    "        self.pw3 = torch.nn.Parameter(torch.randn([9,], dtype=torch.float32), requires_grad=True)\n",
    "        self.pw4 = torch.nn.Parameter(torch.randn([9,], dtype=torch.float32), requires_grad=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: HeteroData) -> Tensor:\n",
    "        # x1_dict, x2_dict = self.encoder(x.x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict = {key: x.x_dict[key] for key in x.x_dict}\n",
    "        x_dict['dep'] = self.dep_embedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_embedding(x_dict['tag'])\n",
    "        \n",
    "        x.edge_attr_dict = {key: (x.edge_attr_dict[key]*self.pw1[i] if x.edge_attr_dict[key] != None else torch.Tensor(0)) for i, key in enumerate(x.edge_attr_dict)}\n",
    "        \n",
    "        \n",
    "        x_dict = self.conv1(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv2(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "        x_dict = self.conv3(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = self.drop(F.relu(self.norm(x_dict['word'], x['word'].batch)))\n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "        \n",
    "        x.edge_attr_dict = {key: (x.edge_attr_dict[key]*self.pw2[i] if x.edge_attr_dict[key] != None else torch.Tensor(0)) for i, key in enumerate(x.edge_attr_dict)}\n",
    "        \n",
    "        x_dict = self.conv4(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "        x_dict = self.conv5(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "        x_dict = self.conv6(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = self.drop(F.relu(self.norm(x_dict['word'], x['word'].batch)))\n",
    "        \n",
    "        x.edge_attr_dict = {key: (x.edge_attr_dict[key]*self.pw3[i] if x.edge_attr_dict[key] != None else torch.Tensor(0)) for i, key in enumerate(x.edge_attr_dict)}\n",
    "        \n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = self.drop(F.relu(self.norm(x_dict['word'], x['word'].batch)))\n",
    "        \n",
    "        x.edge_attr_dict = {key: (x.edge_attr_dict[key]*self.pw4[i] if x.edge_attr_dict[key] != None else torch.Tensor(0)) for i, key in enumerate(x.edge_attr_dict)}\n",
    "        \n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = F.relu(self.norm(x_dict['word'], x['word'].batch))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        x_dict['word'] = self.drop(F.relu(self.norm(x_dict['word'], x['word'].batch)))\n",
    "        x_dict = self.conv7(x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        \n",
    "        # x2_dict['word'] = self.norm(x2_dict['word'], x['word'].batch)\n",
    "                \n",
    "        # x1_dict = self.conv4(x1_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        # x1_dict = self.conv5(x1_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        \n",
    "        # x1_dict, x2_dict, x3_dict, x4_dict = self.encoder(x.x_dict, x.edge_index_dict, x.edge_attr_dict)\n",
    "        # x_att, x4 = self.attention(x3_dict[\"word\"], x4_dict[\"word\"], \n",
    "        #                            x.edge_index_dict[('word', 'seq', 'word')],\n",
    "        #                            x.edge_attr_dict[('word', 'seq', 'word')])\n",
    "        # x_dec = self.decoder(x1_dict[\"word\"], x2_dict[\"word\"], x_att, \n",
    "        #                      x.edge_index_dict[('word', 'seq', 'word')],\n",
    "        #                      x.edge_attr_dict[('word', 'seq', 'word')])\n",
    "        x_pooled, S = self.mem_pool(x_dict['word'], x['word'].batch)\n",
    "        x_pooled = x_pooled.view(x_pooled.shape[0], -1)\n",
    "        out = self.output_layer(x_pooled)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "+------------------------------------------------------------+--------------------------+-----------------------------+-----------+\n",
      "| Layer                                                      | Input Shape              | Output Shape                | #Param    |\n",
      "|------------------------------------------------------------+--------------------------+-----------------------------+-----------|\n",
      "| HeteroGcnGatModel1                                         | [23871, 23871]           | [128, 1]                    | 2,324,827 |\n",
      "| ├─(norm)PairNorm                                           | [10930, 256], [10930]    | [10930, 256]                | --        |\n",
      "| ├─(drop)Dropout                                            | [10930, 64]              | [10930, 64]                 | --        |\n",
      "| ├─(conv1)GraphModule                                       |                          |                             | 1,393,920 |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 1,393,920 |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 256]                | 154,880   |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 256]                 | 154,880   |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 256]                | 154,880   |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 256]                 | 154,880   |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 300], [2, 21604] | [10930, 256]                | 154,880   |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 256]                  | 154,880   |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 256]                  | 154,880   |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 256]                  | 154,880   |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 256]                | 154,880   |\n",
      "| ├─(conv2)GraphModule                                       |                          |                             | 595,584   |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 595,584   |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 128]                | 66,176    |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 128]                 | 66,176    |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 128]                | 66,176    |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 128]                 | 66,176    |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 256], [2, 21604] | [10930, 128]                | 66,176    |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 128]                  | 66,176    |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 128]                  | 66,176    |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 128]                  | 66,176    |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 128]                | 66,176    |\n",
      "| ├─(conv3)GraphModule                                       |                          |                             | 150,336   |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 150,336   |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 64]                 | 16,704    |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 64]                  | 16,704    |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 64]                 | 16,704    |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 64]                  | 16,704    |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 128], [2, 21604] | [10930, 64]                 | 16,704    |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 64]                   | 16,704    |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 64]                   | 16,704    |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 64]                   | 16,704    |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 64]                 | 16,704    |\n",
      "| ├─(conv4)GraphModule                                       |                          |                             | 76,608    |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 76,608    |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 64]                 | 8,512     |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 64]                  | 8,512     |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 64]                 | 8,512     |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 64]                  | 8,512     |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 64], [2, 21604]  | [10930, 64]                 | 8,512     |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 64]                   | 8,512     |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 64]                   | 8,512     |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 64]                   | 8,512     |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 64]                 | 8,512     |\n",
      "| ├─(conv5)GraphModule                                       |                          |                             | 38,304    |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 38,304    |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 32]                 | 4,256     |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 32]                  | 4,256     |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 32]                 | 4,256     |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 32]                  | 4,256     |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 64], [2, 21604]  | [10930, 32]                 | 4,256     |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 32]                   | 4,256     |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 32]                   | 4,256     |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 32]                   | 4,256     |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 32]                 | 4,256     |\n",
      "| ├─(conv6)GraphModule                                       |                          |                             | 19,872    |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 19,872    |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 32]                  | 2,208     |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 32]                  | 2,208     |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 32], [2, 21604]  | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 32]                   | 2,208     |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 32]                   | 2,208     |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 32]                   | 2,208     |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 32]                 | 2,208     |\n",
      "| ├─(conv7)GraphModule                                       |                          |                             | 19,872    |\n",
      "| │    └─(conv1)ModuleDict                                   | --                       | --                          | 19,872    |\n",
      "| │    │    └─(dep__dep_word__word)GATv2Conv                 | [2, 10277]               | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(word__word_dep__dep)GATv2Conv                 | [2, 10277]               | [5760, 32]                  | 2,208     |\n",
      "| │    │    └─(tag__tag_word__word)GATv2Conv                 | [2, 10930]               | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(word__word_tag__tag)GATv2Conv                 | [2, 10930]               | [6400, 32]                  | 2,208     |\n",
      "| │    │    └─(word__seq__word)GATv2Conv                     | [10930, 32], [2, 21604]  | [10930, 32]                 | 2,208     |\n",
      "| │    │    └─(general__general_sentence__sentence)GATv2Conv | [2, 653]                 | [653, 32]                   | 2,208     |\n",
      "| │    │    └─(sentence__sentence_general__general)GATv2Conv | [2, 653]                 | [128, 32]                   | 2,208     |\n",
      "| │    │    └─(word__word_sentence__sentence)GATv2Conv       | [2, 10930]               | [653, 32]                   | 2,208     |\n",
      "| │    │    └─(sentence__sentence_word__word)GATv2Conv       | [2, 10930]               | [10930, 32]                 | 2,208     |\n",
      "| ├─(mem_pool)MemPooling                                     | [10930, 32], [10930]     | [128, 8, 32], [128, 203, 8] | 1,538     |\n",
      "| │    └─(conv)Conv2d                                        | [128, 2, 203, 8]         | [128, 1, 203, 8]            | 2         |\n",
      "| │    └─(lin)Linear                                         | [128, 8, 32]             | [128, 8, 32]                | 1,024     |\n",
      "| ├─(output_layer)Linear                                     | [128, 256]               | [128, 1]                    | 257       |\n",
      "| ├─(dep_embedding)Embedding                                 | [5760]                   | [5760, 300]                 | 13,500    |\n",
      "| ├─(tag_embedding)Embedding                                 | [6400]                   | [6400, 300]                 | 15,000    |\n",
      "+------------------------------------------------------------+--------------------------+-----------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "torch_model = HeteroGcnGatModel1(300, 1, X2.metadata(), 256, dropout=0.2)\n",
    "torch_model = torch_model.to(device)\n",
    "print(next(iter(torch_model.parameters())).device)\n",
    "print(torch_geometric.nn.summary(torch_model, X2.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import BinaryLightningModel\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "    # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "]\n",
    "lightning_model = BinaryLightningModel(torch_model,\n",
    "                                 torch.optim.Adam(torch_model.parameters(), lr=0.00015, weight_decay=0.001),\n",
    "                                       torch.nn.BCEWithLogitsLoss(),\n",
    "                                       learning_rate=00.00015,\n",
    "                                       batch_size=batch_size,\n",
    "                                       ).to(device)\n",
    "model_manager = ClassifierModelManager(torch_model, lightning_model, model_save_dir=r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs', log_name='hetero_model_2', device=device, num_train_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8f33682c2e4d0ba0f52ec9aa694755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 89 steps due to diverging loss.\n",
      "Learning rate set to 0.00030199517204020147\n",
      "Restoring states from the checkpoint path at C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\.lr_find_0aaf0910-7036-4266-8958-272cb20627b4.ckpt\n",
      "Restored all states from the checkpoint at C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\.lr_find_0aaf0910-7036-4266-8958-272cb20627b4.ckpt\n",
      "c:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\Models\\ModelsManager\\ModelManager.py:43: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00030199517204020147"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager.tune(data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | HeteroGcnGatModel1 | 2.3 M \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "2 | train_acc | BinaryAccuracy     | 0     \n",
      "3 | val_acc   | BinaryAccuracy     | 0     \n",
      "4 | test_acc  | BinaryAccuracy     | 0     \n",
      "-------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.299     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1f7bf3a4d24f15a09ff4886f9b61d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309fca476ceb4d778522b8c5a1c0c13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e1905ccdde4fb5b886935d5a720ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aab28898e564b978a03237747f162f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': None,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0.001,\n",
       " 'amsgrad': False,\n",
       " 'maximize': False,\n",
       " 'foreach': None,\n",
       " 'capturable': False,\n",
       " 'differentiable': False,\n",
       " 'fused': None,\n",
       " 'params': [Parameter containing:\n",
       "  tensor([-0.4433, -1.7770,  0.0401,  0.4712,  0.8439,  1.2691,  1.0888,  1.2276,\n",
       "          -0.5463], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.7575,  0.5122,  0.4406,  0.9606,  0.9147,  0.7588, -0.9355, -0.3720,\n",
       "          -0.7030], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.9882, -0.4496,  1.4164,  2.1575, -0.7732, -0.5050, -0.4792, -0.3630,\n",
       "          -0.4692], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.9965, -0.2479, -0.4275,  0.9966, -1.2815, -0.2276,  0.2760, -0.6194,\n",
       "           1.6546], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1439,  0.1358, -0.0916, -0.0502,  0.0634,  0.1429,  0.0811,\n",
       "             0.0435, -0.0012, -0.0153,  0.1195, -0.1176, -0.1504,  0.0568,\n",
       "            -0.1284, -0.0048,  0.0779,  0.0388, -0.1340, -0.0252, -0.1506,\n",
       "             0.0878, -0.0960,  0.0845, -0.0594, -0.1171, -0.0086,  0.0590,\n",
       "             0.1365,  0.0524,  0.0624, -0.0645,  0.0530,  0.0701,  0.0750,\n",
       "             0.1503,  0.1353, -0.0452,  0.0649,  0.0572, -0.1228,  0.0223,\n",
       "             0.0526,  0.0060, -0.1367,  0.1021,  0.0700, -0.0258,  0.0535,\n",
       "            -0.0350, -0.1350,  0.1469,  0.0429, -0.0212,  0.1434,  0.0079,\n",
       "            -0.0813,  0.0912, -0.0274,  0.1098,  0.0201, -0.0210,  0.0975,\n",
       "             0.1400, -0.0849, -0.1074,  0.0036, -0.0003,  0.1451,  0.0296,\n",
       "             0.0522,  0.1466,  0.1456,  0.0308,  0.0198,  0.0479,  0.0323,\n",
       "            -0.1202, -0.1041, -0.1125, -0.0519,  0.1138, -0.0833, -0.0182,\n",
       "            -0.0077, -0.0839, -0.1022, -0.0784, -0.0632, -0.0626,  0.1337,\n",
       "             0.0814, -0.0723, -0.1413,  0.0848, -0.0420, -0.0902, -0.0756,\n",
       "             0.0986, -0.1274,  0.0982, -0.0163, -0.0219,  0.0892, -0.0851,\n",
       "             0.0815,  0.0807,  0.0619, -0.1420, -0.0707, -0.0934, -0.0931,\n",
       "            -0.0736, -0.0684,  0.0068, -0.1255,  0.0502, -0.0394,  0.1342,\n",
       "            -0.0737,  0.1200,  0.1169,  0.0080, -0.1429,  0.1483,  0.1035,\n",
       "             0.1178, -0.0544, -0.0849, -0.0343,  0.0698, -0.0296,  0.0630,\n",
       "            -0.1083,  0.0727,  0.0397,  0.0940, -0.0250,  0.0023,  0.1092,\n",
       "            -0.0138,  0.1254,  0.1480, -0.0592,  0.1208, -0.1281, -0.0311,\n",
       "             0.0828,  0.1203,  0.0497, -0.0425,  0.1209, -0.0389,  0.1099,\n",
       "            -0.1315, -0.1485,  0.1391, -0.0207,  0.0241,  0.0410, -0.0173,\n",
       "            -0.0205,  0.0076,  0.0769, -0.0928,  0.0407, -0.0829,  0.0468,\n",
       "             0.0937, -0.0038,  0.0039,  0.0627, -0.0349,  0.1459,  0.0823,\n",
       "            -0.0581, -0.0668,  0.0576,  0.0536, -0.0971,  0.1470,  0.1403,\n",
       "            -0.0947,  0.1333,  0.0190,  0.0406, -0.0269, -0.1258,  0.0294,\n",
       "             0.0895, -0.1458, -0.0587, -0.0866, -0.1509,  0.1197,  0.0115,\n",
       "             0.0848,  0.0446, -0.0776,  0.0096, -0.0228,  0.0451, -0.0452,\n",
       "             0.0823,  0.0331, -0.0092, -0.1349, -0.1521, -0.1104, -0.0326,\n",
       "             0.0064,  0.1007,  0.0790, -0.0073,  0.1394, -0.1275,  0.1257,\n",
       "            -0.0368, -0.0446, -0.1233, -0.0744,  0.0632, -0.1459,  0.0509,\n",
       "             0.0114,  0.1218, -0.1155,  0.0742, -0.1338, -0.1291,  0.1289,\n",
       "             0.0887, -0.0284,  0.1288, -0.1318, -0.0117,  0.0851, -0.0182,\n",
       "            -0.1253,  0.0476,  0.0321, -0.0344, -0.1043, -0.1005, -0.0660,\n",
       "             0.0025, -0.1398, -0.1168,  0.0919,  0.1452,  0.0368,  0.0907,\n",
       "            -0.1014, -0.0720, -0.0289,  0.0355]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1012, -0.0398,  0.0805,  ..., -0.0084, -0.0145,  0.0184],\n",
       "          [ 0.0604, -0.0409, -0.0932,  ...,  0.0411, -0.0389, -0.0965],\n",
       "          [-0.0364,  0.0702,  0.0834,  ...,  0.0128,  0.0193, -0.0859],\n",
       "          ...,\n",
       "          [-0.0284,  0.0519, -0.0998,  ...,  0.0037,  0.0721,  0.0343],\n",
       "          [-0.1012, -0.0322, -0.0650,  ...,  0.0034,  0.0870,  0.0286],\n",
       "          [ 0.0378,  0.0762, -0.0678,  ..., -0.0574,  0.0892, -0.0414]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0443,  0.0405, -0.0481,  0.0009,  0.0210,  0.0540, -0.0552, -0.0491,\n",
       "          -0.0305,  0.0321, -0.0209, -0.0206,  0.0323, -0.0480, -0.0458,  0.0495,\n",
       "          -0.0510, -0.0099, -0.0031,  0.0026,  0.0126,  0.0327,  0.0098, -0.0003,\n",
       "          -0.0084, -0.0066,  0.0474,  0.0074, -0.0551, -0.0339,  0.0421,  0.0035,\n",
       "           0.0509, -0.0401, -0.0503, -0.0143, -0.0458, -0.0131, -0.0061,  0.0235,\n",
       "          -0.0408, -0.0346,  0.0409, -0.0075, -0.0184, -0.0094,  0.0336, -0.0036,\n",
       "           0.0275,  0.0034,  0.0308,  0.0285, -0.0153, -0.0059, -0.0182,  0.0221,\n",
       "          -0.0295,  0.0201, -0.0416, -0.0339, -0.0366, -0.0073, -0.0534, -0.0332,\n",
       "           0.0086,  0.0253,  0.0020,  0.0139, -0.0342, -0.0379, -0.0459,  0.0551,\n",
       "          -0.0176,  0.0326,  0.0155,  0.0109, -0.0128,  0.0301,  0.0533, -0.0149,\n",
       "          -0.0463, -0.0044,  0.0041,  0.0544, -0.0108,  0.0171, -0.0280, -0.0132,\n",
       "           0.0144,  0.0561,  0.0261, -0.0277,  0.0473, -0.0444,  0.0470,  0.0295,\n",
       "          -0.0253,  0.0358, -0.0183, -0.0100,  0.0576, -0.0077,  0.0222,  0.0547,\n",
       "          -0.0529,  0.0378,  0.0323, -0.0176,  0.0528, -0.0210,  0.0371,  0.0576,\n",
       "           0.0169,  0.0013,  0.0382,  0.0199,  0.0309, -0.0551,  0.0507,  0.0273,\n",
       "           0.0188, -0.0196,  0.0097,  0.0099,  0.0083, -0.0332, -0.0498,  0.0247,\n",
       "          -0.0046,  0.0135, -0.0204,  0.0339, -0.0527, -0.0143,  0.0519,  0.0203,\n",
       "           0.0243, -0.0558, -0.0297,  0.0335, -0.0528,  0.0552,  0.0524,  0.0059,\n",
       "          -0.0377, -0.0529, -0.0390, -0.0331, -0.0142,  0.0212, -0.0375, -0.0102,\n",
       "          -0.0142, -0.0093,  0.0064,  0.0520,  0.0051, -0.0119,  0.0064,  0.0221,\n",
       "          -0.0023,  0.0279, -0.0048,  0.0317, -0.0505, -0.0555, -0.0013, -0.0214,\n",
       "           0.0302,  0.0092,  0.0236,  0.0065,  0.0406, -0.0218,  0.0202, -0.0227,\n",
       "          -0.0220,  0.0435, -0.0251, -0.0447,  0.0438, -0.0220, -0.0099, -0.0458,\n",
       "          -0.0113, -0.0192,  0.0304,  0.0181,  0.0451,  0.0474, -0.0244,  0.0035,\n",
       "           0.0360,  0.0341, -0.0095,  0.0545, -0.0345, -0.0065, -0.0252,  0.0256,\n",
       "          -0.0260,  0.0514, -0.0174,  0.0390,  0.0193,  0.0081,  0.0250,  0.0177,\n",
       "           0.0005,  0.0184,  0.0058, -0.0571,  0.0367, -0.0295,  0.0126, -0.0241,\n",
       "          -0.0009,  0.0346, -0.0120, -0.0093, -0.0407, -0.0272,  0.0057,  0.0121,\n",
       "          -0.0187,  0.0515,  0.0026,  0.0054, -0.0335,  0.0167, -0.0535,  0.0270,\n",
       "           0.0173,  0.0202,  0.0123,  0.0244,  0.0411,  0.0432,  0.0273, -0.0106,\n",
       "          -0.0144,  0.0405,  0.0145,  0.0161,  0.0331,  0.0256, -0.0348, -0.0523,\n",
       "           0.0308, -0.0496, -0.0456, -0.0485, -0.0388,  0.0220, -0.0538,  0.0029],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0065, -0.0606, -0.0340,  ...,  0.0314, -0.0587,  0.1032],\n",
       "          [-0.0819, -0.1011,  0.0899,  ...,  0.0762, -0.0472,  0.0912],\n",
       "          [ 0.0105, -0.0910,  0.0904,  ...,  0.0392,  0.0964, -0.0443],\n",
       "          ...,\n",
       "          [ 0.0351,  0.0246,  0.0300,  ..., -0.0990,  0.0755, -0.0015],\n",
       "          [ 0.0739, -0.0651, -0.0006,  ..., -0.0421, -0.0368, -0.0032],\n",
       "          [-0.0536, -0.0904, -0.0022,  ...,  0.0291,  0.0773,  0.0184]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0518,  0.0194, -0.0566, -0.0047,  0.0021,  0.0164, -0.0173, -0.0074,\n",
       "          -0.0444, -0.0126, -0.0562,  0.0570,  0.0276,  0.0513,  0.0489, -0.0393,\n",
       "          -0.0314,  0.0495,  0.0374,  0.0088,  0.0536,  0.0470,  0.0474,  0.0453,\n",
       "           0.0398,  0.0191, -0.0221, -0.0367, -0.0312,  0.0492, -0.0254, -0.0026,\n",
       "           0.0099, -0.0304,  0.0220,  0.0103, -0.0079, -0.0355, -0.0448, -0.0223,\n",
       "           0.0399, -0.0309,  0.0031,  0.0031, -0.0472, -0.0143,  0.0090,  0.0047,\n",
       "          -0.0576, -0.0215, -0.0440,  0.0506, -0.0169, -0.0445, -0.0484,  0.0431,\n",
       "           0.0119,  0.0246,  0.0294,  0.0381, -0.0030,  0.0490,  0.0223, -0.0407,\n",
       "           0.0413, -0.0482, -0.0129,  0.0288, -0.0178,  0.0425, -0.0386, -0.0228,\n",
       "           0.0185,  0.0200, -0.0176, -0.0125, -0.0492,  0.0027, -0.0155, -0.0004,\n",
       "          -0.0040,  0.0577, -0.0516,  0.0268, -0.0023,  0.0305,  0.0493, -0.0379,\n",
       "          -0.0290,  0.0219, -0.0551,  0.0408, -0.0057, -0.0552, -0.0065,  0.0412,\n",
       "           0.0466, -0.0357,  0.0208, -0.0340,  0.0444, -0.0446, -0.0550, -0.0528,\n",
       "           0.0133,  0.0558, -0.0223,  0.0396,  0.0448, -0.0553, -0.0202,  0.0525,\n",
       "          -0.0458,  0.0422,  0.0131, -0.0317, -0.0116,  0.0486, -0.0352, -0.0562,\n",
       "          -0.0519, -0.0358,  0.0202, -0.0278,  0.0065,  0.0033, -0.0113, -0.0146,\n",
       "           0.0044, -0.0172, -0.0284,  0.0094,  0.0025,  0.0515, -0.0341, -0.0429,\n",
       "          -0.0286, -0.0213, -0.0213,  0.0298, -0.0338, -0.0410,  0.0221,  0.0304,\n",
       "          -0.0347, -0.0143,  0.0095, -0.0456, -0.0268,  0.0421, -0.0161,  0.0227,\n",
       "           0.0577,  0.0357, -0.0134,  0.0408,  0.0015,  0.0541,  0.0208,  0.0105,\n",
       "           0.0320,  0.0437, -0.0128, -0.0355, -0.0493,  0.0553,  0.0167,  0.0345,\n",
       "          -0.0318, -0.0077, -0.0444, -0.0380, -0.0573,  0.0507, -0.0082, -0.0003,\n",
       "           0.0448, -0.0570,  0.0466,  0.0279,  0.0057, -0.0171,  0.0208,  0.0574,\n",
       "           0.0345,  0.0575, -0.0400,  0.0373, -0.0573,  0.0091, -0.0542,  0.0228,\n",
       "           0.0363,  0.0216,  0.0425, -0.0444, -0.0145, -0.0309, -0.0097, -0.0493,\n",
       "           0.0091,  0.0544, -0.0470,  0.0520, -0.0074, -0.0245,  0.0369,  0.0274,\n",
       "          -0.0451,  0.0218,  0.0022, -0.0335, -0.0335, -0.0096, -0.0244,  0.0046,\n",
       "          -0.0271, -0.0330,  0.0540,  0.0328, -0.0409,  0.0398, -0.0325, -0.0567,\n",
       "           0.0291, -0.0572, -0.0382,  0.0207, -0.0485,  0.0481, -0.0117,  0.0436,\n",
       "          -0.0413, -0.0486,  0.0180,  0.0186,  0.0265, -0.0233, -0.0382,  0.0305,\n",
       "           0.0350,  0.0420,  0.0505, -0.0488,  0.0218, -0.0247,  0.0100, -0.0027,\n",
       "          -0.0355,  0.0019, -0.0437,  0.0571, -0.0236,  0.0575, -0.0519, -0.0046],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0145],\n",
       "          [-0.0747],\n",
       "          [ 0.0795],\n",
       "          [-0.0970],\n",
       "          [-0.0615],\n",
       "          [-0.0736],\n",
       "          [-0.1312],\n",
       "          [ 0.1181],\n",
       "          [ 0.0408],\n",
       "          [ 0.0306],\n",
       "          [-0.1054],\n",
       "          [ 0.0244],\n",
       "          [ 0.0519],\n",
       "          [-0.0609],\n",
       "          [-0.1008],\n",
       "          [ 0.1239],\n",
       "          [-0.0830],\n",
       "          [-0.0869],\n",
       "          [ 0.1344],\n",
       "          [-0.0493],\n",
       "          [-0.1250],\n",
       "          [ 0.1173],\n",
       "          [ 0.1116],\n",
       "          [-0.0033],\n",
       "          [ 0.1208],\n",
       "          [ 0.0061],\n",
       "          [ 0.0041],\n",
       "          [ 0.0143],\n",
       "          [ 0.1184],\n",
       "          [-0.0911],\n",
       "          [-0.0610],\n",
       "          [ 0.0320],\n",
       "          [-0.0110],\n",
       "          [ 0.1188],\n",
       "          [-0.0638],\n",
       "          [-0.0905],\n",
       "          [ 0.0215],\n",
       "          [-0.0518],\n",
       "          [ 0.1051],\n",
       "          [-0.0290],\n",
       "          [ 0.1527],\n",
       "          [ 0.1401],\n",
       "          [ 0.1187],\n",
       "          [ 0.0929],\n",
       "          [ 0.1095],\n",
       "          [ 0.0556],\n",
       "          [-0.0723],\n",
       "          [-0.1236],\n",
       "          [ 0.0597],\n",
       "          [-0.1135],\n",
       "          [ 0.0847],\n",
       "          [-0.0036],\n",
       "          [ 0.0621],\n",
       "          [ 0.0074],\n",
       "          [ 0.0186],\n",
       "          [ 0.1142],\n",
       "          [-0.0239],\n",
       "          [-0.0493],\n",
       "          [-0.0132],\n",
       "          [ 0.0992],\n",
       "          [-0.1259],\n",
       "          [ 0.0657],\n",
       "          [-0.1069],\n",
       "          [ 0.0607],\n",
       "          [ 0.0791],\n",
       "          [ 0.0970],\n",
       "          [ 0.0622],\n",
       "          [ 0.0670],\n",
       "          [ 0.0709],\n",
       "          [ 0.0052],\n",
       "          [ 0.0007],\n",
       "          [-0.0343],\n",
       "          [-0.0818],\n",
       "          [ 0.0581],\n",
       "          [ 0.0523],\n",
       "          [ 0.0903],\n",
       "          [ 0.1204],\n",
       "          [ 0.0750],\n",
       "          [ 0.1423],\n",
       "          [ 0.1089],\n",
       "          [ 0.0120],\n",
       "          [-0.0406],\n",
       "          [-0.1389],\n",
       "          [-0.1394],\n",
       "          [ 0.0709],\n",
       "          [ 0.1372],\n",
       "          [ 0.0525],\n",
       "          [ 0.0459],\n",
       "          [-0.1150],\n",
       "          [ 0.0339],\n",
       "          [-0.0234],\n",
       "          [ 0.0897],\n",
       "          [ 0.1001],\n",
       "          [ 0.0743],\n",
       "          [-0.0094],\n",
       "          [-0.0768],\n",
       "          [ 0.1488],\n",
       "          [-0.1026],\n",
       "          [ 0.0840],\n",
       "          [-0.0244],\n",
       "          [-0.0978],\n",
       "          [ 0.1340],\n",
       "          [ 0.0336],\n",
       "          [ 0.0297],\n",
       "          [ 0.1087],\n",
       "          [-0.0314],\n",
       "          [-0.1478],\n",
       "          [ 0.0483],\n",
       "          [-0.1056],\n",
       "          [-0.0867],\n",
       "          [-0.0749],\n",
       "          [-0.1135],\n",
       "          [ 0.0548],\n",
       "          [ 0.0513],\n",
       "          [-0.0685],\n",
       "          [-0.0241],\n",
       "          [-0.1223],\n",
       "          [-0.0195],\n",
       "          [-0.1187],\n",
       "          [ 0.0686],\n",
       "          [-0.0123],\n",
       "          [-0.0332],\n",
       "          [ 0.0728],\n",
       "          [ 0.0436],\n",
       "          [ 0.0500],\n",
       "          [-0.0689],\n",
       "          [ 0.1200],\n",
       "          [-0.1358],\n",
       "          [-0.1311],\n",
       "          [ 0.1208],\n",
       "          [ 0.1489],\n",
       "          [-0.0444],\n",
       "          [-0.0983],\n",
       "          [-0.1230],\n",
       "          [ 0.0613],\n",
       "          [-0.1363],\n",
       "          [-0.1362],\n",
       "          [ 0.0914],\n",
       "          [ 0.0477],\n",
       "          [-0.1119],\n",
       "          [-0.0498],\n",
       "          [ 0.1299],\n",
       "          [ 0.1176],\n",
       "          [ 0.0074],\n",
       "          [-0.0672],\n",
       "          [ 0.0428],\n",
       "          [ 0.1389],\n",
       "          [-0.0461],\n",
       "          [-0.0504],\n",
       "          [ 0.1149],\n",
       "          [ 0.1084],\n",
       "          [-0.1349],\n",
       "          [-0.0905],\n",
       "          [-0.0096],\n",
       "          [ 0.0998],\n",
       "          [ 0.1024],\n",
       "          [ 0.1076],\n",
       "          [-0.0686],\n",
       "          [-0.0139],\n",
       "          [-0.0918],\n",
       "          [ 0.1429],\n",
       "          [-0.0931],\n",
       "          [ 0.0711],\n",
       "          [-0.1242],\n",
       "          [ 0.0546],\n",
       "          [-0.0195],\n",
       "          [ 0.0643],\n",
       "          [ 0.0971],\n",
       "          [ 0.0070],\n",
       "          [-0.0047],\n",
       "          [ 0.1095],\n",
       "          [-0.1154],\n",
       "          [-0.0719],\n",
       "          [-0.1204],\n",
       "          [-0.0023],\n",
       "          [-0.0177],\n",
       "          [ 0.0157],\n",
       "          [-0.0152],\n",
       "          [-0.1427],\n",
       "          [-0.0086],\n",
       "          [-0.1374],\n",
       "          [ 0.0291],\n",
       "          [-0.1177],\n",
       "          [ 0.0048],\n",
       "          [-0.0593],\n",
       "          [-0.1088],\n",
       "          [ 0.0939],\n",
       "          [-0.0867],\n",
       "          [-0.1208],\n",
       "          [-0.0853],\n",
       "          [ 0.0713],\n",
       "          [ 0.0915],\n",
       "          [-0.0346],\n",
       "          [-0.0629],\n",
       "          [ 0.0717],\n",
       "          [-0.0494],\n",
       "          [ 0.0432],\n",
       "          [-0.0403],\n",
       "          [-0.0081],\n",
       "          [-0.1365],\n",
       "          [-0.1106],\n",
       "          [ 0.0957],\n",
       "          [-0.0828],\n",
       "          [-0.0406],\n",
       "          [-0.0866],\n",
       "          [-0.0466],\n",
       "          [-0.0897],\n",
       "          [ 0.0077],\n",
       "          [-0.0494],\n",
       "          [-0.0059],\n",
       "          [ 0.1488],\n",
       "          [ 0.1177],\n",
       "          [ 0.0142],\n",
       "          [ 0.0330],\n",
       "          [ 0.0749],\n",
       "          [ 0.0739],\n",
       "          [-0.1251],\n",
       "          [-0.1122],\n",
       "          [-0.0864],\n",
       "          [ 0.0272],\n",
       "          [ 0.0198],\n",
       "          [-0.0232],\n",
       "          [-0.1123],\n",
       "          [-0.1070],\n",
       "          [ 0.0737],\n",
       "          [ 0.0655],\n",
       "          [ 0.1061],\n",
       "          [-0.1450],\n",
       "          [ 0.1276],\n",
       "          [ 0.0295],\n",
       "          [-0.0891],\n",
       "          [-0.0665],\n",
       "          [-0.1178],\n",
       "          [ 0.0534],\n",
       "          [-0.0102],\n",
       "          [-0.0577],\n",
       "          [-0.0337],\n",
       "          [-0.0532],\n",
       "          [ 0.1370],\n",
       "          [ 0.0907],\n",
       "          [ 0.0738],\n",
       "          [ 0.0438],\n",
       "          [ 0.1389],\n",
       "          [-0.0689],\n",
       "          [ 0.1314],\n",
       "          [-0.0559],\n",
       "          [-0.0858],\n",
       "          [ 0.1445],\n",
       "          [ 0.0186],\n",
       "          [-0.0320],\n",
       "          [ 0.1256],\n",
       "          [ 0.0519],\n",
       "          [-0.1433],\n",
       "          [-0.0288],\n",
       "          [ 0.0269],\n",
       "          [-0.1144]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1345,  0.0490, -0.0346,  0.0662,  0.1363,  0.0226, -0.1236,\n",
       "             0.1522, -0.0716,  0.0681,  0.0243, -0.0359, -0.0697,  0.0191,\n",
       "            -0.1073,  0.1240,  0.0677,  0.0614,  0.0817,  0.0681, -0.0403,\n",
       "             0.1118,  0.0800, -0.0029,  0.0809, -0.0435, -0.0284, -0.1125,\n",
       "             0.1443, -0.0879, -0.1178, -0.0481,  0.1002, -0.0077,  0.0780,\n",
       "            -0.0194,  0.1223,  0.1135,  0.0038,  0.0885, -0.0768, -0.0992,\n",
       "             0.1215,  0.1239, -0.1021, -0.0518, -0.0219, -0.1308,  0.0367,\n",
       "            -0.0898,  0.0663,  0.0034,  0.1134, -0.1510,  0.0270, -0.1082,\n",
       "             0.0094, -0.0666, -0.0377, -0.1357,  0.0732, -0.1033,  0.0690,\n",
       "            -0.0011,  0.1002,  0.0369, -0.0685, -0.0345, -0.0769, -0.0131,\n",
       "            -0.0793, -0.1304, -0.0692, -0.1510,  0.0617, -0.1437, -0.1018,\n",
       "            -0.0612, -0.0188, -0.0975,  0.1494, -0.0947, -0.1023,  0.1303,\n",
       "             0.0224,  0.1218,  0.0252,  0.1309, -0.1504, -0.1342,  0.1113,\n",
       "             0.0834, -0.0541,  0.0477, -0.0397,  0.1411, -0.0518,  0.0974,\n",
       "            -0.0916, -0.1286, -0.0231,  0.1071,  0.0092,  0.0612, -0.1472,\n",
       "             0.0907, -0.1344,  0.0821,  0.1395,  0.0995, -0.0051, -0.0252,\n",
       "             0.0643,  0.1346,  0.0220,  0.0715, -0.0815, -0.1516,  0.0005,\n",
       "             0.0093,  0.0085, -0.0653,  0.1356,  0.0724, -0.1345,  0.0833,\n",
       "             0.1347,  0.0715,  0.0641, -0.0456,  0.0876,  0.0889,  0.0014,\n",
       "            -0.0137,  0.0961,  0.0215,  0.1190,  0.1418, -0.0749,  0.1318,\n",
       "            -0.0071,  0.1456,  0.1392, -0.0785, -0.0114, -0.1115,  0.0606,\n",
       "             0.1242,  0.0915, -0.0905,  0.1038,  0.1044,  0.0178, -0.0603,\n",
       "             0.0993,  0.1028,  0.1242,  0.1363,  0.0438, -0.0040,  0.0080,\n",
       "             0.1423,  0.0291,  0.0641, -0.0940,  0.0167, -0.0316, -0.0272,\n",
       "            -0.0993, -0.0570, -0.1343, -0.1143, -0.0813, -0.0260, -0.1374,\n",
       "             0.0711,  0.1007, -0.0687,  0.0742,  0.0503,  0.1135,  0.0056,\n",
       "            -0.1434,  0.1071,  0.1178, -0.1475,  0.0938,  0.1072,  0.0671,\n",
       "            -0.0171,  0.0011,  0.0468, -0.0429, -0.0058, -0.0703,  0.0770,\n",
       "             0.0514,  0.1410,  0.0312, -0.0083, -0.0925, -0.1111, -0.0766,\n",
       "             0.0963,  0.0929,  0.0415,  0.1026,  0.0366,  0.1290,  0.0261,\n",
       "            -0.0176, -0.0304, -0.1356,  0.1234, -0.0075,  0.0093, -0.1385,\n",
       "             0.0296,  0.1080, -0.1507, -0.0479,  0.0570,  0.1161,  0.1264,\n",
       "             0.0821, -0.0061, -0.1088, -0.0183,  0.0536,  0.0323,  0.1034,\n",
       "            -0.1114,  0.1357,  0.1430,  0.1371,  0.1159, -0.0217, -0.0087,\n",
       "             0.1229,  0.0217, -0.0233, -0.0359, -0.0016, -0.0024, -0.0207,\n",
       "            -0.0996,  0.0380, -0.0409,  0.1525,  0.0826,  0.0052,  0.1509,\n",
       "             0.0147,  0.0510,  0.1515,  0.0201]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 7.2609e-02,  8.8127e-02,  6.6057e-02,  ..., -5.9763e-02,\n",
       "           -8.0420e-02, -1.7416e-02],\n",
       "          [ 3.0018e-02,  8.9290e-02, -4.3216e-02,  ...,  8.0672e-04,\n",
       "            1.9959e-02,  8.2605e-02],\n",
       "          [ 8.8939e-02,  9.1868e-03, -3.0551e-02,  ..., -3.3987e-02,\n",
       "            2.0429e-02,  1.0949e-02],\n",
       "          ...,\n",
       "          [ 7.9818e-02, -7.4842e-02,  7.4003e-02,  ...,  9.0637e-02,\n",
       "           -4.5442e-02,  6.1763e-02],\n",
       "          [ 6.0822e-02,  6.1744e-02, -2.1527e-02,  ..., -4.3716e-02,\n",
       "           -7.3553e-02, -8.7560e-02],\n",
       "          [ 7.8687e-02, -3.9555e-05, -8.2094e-02,  ..., -3.7930e-02,\n",
       "           -6.6299e-02, -5.2452e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0119, -0.0379, -0.0294, -0.0419, -0.0223,  0.0264, -0.0187,  0.0050,\n",
       "           0.0293,  0.0395,  0.0469,  0.0182, -0.0239, -0.0505,  0.0059,  0.0316,\n",
       "          -0.0502,  0.0477,  0.0471,  0.0251, -0.0274, -0.0198,  0.0154, -0.0085,\n",
       "          -0.0197, -0.0137,  0.0253, -0.0484, -0.0238, -0.0342, -0.0571, -0.0229,\n",
       "          -0.0268,  0.0302,  0.0511,  0.0297, -0.0559,  0.0449, -0.0432, -0.0141,\n",
       "          -0.0122,  0.0303,  0.0074, -0.0376,  0.0417,  0.0221, -0.0290,  0.0207,\n",
       "          -0.0540, -0.0426, -0.0206,  0.0534, -0.0419, -0.0110, -0.0528, -0.0546,\n",
       "           0.0124,  0.0339,  0.0574,  0.0420, -0.0308, -0.0158, -0.0415,  0.0054,\n",
       "           0.0437, -0.0360, -0.0201, -0.0367, -0.0172,  0.0321, -0.0283, -0.0572,\n",
       "           0.0087, -0.0087,  0.0080,  0.0512, -0.0494, -0.0495,  0.0030,  0.0310,\n",
       "          -0.0122,  0.0285, -0.0085,  0.0076,  0.0543, -0.0052,  0.0318, -0.0291,\n",
       "           0.0382, -0.0192,  0.0400,  0.0462, -0.0487, -0.0091,  0.0479, -0.0288,\n",
       "          -0.0213, -0.0227, -0.0558, -0.0577,  0.0142, -0.0129, -0.0334, -0.0261,\n",
       "           0.0450, -0.0352, -0.0358,  0.0564, -0.0433,  0.0357,  0.0274,  0.0125,\n",
       "          -0.0471,  0.0357, -0.0010,  0.0402, -0.0333,  0.0073,  0.0295,  0.0178,\n",
       "           0.0084, -0.0384, -0.0054, -0.0063,  0.0382,  0.0005,  0.0331,  0.0155,\n",
       "          -0.0426, -0.0087, -0.0267,  0.0062,  0.0400, -0.0496, -0.0084,  0.0533,\n",
       "           0.0099,  0.0553,  0.0565,  0.0095, -0.0054, -0.0142,  0.0419, -0.0360,\n",
       "           0.0265, -0.0284,  0.0089,  0.0277,  0.0173, -0.0555,  0.0042,  0.0013,\n",
       "           0.0436,  0.0130,  0.0527, -0.0393, -0.0254,  0.0530, -0.0328,  0.0366,\n",
       "           0.0514,  0.0462, -0.0005,  0.0286,  0.0441,  0.0050, -0.0265,  0.0366,\n",
       "          -0.0443, -0.0433,  0.0320,  0.0553,  0.0384,  0.0013,  0.0328,  0.0556,\n",
       "          -0.0025, -0.0558,  0.0238, -0.0284,  0.0370,  0.0509, -0.0046,  0.0153,\n",
       "           0.0568, -0.0173, -0.0058,  0.0117, -0.0460,  0.0408, -0.0330,  0.0290,\n",
       "          -0.0456,  0.0186,  0.0538,  0.0051, -0.0325, -0.0316, -0.0383,  0.0005,\n",
       "          -0.0086, -0.0016,  0.0061, -0.0207,  0.0391,  0.0109,  0.0103, -0.0464,\n",
       "          -0.0142,  0.0329, -0.0416,  0.0339,  0.0058, -0.0347, -0.0057, -0.0331,\n",
       "          -0.0382, -0.0564,  0.0137,  0.0141,  0.0097,  0.0041,  0.0122,  0.0446,\n",
       "          -0.0165,  0.0465, -0.0383,  0.0390, -0.0052, -0.0045,  0.0027,  0.0311,\n",
       "          -0.0088, -0.0428,  0.0428,  0.0008, -0.0444,  0.0105,  0.0070, -0.0206,\n",
       "          -0.0355, -0.0387, -0.0471, -0.0084,  0.0535, -0.0366, -0.0467, -0.0403,\n",
       "          -0.0344, -0.0554, -0.0438, -0.0296, -0.0238,  0.0189, -0.0370,  0.0322],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0863, -0.0002,  0.0102,  ..., -0.0062,  0.0791, -0.0748],\n",
       "          [-0.0448,  0.0743, -0.1018,  ..., -0.0381, -0.0866,  0.0901],\n",
       "          [ 0.0241,  0.0165, -0.0485,  ...,  0.0818, -0.0774, -0.0484],\n",
       "          ...,\n",
       "          [ 0.0009, -0.0599, -0.0781,  ...,  0.0550,  0.0752,  0.0358],\n",
       "          [ 0.0651,  0.0928, -0.0918,  ...,  0.0346,  0.0221,  0.0352],\n",
       "          [-0.0773, -0.0255, -0.0674,  ...,  0.0945, -0.0763, -0.0863]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0296,  0.0307, -0.0032,  0.0550,  0.0064, -0.0287,  0.0464,  0.0361,\n",
       "          -0.0310, -0.0340, -0.0104, -0.0115,  0.0045, -0.0357,  0.0262,  0.0249,\n",
       "           0.0038,  0.0320, -0.0540, -0.0439,  0.0496, -0.0394, -0.0110, -0.0503,\n",
       "           0.0424, -0.0054, -0.0490, -0.0454, -0.0138,  0.0515,  0.0273,  0.0088,\n",
       "           0.0262, -0.0140, -0.0360, -0.0127,  0.0374,  0.0288,  0.0148,  0.0561,\n",
       "           0.0521,  0.0167,  0.0183,  0.0148, -0.0219,  0.0213,  0.0104,  0.0513,\n",
       "           0.0552, -0.0556,  0.0269,  0.0303, -0.0540, -0.0481, -0.0242,  0.0289,\n",
       "           0.0462,  0.0222,  0.0298, -0.0292, -0.0020,  0.0260, -0.0564, -0.0113,\n",
       "          -0.0522,  0.0307,  0.0185,  0.0391, -0.0062, -0.0572,  0.0065, -0.0530,\n",
       "          -0.0072,  0.0473,  0.0155,  0.0228,  0.0352,  0.0069, -0.0230,  0.0438,\n",
       "          -0.0192, -0.0314, -0.0151,  0.0289, -0.0439, -0.0086,  0.0405,  0.0184,\n",
       "          -0.0365,  0.0450, -0.0250, -0.0437,  0.0142,  0.0555,  0.0157, -0.0153,\n",
       "          -0.0370, -0.0069,  0.0197, -0.0396,  0.0013, -0.0433,  0.0537,  0.0371,\n",
       "           0.0084, -0.0332,  0.0519,  0.0386, -0.0103,  0.0417, -0.0042, -0.0134,\n",
       "           0.0319, -0.0068,  0.0009,  0.0408, -0.0183,  0.0200, -0.0224,  0.0090,\n",
       "          -0.0121,  0.0205,  0.0281,  0.0385, -0.0529,  0.0265, -0.0235,  0.0234,\n",
       "           0.0370,  0.0327, -0.0220,  0.0432, -0.0093, -0.0070, -0.0453,  0.0344,\n",
       "          -0.0245,  0.0088,  0.0242, -0.0242,  0.0178, -0.0100,  0.0017,  0.0267,\n",
       "          -0.0044,  0.0430, -0.0146, -0.0370, -0.0024,  0.0417, -0.0468, -0.0543,\n",
       "           0.0024,  0.0085, -0.0189,  0.0112, -0.0252, -0.0263,  0.0256, -0.0453,\n",
       "           0.0078,  0.0213, -0.0196, -0.0335,  0.0233, -0.0079, -0.0536,  0.0020,\n",
       "          -0.0036, -0.0385, -0.0542, -0.0141, -0.0517, -0.0258, -0.0436,  0.0556,\n",
       "           0.0324, -0.0477, -0.0408,  0.0158,  0.0409,  0.0118,  0.0234,  0.0345,\n",
       "           0.0359, -0.0370,  0.0179,  0.0548, -0.0450,  0.0238, -0.0332,  0.0378,\n",
       "          -0.0414, -0.0028, -0.0146,  0.0378,  0.0069, -0.0577,  0.0542, -0.0207,\n",
       "          -0.0267,  0.0394, -0.0102,  0.0498, -0.0553, -0.0572,  0.0045, -0.0145,\n",
       "           0.0341, -0.0127, -0.0112,  0.0534, -0.0559,  0.0508,  0.0304, -0.0279,\n",
       "          -0.0090, -0.0361, -0.0250, -0.0567,  0.0331, -0.0100,  0.0292,  0.0183,\n",
       "           0.0528, -0.0214,  0.0469, -0.0221, -0.0282,  0.0425,  0.0008,  0.0447,\n",
       "           0.0198, -0.0329, -0.0023,  0.0462, -0.0377,  0.0459,  0.0311,  0.0573,\n",
       "          -0.0416,  0.0529,  0.0366,  0.0318,  0.0305, -0.0254,  0.0400,  0.0543,\n",
       "          -0.0140,  0.0556,  0.0431, -0.0540,  0.0554,  0.0375, -0.0073,  0.0297],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0087],\n",
       "          [-0.0264],\n",
       "          [-0.1487],\n",
       "          [ 0.1410],\n",
       "          [ 0.0651],\n",
       "          [-0.0696],\n",
       "          [-0.0810],\n",
       "          [ 0.0608],\n",
       "          [ 0.1430],\n",
       "          [ 0.1156],\n",
       "          [-0.1345],\n",
       "          [ 0.0304],\n",
       "          [ 0.0028],\n",
       "          [-0.0144],\n",
       "          [ 0.1397],\n",
       "          [ 0.0303],\n",
       "          [ 0.0818],\n",
       "          [-0.0263],\n",
       "          [-0.0789],\n",
       "          [-0.0160],\n",
       "          [ 0.1404],\n",
       "          [-0.1315],\n",
       "          [ 0.1340],\n",
       "          [ 0.1452],\n",
       "          [ 0.0370],\n",
       "          [-0.0166],\n",
       "          [-0.0140],\n",
       "          [-0.1132],\n",
       "          [-0.0701],\n",
       "          [-0.0665],\n",
       "          [ 0.1152],\n",
       "          [ 0.0091],\n",
       "          [ 0.0229],\n",
       "          [-0.1099],\n",
       "          [ 0.0725],\n",
       "          [ 0.0563],\n",
       "          [ 0.0410],\n",
       "          [ 0.0833],\n",
       "          [ 0.0619],\n",
       "          [ 0.1343],\n",
       "          [-0.0930],\n",
       "          [-0.1216],\n",
       "          [ 0.0248],\n",
       "          [-0.0824],\n",
       "          [-0.1223],\n",
       "          [-0.0467],\n",
       "          [ 0.1440],\n",
       "          [-0.1142],\n",
       "          [-0.1175],\n",
       "          [ 0.0238],\n",
       "          [-0.0028],\n",
       "          [ 0.1039],\n",
       "          [-0.0688],\n",
       "          [ 0.0549],\n",
       "          [-0.1128],\n",
       "          [-0.0756],\n",
       "          [ 0.0095],\n",
       "          [ 0.0771],\n",
       "          [-0.0049],\n",
       "          [ 0.0577],\n",
       "          [ 0.0189],\n",
       "          [ 0.1100],\n",
       "          [ 0.1503],\n",
       "          [-0.0207],\n",
       "          [ 0.1024],\n",
       "          [-0.0263],\n",
       "          [-0.0211],\n",
       "          [-0.1040],\n",
       "          [-0.0151],\n",
       "          [-0.0964],\n",
       "          [-0.1370],\n",
       "          [-0.0454],\n",
       "          [-0.1201],\n",
       "          [-0.0265],\n",
       "          [ 0.1509],\n",
       "          [-0.1060],\n",
       "          [-0.1400],\n",
       "          [ 0.1124],\n",
       "          [ 0.1145],\n",
       "          [-0.0626],\n",
       "          [ 0.1455],\n",
       "          [ 0.0758],\n",
       "          [ 0.0101],\n",
       "          [-0.0395],\n",
       "          [ 0.0197],\n",
       "          [ 0.1345],\n",
       "          [-0.1411],\n",
       "          [ 0.1080],\n",
       "          [-0.0928],\n",
       "          [ 0.0732],\n",
       "          [-0.0135],\n",
       "          [ 0.0485],\n",
       "          [-0.0879],\n",
       "          [-0.0223],\n",
       "          [-0.0441],\n",
       "          [ 0.0337],\n",
       "          [ 0.0435],\n",
       "          [ 0.0402],\n",
       "          [-0.0408],\n",
       "          [ 0.0873],\n",
       "          [ 0.0892],\n",
       "          [ 0.1266],\n",
       "          [ 0.0162],\n",
       "          [-0.1483],\n",
       "          [ 0.0111],\n",
       "          [-0.0497],\n",
       "          [-0.0014],\n",
       "          [ 0.1091],\n",
       "          [-0.0848],\n",
       "          [ 0.0420],\n",
       "          [ 0.0361],\n",
       "          [ 0.1522],\n",
       "          [-0.1381],\n",
       "          [-0.0953],\n",
       "          [-0.1198],\n",
       "          [ 0.1212],\n",
       "          [ 0.0260],\n",
       "          [ 0.0883],\n",
       "          [-0.0607],\n",
       "          [-0.1316],\n",
       "          [ 0.0644],\n",
       "          [-0.0817],\n",
       "          [ 0.0127],\n",
       "          [ 0.1222],\n",
       "          [-0.0800],\n",
       "          [ 0.0390],\n",
       "          [-0.0553],\n",
       "          [-0.0293],\n",
       "          [-0.1502],\n",
       "          [-0.1280],\n",
       "          [-0.1319],\n",
       "          [ 0.1328],\n",
       "          [ 0.0863],\n",
       "          [ 0.0142],\n",
       "          [-0.0110],\n",
       "          [ 0.0830],\n",
       "          [ 0.0307],\n",
       "          [ 0.0691],\n",
       "          [-0.0780],\n",
       "          [ 0.0244],\n",
       "          [-0.0420],\n",
       "          [ 0.0145],\n",
       "          [-0.0161],\n",
       "          [ 0.0981],\n",
       "          [-0.0582],\n",
       "          [ 0.0319],\n",
       "          [-0.0414],\n",
       "          [-0.0057],\n",
       "          [-0.0573],\n",
       "          [ 0.0165],\n",
       "          [-0.0463],\n",
       "          [ 0.1253],\n",
       "          [ 0.0492],\n",
       "          [-0.0741],\n",
       "          [-0.0107],\n",
       "          [ 0.0440],\n",
       "          [-0.0117],\n",
       "          [-0.0531],\n",
       "          [ 0.0919],\n",
       "          [-0.0758],\n",
       "          [-0.0717],\n",
       "          [-0.0216],\n",
       "          [-0.1212],\n",
       "          [-0.0606],\n",
       "          [-0.1113],\n",
       "          [-0.1284],\n",
       "          [-0.1135],\n",
       "          [-0.0010],\n",
       "          [ 0.0039],\n",
       "          [ 0.0095],\n",
       "          [-0.1298],\n",
       "          [-0.0743],\n",
       "          [ 0.0730],\n",
       "          [-0.0856],\n",
       "          [-0.0288],\n",
       "          [-0.0630],\n",
       "          [ 0.1276],\n",
       "          [ 0.0900],\n",
       "          [ 0.0999],\n",
       "          [ 0.0289],\n",
       "          [ 0.0281],\n",
       "          [ 0.0830],\n",
       "          [-0.0405],\n",
       "          [ 0.1073],\n",
       "          [-0.0016],\n",
       "          [-0.1209],\n",
       "          [ 0.0428],\n",
       "          [-0.1018],\n",
       "          [-0.1345],\n",
       "          [-0.0920],\n",
       "          [-0.0334],\n",
       "          [ 0.1524],\n",
       "          [ 0.0839],\n",
       "          [-0.0485],\n",
       "          [ 0.1476],\n",
       "          [-0.0663],\n",
       "          [-0.0720],\n",
       "          [ 0.1064],\n",
       "          [-0.0238],\n",
       "          [ 0.0228],\n",
       "          [ 0.0821],\n",
       "          [-0.0445],\n",
       "          [-0.0471],\n",
       "          [-0.0479],\n",
       "          [-0.1325],\n",
       "          [-0.0478],\n",
       "          [-0.1487],\n",
       "          [-0.1060],\n",
       "          [-0.1267],\n",
       "          [-0.0101],\n",
       "          [ 0.0719],\n",
       "          [ 0.1419],\n",
       "          [-0.0199],\n",
       "          [-0.0924],\n",
       "          [-0.0329],\n",
       "          [ 0.1090],\n",
       "          [-0.0896],\n",
       "          [-0.1512],\n",
       "          [ 0.0719],\n",
       "          [ 0.0219],\n",
       "          [-0.0860],\n",
       "          [-0.0510],\n",
       "          [-0.0553],\n",
       "          [ 0.0731],\n",
       "          [-0.0919],\n",
       "          [ 0.0656],\n",
       "          [ 0.0546],\n",
       "          [-0.0160],\n",
       "          [ 0.0297],\n",
       "          [-0.1026],\n",
       "          [ 0.1325],\n",
       "          [-0.0264],\n",
       "          [ 0.1269],\n",
       "          [ 0.0494],\n",
       "          [-0.0375],\n",
       "          [ 0.0474],\n",
       "          [-0.0964],\n",
       "          [-0.1389],\n",
       "          [-0.1417],\n",
       "          [ 0.1217],\n",
       "          [-0.0474],\n",
       "          [ 0.0894],\n",
       "          [-0.0941],\n",
       "          [-0.1163],\n",
       "          [-0.0018],\n",
       "          [ 0.0168],\n",
       "          [-0.0359],\n",
       "          [ 0.0160],\n",
       "          [ 0.0586],\n",
       "          [ 0.1430],\n",
       "          [-0.0571],\n",
       "          [-0.0201],\n",
       "          [ 0.0182],\n",
       "          [-0.0900],\n",
       "          [-0.1405],\n",
       "          [-0.1120]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0094, -0.0933,  0.0220,  0.0625,  0.0963, -0.0105,  0.0399,\n",
       "             0.0737, -0.0914, -0.0854,  0.0525,  0.0370,  0.1030, -0.0319,\n",
       "            -0.0451,  0.0421,  0.1428,  0.0198, -0.0933, -0.0029,  0.0403,\n",
       "            -0.0874, -0.0410,  0.0553, -0.1136,  0.0010, -0.1346, -0.0314,\n",
       "             0.1474, -0.1100, -0.0320,  0.0400, -0.0731,  0.1522,  0.0986,\n",
       "             0.0668, -0.1359,  0.0343,  0.1198, -0.0079,  0.0646,  0.0526,\n",
       "            -0.1154,  0.0554,  0.1251,  0.1156, -0.0561,  0.0773, -0.0272,\n",
       "             0.1214,  0.0363,  0.0932,  0.0865,  0.1338,  0.0933,  0.0925,\n",
       "             0.0611, -0.0868, -0.1250, -0.0270,  0.0219, -0.1337,  0.0080,\n",
       "            -0.0563,  0.0158,  0.1079, -0.0762,  0.0930,  0.1494,  0.0416,\n",
       "            -0.0233,  0.0406, -0.1184, -0.0123, -0.0754, -0.0540, -0.0873,\n",
       "            -0.0792,  0.0930,  0.0763, -0.0439, -0.0745, -0.1441,  0.1366,\n",
       "            -0.1027,  0.0555, -0.0669,  0.0005,  0.0550, -0.0132,  0.1441,\n",
       "             0.1410,  0.1090,  0.0214,  0.0147, -0.0700, -0.0534,  0.0732,\n",
       "             0.1284,  0.1419,  0.0341, -0.0638,  0.0131, -0.1393, -0.0597,\n",
       "            -0.0531, -0.0728, -0.0326, -0.1012,  0.1385,  0.0780, -0.1015,\n",
       "             0.1311, -0.0023,  0.1349, -0.1108,  0.1200, -0.0556,  0.1289,\n",
       "            -0.1285,  0.1478, -0.0015, -0.0869, -0.1503,  0.0334, -0.1167,\n",
       "            -0.0898,  0.0534,  0.0215,  0.0402, -0.1316,  0.0538, -0.0668,\n",
       "             0.1094,  0.0210,  0.0199, -0.0113,  0.0914, -0.0968, -0.0128,\n",
       "             0.0680,  0.0973,  0.0609, -0.1091, -0.0989, -0.1048, -0.1481,\n",
       "            -0.1032, -0.0607, -0.1062,  0.0503,  0.0592, -0.1027, -0.0662,\n",
       "             0.1444,  0.0654, -0.0509,  0.1152,  0.0078, -0.0881, -0.1381,\n",
       "            -0.1070, -0.1092,  0.0014,  0.0274,  0.0654, -0.0004,  0.0840,\n",
       "            -0.1229,  0.1514, -0.0090,  0.0533, -0.0852, -0.0792,  0.1173,\n",
       "            -0.0900,  0.1114, -0.0969,  0.1416, -0.0403, -0.0602,  0.0722,\n",
       "             0.0581,  0.0186,  0.0309, -0.0412,  0.0991, -0.1141,  0.0701,\n",
       "            -0.1317,  0.1002,  0.0446,  0.0127, -0.0226, -0.1013,  0.1486,\n",
       "             0.0595, -0.0519,  0.0588, -0.0568,  0.0486,  0.1151,  0.0206,\n",
       "             0.1331, -0.0825,  0.1189, -0.1469, -0.0254, -0.0157,  0.1450,\n",
       "             0.0090, -0.0341, -0.0239,  0.1328, -0.1127,  0.1101,  0.1432,\n",
       "            -0.0070, -0.0587, -0.0946, -0.0875, -0.1431,  0.0356,  0.0700,\n",
       "             0.0161,  0.0865, -0.0695, -0.0251,  0.1405,  0.1203, -0.0916,\n",
       "            -0.0499, -0.1313,  0.0061,  0.0687, -0.1475,  0.0590,  0.0637,\n",
       "             0.0421, -0.1409,  0.1197,  0.1391,  0.0328, -0.1361, -0.1439,\n",
       "            -0.0715, -0.0101, -0.0402,  0.1423, -0.0663, -0.0198, -0.0644,\n",
       "            -0.0879, -0.0424, -0.0079, -0.0067]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0554, -0.0808, -0.0007,  ...,  0.0428, -0.0069,  0.0638],\n",
       "          [ 0.0229, -0.0761, -0.0753,  ...,  0.1022, -0.0080,  0.0908],\n",
       "          [-0.0673, -0.0505, -0.0744,  ...,  0.0625, -0.0619,  0.0661],\n",
       "          ...,\n",
       "          [-0.0942, -0.0604, -0.0645,  ...,  0.1038,  0.0412,  0.0605],\n",
       "          [-0.0741,  0.0212, -0.0154,  ...,  0.0775,  0.0570,  0.0423],\n",
       "          [ 0.0347,  0.0068,  0.0050,  ...,  0.0737,  0.0448,  0.0008]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0415, -0.0528, -0.0050, -0.0472, -0.0125,  0.0569,  0.0543, -0.0453,\n",
       "           0.0034,  0.0270, -0.0042,  0.0292,  0.0490, -0.0305,  0.0483,  0.0336,\n",
       "           0.0264,  0.0190,  0.0421,  0.0574, -0.0343,  0.0003,  0.0197,  0.0366,\n",
       "           0.0181, -0.0116,  0.0285,  0.0441, -0.0229,  0.0212, -0.0078, -0.0019,\n",
       "           0.0360,  0.0130, -0.0398,  0.0561, -0.0558,  0.0565, -0.0078,  0.0355,\n",
       "           0.0107, -0.0478, -0.0068, -0.0304, -0.0107,  0.0460, -0.0461,  0.0019,\n",
       "           0.0354,  0.0192, -0.0557, -0.0315,  0.0512,  0.0158, -0.0501, -0.0114,\n",
       "          -0.0032, -0.0468,  0.0522, -0.0215,  0.0293, -0.0198, -0.0294, -0.0533,\n",
       "          -0.0201,  0.0532,  0.0062, -0.0083, -0.0250,  0.0369, -0.0489, -0.0493,\n",
       "          -0.0151,  0.0574,  0.0170, -0.0271, -0.0048, -0.0299,  0.0336,  0.0489,\n",
       "           0.0557,  0.0196,  0.0326, -0.0574,  0.0285,  0.0253,  0.0289, -0.0163,\n",
       "           0.0070,  0.0253,  0.0133, -0.0454,  0.0535, -0.0189, -0.0107,  0.0474,\n",
       "           0.0284,  0.0451, -0.0115, -0.0477,  0.0566,  0.0081, -0.0194,  0.0524,\n",
       "          -0.0489, -0.0100,  0.0244, -0.0465, -0.0190, -0.0038, -0.0555, -0.0540,\n",
       "           0.0400,  0.0429, -0.0225,  0.0576, -0.0366, -0.0045,  0.0573, -0.0258,\n",
       "           0.0407,  0.0328,  0.0095,  0.0055,  0.0239, -0.0048, -0.0461,  0.0026,\n",
       "           0.0226, -0.0106, -0.0020,  0.0226, -0.0106, -0.0110,  0.0235,  0.0344,\n",
       "           0.0417,  0.0076, -0.0094, -0.0231, -0.0226, -0.0401, -0.0094, -0.0214,\n",
       "           0.0393,  0.0004,  0.0436,  0.0038, -0.0221, -0.0227, -0.0148, -0.0234,\n",
       "          -0.0483,  0.0528, -0.0463,  0.0251,  0.0569, -0.0456,  0.0567,  0.0201,\n",
       "          -0.0413,  0.0404,  0.0412,  0.0156, -0.0477, -0.0364, -0.0496,  0.0446,\n",
       "           0.0077, -0.0176, -0.0365,  0.0087,  0.0361, -0.0357,  0.0388,  0.0545,\n",
       "           0.0552, -0.0508, -0.0494, -0.0102,  0.0484, -0.0194,  0.0014,  0.0089,\n",
       "          -0.0536, -0.0348, -0.0137, -0.0006, -0.0159, -0.0237, -0.0307,  0.0037,\n",
       "          -0.0128, -0.0566,  0.0247, -0.0077, -0.0486,  0.0505, -0.0534, -0.0444,\n",
       "           0.0078, -0.0379, -0.0542,  0.0380,  0.0189,  0.0421, -0.0239, -0.0219,\n",
       "          -0.0011, -0.0379,  0.0331,  0.0387,  0.0196,  0.0224, -0.0002, -0.0188,\n",
       "          -0.0549,  0.0353,  0.0107, -0.0460, -0.0085, -0.0313, -0.0176,  0.0219,\n",
       "           0.0494,  0.0173,  0.0227,  0.0554,  0.0394,  0.0096,  0.0016,  0.0206,\n",
       "          -0.0160, -0.0405,  0.0117, -0.0476,  0.0148, -0.0495,  0.0314, -0.0258,\n",
       "          -0.0515,  0.0512,  0.0213, -0.0378, -0.0209, -0.0459,  0.0402,  0.0434,\n",
       "          -0.0056, -0.0115,  0.0326,  0.0399,  0.0254,  0.0315,  0.0012, -0.0160],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0834,  0.0479, -0.0112,  ..., -0.0845,  0.0874, -0.1002],\n",
       "          [-0.0787, -0.0965,  0.0616,  ..., -0.0149,  0.0615, -0.0295],\n",
       "          [ 0.0382, -0.0023, -0.0119,  ..., -0.0876, -0.0301,  0.0200],\n",
       "          ...,\n",
       "          [-0.0508,  0.0817,  0.0815,  ...,  0.0416,  0.0603, -0.0236],\n",
       "          [-0.0934, -0.1004,  0.0639,  ..., -0.0339, -0.0760,  0.0389],\n",
       "          [ 0.0495, -0.0943,  0.0282,  ...,  0.0704, -0.0511, -0.0420]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 4.1378e-02,  2.5201e-02,  1.2878e-02, -4.4531e-02,  3.0013e-02,\n",
       "          -4.5224e-02, -1.4930e-02,  2.3107e-02, -3.1164e-02, -2.9660e-02,\n",
       "           7.6895e-03,  1.7058e-02, -1.4159e-03, -4.3656e-03, -1.9887e-03,\n",
       "           3.2383e-03, -2.9301e-02, -2.7889e-02, -2.1867e-02,  5.4629e-02,\n",
       "           1.6071e-02, -3.9627e-02, -1.9905e-03,  2.9360e-02,  3.1221e-02,\n",
       "           3.5625e-02,  3.7266e-02,  4.1969e-02, -3.8969e-02, -3.7615e-02,\n",
       "           4.6556e-02, -2.0067e-02, -5.7644e-02, -8.6228e-03,  5.3914e-02,\n",
       "          -8.6669e-03, -4.0013e-02, -2.2413e-02,  4.2822e-02,  1.5984e-02,\n",
       "          -9.7369e-03,  2.6359e-03, -4.9189e-02,  2.2720e-02,  4.8557e-02,\n",
       "          -3.4610e-02,  3.9455e-02,  1.9627e-02,  4.9330e-02,  4.6903e-02,\n",
       "          -3.6513e-02, -3.6590e-02,  8.9661e-03, -3.6353e-02,  3.4851e-03,\n",
       "          -1.4778e-03, -1.4909e-02,  5.3499e-02, -6.9842e-03,  2.7301e-02,\n",
       "          -3.4904e-02, -5.4373e-02, -1.8371e-02,  5.0271e-02, -3.5304e-02,\n",
       "          -2.3888e-02, -1.8753e-02,  3.4871e-02, -5.1841e-02, -5.0160e-02,\n",
       "          -1.3445e-02, -4.5107e-02,  5.3793e-02, -1.6712e-02,  6.1106e-03,\n",
       "           2.7458e-02,  5.0805e-02, -1.6767e-02,  2.3330e-02, -1.6354e-02,\n",
       "          -4.4802e-02, -3.4931e-02,  2.2598e-02,  1.4250e-04, -3.9104e-02,\n",
       "           5.7587e-02, -2.3143e-02, -4.0281e-02, -3.9527e-02,  3.6013e-02,\n",
       "           2.0795e-02, -4.5245e-03,  2.9127e-02, -4.2081e-02,  3.5136e-02,\n",
       "           5.7312e-02,  2.2508e-02,  1.1306e-03, -5.3802e-02, -1.8147e-02,\n",
       "           4.3682e-02,  1.5155e-02, -4.7409e-02, -1.1423e-02, -3.5537e-02,\n",
       "           5.3629e-02,  2.1944e-02,  3.3467e-02, -1.3247e-02,  3.4309e-02,\n",
       "           5.7595e-02, -2.1324e-02,  2.9611e-02,  2.5384e-03,  2.9748e-02,\n",
       "           3.2853e-02, -8.3486e-03, -2.1205e-02, -4.1127e-02,  2.3827e-02,\n",
       "           4.9452e-02,  5.6098e-02,  7.8071e-03, -3.5629e-02, -9.9762e-03,\n",
       "           3.1631e-02,  5.2155e-02, -5.5099e-02,  3.8081e-02,  3.9688e-02,\n",
       "          -5.4675e-02,  2.4607e-02, -1.4433e-03, -5.2771e-02,  1.3378e-02,\n",
       "           1.2146e-02, -1.8599e-02,  3.6126e-02,  9.2405e-03,  4.4094e-02,\n",
       "          -2.0020e-02, -4.4839e-02,  3.4477e-02,  2.8019e-02, -1.8376e-02,\n",
       "           2.9585e-02, -1.7370e-02,  3.9694e-02,  1.5005e-04,  3.3973e-02,\n",
       "          -9.6228e-03,  2.1306e-02, -1.3931e-03,  5.7126e-02,  6.7797e-03,\n",
       "          -3.3703e-02, -1.0326e-02,  1.6002e-02, -3.2243e-02, -1.7773e-02,\n",
       "           1.1563e-02, -2.0756e-02,  1.5753e-02, -3.2836e-02,  4.7273e-02,\n",
       "           5.5444e-02, -2.1392e-02, -6.7884e-03, -4.5362e-02,  5.3590e-02,\n",
       "          -8.4048e-03, -1.2169e-02,  4.8026e-02,  3.0250e-02, -1.2736e-02,\n",
       "           1.4438e-02, -3.5965e-02, -4.0972e-02,  2.7417e-02,  1.7214e-02,\n",
       "          -7.0065e-03, -5.2408e-02,  5.2205e-02, -2.2141e-02, -2.8370e-02,\n",
       "          -4.2484e-02, -5.4301e-02,  4.0987e-02, -1.3077e-02,  1.9813e-03,\n",
       "          -9.1747e-03, -5.7195e-02, -2.3717e-02,  1.1772e-02, -4.7985e-02,\n",
       "          -5.6108e-02,  3.5992e-02, -4.1772e-02, -5.6143e-02,  5.5053e-02,\n",
       "          -3.1615e-02,  1.8610e-02, -4.3962e-02,  4.9778e-02, -5.7282e-02,\n",
       "          -1.7609e-02,  2.5029e-02, -5.5533e-03,  5.3252e-02, -2.9290e-02,\n",
       "          -3.3748e-02,  3.9186e-02, -4.5596e-02,  4.2549e-02,  1.1532e-02,\n",
       "          -1.2672e-02,  1.1526e-02, -2.4333e-02, -5.5637e-02, -1.3091e-02,\n",
       "           5.5908e-02,  3.5688e-02,  4.0731e-02,  3.5788e-02, -1.3998e-02,\n",
       "           1.6504e-02, -6.2427e-03, -3.6403e-02, -2.5464e-02, -5.8794e-03,\n",
       "          -7.6786e-03, -3.5057e-02,  4.3409e-02,  4.1221e-02,  5.2659e-02,\n",
       "           2.6556e-02,  9.3164e-03, -8.4588e-03,  5.3697e-03,  2.0943e-02,\n",
       "           4.1006e-02, -1.6973e-02,  4.8336e-02,  3.3439e-02, -5.1387e-05,\n",
       "           2.8183e-02, -1.0088e-02,  3.8567e-02,  3.4150e-03, -2.0393e-02,\n",
       "           2.0587e-02, -4.2251e-02,  2.4585e-02, -3.9823e-02, -3.3882e-02,\n",
       "          -4.2254e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0086],\n",
       "          [ 0.0107],\n",
       "          [ 0.0683],\n",
       "          [ 0.0525],\n",
       "          [-0.1271],\n",
       "          [ 0.1498],\n",
       "          [-0.0288],\n",
       "          [-0.0708],\n",
       "          [ 0.0028],\n",
       "          [ 0.0224],\n",
       "          [ 0.1136],\n",
       "          [-0.0416],\n",
       "          [ 0.0716],\n",
       "          [ 0.1235],\n",
       "          [ 0.0793],\n",
       "          [ 0.0056],\n",
       "          [ 0.0226],\n",
       "          [ 0.0893],\n",
       "          [ 0.0357],\n",
       "          [-0.1047],\n",
       "          [ 0.1443],\n",
       "          [-0.0136],\n",
       "          [ 0.0496],\n",
       "          [-0.0290],\n",
       "          [-0.1461],\n",
       "          [-0.0931],\n",
       "          [-0.0144],\n",
       "          [ 0.0700],\n",
       "          [-0.0874],\n",
       "          [-0.1502],\n",
       "          [ 0.1070],\n",
       "          [-0.1189],\n",
       "          [ 0.1339],\n",
       "          [ 0.0801],\n",
       "          [-0.0231],\n",
       "          [-0.0181],\n",
       "          [-0.1257],\n",
       "          [-0.1023],\n",
       "          [ 0.0542],\n",
       "          [-0.0394],\n",
       "          [ 0.1340],\n",
       "          [-0.1396],\n",
       "          [-0.1282],\n",
       "          [-0.0569],\n",
       "          [-0.0475],\n",
       "          [ 0.0775],\n",
       "          [-0.0842],\n",
       "          [-0.0646],\n",
       "          [ 0.0564],\n",
       "          [-0.1206],\n",
       "          [ 0.1438],\n",
       "          [-0.0456],\n",
       "          [-0.0280],\n",
       "          [ 0.0210],\n",
       "          [-0.1460],\n",
       "          [ 0.0905],\n",
       "          [-0.0332],\n",
       "          [ 0.0078],\n",
       "          [-0.0063],\n",
       "          [-0.1002],\n",
       "          [ 0.0396],\n",
       "          [ 0.0351],\n",
       "          [-0.0849],\n",
       "          [-0.0956],\n",
       "          [-0.1492],\n",
       "          [ 0.0367],\n",
       "          [ 0.1209],\n",
       "          [-0.0493],\n",
       "          [ 0.0490],\n",
       "          [ 0.1014],\n",
       "          [ 0.1453],\n",
       "          [ 0.0285],\n",
       "          [ 0.1090],\n",
       "          [-0.0097],\n",
       "          [ 0.0130],\n",
       "          [ 0.1024],\n",
       "          [-0.0071],\n",
       "          [-0.0805],\n",
       "          [ 0.0860],\n",
       "          [-0.0163],\n",
       "          [-0.0348],\n",
       "          [ 0.0765],\n",
       "          [ 0.1130],\n",
       "          [ 0.0496],\n",
       "          [-0.0399],\n",
       "          [ 0.1379],\n",
       "          [ 0.0861],\n",
       "          [ 0.0901],\n",
       "          [ 0.0231],\n",
       "          [ 0.1382],\n",
       "          [-0.0602],\n",
       "          [ 0.0027],\n",
       "          [ 0.0634],\n",
       "          [-0.0519],\n",
       "          [ 0.0597],\n",
       "          [ 0.0250],\n",
       "          [ 0.0520],\n",
       "          [ 0.1323],\n",
       "          [-0.1020],\n",
       "          [-0.1441],\n",
       "          [-0.1440],\n",
       "          [-0.1131],\n",
       "          [ 0.0538],\n",
       "          [ 0.0116],\n",
       "          [ 0.1067],\n",
       "          [-0.0199],\n",
       "          [ 0.0689],\n",
       "          [ 0.1379],\n",
       "          [-0.0334],\n",
       "          [-0.0506],\n",
       "          [ 0.1212],\n",
       "          [-0.0217],\n",
       "          [-0.0543],\n",
       "          [-0.0102],\n",
       "          [ 0.1017],\n",
       "          [ 0.0112],\n",
       "          [ 0.0600],\n",
       "          [ 0.1230],\n",
       "          [ 0.0820],\n",
       "          [ 0.0189],\n",
       "          [ 0.0315],\n",
       "          [ 0.0385],\n",
       "          [ 0.1512],\n",
       "          [-0.0608],\n",
       "          [ 0.1509],\n",
       "          [ 0.1193],\n",
       "          [-0.0651],\n",
       "          [ 0.1031],\n",
       "          [-0.0588],\n",
       "          [ 0.1236],\n",
       "          [-0.0260],\n",
       "          [ 0.0688],\n",
       "          [-0.0281],\n",
       "          [-0.0713],\n",
       "          [-0.1483],\n",
       "          [ 0.0959],\n",
       "          [-0.1355],\n",
       "          [-0.0446],\n",
       "          [-0.0645],\n",
       "          [ 0.0358],\n",
       "          [ 0.1525],\n",
       "          [-0.0442],\n",
       "          [-0.0976],\n",
       "          [-0.1465],\n",
       "          [-0.0303],\n",
       "          [ 0.0963],\n",
       "          [-0.0222],\n",
       "          [-0.0671],\n",
       "          [ 0.0023],\n",
       "          [-0.0797],\n",
       "          [ 0.0765],\n",
       "          [ 0.0592],\n",
       "          [-0.0016],\n",
       "          [ 0.0665],\n",
       "          [ 0.1297],\n",
       "          [-0.0405],\n",
       "          [-0.0654],\n",
       "          [-0.0080],\n",
       "          [ 0.0198],\n",
       "          [-0.0689],\n",
       "          [-0.0868],\n",
       "          [-0.0083],\n",
       "          [ 0.0017],\n",
       "          [ 0.0230],\n",
       "          [-0.1320],\n",
       "          [-0.1415],\n",
       "          [-0.0365],\n",
       "          [ 0.0020],\n",
       "          [-0.0558],\n",
       "          [-0.1270],\n",
       "          [-0.1330],\n",
       "          [ 0.0142],\n",
       "          [ 0.0987],\n",
       "          [ 0.0128],\n",
       "          [ 0.1375],\n",
       "          [-0.1093],\n",
       "          [ 0.0670],\n",
       "          [ 0.0401],\n",
       "          [ 0.0009],\n",
       "          [ 0.0570],\n",
       "          [-0.1334],\n",
       "          [-0.1427],\n",
       "          [ 0.0865],\n",
       "          [ 0.1176],\n",
       "          [-0.1097],\n",
       "          [ 0.1258],\n",
       "          [-0.0880],\n",
       "          [ 0.0368],\n",
       "          [ 0.0021],\n",
       "          [ 0.0577],\n",
       "          [-0.0251],\n",
       "          [-0.0633],\n",
       "          [ 0.0524],\n",
       "          [-0.0327],\n",
       "          [ 0.0406],\n",
       "          [-0.0685],\n",
       "          [ 0.0482],\n",
       "          [ 0.0889],\n",
       "          [-0.0494],\n",
       "          [ 0.1438],\n",
       "          [ 0.1306],\n",
       "          [ 0.1128],\n",
       "          [ 0.0865],\n",
       "          [ 0.0908],\n",
       "          [-0.1385],\n",
       "          [ 0.0114],\n",
       "          [-0.0584],\n",
       "          [-0.1191],\n",
       "          [-0.1092],\n",
       "          [-0.1349],\n",
       "          [ 0.0504],\n",
       "          [ 0.1500],\n",
       "          [ 0.0937],\n",
       "          [-0.1097],\n",
       "          [ 0.0834],\n",
       "          [-0.1343],\n",
       "          [-0.0019],\n",
       "          [ 0.0887],\n",
       "          [-0.1214],\n",
       "          [ 0.0555],\n",
       "          [-0.1009],\n",
       "          [ 0.0882],\n",
       "          [-0.0316],\n",
       "          [ 0.1014],\n",
       "          [-0.0825],\n",
       "          [ 0.0997],\n",
       "          [-0.0898],\n",
       "          [-0.0465],\n",
       "          [ 0.0502],\n",
       "          [ 0.0105],\n",
       "          [-0.0166],\n",
       "          [-0.0291],\n",
       "          [ 0.0722],\n",
       "          [-0.0499],\n",
       "          [ 0.0924],\n",
       "          [-0.0631],\n",
       "          [ 0.0338],\n",
       "          [-0.0902],\n",
       "          [ 0.0448],\n",
       "          [-0.0670],\n",
       "          [ 0.1258],\n",
       "          [ 0.0051],\n",
       "          [ 0.1170],\n",
       "          [ 0.0304],\n",
       "          [-0.0825],\n",
       "          [-0.0845],\n",
       "          [-0.0707],\n",
       "          [-0.0200],\n",
       "          [-0.0549],\n",
       "          [ 0.0450],\n",
       "          [-0.0916],\n",
       "          [-0.0434],\n",
       "          [-0.0847],\n",
       "          [ 0.0211],\n",
       "          [ 0.1449],\n",
       "          [ 0.1446]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0240, -0.0002,  0.1474, -0.1374,  0.0824, -0.1188, -0.0636,\n",
       "             0.0706,  0.0196, -0.0491, -0.0845, -0.0858, -0.0015, -0.0779,\n",
       "             0.0179, -0.0991,  0.0622,  0.1315,  0.0615,  0.0822, -0.1096,\n",
       "             0.0911,  0.0640,  0.1100, -0.0240,  0.0782, -0.1241,  0.0620,\n",
       "            -0.0270, -0.1057, -0.0746,  0.1069, -0.0714,  0.0564,  0.1329,\n",
       "             0.0964,  0.0250,  0.0162, -0.0169, -0.0708, -0.0218, -0.1002,\n",
       "             0.0740,  0.1299,  0.1131,  0.0296, -0.0605, -0.1456, -0.0324,\n",
       "            -0.0888,  0.0607,  0.0748,  0.0475,  0.1368,  0.0533, -0.1467,\n",
       "            -0.0135,  0.1113, -0.1309, -0.0391, -0.1127, -0.0533, -0.0851,\n",
       "             0.1073, -0.0102, -0.0058,  0.0738, -0.0226,  0.1305,  0.0659,\n",
       "             0.0440, -0.0989,  0.0592,  0.0016,  0.1134, -0.1309,  0.0120,\n",
       "             0.0488, -0.1181, -0.1225,  0.1337,  0.1250, -0.1385, -0.1361,\n",
       "            -0.0263, -0.0075,  0.0012, -0.1260, -0.1039,  0.0572, -0.0005,\n",
       "             0.1044,  0.0571,  0.0468, -0.1438, -0.1102, -0.1472, -0.0040,\n",
       "             0.1085,  0.0603,  0.0394, -0.0687,  0.0050,  0.0408,  0.0548,\n",
       "            -0.0795,  0.0651, -0.0349,  0.0439,  0.0790, -0.1073, -0.1479,\n",
       "             0.0801,  0.0201,  0.1154, -0.1504, -0.0840, -0.1293, -0.0585,\n",
       "            -0.0238,  0.1316,  0.0841, -0.0298, -0.0251,  0.0331,  0.0442,\n",
       "             0.1029, -0.1233, -0.0421,  0.0411,  0.0810,  0.0325, -0.1012,\n",
       "             0.1007, -0.0326,  0.0069,  0.1368,  0.0284,  0.0977, -0.0535,\n",
       "             0.0480, -0.0721, -0.1506, -0.0063,  0.0886, -0.1404, -0.0571,\n",
       "            -0.0598,  0.0485,  0.1103, -0.0816, -0.0894,  0.0168,  0.0054,\n",
       "            -0.0616, -0.0750, -0.0085, -0.0148, -0.0159,  0.1378, -0.1286,\n",
       "             0.0953,  0.1200, -0.0714,  0.1515, -0.1419,  0.0531,  0.1010,\n",
       "             0.0042,  0.0150,  0.0085,  0.0836, -0.0055, -0.1376, -0.0294,\n",
       "            -0.0170, -0.0118, -0.1188,  0.0489,  0.0052,  0.0219,  0.1104,\n",
       "             0.0414, -0.1498, -0.0933, -0.0742, -0.0153,  0.0624,  0.0282,\n",
       "            -0.0220,  0.0224, -0.0223, -0.0690, -0.0787,  0.1239,  0.0933,\n",
       "            -0.1504, -0.0647,  0.0175, -0.0992,  0.0847, -0.0097, -0.1127,\n",
       "            -0.1133, -0.1021,  0.0226,  0.1140, -0.1060,  0.1112, -0.0028,\n",
       "            -0.0571,  0.1223,  0.0439, -0.0417,  0.0184,  0.0998, -0.0002,\n",
       "            -0.0625,  0.0257,  0.0714,  0.0069, -0.0827, -0.1229,  0.0653,\n",
       "             0.0718,  0.0980, -0.1458,  0.1147, -0.0952, -0.1071, -0.0449,\n",
       "            -0.0702, -0.1105, -0.0508, -0.0175, -0.0629, -0.1074,  0.1017,\n",
       "            -0.1180, -0.0863, -0.0716, -0.0708,  0.1127,  0.1367, -0.0885,\n",
       "            -0.1111,  0.1506, -0.0451,  0.1500,  0.0139,  0.0368, -0.1042,\n",
       "            -0.1373, -0.1163,  0.1111,  0.0549]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0821, -0.0237, -0.0849,  ..., -0.0819,  0.0484, -0.0100],\n",
       "          [-0.0150,  0.0879,  0.0395,  ..., -0.0326, -0.0206, -0.0070],\n",
       "          [ 0.0756,  0.0755,  0.0121,  ..., -0.0251,  0.0243,  0.0193],\n",
       "          ...,\n",
       "          [-0.0814,  0.0315, -0.0130,  ...,  0.0738,  0.0220, -0.0242],\n",
       "          [-0.0305,  0.0809, -0.0655,  ..., -0.0868, -0.0811, -0.0732],\n",
       "          [ 0.0079,  0.0269, -0.0831,  ..., -0.0368, -0.0769, -0.0759]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0558,  0.0071, -0.0027,  0.0010, -0.0018,  0.0241,  0.0499, -0.0532,\n",
       "           0.0529,  0.0380, -0.0482,  0.0544,  0.0161,  0.0369, -0.0082, -0.0345,\n",
       "           0.0560, -0.0198, -0.0049, -0.0120,  0.0222,  0.0056,  0.0527, -0.0014,\n",
       "           0.0465,  0.0568,  0.0571, -0.0519, -0.0017, -0.0194,  0.0474,  0.0237,\n",
       "           0.0503, -0.0256, -0.0263, -0.0072,  0.0325,  0.0396, -0.0324, -0.0380,\n",
       "           0.0248, -0.0477,  0.0554, -0.0509, -0.0121,  0.0440,  0.0227,  0.0201,\n",
       "          -0.0295, -0.0412, -0.0318,  0.0515, -0.0564,  0.0250, -0.0120, -0.0517,\n",
       "           0.0549, -0.0145,  0.0472,  0.0560, -0.0282, -0.0070,  0.0462, -0.0247,\n",
       "           0.0292, -0.0242,  0.0385,  0.0296, -0.0016,  0.0459,  0.0399,  0.0237,\n",
       "           0.0403,  0.0490, -0.0187,  0.0328,  0.0517, -0.0324,  0.0318,  0.0275,\n",
       "          -0.0327, -0.0307,  0.0107,  0.0128, -0.0501,  0.0554,  0.0140, -0.0134,\n",
       "           0.0347,  0.0346,  0.0040, -0.0515, -0.0031, -0.0454, -0.0152,  0.0322,\n",
       "           0.0221,  0.0339,  0.0520,  0.0465, -0.0348,  0.0274, -0.0418, -0.0132,\n",
       "           0.0257,  0.0322, -0.0228,  0.0262, -0.0202, -0.0516,  0.0312, -0.0135,\n",
       "           0.0464,  0.0555, -0.0373,  0.0563,  0.0483,  0.0147, -0.0392,  0.0275,\n",
       "           0.0172,  0.0019, -0.0378, -0.0341,  0.0058,  0.0271,  0.0519,  0.0266,\n",
       "          -0.0279,  0.0545, -0.0076,  0.0476,  0.0324, -0.0287, -0.0176,  0.0486,\n",
       "           0.0264,  0.0450,  0.0141,  0.0511, -0.0338, -0.0445, -0.0329,  0.0066,\n",
       "          -0.0202,  0.0262,  0.0118,  0.0561,  0.0156,  0.0379,  0.0198,  0.0039,\n",
       "           0.0277, -0.0550, -0.0108, -0.0206, -0.0463,  0.0416,  0.0043,  0.0308,\n",
       "          -0.0139,  0.0143, -0.0195, -0.0167,  0.0479,  0.0446,  0.0206, -0.0479,\n",
       "          -0.0251, -0.0010,  0.0464,  0.0053, -0.0037,  0.0575,  0.0546, -0.0573,\n",
       "           0.0123,  0.0523,  0.0036,  0.0093,  0.0167, -0.0473,  0.0365,  0.0151,\n",
       "           0.0539,  0.0545,  0.0051,  0.0380, -0.0529, -0.0015,  0.0351,  0.0224,\n",
       "           0.0312, -0.0072, -0.0068, -0.0279,  0.0234, -0.0397, -0.0054, -0.0558,\n",
       "          -0.0503,  0.0467,  0.0353, -0.0507,  0.0336, -0.0335, -0.0256, -0.0137,\n",
       "           0.0534, -0.0447, -0.0050,  0.0182, -0.0314, -0.0109, -0.0358,  0.0241,\n",
       "          -0.0170, -0.0482,  0.0570, -0.0279,  0.0026,  0.0361,  0.0235,  0.0122,\n",
       "           0.0318, -0.0221, -0.0093,  0.0281,  0.0128,  0.0517, -0.0142,  0.0524,\n",
       "           0.0274, -0.0435, -0.0514, -0.0290,  0.0014,  0.0293,  0.0262,  0.0138,\n",
       "          -0.0328,  0.0085, -0.0249,  0.0229,  0.0021, -0.0177,  0.0359, -0.0306,\n",
       "          -0.0301,  0.0490,  0.0021, -0.0468, -0.0140, -0.0348, -0.0256, -0.0486],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0961,  0.0809, -0.1024,  ..., -0.0523, -0.0276, -0.0740],\n",
       "          [-0.0676,  0.0691,  0.0359,  ..., -0.0804,  0.0241,  0.0121],\n",
       "          [ 0.0672,  0.0981,  0.0555,  ...,  0.0683,  0.0979, -0.0599],\n",
       "          ...,\n",
       "          [ 0.0516, -0.0306,  0.0045,  ..., -0.0775, -0.0459,  0.0339],\n",
       "          [-0.0611,  0.0253,  0.0578,  ...,  0.0933, -0.0450, -0.0068],\n",
       "          [ 0.0954,  0.0455, -0.0484,  ...,  0.0930,  0.0209,  0.0173]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0152, -0.0382, -0.0515, -0.0137,  0.0281, -0.0139, -0.0141, -0.0303,\n",
       "           0.0002, -0.0245, -0.0219, -0.0085, -0.0269,  0.0416, -0.0189,  0.0365,\n",
       "          -0.0252, -0.0369, -0.0238, -0.0062, -0.0275,  0.0390,  0.0350, -0.0047,\n",
       "           0.0513,  0.0165, -0.0520, -0.0263,  0.0569,  0.0275,  0.0040, -0.0336,\n",
       "          -0.0576,  0.0226,  0.0401,  0.0170, -0.0233, -0.0532, -0.0223,  0.0168,\n",
       "           0.0209, -0.0126, -0.0462,  0.0401, -0.0277,  0.0369, -0.0421, -0.0477,\n",
       "           0.0156,  0.0210,  0.0123,  0.0352,  0.0482, -0.0571,  0.0185,  0.0315,\n",
       "           0.0393,  0.0127,  0.0474,  0.0477,  0.0172, -0.0460, -0.0546, -0.0290,\n",
       "           0.0366, -0.0053, -0.0353,  0.0429, -0.0302,  0.0049,  0.0538,  0.0570,\n",
       "           0.0154,  0.0561, -0.0164,  0.0253,  0.0335,  0.0395,  0.0113,  0.0288,\n",
       "           0.0245, -0.0566, -0.0329,  0.0299, -0.0357,  0.0533,  0.0190, -0.0309,\n",
       "          -0.0287, -0.0429, -0.0185, -0.0142,  0.0456, -0.0271, -0.0065, -0.0486,\n",
       "          -0.0230, -0.0272,  0.0104,  0.0522,  0.0541, -0.0164,  0.0280, -0.0120,\n",
       "          -0.0528, -0.0093, -0.0045,  0.0415,  0.0533,  0.0236,  0.0510, -0.0434,\n",
       "           0.0183, -0.0168,  0.0299, -0.0256,  0.0479,  0.0263, -0.0350, -0.0059,\n",
       "           0.0250, -0.0098,  0.0563,  0.0458,  0.0134, -0.0261, -0.0292,  0.0418,\n",
       "          -0.0469,  0.0555, -0.0119,  0.0209, -0.0057,  0.0089, -0.0498, -0.0410,\n",
       "           0.0215, -0.0046,  0.0366,  0.0559,  0.0384,  0.0397,  0.0573, -0.0014,\n",
       "           0.0422, -0.0156, -0.0326, -0.0274,  0.0357,  0.0506, -0.0511,  0.0330,\n",
       "          -0.0537, -0.0174, -0.0346,  0.0213,  0.0103,  0.0177, -0.0507, -0.0156,\n",
       "           0.0485, -0.0179,  0.0350,  0.0208,  0.0267,  0.0171, -0.0393,  0.0102,\n",
       "          -0.0181, -0.0021,  0.0297,  0.0416, -0.0536, -0.0461, -0.0231, -0.0205,\n",
       "           0.0371, -0.0478,  0.0030, -0.0349, -0.0435,  0.0163, -0.0019, -0.0016,\n",
       "          -0.0208, -0.0533, -0.0363, -0.0454, -0.0046, -0.0346, -0.0435, -0.0546,\n",
       "           0.0453,  0.0124, -0.0482, -0.0251, -0.0116, -0.0296,  0.0571, -0.0191,\n",
       "           0.0029, -0.0232, -0.0072, -0.0123,  0.0014, -0.0421,  0.0249, -0.0442,\n",
       "           0.0182, -0.0412, -0.0551,  0.0513,  0.0512,  0.0143,  0.0319, -0.0539,\n",
       "           0.0048,  0.0450, -0.0095, -0.0569, -0.0379,  0.0185,  0.0309, -0.0304,\n",
       "          -0.0572, -0.0299,  0.0048, -0.0413,  0.0420,  0.0026, -0.0377,  0.0291,\n",
       "          -0.0256, -0.0359,  0.0048,  0.0117, -0.0279,  0.0248, -0.0033,  0.0115,\n",
       "           0.0542,  0.0165, -0.0253, -0.0317, -0.0147,  0.0139,  0.0275, -0.0334,\n",
       "           0.0259,  0.0515, -0.0312, -0.0476,  0.0059,  0.0135, -0.0290,  0.0329],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0616],\n",
       "          [ 0.1376],\n",
       "          [-0.0884],\n",
       "          [ 0.0339],\n",
       "          [-0.1421],\n",
       "          [ 0.0444],\n",
       "          [ 0.0156],\n",
       "          [-0.0864],\n",
       "          [ 0.1105],\n",
       "          [ 0.0698],\n",
       "          [ 0.0713],\n",
       "          [ 0.0698],\n",
       "          [-0.0561],\n",
       "          [-0.0153],\n",
       "          [-0.0688],\n",
       "          [ 0.0740],\n",
       "          [ 0.1229],\n",
       "          [ 0.0375],\n",
       "          [-0.1423],\n",
       "          [-0.0581],\n",
       "          [-0.1483],\n",
       "          [ 0.1238],\n",
       "          [ 0.1112],\n",
       "          [-0.1029],\n",
       "          [-0.1000],\n",
       "          [-0.0319],\n",
       "          [ 0.0330],\n",
       "          [-0.1174],\n",
       "          [ 0.0178],\n",
       "          [-0.0743],\n",
       "          [-0.0471],\n",
       "          [-0.0531],\n",
       "          [ 0.0797],\n",
       "          [ 0.0452],\n",
       "          [-0.1185],\n",
       "          [ 0.0675],\n",
       "          [ 0.1087],\n",
       "          [-0.1240],\n",
       "          [ 0.1329],\n",
       "          [-0.1203],\n",
       "          [ 0.0137],\n",
       "          [ 0.1061],\n",
       "          [ 0.0169],\n",
       "          [ 0.0971],\n",
       "          [ 0.0491],\n",
       "          [ 0.1427],\n",
       "          [-0.0906],\n",
       "          [-0.0969],\n",
       "          [-0.0929],\n",
       "          [-0.0096],\n",
       "          [-0.0532],\n",
       "          [ 0.1343],\n",
       "          [-0.0113],\n",
       "          [-0.1140],\n",
       "          [-0.0565],\n",
       "          [ 0.0401],\n",
       "          [-0.0887],\n",
       "          [-0.1365],\n",
       "          [-0.0652],\n",
       "          [ 0.0614],\n",
       "          [-0.1162],\n",
       "          [ 0.0890],\n",
       "          [-0.1048],\n",
       "          [ 0.0363],\n",
       "          [-0.0811],\n",
       "          [-0.1187],\n",
       "          [-0.0199],\n",
       "          [-0.1022],\n",
       "          [ 0.0928],\n",
       "          [ 0.1063],\n",
       "          [-0.0552],\n",
       "          [ 0.0245],\n",
       "          [ 0.0128],\n",
       "          [-0.0389],\n",
       "          [ 0.0695],\n",
       "          [ 0.0703],\n",
       "          [-0.0712],\n",
       "          [-0.1517],\n",
       "          [ 0.1353],\n",
       "          [-0.0408],\n",
       "          [ 0.1343],\n",
       "          [ 0.0341],\n",
       "          [ 0.0478],\n",
       "          [-0.1266],\n",
       "          [-0.0129],\n",
       "          [-0.0278],\n",
       "          [-0.1042],\n",
       "          [ 0.1403],\n",
       "          [ 0.0457],\n",
       "          [ 0.0211],\n",
       "          [-0.1267],\n",
       "          [-0.0430],\n",
       "          [ 0.1058],\n",
       "          [-0.0906],\n",
       "          [ 0.1129],\n",
       "          [ 0.1231],\n",
       "          [ 0.0009],\n",
       "          [-0.1093],\n",
       "          [-0.0359],\n",
       "          [-0.1356],\n",
       "          [ 0.0859],\n",
       "          [-0.0141],\n",
       "          [ 0.0416],\n",
       "          [-0.1089],\n",
       "          [ 0.0574],\n",
       "          [-0.1313],\n",
       "          [-0.1241],\n",
       "          [ 0.0832],\n",
       "          [ 0.0111],\n",
       "          [ 0.0610],\n",
       "          [ 0.1010],\n",
       "          [ 0.1513],\n",
       "          [ 0.0143],\n",
       "          [ 0.0937],\n",
       "          [ 0.1173],\n",
       "          [ 0.1203],\n",
       "          [-0.1430],\n",
       "          [ 0.1414],\n",
       "          [-0.1183],\n",
       "          [-0.0906],\n",
       "          [-0.1499],\n",
       "          [-0.0276],\n",
       "          [ 0.1122],\n",
       "          [ 0.0048],\n",
       "          [-0.0038],\n",
       "          [-0.0884],\n",
       "          [-0.0450],\n",
       "          [ 0.0593],\n",
       "          [-0.1317],\n",
       "          [ 0.1239],\n",
       "          [-0.0897],\n",
       "          [ 0.0115],\n",
       "          [ 0.1109],\n",
       "          [-0.0302],\n",
       "          [-0.1338],\n",
       "          [ 0.1493],\n",
       "          [-0.0629],\n",
       "          [-0.0538],\n",
       "          [ 0.0745],\n",
       "          [ 0.0313],\n",
       "          [ 0.1238],\n",
       "          [-0.0392],\n",
       "          [ 0.1427],\n",
       "          [-0.1477],\n",
       "          [-0.0550],\n",
       "          [ 0.0184],\n",
       "          [ 0.0654],\n",
       "          [-0.0365],\n",
       "          [-0.1168],\n",
       "          [-0.1040],\n",
       "          [ 0.0851],\n",
       "          [-0.0442],\n",
       "          [-0.0094],\n",
       "          [ 0.0233],\n",
       "          [-0.1248],\n",
       "          [-0.0934],\n",
       "          [-0.0842],\n",
       "          [-0.0002],\n",
       "          [ 0.1467],\n",
       "          [ 0.0531],\n",
       "          [-0.0224],\n",
       "          [-0.0508],\n",
       "          [ 0.1295],\n",
       "          [-0.0650],\n",
       "          [-0.0372],\n",
       "          [-0.1378],\n",
       "          [ 0.0342],\n",
       "          [ 0.1514],\n",
       "          [ 0.1510],\n",
       "          [-0.0693],\n",
       "          [ 0.1298],\n",
       "          [-0.1175],\n",
       "          [-0.0089],\n",
       "          [-0.1300],\n",
       "          [-0.0631],\n",
       "          [ 0.0519],\n",
       "          [ 0.1238],\n",
       "          [ 0.1467],\n",
       "          [-0.0444],\n",
       "          [ 0.0674],\n",
       "          [-0.0853],\n",
       "          [ 0.1139],\n",
       "          [ 0.0193],\n",
       "          [-0.0786],\n",
       "          [ 0.0793],\n",
       "          [-0.1344],\n",
       "          [ 0.0232],\n",
       "          [ 0.1501],\n",
       "          [-0.1236],\n",
       "          [-0.0284],\n",
       "          [-0.1066],\n",
       "          [-0.1472],\n",
       "          [-0.1407],\n",
       "          [-0.1374],\n",
       "          [ 0.0598],\n",
       "          [ 0.1210],\n",
       "          [-0.1237],\n",
       "          [ 0.1183],\n",
       "          [-0.0454],\n",
       "          [-0.1122],\n",
       "          [-0.1510],\n",
       "          [ 0.0426],\n",
       "          [ 0.1367],\n",
       "          [ 0.1486],\n",
       "          [-0.0850],\n",
       "          [-0.0501],\n",
       "          [-0.0312],\n",
       "          [ 0.0614],\n",
       "          [ 0.1173],\n",
       "          [ 0.0058],\n",
       "          [-0.0042],\n",
       "          [-0.0546],\n",
       "          [ 0.1447],\n",
       "          [-0.0503],\n",
       "          [ 0.0321],\n",
       "          [-0.0646],\n",
       "          [ 0.1051],\n",
       "          [ 0.1362],\n",
       "          [ 0.0742],\n",
       "          [ 0.0074],\n",
       "          [-0.0064],\n",
       "          [-0.1053],\n",
       "          [-0.0491],\n",
       "          [-0.0655],\n",
       "          [ 0.0760],\n",
       "          [ 0.0199],\n",
       "          [-0.0170],\n",
       "          [ 0.0810],\n",
       "          [-0.0680],\n",
       "          [ 0.1105],\n",
       "          [-0.1465],\n",
       "          [ 0.0608],\n",
       "          [-0.0029],\n",
       "          [-0.1419],\n",
       "          [-0.0955],\n",
       "          [-0.1396],\n",
       "          [-0.0699],\n",
       "          [-0.0728],\n",
       "          [-0.0552],\n",
       "          [-0.1046],\n",
       "          [-0.0010],\n",
       "          [-0.1247],\n",
       "          [ 0.0404],\n",
       "          [ 0.1229],\n",
       "          [ 0.0480],\n",
       "          [-0.0706],\n",
       "          [ 0.0172],\n",
       "          [ 0.0846],\n",
       "          [ 0.0483],\n",
       "          [ 0.0829],\n",
       "          [ 0.0362],\n",
       "          [ 0.1472],\n",
       "          [-0.0408],\n",
       "          [ 0.0346],\n",
       "          [ 0.1472],\n",
       "          [-0.0984]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1229, -0.0910, -0.1437,  0.1024,  0.0456, -0.0210, -0.0814,\n",
       "            -0.1192,  0.0184,  0.0286, -0.0520, -0.0303,  0.1030, -0.0975,\n",
       "             0.0185, -0.0319,  0.0410,  0.1351, -0.0874,  0.0315,  0.0459,\n",
       "            -0.1108,  0.0152, -0.0954,  0.0751, -0.1186,  0.0059, -0.1228,\n",
       "            -0.0021, -0.0029, -0.0689,  0.1232, -0.0070, -0.1289, -0.0872,\n",
       "            -0.0104,  0.0566,  0.0358,  0.0896, -0.0162, -0.0331,  0.1385,\n",
       "            -0.0906, -0.0194, -0.0333, -0.0201,  0.0255, -0.0500, -0.1285,\n",
       "            -0.0776, -0.1387,  0.0091,  0.1265,  0.1312, -0.1278, -0.1110,\n",
       "             0.0314,  0.1094,  0.0397, -0.0154, -0.0762, -0.1095,  0.0855,\n",
       "             0.0262,  0.0557,  0.0480, -0.0514,  0.0514,  0.0794,  0.0582,\n",
       "             0.0016,  0.0418, -0.1143, -0.0107, -0.1282, -0.0411,  0.0508,\n",
       "            -0.1520,  0.0609, -0.0658,  0.1044,  0.1168, -0.0407,  0.1450,\n",
       "            -0.0157, -0.0659, -0.1354, -0.1134, -0.1096,  0.0623,  0.0635,\n",
       "            -0.1067,  0.0173,  0.0232,  0.1502, -0.1123,  0.0647,  0.0037,\n",
       "             0.1125,  0.0345, -0.0547,  0.0324,  0.1193,  0.0596,  0.0150,\n",
       "             0.0805, -0.1311,  0.0058, -0.1159,  0.1142,  0.0809,  0.0955,\n",
       "            -0.0475,  0.0687, -0.1335,  0.0592,  0.1142,  0.0638,  0.0647,\n",
       "            -0.1479,  0.0938, -0.0988, -0.1309,  0.0982, -0.0945, -0.1432,\n",
       "             0.1506, -0.0059,  0.1026,  0.0397,  0.0872,  0.0231, -0.1453,\n",
       "             0.0437,  0.0476,  0.0783,  0.1319, -0.0767, -0.1374,  0.1444,\n",
       "             0.1237,  0.1087, -0.1229, -0.0299,  0.1370,  0.0358, -0.0444,\n",
       "             0.0955, -0.1069,  0.0981,  0.1515, -0.0441, -0.0865, -0.0185,\n",
       "            -0.1272,  0.0226, -0.0642,  0.1502, -0.0076,  0.0789, -0.1338,\n",
       "             0.0768, -0.1307,  0.0153,  0.0150,  0.0841,  0.0548,  0.1215,\n",
       "            -0.1149,  0.1492,  0.0922, -0.0978,  0.1034,  0.1448, -0.0712,\n",
       "            -0.0012, -0.0331,  0.1210,  0.1339, -0.0321, -0.0302, -0.0334,\n",
       "             0.0661, -0.1261,  0.0851,  0.0639, -0.1022,  0.1401, -0.0853,\n",
       "             0.0150, -0.1148,  0.1394, -0.0425, -0.0734,  0.0540, -0.0344,\n",
       "            -0.1079,  0.0216,  0.0078, -0.0126, -0.1319, -0.1268, -0.0982,\n",
       "            -0.0974, -0.0465, -0.0727,  0.0082, -0.1287,  0.1405, -0.1507,\n",
       "            -0.1524,  0.1475, -0.1114, -0.1232,  0.0957, -0.1292, -0.0598,\n",
       "            -0.1497, -0.1082, -0.1325, -0.0185,  0.0341,  0.0704,  0.1408,\n",
       "             0.0687, -0.1143,  0.0152,  0.0934, -0.0487, -0.1271,  0.1444,\n",
       "             0.0571,  0.1310,  0.0525,  0.0073,  0.0612, -0.0633,  0.1129,\n",
       "            -0.1103, -0.0937,  0.1484, -0.0726,  0.0487,  0.1179,  0.0677,\n",
       "            -0.0808, -0.0825, -0.0044, -0.0984,  0.1446, -0.0674, -0.0335,\n",
       "             0.1368,  0.1161, -0.1507, -0.0082]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0651,  0.0220,  0.0907,  ..., -0.0694, -0.0344, -0.0008],\n",
       "          [ 0.0040, -0.0109, -0.0460,  ..., -0.0988, -0.0628, -0.0186],\n",
       "          [ 0.0016, -0.0406, -0.0085,  ...,  0.0019, -0.0393,  0.0753],\n",
       "          ...,\n",
       "          [ 0.0701,  0.0924, -0.0499,  ...,  0.0167,  0.0021, -0.0647],\n",
       "          [-0.0729, -0.0057, -0.0361,  ..., -0.0983,  0.0055, -0.0789],\n",
       "          [ 0.0646,  0.0361, -0.0094,  ...,  0.0456,  0.0978, -0.0681]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-7.0414e-03, -4.8342e-02,  2.2232e-02,  1.8864e-02, -4.3727e-02,\n",
       "           8.3582e-03, -4.8287e-02,  5.2587e-03,  5.7577e-02,  5.5121e-02,\n",
       "           2.8108e-02, -5.1428e-02,  2.8539e-02,  2.0552e-02,  4.9439e-02,\n",
       "          -1.9302e-02, -1.1966e-02,  9.1055e-03, -3.3348e-02,  1.6045e-02,\n",
       "           1.8736e-02,  5.5757e-02,  2.6803e-02, -2.6299e-02,  3.4841e-02,\n",
       "          -2.0776e-03,  4.0130e-02, -3.0178e-03,  4.8751e-02,  2.2675e-02,\n",
       "           5.5538e-02, -2.7625e-02, -3.7696e-02,  2.6395e-02,  3.8181e-02,\n",
       "          -3.1580e-02,  4.9523e-02,  4.9845e-02,  3.6199e-03, -2.7925e-02,\n",
       "           5.5887e-02,  3.8148e-02,  4.9069e-02, -5.0782e-02,  1.1574e-02,\n",
       "          -2.3914e-02, -2.2748e-03, -4.1608e-02,  1.4764e-02, -4.0498e-02,\n",
       "           5.6438e-02,  5.3192e-02, -3.8171e-02, -4.6229e-02, -4.1099e-02,\n",
       "           5.4072e-02,  3.2838e-02,  1.0849e-02,  5.0716e-02,  2.1276e-02,\n",
       "          -3.4748e-02,  4.6866e-02, -2.3465e-02, -9.3583e-05, -1.6658e-02,\n",
       "           3.6354e-02,  2.9546e-02, -1.0754e-02, -2.3103e-02,  2.7272e-02,\n",
       "           1.2843e-02,  5.1773e-02, -4.3551e-02,  2.1025e-02, -2.1285e-02,\n",
       "          -2.3972e-02,  4.1788e-02,  5.1066e-02, -1.7963e-02,  4.1167e-02,\n",
       "           7.7318e-03, -5.5411e-02, -5.2669e-02,  4.0581e-02, -2.6203e-02,\n",
       "          -9.2787e-03, -1.6470e-02, -1.7837e-02, -6.0578e-03,  5.9250e-03,\n",
       "           2.9181e-03,  3.0805e-02,  4.1206e-02,  3.8013e-03,  3.9474e-03,\n",
       "          -3.6088e-02, -1.2301e-03, -5.4225e-03, -6.9876e-03, -6.7137e-03,\n",
       "           5.8709e-03,  6.6797e-03,  1.4788e-02, -1.6135e-02, -5.6732e-02,\n",
       "          -4.2283e-02, -4.6703e-02,  2.8921e-02, -2.0973e-02, -1.4406e-02,\n",
       "           5.1206e-02, -3.9062e-03, -3.9700e-02, -5.0109e-02,  5.4901e-02,\n",
       "          -5.0530e-02, -1.8038e-02,  2.3962e-03,  5.7145e-02,  4.1682e-02,\n",
       "           1.8642e-02,  1.5070e-02, -8.7619e-03, -1.0657e-02,  2.2343e-02,\n",
       "           1.5910e-03, -5.4276e-02, -8.5812e-03,  1.5411e-02, -4.8919e-03,\n",
       "           4.0133e-02,  4.7164e-02,  1.5798e-03,  1.1240e-02,  5.2488e-02,\n",
       "          -3.8094e-02, -5.7493e-02, -5.5442e-02,  6.2225e-03, -2.5566e-02,\n",
       "          -3.2696e-02,  5.4105e-02,  1.4668e-02,  2.1765e-02, -5.0207e-02,\n",
       "           5.3792e-02, -3.3191e-02, -7.1522e-03,  3.4504e-02,  5.3957e-02,\n",
       "          -5.6855e-02,  1.8519e-02, -2.9034e-02,  3.5861e-02,  2.7812e-02,\n",
       "           3.9950e-02,  7.2886e-03,  8.8817e-03,  9.5037e-03,  5.0859e-03,\n",
       "           3.8117e-02,  2.7171e-02, -5.2201e-02,  2.1691e-02,  4.4149e-02,\n",
       "           5.4999e-04, -1.5374e-02,  3.0893e-02,  1.5334e-02,  5.0663e-02,\n",
       "          -1.2579e-02,  4.7712e-02, -1.3465e-02,  2.0747e-02, -2.2078e-02,\n",
       "           9.8446e-04,  5.2139e-02, -3.7832e-02, -1.8676e-02,  5.5542e-02,\n",
       "          -3.4748e-02, -2.6746e-02, -3.2822e-02, -4.5343e-02, -5.6903e-02,\n",
       "          -3.3292e-02,  3.2473e-02,  1.2975e-02,  1.7314e-02, -3.2220e-02,\n",
       "           2.0512e-02, -1.1081e-02, -2.2445e-02, -3.8486e-02, -2.0724e-02,\n",
       "           2.7915e-02, -4.1813e-02,  2.9796e-02,  2.1258e-02, -7.4924e-03,\n",
       "          -1.2197e-02, -7.3498e-03, -3.6004e-02, -3.9193e-02, -5.2698e-02,\n",
       "           1.5200e-02,  4.7958e-02, -2.0630e-02,  2.0689e-03, -2.5783e-02,\n",
       "           5.7802e-03, -4.8120e-02, -3.7711e-02,  3.0198e-02, -9.2308e-03,\n",
       "          -3.6362e-02, -3.7087e-02,  1.5304e-02, -1.2012e-02, -4.8676e-02,\n",
       "          -2.1268e-02, -2.2312e-02, -1.6511e-03,  2.6798e-02,  4.1022e-02,\n",
       "          -3.4767e-02, -3.5318e-02,  5.4814e-02, -5.1489e-02,  3.9528e-02,\n",
       "           5.4684e-02,  2.8528e-02, -4.8847e-02, -1.9454e-02, -5.2976e-02,\n",
       "           5.1214e-02, -2.5866e-02, -7.5532e-04, -5.2154e-02,  4.0336e-02,\n",
       "          -2.4283e-02, -4.6774e-02,  8.6750e-03,  4.9278e-02, -2.8993e-03,\n",
       "           3.6551e-02, -2.6842e-02, -7.1915e-03, -3.4734e-02, -5.0944e-02,\n",
       "           4.7351e-02, -3.6387e-02, -2.3985e-02, -3.8185e-03,  3.5232e-02,\n",
       "           3.8975e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0710,  0.0674,  0.0895,  ...,  0.0633, -0.0577,  0.0795],\n",
       "          [ 0.0979, -0.0706, -0.0159,  ...,  0.0852, -0.0966,  0.0206],\n",
       "          [-0.0217, -0.1021,  0.0324,  ...,  0.0541, -0.0752,  0.0650],\n",
       "          ...,\n",
       "          [ 0.0634, -0.0338, -0.0279,  ...,  0.0814, -0.0793,  0.0019],\n",
       "          [-0.0753,  0.0139, -0.0215,  ..., -0.0058,  0.0518, -0.0607],\n",
       "          [-0.0170,  0.0093, -0.0295,  ...,  0.0391,  0.1009,  0.0969]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.6059e-02,  2.9327e-02,  1.7357e-02,  2.5863e-02,  9.6932e-03,\n",
       "          -4.5330e-02,  1.0508e-02, -1.2771e-02,  2.3091e-02,  2.8808e-03,\n",
       "           3.6703e-02, -2.8976e-02, -4.8839e-02, -2.8501e-02,  7.1955e-03,\n",
       "           1.9802e-02,  4.4079e-02,  5.1872e-03,  3.8326e-02,  2.3192e-02,\n",
       "           3.5423e-04,  5.3195e-02,  3.2063e-02, -3.8847e-02,  2.2200e-02,\n",
       "          -4.9780e-02,  4.3717e-03, -4.5108e-02, -2.4500e-02, -1.4744e-02,\n",
       "           1.2509e-02, -4.3610e-04,  8.5440e-03,  4.9445e-02, -1.6789e-02,\n",
       "           2.4224e-02, -4.2640e-02, -4.3570e-02,  2.7098e-02, -5.3008e-02,\n",
       "           3.1268e-02,  4.3746e-02, -9.9694e-03,  3.7768e-02,  5.1803e-02,\n",
       "          -4.1947e-02,  8.3822e-04, -9.5522e-03, -8.2856e-03, -2.1812e-02,\n",
       "          -2.7039e-02,  3.6287e-02,  3.0760e-03,  1.6052e-02, -3.7072e-02,\n",
       "           2.6070e-02, -4.5938e-02, -5.6001e-02, -1.0691e-02,  3.4625e-03,\n",
       "          -2.6801e-02,  1.7201e-02,  1.0569e-02, -3.1315e-02,  5.0588e-02,\n",
       "           2.8747e-02, -4.7902e-02,  3.6022e-02, -4.2620e-02, -5.6787e-02,\n",
       "          -4.3451e-02, -5.2855e-02,  5.5589e-02,  5.6309e-02,  7.5825e-03,\n",
       "           1.8660e-02, -1.2031e-02,  1.4795e-02,  5.4254e-02, -5.0286e-04,\n",
       "           1.8962e-02, -1.6656e-02,  1.7133e-02, -2.7236e-02, -1.2386e-02,\n",
       "          -3.6642e-02, -3.1332e-02,  5.0071e-02, -5.6983e-02, -5.4031e-02,\n",
       "          -6.8403e-03, -4.8163e-03, -2.0527e-03, -4.1993e-02,  3.9805e-02,\n",
       "          -1.1983e-02,  1.4153e-02,  1.5647e-03,  3.7793e-02,  5.6970e-02,\n",
       "           2.4801e-02, -7.9599e-03,  3.3726e-02,  2.3590e-02,  1.9545e-02,\n",
       "          -3.6781e-02, -2.5270e-02,  5.7673e-02, -1.2274e-02,  1.8507e-02,\n",
       "           4.6352e-02,  4.1933e-02, -4.8406e-02, -1.4292e-02, -9.1694e-03,\n",
       "           4.2518e-02,  5.8751e-03, -3.4229e-03,  4.5268e-02, -5.6217e-02,\n",
       "           5.4114e-02,  5.5516e-03, -1.4248e-02,  8.0023e-05,  3.3958e-02,\n",
       "           5.4647e-02, -1.5234e-02,  3.4949e-02, -7.9006e-03, -2.0031e-02,\n",
       "           2.0074e-02,  1.6926e-02,  4.7393e-02, -5.1449e-02,  1.3414e-02,\n",
       "           1.2456e-02,  1.3340e-02,  3.9630e-02, -2.7021e-02, -2.7145e-02,\n",
       "           5.6836e-02, -1.6873e-02,  3.2562e-02,  2.5141e-03, -3.7476e-02,\n",
       "          -5.0626e-02,  2.3788e-02, -5.5175e-02,  4.9265e-02,  1.4480e-02,\n",
       "          -2.1005e-02,  3.8400e-02,  2.9152e-02,  5.2070e-03,  5.4686e-02,\n",
       "           4.8682e-02,  9.7197e-03, -3.1330e-02, -1.3566e-02, -4.0975e-02,\n",
       "           9.1511e-03,  2.3896e-02,  3.8010e-02,  3.0977e-02, -4.0541e-02,\n",
       "          -5.9242e-03,  3.9037e-03,  8.7938e-03, -7.4292e-03,  2.0162e-02,\n",
       "          -3.8084e-02, -8.5595e-03,  5.1458e-02,  1.7757e-02, -3.8393e-02,\n",
       "          -8.0149e-03, -5.1280e-02, -5.7098e-02,  4.6344e-02, -5.0277e-02,\n",
       "           4.4495e-02,  5.1146e-03,  7.0020e-03,  1.0556e-02, -3.5335e-02,\n",
       "          -4.3506e-02, -1.7442e-03,  1.5651e-02,  3.7645e-03, -4.9164e-02,\n",
       "          -4.0554e-02,  3.8852e-03,  3.4029e-02,  2.8357e-02, -2.4714e-02,\n",
       "           2.0260e-03,  2.7773e-02,  2.1797e-02, -4.3818e-02, -5.1862e-03,\n",
       "           5.1627e-02,  2.2808e-02, -2.2232e-02,  3.9535e-02, -3.7024e-02,\n",
       "          -5.5565e-02,  3.8327e-02,  2.2156e-03, -1.4478e-02, -5.3293e-02,\n",
       "           3.9136e-02, -2.2497e-02,  5.2170e-02,  4.6717e-02,  4.0977e-02,\n",
       "           3.3615e-02,  3.0945e-02,  2.1156e-02, -3.6641e-02,  2.9128e-02,\n",
       "           4.5693e-02, -1.3128e-02, -1.7245e-02, -3.2844e-02, -1.7776e-03,\n",
       "          -1.1436e-02,  2.9438e-02,  5.3240e-02, -1.9584e-02,  9.5045e-03,\n",
       "           3.9011e-02,  5.2179e-02, -3.5352e-02,  5.0486e-02,  3.6252e-02,\n",
       "           1.8861e-02,  2.2525e-03,  3.9008e-02, -2.9341e-02, -3.7692e-02,\n",
       "          -2.9471e-02, -5.1297e-02,  2.5659e-02, -1.1134e-03,  2.9992e-02,\n",
       "           3.8838e-02,  2.6410e-03,  3.2339e-03,  4.5923e-02, -3.7246e-02,\n",
       "          -2.3121e-02, -4.5486e-02,  4.7511e-02, -1.7227e-02, -4.5948e-02,\n",
       "           5.6819e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1200],\n",
       "          [-0.0884],\n",
       "          [-0.0838],\n",
       "          [ 0.0021],\n",
       "          [-0.1232],\n",
       "          [-0.0976],\n",
       "          [ 0.0752],\n",
       "          [-0.0357],\n",
       "          [ 0.0194],\n",
       "          [ 0.0725],\n",
       "          [ 0.1024],\n",
       "          [-0.0162],\n",
       "          [-0.0284],\n",
       "          [ 0.0019],\n",
       "          [ 0.1376],\n",
       "          [-0.0956],\n",
       "          [ 0.1198],\n",
       "          [ 0.0479],\n",
       "          [ 0.0165],\n",
       "          [-0.0557],\n",
       "          [ 0.1386],\n",
       "          [-0.1484],\n",
       "          [-0.0506],\n",
       "          [-0.0543],\n",
       "          [ 0.0152],\n",
       "          [-0.0719],\n",
       "          [-0.0433],\n",
       "          [ 0.0720],\n",
       "          [-0.1112],\n",
       "          [-0.0674],\n",
       "          [ 0.1095],\n",
       "          [-0.1528],\n",
       "          [ 0.1401],\n",
       "          [-0.1441],\n",
       "          [ 0.0916],\n",
       "          [ 0.0739],\n",
       "          [-0.1098],\n",
       "          [-0.0546],\n",
       "          [-0.0314],\n",
       "          [-0.0156],\n",
       "          [-0.0543],\n",
       "          [-0.1148],\n",
       "          [ 0.1281],\n",
       "          [-0.0997],\n",
       "          [ 0.0026],\n",
       "          [ 0.0604],\n",
       "          [ 0.1325],\n",
       "          [ 0.1105],\n",
       "          [-0.0160],\n",
       "          [ 0.0855],\n",
       "          [ 0.0345],\n",
       "          [-0.0341],\n",
       "          [ 0.0967],\n",
       "          [-0.1121],\n",
       "          [ 0.0404],\n",
       "          [ 0.0234],\n",
       "          [-0.0160],\n",
       "          [-0.0801],\n",
       "          [-0.1454],\n",
       "          [ 0.1084],\n",
       "          [ 0.1270],\n",
       "          [-0.0223],\n",
       "          [-0.0610],\n",
       "          [ 0.0489],\n",
       "          [-0.0539],\n",
       "          [-0.1031],\n",
       "          [ 0.0338],\n",
       "          [-0.0413],\n",
       "          [-0.0535],\n",
       "          [-0.0483],\n",
       "          [-0.1452],\n",
       "          [ 0.0465],\n",
       "          [ 0.0462],\n",
       "          [ 0.0227],\n",
       "          [ 0.0524],\n",
       "          [-0.1397],\n",
       "          [-0.0779],\n",
       "          [-0.0018],\n",
       "          [ 0.1001],\n",
       "          [ 0.1025],\n",
       "          [ 0.0817],\n",
       "          [-0.1048],\n",
       "          [-0.0834],\n",
       "          [-0.0875],\n",
       "          [-0.0808],\n",
       "          [ 0.0462],\n",
       "          [-0.1509],\n",
       "          [-0.1334],\n",
       "          [-0.0329],\n",
       "          [-0.0188],\n",
       "          [ 0.0168],\n",
       "          [ 0.1322],\n",
       "          [-0.1182],\n",
       "          [-0.0047],\n",
       "          [-0.1154],\n",
       "          [-0.0486],\n",
       "          [-0.0512],\n",
       "          [-0.0709],\n",
       "          [-0.0208],\n",
       "          [ 0.1062],\n",
       "          [-0.0264],\n",
       "          [ 0.0751],\n",
       "          [ 0.1502],\n",
       "          [ 0.1464],\n",
       "          [ 0.1129],\n",
       "          [ 0.1518],\n",
       "          [ 0.0080],\n",
       "          [ 0.1190],\n",
       "          [ 0.1070],\n",
       "          [-0.1222],\n",
       "          [-0.1366],\n",
       "          [-0.0766],\n",
       "          [-0.1329],\n",
       "          [ 0.0375],\n",
       "          [ 0.0698],\n",
       "          [-0.0894],\n",
       "          [-0.1360],\n",
       "          [-0.1497],\n",
       "          [-0.0068],\n",
       "          [-0.0689],\n",
       "          [ 0.0081],\n",
       "          [-0.0145],\n",
       "          [-0.1227],\n",
       "          [ 0.0648],\n",
       "          [-0.0557],\n",
       "          [ 0.0750],\n",
       "          [-0.1341],\n",
       "          [-0.0845],\n",
       "          [-0.0833],\n",
       "          [ 0.1161],\n",
       "          [-0.0879],\n",
       "          [ 0.1454],\n",
       "          [-0.0415],\n",
       "          [ 0.0535],\n",
       "          [-0.0849],\n",
       "          [ 0.0167],\n",
       "          [ 0.1221],\n",
       "          [ 0.0250],\n",
       "          [ 0.0301],\n",
       "          [ 0.1253],\n",
       "          [-0.1380],\n",
       "          [-0.0220],\n",
       "          [ 0.1054],\n",
       "          [-0.0024],\n",
       "          [ 0.1316],\n",
       "          [ 0.1014],\n",
       "          [ 0.0598],\n",
       "          [-0.1178],\n",
       "          [-0.1251],\n",
       "          [ 0.0613],\n",
       "          [-0.0094],\n",
       "          [-0.0503],\n",
       "          [ 0.1282],\n",
       "          [-0.0301],\n",
       "          [-0.1200],\n",
       "          [-0.0188],\n",
       "          [ 0.0551],\n",
       "          [-0.1160],\n",
       "          [-0.0829],\n",
       "          [-0.0539],\n",
       "          [ 0.1428],\n",
       "          [-0.0466],\n",
       "          [-0.1098],\n",
       "          [ 0.1218],\n",
       "          [ 0.0960],\n",
       "          [-0.0898],\n",
       "          [-0.0074],\n",
       "          [ 0.1019],\n",
       "          [-0.0022],\n",
       "          [ 0.0781],\n",
       "          [-0.0383],\n",
       "          [-0.0078],\n",
       "          [ 0.1018],\n",
       "          [-0.1181],\n",
       "          [ 0.0744],\n",
       "          [-0.1450],\n",
       "          [-0.0722],\n",
       "          [-0.1381],\n",
       "          [ 0.0678],\n",
       "          [-0.1342],\n",
       "          [-0.1466],\n",
       "          [ 0.0049],\n",
       "          [-0.0305],\n",
       "          [-0.0908],\n",
       "          [-0.1262],\n",
       "          [ 0.1263],\n",
       "          [ 0.0091],\n",
       "          [-0.1332],\n",
       "          [ 0.0338],\n",
       "          [ 0.1482],\n",
       "          [ 0.0249],\n",
       "          [-0.0051],\n",
       "          [ 0.0123],\n",
       "          [-0.0045],\n",
       "          [ 0.1355],\n",
       "          [ 0.0060],\n",
       "          [ 0.0506],\n",
       "          [ 0.1270],\n",
       "          [ 0.1297],\n",
       "          [ 0.0863],\n",
       "          [ 0.1085],\n",
       "          [-0.0778],\n",
       "          [-0.0466],\n",
       "          [ 0.0842],\n",
       "          [-0.0145],\n",
       "          [-0.1459],\n",
       "          [-0.0741],\n",
       "          [ 0.0203],\n",
       "          [-0.0055],\n",
       "          [ 0.0795],\n",
       "          [-0.0084],\n",
       "          [ 0.0303],\n",
       "          [ 0.0898],\n",
       "          [ 0.1315],\n",
       "          [ 0.1131],\n",
       "          [-0.0036],\n",
       "          [ 0.1225],\n",
       "          [ 0.1118],\n",
       "          [-0.0532],\n",
       "          [ 0.0936],\n",
       "          [-0.0780],\n",
       "          [-0.0143],\n",
       "          [ 0.0772],\n",
       "          [ 0.0147],\n",
       "          [ 0.0101],\n",
       "          [ 0.0042],\n",
       "          [ 0.0206],\n",
       "          [-0.0839],\n",
       "          [ 0.1440],\n",
       "          [ 0.1246],\n",
       "          [-0.0006],\n",
       "          [-0.0237],\n",
       "          [-0.0645],\n",
       "          [ 0.1475],\n",
       "          [ 0.1301],\n",
       "          [-0.0065],\n",
       "          [ 0.1442],\n",
       "          [-0.0318],\n",
       "          [-0.0436],\n",
       "          [ 0.1518],\n",
       "          [-0.0352],\n",
       "          [ 0.1148],\n",
       "          [ 0.0843],\n",
       "          [ 0.0159],\n",
       "          [-0.1083],\n",
       "          [-0.0925],\n",
       "          [-0.0410],\n",
       "          [-0.1322],\n",
       "          [-0.0863],\n",
       "          [ 0.0579],\n",
       "          [-0.0024],\n",
       "          [ 0.1027],\n",
       "          [ 0.1311],\n",
       "          [ 0.0773],\n",
       "          [ 0.0674],\n",
       "          [ 0.1395]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-4.8572e-02, -1.4684e-01, -1.1006e-01, -5.2097e-02, -1.4825e-01,\n",
       "            -9.9246e-02,  4.4365e-02,  3.3099e-02,  1.3679e-01,  2.2595e-02,\n",
       "             1.9641e-02,  5.5871e-02, -1.4785e-01,  1.4644e-01,  9.7881e-02,\n",
       "            -1.2932e-01, -5.0715e-02, -7.8181e-02,  3.4162e-02,  1.0636e-01,\n",
       "             3.4878e-02,  4.4073e-03, -1.0522e-01,  2.9500e-02,  2.5043e-02,\n",
       "             1.4033e-01, -1.5363e-02, -3.2413e-02,  7.6684e-02,  8.0807e-02,\n",
       "            -3.3871e-02,  9.6751e-03, -1.2351e-01, -1.0651e-01,  7.1480e-02,\n",
       "             1.2321e-01, -5.4343e-02,  9.9426e-02,  1.4945e-01, -1.0300e-01,\n",
       "            -8.2429e-02,  1.1899e-01, -9.0851e-02, -7.2724e-02, -7.1635e-02,\n",
       "             9.1773e-02,  4.3651e-02,  1.1155e-01, -8.3270e-02, -3.0125e-02,\n",
       "            -1.3189e-02, -4.3283e-02, -7.9882e-02,  1.2452e-01,  8.2793e-02,\n",
       "             8.7278e-02, -2.9533e-02, -1.1648e-01,  1.2191e-01, -2.1351e-02,\n",
       "            -8.6558e-02, -8.0477e-02, -7.1683e-02,  8.6509e-02, -1.0667e-01,\n",
       "             3.5581e-02,  7.8249e-02,  7.2656e-02,  8.6127e-02,  9.1101e-03,\n",
       "            -9.7097e-02, -6.1328e-02,  2.1775e-02,  9.0940e-02,  4.9461e-02,\n",
       "             1.1254e-01,  1.2850e-01, -2.4884e-02, -1.3157e-01,  1.4122e-01,\n",
       "             1.1121e-01, -1.7275e-02,  1.2814e-01, -1.4972e-01, -1.4349e-01,\n",
       "            -4.3695e-02, -7.8025e-02,  1.3023e-01, -2.1645e-02,  8.9821e-02,\n",
       "             4.7791e-02,  1.1715e-01, -1.0561e-01,  6.9148e-02, -4.4470e-02,\n",
       "            -6.8848e-02, -1.0952e-01, -1.7916e-02, -2.5972e-02,  2.3607e-02,\n",
       "            -5.5713e-02, -9.6306e-02,  9.7496e-02,  1.5442e-02,  5.3843e-02,\n",
       "             9.0482e-02, -9.4302e-02,  9.1929e-02,  4.6141e-02, -9.1460e-02,\n",
       "             7.6200e-02,  1.1640e-01, -7.9302e-02,  4.8073e-02, -8.4997e-02,\n",
       "             1.0903e-02, -7.7647e-02,  5.4215e-02, -2.4289e-02,  2.9028e-02,\n",
       "            -5.2273e-02, -4.5039e-03, -9.1761e-02,  6.3244e-02, -7.6611e-02,\n",
       "             6.2438e-02,  2.5377e-02,  1.0435e-01,  8.8591e-02, -1.4406e-01,\n",
       "            -4.0016e-02, -8.4609e-02,  1.1068e-01, -6.6041e-02,  3.4143e-02,\n",
       "            -4.3797e-02, -1.4862e-01,  6.7356e-02, -7.2146e-02,  2.5037e-03,\n",
       "             3.7691e-03,  3.3115e-02,  1.3350e-01,  1.0067e-01,  6.5286e-02,\n",
       "            -8.1909e-02, -1.1473e-01, -6.2758e-02,  5.2601e-05,  1.0232e-01,\n",
       "            -1.1050e-01, -2.1161e-03,  2.7644e-02, -1.4507e-01,  1.3468e-01,\n",
       "            -3.2222e-03,  1.5081e-01, -1.1184e-01, -8.7294e-02, -1.0167e-01,\n",
       "            -1.4559e-01, -1.2769e-01,  6.3164e-02,  5.3734e-02, -1.3241e-01,\n",
       "             9.7770e-02,  2.1111e-02,  1.4298e-01, -2.5727e-02, -6.8298e-02,\n",
       "             6.3999e-02, -1.2018e-01,  3.4180e-02,  7.3058e-02,  1.1557e-01,\n",
       "            -2.7130e-02, -4.6993e-02,  5.4959e-02, -1.3179e-01, -4.0024e-02,\n",
       "             1.3670e-01, -9.6488e-03, -1.1475e-01, -4.7492e-02,  4.6995e-02,\n",
       "            -1.4932e-01, -9.8413e-02, -2.4704e-03, -3.1406e-02,  4.5400e-02,\n",
       "            -1.3057e-01, -1.2794e-01,  1.1803e-02, -9.1493e-02,  9.3719e-02,\n",
       "            -1.0312e-02, -9.9486e-02,  6.2241e-02, -1.0299e-01, -4.7462e-02,\n",
       "             1.0159e-01, -1.1201e-01, -9.7469e-02,  1.5010e-01, -1.1134e-01,\n",
       "             5.0926e-03,  1.5161e-01, -1.9032e-02,  1.4824e-01,  8.6709e-02,\n",
       "             1.4065e-01,  9.6326e-02, -1.4264e-01, -2.5290e-02,  7.7448e-02,\n",
       "             1.6060e-02, -2.0305e-02,  1.5200e-01,  3.4050e-02,  4.2591e-02,\n",
       "             8.5279e-02,  1.0647e-01, -5.2181e-02, -1.0882e-01, -9.7191e-02,\n",
       "            -1.2606e-01,  1.1457e-01,  1.2757e-01,  9.1308e-02,  3.5969e-02,\n",
       "            -7.9367e-02, -1.0166e-01, -4.8166e-02, -9.1802e-02,  3.6132e-02,\n",
       "             1.5100e-01,  5.8721e-02, -1.9583e-02,  4.3577e-02, -6.3517e-02,\n",
       "             1.0967e-01, -1.2317e-02,  5.5644e-02,  8.4709e-02, -5.1082e-02,\n",
       "            -1.5055e-01, -7.8413e-02,  6.6218e-02, -8.0932e-02, -5.9131e-02,\n",
       "             1.4371e-01, -1.1762e-01,  5.2919e-02, -1.4308e-01, -1.0032e-01,\n",
       "            -3.9181e-02]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0333,  0.0416, -0.0105,  ...,  0.0974, -0.0561, -0.0490],\n",
       "          [ 0.0255,  0.0800, -0.0762,  ...,  0.1001, -0.0570,  0.0686],\n",
       "          [-0.0505,  0.0831,  0.0879,  ..., -0.0038,  0.0381, -0.0051],\n",
       "          ...,\n",
       "          [-0.0156, -0.0827, -0.0748,  ..., -0.0605, -0.0128, -0.0476],\n",
       "          [ 0.0123,  0.0507, -0.0782,  ...,  0.0132,  0.0260, -0.0808],\n",
       "          [ 0.0973,  0.0645, -0.0486,  ..., -0.0214, -0.1035, -0.0546]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0387, -0.0568,  0.0399,  0.0028,  0.0534, -0.0161,  0.0150, -0.0564,\n",
       "           0.0289,  0.0321,  0.0264,  0.0549, -0.0426, -0.0012,  0.0452, -0.0441,\n",
       "          -0.0244, -0.0413, -0.0235, -0.0096,  0.0143, -0.0524, -0.0050,  0.0250,\n",
       "          -0.0362,  0.0274,  0.0506, -0.0063,  0.0400,  0.0236,  0.0192, -0.0097,\n",
       "          -0.0477,  0.0077, -0.0526, -0.0151, -0.0368,  0.0211,  0.0298, -0.0062,\n",
       "           0.0098,  0.0470, -0.0408, -0.0087, -0.0230,  0.0201, -0.0306,  0.0357,\n",
       "          -0.0294,  0.0111,  0.0286, -0.0472,  0.0143, -0.0173, -0.0390, -0.0275,\n",
       "          -0.0009,  0.0544, -0.0020,  0.0531, -0.0014, -0.0404, -0.0371,  0.0417,\n",
       "           0.0501, -0.0350, -0.0465, -0.0451, -0.0259, -0.0540,  0.0297, -0.0004,\n",
       "          -0.0144,  0.0170, -0.0200, -0.0334, -0.0152, -0.0270, -0.0222,  0.0223,\n",
       "          -0.0350, -0.0542, -0.0505, -0.0243,  0.0036, -0.0016,  0.0398, -0.0296,\n",
       "          -0.0041,  0.0259, -0.0287, -0.0003, -0.0561, -0.0176, -0.0489, -0.0571,\n",
       "          -0.0228,  0.0559,  0.0395, -0.0319,  0.0507,  0.0407, -0.0499, -0.0499,\n",
       "          -0.0110, -0.0126, -0.0361, -0.0413,  0.0546, -0.0454,  0.0468, -0.0173,\n",
       "           0.0385,  0.0425,  0.0479,  0.0082, -0.0350, -0.0508,  0.0529,  0.0131,\n",
       "           0.0522,  0.0307,  0.0420,  0.0106,  0.0324, -0.0010, -0.0361, -0.0295,\n",
       "          -0.0551,  0.0508, -0.0281,  0.0197, -0.0550,  0.0356, -0.0380,  0.0515,\n",
       "          -0.0262,  0.0148, -0.0172, -0.0480,  0.0004, -0.0159, -0.0173,  0.0540,\n",
       "           0.0382,  0.0470, -0.0468,  0.0131,  0.0309, -0.0460, -0.0514, -0.0116,\n",
       "          -0.0033, -0.0189, -0.0451, -0.0097,  0.0214,  0.0534,  0.0450,  0.0405,\n",
       "          -0.0106, -0.0320,  0.0421, -0.0230,  0.0515, -0.0071, -0.0344,  0.0298,\n",
       "          -0.0217,  0.0531, -0.0384, -0.0033, -0.0497, -0.0398, -0.0563,  0.0476,\n",
       "          -0.0016,  0.0467, -0.0559, -0.0561, -0.0361,  0.0103,  0.0053, -0.0168,\n",
       "          -0.0221,  0.0441, -0.0416, -0.0153,  0.0300,  0.0052, -0.0350, -0.0096,\n",
       "          -0.0570,  0.0093,  0.0557,  0.0065, -0.0144,  0.0553, -0.0475,  0.0470,\n",
       "           0.0510, -0.0295, -0.0393,  0.0192,  0.0408, -0.0389, -0.0524, -0.0407,\n",
       "          -0.0333,  0.0234,  0.0459,  0.0422, -0.0179,  0.0245, -0.0269, -0.0526,\n",
       "           0.0407,  0.0496, -0.0483, -0.0568, -0.0105,  0.0129, -0.0059,  0.0280,\n",
       "          -0.0370, -0.0454, -0.0021,  0.0577, -0.0383,  0.0259, -0.0396, -0.0233,\n",
       "           0.0127, -0.0298,  0.0425, -0.0412, -0.0553, -0.0216,  0.0500, -0.0388,\n",
       "           0.0265, -0.0236,  0.0114, -0.0174,  0.0386,  0.0016, -0.0167, -0.0289,\n",
       "           0.0531, -0.0557, -0.0305, -0.0253,  0.0245, -0.0468,  0.0107, -0.0058],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0166, -0.0026,  0.0089,  ...,  0.0901,  0.0213, -0.0406],\n",
       "          [-0.0918, -0.0820,  0.0681,  ...,  0.0423,  0.0393, -0.0968],\n",
       "          [-0.0441,  0.0719, -0.0013,  ...,  0.0085, -0.0170, -0.0409],\n",
       "          ...,\n",
       "          [ 0.0195,  0.0620,  0.0257,  ..., -0.0619,  0.0074,  0.0772],\n",
       "          [-0.0784,  0.0512, -0.0214,  ...,  0.0815,  0.0922,  0.0935],\n",
       "          [ 0.0881, -0.0760, -0.0736,  ..., -0.0768,  0.0030,  0.1026]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.5639e-02, -2.0345e-02,  1.9420e-02,  9.7381e-03,  8.3421e-03,\n",
       "           3.7025e-02,  4.3227e-02,  2.9467e-02,  1.4473e-02, -2.9181e-02,\n",
       "          -4.6531e-02, -1.8095e-03, -4.4366e-02, -4.6259e-02,  5.0556e-02,\n",
       "           3.4431e-02,  5.2789e-02, -2.7908e-02, -5.1113e-02, -5.6378e-03,\n",
       "           5.0735e-02, -4.2735e-02, -3.0335e-03, -3.8173e-02,  3.4970e-02,\n",
       "          -5.5742e-02,  1.0770e-02, -4.2431e-02, -5.7331e-02,  1.5154e-02,\n",
       "           3.0358e-02, -3.5886e-05, -1.7750e-04, -4.5116e-02,  6.7649e-03,\n",
       "           1.3233e-02,  1.2857e-02, -4.7664e-02,  2.1160e-02, -5.4447e-02,\n",
       "           4.5447e-02, -2.2828e-02, -5.4542e-03, -1.7678e-02, -1.0705e-02,\n",
       "           8.0188e-03, -1.2914e-02, -3.5208e-02, -3.9072e-02, -5.4833e-02,\n",
       "          -5.4489e-02, -2.0097e-02, -3.3143e-02, -6.2393e-03, -4.1616e-02,\n",
       "           1.7145e-02,  2.0931e-02, -2.1731e-02,  1.0417e-02, -2.2217e-02,\n",
       "           3.6665e-02,  1.5879e-02, -3.4917e-02,  2.8080e-02, -4.2723e-02,\n",
       "          -2.5183e-02,  9.1907e-03, -1.6877e-02,  3.2047e-02, -3.9544e-02,\n",
       "           5.0505e-02, -5.6695e-02, -4.3489e-02, -3.7016e-02, -4.2774e-02,\n",
       "          -1.2644e-03, -1.5915e-02,  1.7293e-02, -4.6028e-02,  3.4151e-02,\n",
       "          -2.7543e-02,  5.4354e-02,  1.6308e-02, -5.9559e-03, -9.7885e-03,\n",
       "          -5.4015e-02,  3.9551e-02, -1.1430e-02, -2.4651e-02, -5.3027e-04,\n",
       "           3.0863e-03, -2.7113e-02, -4.4999e-02,  4.4918e-02,  6.7013e-03,\n",
       "           1.6910e-02, -1.1467e-02,  3.5753e-02, -3.6335e-02,  4.9539e-02,\n",
       "           5.6170e-03,  3.3067e-02,  2.0589e-02, -3.4694e-03, -3.9004e-02,\n",
       "          -5.4680e-03, -3.5270e-02,  4.8698e-02, -2.7076e-02, -1.6958e-02,\n",
       "           5.5213e-02, -4.0263e-02, -2.6131e-02,  7.1967e-03,  1.6877e-02,\n",
       "          -5.1159e-02,  2.9616e-02,  2.2292e-02,  3.8730e-02, -4.0790e-02,\n",
       "          -1.0735e-02, -3.9776e-02,  4.7824e-02, -3.5448e-02,  3.4740e-02,\n",
       "          -2.8359e-02,  2.3441e-02,  4.7046e-02,  5.5007e-02,  6.6726e-03,\n",
       "           3.7920e-02, -5.5648e-02,  2.5686e-02, -3.6175e-02,  1.9200e-02,\n",
       "          -2.1331e-02, -3.2222e-02,  7.9746e-03, -2.4369e-02, -2.3736e-02,\n",
       "           3.3471e-02, -6.2416e-03,  1.2619e-02,  7.1408e-04,  9.5669e-03,\n",
       "          -5.4887e-03,  4.2376e-02, -2.4336e-02,  4.8006e-02, -1.0918e-02,\n",
       "           1.0456e-03, -4.0300e-03, -5.0312e-03, -2.5552e-02, -2.4431e-02,\n",
       "           2.5966e-02, -2.1496e-02, -2.2173e-02,  2.3121e-02, -4.5999e-02,\n",
       "          -4.1020e-02,  3.0053e-02,  4.0823e-02,  3.0014e-02, -1.4625e-03,\n",
       "           8.1637e-03,  5.5918e-02,  3.0592e-02, -4.7347e-02,  4.8961e-02,\n",
       "           3.8642e-02,  2.4251e-03, -1.7086e-03,  4.0648e-02,  3.0477e-02,\n",
       "           1.2001e-02,  5.2622e-02,  1.2830e-02,  5.8799e-03,  8.0098e-03,\n",
       "           3.2796e-02,  4.3057e-03, -4.5195e-02,  1.8305e-02,  2.2456e-02,\n",
       "           1.6853e-02,  5.6820e-02,  4.5771e-02, -4.6846e-02, -5.6256e-03,\n",
       "           4.4953e-02,  4.7567e-02, -3.0906e-03, -1.7437e-02, -4.3321e-03,\n",
       "          -1.7389e-02,  4.1166e-02, -3.4840e-03,  1.9230e-02,  4.9129e-02,\n",
       "          -4.9776e-02, -5.3240e-02,  4.8241e-02,  4.2893e-02, -3.2720e-02,\n",
       "          -3.0791e-02,  4.3821e-02, -1.2929e-02,  4.0385e-02,  1.9576e-02,\n",
       "          -5.6233e-02, -5.4424e-02,  4.6919e-02,  3.9835e-02, -1.5390e-02,\n",
       "           3.3422e-03, -2.6954e-02, -2.6072e-02,  2.7340e-02,  3.9069e-02,\n",
       "          -1.0826e-02, -2.1254e-02, -3.3376e-03,  3.1375e-02,  2.0184e-02,\n",
       "          -1.0111e-03,  3.3001e-02, -9.6493e-03, -1.6380e-02, -1.9231e-02,\n",
       "           1.2775e-02, -4.7699e-02,  4.8363e-02,  3.6213e-02,  1.0406e-02,\n",
       "          -4.7977e-03,  9.3707e-03,  5.5416e-02,  3.6096e-02,  4.0212e-02,\n",
       "           2.6419e-02,  5.1061e-02,  4.3922e-02,  4.2493e-02, -1.9356e-02,\n",
       "           2.2333e-02, -1.4449e-02, -4.8438e-02,  3.3340e-02, -7.0766e-05,\n",
       "           5.6865e-02,  5.4207e-03, -2.3928e-02,  5.2375e-02, -2.6865e-02,\n",
       "           1.5584e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1045],\n",
       "          [-0.1208],\n",
       "          [-0.1036],\n",
       "          [ 0.0122],\n",
       "          [-0.0427],\n",
       "          [ 0.0573],\n",
       "          [ 0.0841],\n",
       "          [-0.0639],\n",
       "          [ 0.0816],\n",
       "          [-0.0239],\n",
       "          [-0.0710],\n",
       "          [ 0.0463],\n",
       "          [-0.0707],\n",
       "          [-0.0026],\n",
       "          [ 0.0709],\n",
       "          [ 0.0934],\n",
       "          [ 0.1295],\n",
       "          [ 0.0230],\n",
       "          [ 0.0199],\n",
       "          [ 0.1332],\n",
       "          [ 0.1324],\n",
       "          [-0.0773],\n",
       "          [-0.0229],\n",
       "          [ 0.0577],\n",
       "          [ 0.0481],\n",
       "          [ 0.0259],\n",
       "          [-0.0250],\n",
       "          [-0.1096],\n",
       "          [ 0.1052],\n",
       "          [-0.1459],\n",
       "          [ 0.1220],\n",
       "          [-0.1384],\n",
       "          [ 0.0124],\n",
       "          [-0.1434],\n",
       "          [ 0.0393],\n",
       "          [-0.0684],\n",
       "          [ 0.0766],\n",
       "          [-0.1035],\n",
       "          [-0.0897],\n",
       "          [ 0.1311],\n",
       "          [ 0.0137],\n",
       "          [-0.0908],\n",
       "          [-0.0747],\n",
       "          [-0.1489],\n",
       "          [-0.1092],\n",
       "          [ 0.1336],\n",
       "          [ 0.1245],\n",
       "          [-0.0216],\n",
       "          [-0.0658],\n",
       "          [ 0.0343],\n",
       "          [ 0.1499],\n",
       "          [ 0.0100],\n",
       "          [ 0.1003],\n",
       "          [ 0.0485],\n",
       "          [-0.1455],\n",
       "          [ 0.0908],\n",
       "          [ 0.0449],\n",
       "          [ 0.0105],\n",
       "          [-0.0603],\n",
       "          [-0.0655],\n",
       "          [-0.0308],\n",
       "          [ 0.0526],\n",
       "          [ 0.1096],\n",
       "          [ 0.0308],\n",
       "          [-0.0985],\n",
       "          [ 0.1006],\n",
       "          [-0.0584],\n",
       "          [-0.0014],\n",
       "          [ 0.0717],\n",
       "          [-0.0413],\n",
       "          [-0.0948],\n",
       "          [ 0.0129],\n",
       "          [-0.0402],\n",
       "          [ 0.1099],\n",
       "          [ 0.0823],\n",
       "          [ 0.1388],\n",
       "          [-0.1380],\n",
       "          [-0.1054],\n",
       "          [-0.1470],\n",
       "          [ 0.0440],\n",
       "          [-0.1131],\n",
       "          [ 0.1345],\n",
       "          [ 0.0818],\n",
       "          [ 0.0637],\n",
       "          [ 0.0830],\n",
       "          [ 0.1077],\n",
       "          [ 0.0312],\n",
       "          [-0.0073],\n",
       "          [-0.1478],\n",
       "          [ 0.0530],\n",
       "          [-0.0726],\n",
       "          [-0.1090],\n",
       "          [-0.0482],\n",
       "          [ 0.0749],\n",
       "          [ 0.1443],\n",
       "          [ 0.0395],\n",
       "          [ 0.0046],\n",
       "          [-0.0355],\n",
       "          [ 0.0647],\n",
       "          [ 0.0124],\n",
       "          [ 0.0079],\n",
       "          [ 0.0468],\n",
       "          [-0.1070],\n",
       "          [ 0.0362],\n",
       "          [ 0.0989],\n",
       "          [ 0.1263],\n",
       "          [ 0.1456],\n",
       "          [ 0.0262],\n",
       "          [-0.0146],\n",
       "          [ 0.1377],\n",
       "          [-0.1474],\n",
       "          [-0.0099],\n",
       "          [ 0.0397],\n",
       "          [ 0.1079],\n",
       "          [ 0.0591],\n",
       "          [ 0.0988],\n",
       "          [ 0.1126],\n",
       "          [ 0.0244],\n",
       "          [-0.0658],\n",
       "          [ 0.1455],\n",
       "          [-0.1324],\n",
       "          [-0.1359],\n",
       "          [-0.0132],\n",
       "          [ 0.0118],\n",
       "          [-0.0506],\n",
       "          [ 0.1416],\n",
       "          [-0.0723],\n",
       "          [-0.1330],\n",
       "          [ 0.0023],\n",
       "          [ 0.0384],\n",
       "          [-0.1494],\n",
       "          [ 0.0094],\n",
       "          [-0.1034],\n",
       "          [ 0.0539],\n",
       "          [ 0.0391],\n",
       "          [-0.0971],\n",
       "          [ 0.0550],\n",
       "          [ 0.0793],\n",
       "          [-0.0494],\n",
       "          [ 0.1270],\n",
       "          [ 0.0691],\n",
       "          [ 0.1336],\n",
       "          [-0.0193],\n",
       "          [-0.0888],\n",
       "          [ 0.0333],\n",
       "          [-0.1386],\n",
       "          [-0.0470],\n",
       "          [ 0.0531],\n",
       "          [-0.0364],\n",
       "          [ 0.0534],\n",
       "          [ 0.1236],\n",
       "          [ 0.0996],\n",
       "          [-0.0423],\n",
       "          [ 0.1418],\n",
       "          [ 0.0731],\n",
       "          [ 0.0110],\n",
       "          [ 0.0528],\n",
       "          [ 0.1117],\n",
       "          [ 0.0478],\n",
       "          [ 0.0060],\n",
       "          [-0.0350],\n",
       "          [-0.0827],\n",
       "          [ 0.0822],\n",
       "          [-0.0573],\n",
       "          [-0.0215],\n",
       "          [-0.0893],\n",
       "          [ 0.0221],\n",
       "          [-0.0307],\n",
       "          [ 0.0032],\n",
       "          [-0.0543],\n",
       "          [ 0.0961],\n",
       "          [ 0.1498],\n",
       "          [-0.0725],\n",
       "          [-0.0585],\n",
       "          [-0.1171],\n",
       "          [-0.0041],\n",
       "          [ 0.0640],\n",
       "          [-0.1187],\n",
       "          [-0.0592],\n",
       "          [-0.0161],\n",
       "          [-0.1349],\n",
       "          [ 0.0230],\n",
       "          [-0.0140],\n",
       "          [-0.1157],\n",
       "          [-0.0271],\n",
       "          [-0.0055],\n",
       "          [-0.0090],\n",
       "          [ 0.1490],\n",
       "          [ 0.0381],\n",
       "          [-0.1189],\n",
       "          [-0.0492],\n",
       "          [-0.0610],\n",
       "          [-0.0625],\n",
       "          [-0.1022],\n",
       "          [ 0.0227],\n",
       "          [-0.1260],\n",
       "          [-0.1033],\n",
       "          [ 0.0917],\n",
       "          [-0.0225],\n",
       "          [ 0.1225],\n",
       "          [-0.1363],\n",
       "          [ 0.1404],\n",
       "          [ 0.1199],\n",
       "          [ 0.0770],\n",
       "          [-0.1181],\n",
       "          [ 0.0437],\n",
       "          [ 0.1371],\n",
       "          [ 0.0636],\n",
       "          [ 0.1482],\n",
       "          [-0.1517],\n",
       "          [-0.1311],\n",
       "          [-0.0822],\n",
       "          [ 0.0009],\n",
       "          [ 0.1483],\n",
       "          [-0.0207],\n",
       "          [-0.1410],\n",
       "          [ 0.1162],\n",
       "          [-0.0438],\n",
       "          [ 0.1033],\n",
       "          [-0.1199],\n",
       "          [ 0.0943],\n",
       "          [-0.0584],\n",
       "          [ 0.0494],\n",
       "          [-0.1451],\n",
       "          [-0.1491],\n",
       "          [ 0.0561],\n",
       "          [ 0.1127],\n",
       "          [ 0.1455],\n",
       "          [-0.0287],\n",
       "          [-0.0446],\n",
       "          [-0.0312],\n",
       "          [-0.0730],\n",
       "          [ 0.1213],\n",
       "          [-0.0628],\n",
       "          [ 0.0015],\n",
       "          [-0.0206],\n",
       "          [-0.0291],\n",
       "          [ 0.0022],\n",
       "          [ 0.1279],\n",
       "          [-0.0904],\n",
       "          [ 0.0645],\n",
       "          [-0.0634],\n",
       "          [ 0.1170],\n",
       "          [ 0.0966],\n",
       "          [-0.0116],\n",
       "          [ 0.0974],\n",
       "          [-0.1459],\n",
       "          [-0.1146],\n",
       "          [-0.1195],\n",
       "          [-0.1292],\n",
       "          [ 0.0065],\n",
       "          [ 0.1350],\n",
       "          [-0.0844],\n",
       "          [ 0.1527],\n",
       "          [ 0.1009],\n",
       "          [-0.1093]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1109,  0.0031, -0.0842, -0.0272,  0.1521, -0.1479, -0.1295,\n",
       "             0.1151,  0.0591,  0.0690,  0.1141, -0.0137, -0.1296,  0.1521,\n",
       "             0.0096,  0.0968,  0.0703,  0.1066,  0.0442,  0.1424, -0.0939,\n",
       "             0.0579, -0.0788,  0.0748,  0.1122, -0.0707, -0.1347, -0.0105,\n",
       "            -0.1174,  0.0202, -0.0311,  0.0261, -0.0176, -0.0254,  0.0634,\n",
       "             0.0927,  0.0018, -0.0665,  0.0221, -0.0685,  0.0576,  0.1056,\n",
       "             0.0186,  0.1230, -0.0069, -0.0895,  0.0074, -0.0026, -0.0200,\n",
       "             0.0736, -0.0601,  0.0153, -0.1374, -0.1502,  0.0175,  0.1518,\n",
       "            -0.1224, -0.1050, -0.0875, -0.1297,  0.1083, -0.1407,  0.0069,\n",
       "             0.1429, -0.0564, -0.0937, -0.0818, -0.1094,  0.0637,  0.1148,\n",
       "             0.0965,  0.0829, -0.0774, -0.0884, -0.0343, -0.0563,  0.0249,\n",
       "            -0.0366,  0.0692,  0.0189, -0.0654, -0.0604,  0.0786,  0.1514,\n",
       "             0.1241,  0.0372, -0.0219,  0.1494, -0.0606, -0.1189, -0.0150,\n",
       "             0.1527,  0.0076, -0.1028, -0.0635,  0.0268, -0.0240, -0.0691,\n",
       "            -0.1031, -0.1466, -0.0455, -0.1483, -0.0529,  0.1247, -0.0102,\n",
       "            -0.1166, -0.0318,  0.0113, -0.1153,  0.1528, -0.0892, -0.1125,\n",
       "            -0.0395,  0.0760,  0.1367,  0.1336, -0.0591,  0.0500,  0.1070,\n",
       "            -0.0347, -0.1042,  0.1307, -0.1350,  0.0632, -0.0850,  0.0959,\n",
       "            -0.0670,  0.0888, -0.1157,  0.0263, -0.0875,  0.0520,  0.0708,\n",
       "            -0.1011, -0.1340, -0.0351, -0.0251,  0.1083,  0.0748,  0.0233,\n",
       "             0.1310, -0.0577,  0.0635,  0.0334,  0.0523,  0.0799,  0.0186,\n",
       "             0.1383,  0.0747, -0.1065,  0.0608,  0.0194,  0.1060, -0.1510,\n",
       "            -0.0067, -0.0236,  0.0973, -0.0117, -0.1490, -0.0776,  0.0924,\n",
       "            -0.1124, -0.0561,  0.0878,  0.0551,  0.1148, -0.0974,  0.0522,\n",
       "             0.0475, -0.0220, -0.0214,  0.1252, -0.0561, -0.1476,  0.0786,\n",
       "            -0.1108, -0.0112,  0.0715,  0.0792,  0.1364,  0.0674,  0.1150,\n",
       "            -0.1189, -0.0157,  0.1353,  0.1230, -0.0009, -0.0068, -0.0242,\n",
       "            -0.0571, -0.0209, -0.1459, -0.0331,  0.0911,  0.1329,  0.0195,\n",
       "             0.0411,  0.0199, -0.1183,  0.0850, -0.0091, -0.1383,  0.0363,\n",
       "            -0.1237, -0.0765,  0.1360,  0.0684,  0.0761,  0.1341, -0.0378,\n",
       "             0.0606, -0.1143,  0.1030, -0.1110, -0.0638, -0.0389,  0.0109,\n",
       "            -0.0403, -0.1367, -0.1010, -0.0936, -0.0772,  0.0155,  0.0006,\n",
       "             0.0690,  0.0115,  0.1392, -0.0494, -0.0563,  0.0645,  0.1387,\n",
       "            -0.0240, -0.0220,  0.0239,  0.1315, -0.0495, -0.0077, -0.0182,\n",
       "            -0.0626, -0.0983,  0.1190, -0.0942, -0.0436,  0.0021, -0.0926,\n",
       "            -0.1457, -0.0812,  0.0142, -0.0819, -0.1146,  0.1369, -0.0140,\n",
       "             0.1277,  0.0564, -0.0712, -0.0959]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0361, -0.0036, -0.0164,  ...,  0.0700, -0.0579,  0.0186],\n",
       "          [ 0.0717, -0.0578, -0.0722,  ...,  0.0470,  0.0431,  0.0824],\n",
       "          [-0.0773,  0.0825,  0.0080,  ...,  0.0150,  0.0974, -0.0233],\n",
       "          ...,\n",
       "          [ 0.0540, -0.0430, -0.0455,  ..., -0.0164,  0.0849,  0.0253],\n",
       "          [-0.0238,  0.0999, -0.0038,  ...,  0.0966, -0.0472,  0.0681],\n",
       "          [-0.0948,  0.0828,  0.0180,  ..., -0.0444, -0.0133,  0.0174]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0375,  0.0011, -0.0528,  0.0489,  0.0379,  0.0192, -0.0107,  0.0193,\n",
       "          -0.0050,  0.0131, -0.0571, -0.0180, -0.0034, -0.0158, -0.0485,  0.0274,\n",
       "           0.0513, -0.0323,  0.0388, -0.0577,  0.0573,  0.0085,  0.0362, -0.0135,\n",
       "          -0.0530, -0.0457,  0.0066, -0.0398, -0.0133,  0.0492, -0.0542, -0.0011,\n",
       "          -0.0021,  0.0170, -0.0453, -0.0143, -0.0384,  0.0444, -0.0205,  0.0108,\n",
       "          -0.0288,  0.0048, -0.0215, -0.0242, -0.0262,  0.0163, -0.0568,  0.0451,\n",
       "          -0.0328,  0.0356,  0.0291, -0.0488, -0.0450, -0.0443,  0.0494, -0.0455,\n",
       "          -0.0078,  0.0146, -0.0462,  0.0561, -0.0210,  0.0424,  0.0226, -0.0074,\n",
       "           0.0432,  0.0473, -0.0314,  0.0391, -0.0520,  0.0103, -0.0020,  0.0028,\n",
       "          -0.0376,  0.0252, -0.0433,  0.0387,  0.0215,  0.0132, -0.0470,  0.0476,\n",
       "           0.0352, -0.0460,  0.0055, -0.0504,  0.0077, -0.0245, -0.0025, -0.0132,\n",
       "           0.0150, -0.0221,  0.0199, -0.0149,  0.0307, -0.0532, -0.0205,  0.0225,\n",
       "           0.0032, -0.0028,  0.0310,  0.0335,  0.0553,  0.0264,  0.0228,  0.0056,\n",
       "          -0.0233,  0.0002,  0.0132,  0.0278, -0.0465,  0.0386,  0.0542, -0.0271,\n",
       "           0.0182, -0.0223, -0.0558, -0.0194,  0.0075,  0.0392,  0.0393,  0.0376,\n",
       "           0.0068,  0.0421, -0.0061, -0.0050, -0.0186,  0.0136,  0.0566, -0.0404,\n",
       "           0.0451,  0.0520,  0.0260,  0.0188,  0.0063,  0.0073, -0.0315, -0.0121,\n",
       "           0.0275,  0.0360,  0.0289,  0.0441, -0.0338, -0.0107,  0.0052,  0.0404,\n",
       "           0.0226, -0.0512, -0.0552,  0.0378,  0.0336,  0.0241,  0.0370,  0.0058,\n",
       "           0.0359, -0.0329,  0.0403, -0.0371,  0.0164, -0.0301,  0.0145,  0.0010,\n",
       "          -0.0242, -0.0386, -0.0062, -0.0131, -0.0020, -0.0549,  0.0453,  0.0515,\n",
       "           0.0473,  0.0414,  0.0554, -0.0305, -0.0253,  0.0533, -0.0443, -0.0314,\n",
       "           0.0406,  0.0329,  0.0117,  0.0256, -0.0250, -0.0456,  0.0555, -0.0072,\n",
       "           0.0251,  0.0434, -0.0114, -0.0415,  0.0470,  0.0388,  0.0351,  0.0469,\n",
       "           0.0489, -0.0304, -0.0510,  0.0274, -0.0408, -0.0213, -0.0560, -0.0297,\n",
       "           0.0397, -0.0567,  0.0498, -0.0283, -0.0259,  0.0087,  0.0284,  0.0573,\n",
       "           0.0321,  0.0278,  0.0054, -0.0122, -0.0418, -0.0342,  0.0098, -0.0026,\n",
       "          -0.0092,  0.0449,  0.0527,  0.0127, -0.0499, -0.0313, -0.0349,  0.0241,\n",
       "           0.0057, -0.0483,  0.0015, -0.0136,  0.0151,  0.0552, -0.0215,  0.0357,\n",
       "           0.0263,  0.0538, -0.0154,  0.0316,  0.0040, -0.0368,  0.0519,  0.0346,\n",
       "          -0.0479, -0.0267, -0.0170,  0.0061, -0.0284, -0.0318, -0.0151,  0.0020,\n",
       "          -0.0418, -0.0483, -0.0061,  0.0346,  0.0455,  0.0154,  0.0006, -0.0196],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1000,  0.0139,  0.0548,  ..., -0.0489,  0.0900,  0.0987],\n",
       "          [-0.0005,  0.1019, -0.0199,  ...,  0.0435, -0.0966, -0.0315],\n",
       "          [ 0.0181,  0.0673,  0.0626,  ..., -0.0549,  0.0302, -0.0099],\n",
       "          ...,\n",
       "          [ 0.0832,  0.0885, -0.0859,  ..., -0.0850,  0.0217,  0.0512],\n",
       "          [-0.0342,  0.0878, -0.0856,  ..., -0.0837, -0.0538,  0.0818],\n",
       "          [-0.0417, -0.0795, -0.1016,  ...,  0.0095, -0.0531,  0.0029]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.6091e-02,  4.7336e-02,  5.6365e-02, -1.9948e-02, -8.0109e-03,\n",
       "           5.1776e-02,  8.2116e-03, -4.6505e-02,  3.6152e-02, -2.7115e-02,\n",
       "           4.4480e-02, -4.0254e-02,  2.4832e-02, -9.3525e-03, -2.5261e-02,\n",
       "          -3.5749e-02,  3.3276e-02, -1.7239e-02, -4.2290e-03,  5.0374e-02,\n",
       "           5.2883e-02,  2.2956e-02, -2.1358e-02, -3.8048e-02,  2.5183e-02,\n",
       "          -1.8325e-02, -9.2849e-04, -4.2429e-02,  8.7945e-03,  3.0047e-03,\n",
       "           1.7626e-02, -3.5406e-02,  3.0600e-02,  4.6429e-02, -3.1602e-02,\n",
       "           2.4972e-02,  1.1611e-02,  3.4296e-02,  4.3097e-03,  2.7875e-02,\n",
       "           1.6456e-03, -4.5189e-02, -5.3585e-02,  2.6199e-02,  1.3243e-03,\n",
       "          -7.8815e-03,  3.3948e-02, -3.1860e-02, -4.4212e-02, -5.5716e-02,\n",
       "          -2.8785e-02,  6.0651e-03,  6.4078e-03, -5.5317e-02, -4.1972e-02,\n",
       "          -1.1445e-02, -3.1386e-02, -5.2483e-02, -3.3462e-02,  2.8461e-02,\n",
       "           3.1156e-02, -4.7418e-02, -2.0896e-02, -5.0193e-02, -7.7484e-03,\n",
       "           2.9476e-02, -3.4989e-02,  3.2831e-02, -2.4688e-02,  1.1073e-02,\n",
       "          -2.5240e-02, -2.7508e-03, -2.5855e-02,  4.1166e-02,  3.8084e-02,\n",
       "          -1.6544e-02, -2.4384e-02,  2.9758e-02, -4.3135e-02, -2.0106e-02,\n",
       "          -5.2604e-02, -4.7505e-02,  5.2016e-04,  5.4569e-02,  4.5961e-02,\n",
       "           1.5650e-02,  3.9457e-02, -3.5168e-02,  5.1695e-02, -6.7763e-03,\n",
       "           3.3775e-02,  1.7515e-03, -7.6837e-03,  2.6554e-02,  2.0291e-02,\n",
       "          -2.8924e-02, -5.0748e-03,  1.2702e-02,  3.3048e-02,  4.1782e-02,\n",
       "          -5.0309e-02, -4.3167e-02, -9.3931e-03,  1.6093e-02,  4.1382e-02,\n",
       "           2.1389e-02, -4.5791e-02, -2.4252e-02, -6.6688e-03,  3.4925e-02,\n",
       "           1.0342e-02,  5.0307e-02, -4.2032e-02, -5.3475e-02,  2.5247e-02,\n",
       "          -5.1323e-02, -3.4923e-03, -4.5115e-02, -4.0449e-02, -4.2075e-02,\n",
       "          -1.2874e-02,  3.5945e-02,  4.7694e-02,  5.0699e-02,  1.9238e-02,\n",
       "           4.7549e-02,  3.0381e-02, -4.7639e-02, -3.1555e-02,  4.5105e-02,\n",
       "           4.5948e-02, -7.2088e-05, -1.3259e-02, -4.4314e-02, -1.8799e-02,\n",
       "           3.9987e-02,  5.2975e-02, -1.6831e-02, -1.1231e-02, -2.8872e-02,\n",
       "           1.9752e-02,  4.8770e-02, -3.3464e-02,  2.7654e-02,  1.7407e-03,\n",
       "           2.8437e-02, -3.9738e-02,  4.1083e-02,  4.6283e-02, -4.2944e-02,\n",
       "           4.3701e-02, -5.0436e-02,  5.0812e-02, -1.8229e-04,  4.6031e-02,\n",
       "           1.3941e-02, -5.1237e-02, -5.2993e-02, -5.5520e-02, -3.6848e-02,\n",
       "          -2.9003e-02, -1.1406e-02, -1.0164e-02, -4.1156e-02,  1.3169e-02,\n",
       "           1.5851e-02, -4.8337e-02,  1.3539e-03, -3.8527e-03,  2.1186e-02,\n",
       "           1.0484e-02,  2.5840e-03,  3.6979e-02,  4.6860e-02, -3.8812e-02,\n",
       "          -4.0138e-02, -2.7778e-02, -3.7499e-02, -3.1880e-02,  5.2304e-02,\n",
       "          -1.2965e-02,  3.5991e-02, -4.7037e-02,  3.1137e-02,  2.3993e-02,\n",
       "          -4.7348e-02, -4.5483e-02, -8.1320e-03, -1.5778e-02, -5.7127e-02,\n",
       "          -5.4638e-02,  3.9669e-02, -1.9328e-03,  5.5458e-02,  2.1205e-02,\n",
       "          -5.7570e-02,  2.1394e-02,  3.1880e-02,  1.3584e-02,  5.0600e-02,\n",
       "          -1.2656e-02, -4.5315e-02,  1.3970e-02, -4.5261e-02,  2.2063e-02,\n",
       "           4.8502e-02,  1.0154e-02,  3.0780e-02,  2.4839e-02, -3.0968e-02,\n",
       "           8.2017e-03, -3.5733e-03,  4.0932e-02, -6.0785e-04, -4.4535e-02,\n",
       "          -4.9456e-03,  2.8829e-02, -9.0034e-03, -3.3079e-02,  1.0397e-02,\n",
       "           3.6263e-02,  3.6626e-02,  5.0662e-02, -3.7685e-02, -9.4996e-03,\n",
       "          -5.4481e-02, -1.3229e-02,  5.8182e-04,  3.3382e-02, -2.5187e-03,\n",
       "           9.7577e-03,  3.3123e-03,  4.8596e-02, -3.9889e-02, -3.1827e-02,\n",
       "           2.0560e-02,  4.7214e-02, -5.7551e-02,  3.3883e-02, -3.3474e-02,\n",
       "          -3.4928e-02, -5.1919e-02,  1.1288e-02, -2.7117e-02,  8.5186e-03,\n",
       "           4.1935e-02, -5.1736e-03, -2.4296e-03, -3.5055e-02, -1.1808e-02,\n",
       "          -2.3731e-02,  6.0229e-04, -9.9678e-03,  2.7176e-02, -1.8562e-02,\n",
       "           5.1778e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 6.5138e-02],\n",
       "          [-1.0555e-01],\n",
       "          [-1.1951e-01],\n",
       "          [-9.3638e-02],\n",
       "          [-3.0789e-02],\n",
       "          [ 8.9555e-02],\n",
       "          [ 4.6653e-04],\n",
       "          [-7.6890e-02],\n",
       "          [ 1.4756e-01],\n",
       "          [ 1.3169e-01],\n",
       "          [ 3.6220e-02],\n",
       "          [-3.3913e-03],\n",
       "          [-1.2832e-01],\n",
       "          [ 2.1451e-02],\n",
       "          [-2.1865e-02],\n",
       "          [-1.1121e-01],\n",
       "          [ 6.1446e-02],\n",
       "          [-8.4628e-02],\n",
       "          [-1.1628e-01],\n",
       "          [ 7.4611e-02],\n",
       "          [-8.6980e-02],\n",
       "          [-7.6177e-02],\n",
       "          [ 1.5103e-01],\n",
       "          [-1.1583e-01],\n",
       "          [ 3.0403e-02],\n",
       "          [ 6.1061e-02],\n",
       "          [-1.2766e-01],\n",
       "          [-3.6630e-02],\n",
       "          [ 1.0471e-01],\n",
       "          [ 1.7291e-02],\n",
       "          [ 1.4167e-01],\n",
       "          [-9.5711e-02],\n",
       "          [-1.1944e-01],\n",
       "          [ 8.7217e-02],\n",
       "          [ 5.7807e-02],\n",
       "          [ 9.9490e-03],\n",
       "          [ 9.9042e-02],\n",
       "          [-1.0606e-01],\n",
       "          [ 6.8854e-02],\n",
       "          [-9.5800e-03],\n",
       "          [ 3.3632e-02],\n",
       "          [ 7.0062e-02],\n",
       "          [-8.9142e-02],\n",
       "          [ 1.0412e-01],\n",
       "          [ 1.1134e-01],\n",
       "          [-1.2272e-01],\n",
       "          [ 1.3127e-01],\n",
       "          [ 5.6195e-02],\n",
       "          [-6.3228e-02],\n",
       "          [-9.4897e-02],\n",
       "          [-1.8838e-02],\n",
       "          [-1.4677e-01],\n",
       "          [ 1.0180e-01],\n",
       "          [ 6.4428e-02],\n",
       "          [ 2.9609e-02],\n",
       "          [ 9.9732e-02],\n",
       "          [-7.3748e-02],\n",
       "          [ 1.2688e-01],\n",
       "          [ 7.6877e-02],\n",
       "          [-9.6943e-02],\n",
       "          [ 4.1958e-02],\n",
       "          [ 1.4589e-01],\n",
       "          [ 7.2783e-02],\n",
       "          [-2.4957e-02],\n",
       "          [ 1.3917e-01],\n",
       "          [-9.1361e-02],\n",
       "          [-1.5271e-01],\n",
       "          [ 1.0107e-01],\n",
       "          [ 9.8033e-02],\n",
       "          [ 1.3973e-01],\n",
       "          [-1.1406e-01],\n",
       "          [ 1.4910e-01],\n",
       "          [-1.3152e-01],\n",
       "          [-1.0814e-01],\n",
       "          [ 2.0306e-02],\n",
       "          [ 5.8952e-02],\n",
       "          [-4.8965e-02],\n",
       "          [ 1.2776e-01],\n",
       "          [-2.1667e-02],\n",
       "          [ 1.4651e-01],\n",
       "          [ 9.2404e-02],\n",
       "          [ 1.3663e-01],\n",
       "          [-2.5674e-02],\n",
       "          [-1.8352e-03],\n",
       "          [-7.3284e-05],\n",
       "          [-4.1976e-02],\n",
       "          [ 9.6972e-02],\n",
       "          [ 1.4934e-01],\n",
       "          [-8.8141e-02],\n",
       "          [-2.4897e-02],\n",
       "          [-1.0352e-01],\n",
       "          [ 1.1482e-01],\n",
       "          [-1.4198e-01],\n",
       "          [ 1.2530e-01],\n",
       "          [ 1.4589e-01],\n",
       "          [ 3.7408e-02],\n",
       "          [ 1.3903e-01],\n",
       "          [-1.1581e-01],\n",
       "          [-3.7432e-02],\n",
       "          [ 3.5703e-02],\n",
       "          [-3.2619e-02],\n",
       "          [-6.0204e-02],\n",
       "          [-2.0707e-02],\n",
       "          [-1.4376e-01],\n",
       "          [ 1.4165e-01],\n",
       "          [ 1.5214e-01],\n",
       "          [-1.6621e-02],\n",
       "          [ 6.1765e-02],\n",
       "          [ 3.5992e-02],\n",
       "          [-8.4614e-02],\n",
       "          [ 1.9565e-03],\n",
       "          [-9.7764e-02],\n",
       "          [ 1.3548e-01],\n",
       "          [ 1.3531e-01],\n",
       "          [-1.0078e-01],\n",
       "          [ 1.3611e-01],\n",
       "          [ 1.1211e-01],\n",
       "          [-5.2823e-02],\n",
       "          [-1.4120e-01],\n",
       "          [ 7.6559e-02],\n",
       "          [-7.7369e-02],\n",
       "          [ 5.3392e-02],\n",
       "          [-4.7518e-02],\n",
       "          [-9.6444e-02],\n",
       "          [ 1.3772e-01],\n",
       "          [ 6.1131e-02],\n",
       "          [-9.7539e-02],\n",
       "          [ 1.3798e-01],\n",
       "          [-5.3759e-02],\n",
       "          [-2.8996e-02],\n",
       "          [-1.3353e-01],\n",
       "          [-1.2838e-01],\n",
       "          [ 4.6669e-03],\n",
       "          [ 1.1394e-01],\n",
       "          [-8.6036e-02],\n",
       "          [ 6.7341e-02],\n",
       "          [-5.9942e-02],\n",
       "          [ 7.5955e-02],\n",
       "          [ 1.3383e-01],\n",
       "          [-7.8718e-02],\n",
       "          [-7.2336e-02],\n",
       "          [ 1.0391e-01],\n",
       "          [ 1.3512e-01],\n",
       "          [ 1.0223e-01],\n",
       "          [ 6.2124e-02],\n",
       "          [-1.2897e-01],\n",
       "          [-6.4425e-02],\n",
       "          [ 7.8625e-02],\n",
       "          [ 1.4810e-01],\n",
       "          [-8.8094e-02],\n",
       "          [-3.6486e-02],\n",
       "          [ 1.8399e-02],\n",
       "          [-3.0924e-02],\n",
       "          [ 1.3931e-01],\n",
       "          [-5.4067e-02],\n",
       "          [-1.1880e-01],\n",
       "          [-7.7025e-02],\n",
       "          [-5.7092e-02],\n",
       "          [-5.7220e-02],\n",
       "          [ 1.4002e-01],\n",
       "          [ 1.2927e-01],\n",
       "          [-1.0976e-01],\n",
       "          [ 3.7245e-02],\n",
       "          [-1.0347e-01],\n",
       "          [ 6.4874e-03],\n",
       "          [-1.1999e-01],\n",
       "          [-3.7823e-02],\n",
       "          [-8.5290e-02],\n",
       "          [-1.3581e-01],\n",
       "          [-1.2323e-01],\n",
       "          [ 1.2637e-01],\n",
       "          [-1.2263e-01],\n",
       "          [ 1.3761e-01],\n",
       "          [ 6.0015e-02],\n",
       "          [ 4.9847e-02],\n",
       "          [ 8.1319e-03],\n",
       "          [ 5.3792e-02],\n",
       "          [ 7.7560e-02],\n",
       "          [ 1.3273e-02],\n",
       "          [ 1.3152e-01],\n",
       "          [-6.2551e-02],\n",
       "          [-1.0542e-02],\n",
       "          [ 2.8491e-05],\n",
       "          [-3.5683e-02],\n",
       "          [ 3.8988e-02],\n",
       "          [ 2.3293e-02],\n",
       "          [ 1.4270e-01],\n",
       "          [ 3.5449e-02],\n",
       "          [-2.2364e-02],\n",
       "          [ 6.0039e-02],\n",
       "          [ 1.3590e-01],\n",
       "          [-1.2027e-01],\n",
       "          [-1.2147e-01],\n",
       "          [-1.0514e-01],\n",
       "          [ 8.7425e-02],\n",
       "          [ 1.2469e-01],\n",
       "          [ 1.1193e-01],\n",
       "          [ 1.0651e-01],\n",
       "          [ 3.9099e-02],\n",
       "          [ 9.2495e-02],\n",
       "          [-6.1577e-02],\n",
       "          [-1.0499e-01],\n",
       "          [-6.1691e-02],\n",
       "          [ 1.1458e-01],\n",
       "          [ 1.0853e-01],\n",
       "          [-5.8919e-03],\n",
       "          [-1.3618e-01],\n",
       "          [-9.0774e-02],\n",
       "          [ 5.3302e-02],\n",
       "          [-6.7667e-02],\n",
       "          [-3.2608e-03],\n",
       "          [-3.4159e-02],\n",
       "          [ 1.2177e-01],\n",
       "          [-3.2149e-02],\n",
       "          [-9.4513e-02],\n",
       "          [ 6.9553e-03],\n",
       "          [ 4.0823e-02],\n",
       "          [ 8.3491e-02],\n",
       "          [-7.2701e-02],\n",
       "          [-8.8550e-03],\n",
       "          [ 1.8026e-02],\n",
       "          [-4.9296e-02],\n",
       "          [ 7.3231e-02],\n",
       "          [-7.5869e-02],\n",
       "          [ 1.0103e-01],\n",
       "          [ 2.0951e-02],\n",
       "          [ 6.3785e-03],\n",
       "          [-3.6289e-02],\n",
       "          [ 1.5240e-01],\n",
       "          [-2.8639e-02],\n",
       "          [-4.5708e-02],\n",
       "          [-8.2029e-02],\n",
       "          [-5.9325e-02],\n",
       "          [-4.3898e-03],\n",
       "          [ 1.6693e-02],\n",
       "          [-1.3213e-01],\n",
       "          [ 3.0997e-02],\n",
       "          [-8.8939e-03],\n",
       "          [ 1.3971e-01],\n",
       "          [-1.2770e-01],\n",
       "          [-1.2715e-01],\n",
       "          [ 1.6073e-03],\n",
       "          [ 1.0624e-01],\n",
       "          [-9.5577e-02],\n",
       "          [ 1.0399e-01],\n",
       "          [ 4.2856e-02],\n",
       "          [-3.4544e-02],\n",
       "          [-1.2901e-01],\n",
       "          [ 9.1112e-02],\n",
       "          [-2.5522e-02],\n",
       "          [ 2.1053e-02],\n",
       "          [-1.1582e-01],\n",
       "          [-2.6154e-02],\n",
       "          [-1.2980e-01],\n",
       "          [-1.0784e-01],\n",
       "          [-1.0116e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0582,  0.1203,  0.0177,  0.1297, -0.1300,  0.0179,  0.1524,\n",
       "             0.0440, -0.0688,  0.1258, -0.0944,  0.0280,  0.0347,  0.0660,\n",
       "             0.1158,  0.0711,  0.1239,  0.1269,  0.0570,  0.1395, -0.0605,\n",
       "            -0.0024,  0.0675,  0.0187, -0.0086, -0.1393, -0.0418, -0.1300,\n",
       "             0.1056, -0.0896,  0.0109, -0.1475,  0.1380,  0.0732, -0.0813,\n",
       "            -0.1288, -0.0725,  0.0771,  0.1155,  0.0577,  0.0401,  0.0301,\n",
       "            -0.0573,  0.0223, -0.0631,  0.1257, -0.0942, -0.1250, -0.0838,\n",
       "             0.0082,  0.1421,  0.1084,  0.0427,  0.0887, -0.0988,  0.1230,\n",
       "            -0.1334,  0.1132, -0.0641,  0.1275, -0.0056,  0.0971,  0.0254,\n",
       "             0.0999, -0.0613,  0.0534,  0.0063,  0.0146, -0.1013, -0.0214,\n",
       "            -0.1214, -0.0154, -0.0754,  0.0062, -0.0192,  0.1204,  0.1514,\n",
       "            -0.1406,  0.0637, -0.1135, -0.1047, -0.0424,  0.1371, -0.1493,\n",
       "             0.1213, -0.0848,  0.0408, -0.0995, -0.0703,  0.0853,  0.1208,\n",
       "             0.1127, -0.0959, -0.1277,  0.0427,  0.0675,  0.1029,  0.1140,\n",
       "            -0.1053, -0.0819,  0.1188,  0.0113,  0.1334, -0.0999,  0.0673,\n",
       "            -0.1080, -0.0071, -0.1071, -0.1455, -0.0763,  0.0454, -0.0961,\n",
       "             0.0366, -0.0863,  0.0408, -0.1076,  0.1407,  0.0620,  0.0877,\n",
       "            -0.0577,  0.1210,  0.1297,  0.1048, -0.1387,  0.0861, -0.1330,\n",
       "             0.0435, -0.1040,  0.0466, -0.0235,  0.1323, -0.1313, -0.0489,\n",
       "             0.0821,  0.1029, -0.1164, -0.1497, -0.0865, -0.0482, -0.0050,\n",
       "             0.1341, -0.0636,  0.0820, -0.0512,  0.1329, -0.0998, -0.1121,\n",
       "            -0.0853,  0.0525, -0.0471, -0.1446,  0.0196, -0.1192, -0.0822,\n",
       "             0.0397, -0.1345,  0.0826,  0.0546,  0.0936, -0.0120, -0.1200,\n",
       "             0.0471, -0.1255,  0.0868,  0.0328,  0.1103,  0.1050,  0.1164,\n",
       "             0.0848,  0.1432,  0.1222,  0.0853, -0.1088,  0.0699,  0.0912,\n",
       "            -0.1417, -0.1231,  0.1138, -0.1180, -0.0602,  0.1389, -0.0691,\n",
       "             0.0594,  0.1294, -0.0253,  0.1262, -0.0639, -0.1342, -0.0786,\n",
       "             0.1089,  0.0506,  0.0588, -0.0154, -0.0956,  0.0710, -0.0991,\n",
       "             0.0206,  0.0757, -0.1096, -0.1248,  0.0196, -0.1462, -0.0282,\n",
       "             0.0478,  0.0101,  0.1015, -0.0456, -0.1525, -0.0240,  0.0092,\n",
       "            -0.0610,  0.0244, -0.0344,  0.1102,  0.0054, -0.0272, -0.0143,\n",
       "             0.0444,  0.1479, -0.1350,  0.1095, -0.1344, -0.1444, -0.1139,\n",
       "             0.0889,  0.0794, -0.0892, -0.0286, -0.0515, -0.1275, -0.1011,\n",
       "            -0.0016, -0.0388,  0.1398, -0.0783,  0.1160,  0.0093,  0.1338,\n",
       "            -0.1023, -0.1510, -0.1141,  0.0713, -0.0487,  0.0120, -0.0699,\n",
       "             0.0993,  0.1072,  0.0373,  0.0496,  0.1434,  0.1415, -0.1352,\n",
       "             0.0826,  0.0681, -0.0892,  0.0589]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0781,  0.0745,  0.0810,  ..., -0.0594, -0.0111,  0.0583],\n",
       "          [ 0.0307, -0.0818, -0.0007,  ...,  0.1008, -0.0822, -0.0925],\n",
       "          [-0.0320,  0.0830,  0.0081,  ..., -0.0627, -0.0909,  0.0302],\n",
       "          ...,\n",
       "          [ 0.0072,  0.0886, -0.0953,  ..., -0.0175,  0.0450, -0.0078],\n",
       "          [ 0.0481,  0.0493, -0.0423,  ..., -0.0784, -0.0745,  0.0194],\n",
       "          [ 0.0259, -0.0649,  0.0065,  ..., -0.0355,  0.0599,  0.0019]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0373, -0.0423, -0.0375,  0.0402,  0.0317,  0.0367, -0.0432, -0.0426,\n",
       "          -0.0337,  0.0488, -0.0107,  0.0182,  0.0490, -0.0182,  0.0417,  0.0009,\n",
       "           0.0050,  0.0132,  0.0512,  0.0378, -0.0090,  0.0294,  0.0199,  0.0445,\n",
       "          -0.0523, -0.0189,  0.0372,  0.0131, -0.0342,  0.0096, -0.0479,  0.0331,\n",
       "           0.0199,  0.0047,  0.0175, -0.0236,  0.0102,  0.0387, -0.0278,  0.0482,\n",
       "           0.0007, -0.0258,  0.0163,  0.0501, -0.0473, -0.0507,  0.0362, -0.0424,\n",
       "           0.0143,  0.0122,  0.0464, -0.0475, -0.0477,  0.0206,  0.0178, -0.0095,\n",
       "          -0.0103,  0.0004,  0.0537, -0.0203,  0.0040, -0.0474,  0.0114,  0.0417,\n",
       "           0.0457, -0.0020, -0.0062, -0.0388, -0.0153, -0.0235, -0.0096, -0.0030,\n",
       "          -0.0282,  0.0076, -0.0340,  0.0533,  0.0009, -0.0497,  0.0553,  0.0546,\n",
       "           0.0287, -0.0380, -0.0182, -0.0283,  0.0404, -0.0216,  0.0531, -0.0196,\n",
       "           0.0481,  0.0192, -0.0099,  0.0288,  0.0321,  0.0103, -0.0030, -0.0100,\n",
       "           0.0117, -0.0128,  0.0040, -0.0145,  0.0198, -0.0139,  0.0074, -0.0051,\n",
       "           0.0505,  0.0195,  0.0034, -0.0250, -0.0406,  0.0144,  0.0048,  0.0511,\n",
       "          -0.0277,  0.0190, -0.0495,  0.0531, -0.0355, -0.0296, -0.0329, -0.0270,\n",
       "           0.0237,  0.0489, -0.0042, -0.0352,  0.0230, -0.0400, -0.0380,  0.0189,\n",
       "          -0.0387, -0.0003, -0.0573,  0.0044,  0.0194,  0.0251, -0.0024, -0.0159,\n",
       "           0.0392,  0.0520, -0.0064, -0.0301, -0.0531, -0.0016,  0.0282, -0.0576,\n",
       "          -0.0012,  0.0438,  0.0428,  0.0348,  0.0180, -0.0441, -0.0287, -0.0502,\n",
       "           0.0554, -0.0172, -0.0467, -0.0178, -0.0462, -0.0098,  0.0179, -0.0390,\n",
       "          -0.0211, -0.0415,  0.0511, -0.0299,  0.0135,  0.0303, -0.0070, -0.0168,\n",
       "           0.0437, -0.0287, -0.0386, -0.0178, -0.0153, -0.0482, -0.0387, -0.0347,\n",
       "           0.0085,  0.0554,  0.0099,  0.0151,  0.0036, -0.0210,  0.0330, -0.0176,\n",
       "          -0.0381, -0.0108,  0.0363, -0.0525, -0.0545,  0.0510, -0.0048,  0.0193,\n",
       "           0.0404,  0.0185,  0.0180,  0.0380, -0.0071, -0.0021,  0.0280, -0.0336,\n",
       "           0.0057, -0.0090, -0.0352, -0.0510, -0.0213, -0.0039,  0.0251,  0.0421,\n",
       "          -0.0128,  0.0481, -0.0026, -0.0217, -0.0410,  0.0295, -0.0216,  0.0048,\n",
       "          -0.0388,  0.0393,  0.0541,  0.0462, -0.0001,  0.0046,  0.0511, -0.0385,\n",
       "          -0.0503,  0.0272,  0.0060,  0.0483,  0.0419, -0.0027, -0.0525,  0.0091,\n",
       "           0.0283,  0.0384, -0.0261,  0.0291, -0.0017,  0.0167,  0.0443,  0.0491,\n",
       "           0.0166,  0.0322,  0.0517, -0.0298, -0.0490,  0.0381, -0.0465, -0.0297,\n",
       "          -0.0209, -0.0506,  0.0341,  0.0170,  0.0360,  0.0508,  0.0253,  0.0122],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0501, -0.0324, -0.0095,  ..., -0.0267,  0.0229,  0.0076],\n",
       "          [ 0.0654, -0.0617, -0.0193,  ...,  0.0252, -0.0716, -0.0532],\n",
       "          [-0.0568, -0.0879, -0.0177,  ..., -0.0165, -0.0311,  0.0915],\n",
       "          ...,\n",
       "          [-0.0433, -0.0437,  0.0151,  ..., -0.0062, -0.0657, -0.0301],\n",
       "          [ 0.0230,  0.0756,  0.0217,  ...,  0.0234, -0.0679, -0.1001],\n",
       "          [ 0.0867, -0.0891, -0.0523,  ..., -0.0548,  0.0286,  0.0593]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0010,  0.0250, -0.0274,  0.0298,  0.0076, -0.0499,  0.0033, -0.0406,\n",
       "          -0.0481, -0.0329,  0.0565, -0.0272,  0.0090,  0.0314, -0.0327, -0.0077,\n",
       "           0.0021,  0.0129, -0.0061,  0.0542, -0.0359, -0.0410,  0.0399,  0.0540,\n",
       "           0.0486, -0.0259,  0.0001,  0.0149,  0.0547, -0.0212, -0.0522,  0.0021,\n",
       "           0.0119, -0.0123, -0.0212,  0.0500, -0.0468, -0.0341, -0.0537, -0.0366,\n",
       "           0.0283,  0.0413, -0.0515, -0.0422, -0.0565, -0.0023,  0.0299,  0.0498,\n",
       "          -0.0509,  0.0317,  0.0466,  0.0083, -0.0118,  0.0066,  0.0074,  0.0537,\n",
       "          -0.0181,  0.0201, -0.0189, -0.0069,  0.0077, -0.0327,  0.0403,  0.0411,\n",
       "           0.0382, -0.0507,  0.0200, -0.0089,  0.0030, -0.0004, -0.0223, -0.0493,\n",
       "           0.0519, -0.0069,  0.0081,  0.0571, -0.0423, -0.0078,  0.0064, -0.0030,\n",
       "          -0.0475,  0.0026,  0.0100, -0.0133,  0.0164, -0.0148, -0.0376,  0.0459,\n",
       "           0.0310, -0.0124,  0.0479,  0.0044,  0.0130,  0.0264, -0.0545, -0.0223,\n",
       "           0.0292, -0.0477,  0.0056,  0.0369,  0.0200, -0.0458, -0.0318,  0.0306,\n",
       "           0.0085,  0.0410,  0.0105,  0.0016,  0.0497,  0.0560,  0.0215,  0.0420,\n",
       "          -0.0493, -0.0471, -0.0257,  0.0259, -0.0050,  0.0086, -0.0449,  0.0109,\n",
       "          -0.0563,  0.0359, -0.0150, -0.0180,  0.0056, -0.0484,  0.0028,  0.0027,\n",
       "           0.0048, -0.0228,  0.0331,  0.0403, -0.0025,  0.0304, -0.0482, -0.0311,\n",
       "          -0.0143, -0.0180,  0.0379, -0.0552, -0.0506,  0.0167,  0.0233, -0.0479,\n",
       "          -0.0299, -0.0194,  0.0133, -0.0028, -0.0182, -0.0070,  0.0541,  0.0317,\n",
       "           0.0417, -0.0184,  0.0243, -0.0018, -0.0177,  0.0181,  0.0276,  0.0169,\n",
       "          -0.0446, -0.0401, -0.0146, -0.0142,  0.0356,  0.0100,  0.0313,  0.0204,\n",
       "           0.0189,  0.0326,  0.0457, -0.0479,  0.0103, -0.0577, -0.0561, -0.0093,\n",
       "           0.0520, -0.0435, -0.0206, -0.0306,  0.0344, -0.0305,  0.0500, -0.0496,\n",
       "           0.0082,  0.0092, -0.0187, -0.0401,  0.0423,  0.0505,  0.0429, -0.0554,\n",
       "          -0.0489, -0.0396, -0.0126,  0.0294, -0.0025, -0.0014, -0.0008, -0.0208,\n",
       "           0.0070,  0.0251, -0.0273, -0.0043,  0.0348,  0.0425,  0.0565,  0.0045,\n",
       "          -0.0173,  0.0201, -0.0196,  0.0137, -0.0112, -0.0182, -0.0464, -0.0290,\n",
       "           0.0229,  0.0147, -0.0282,  0.0133, -0.0405,  0.0210,  0.0070, -0.0094,\n",
       "          -0.0397, -0.0399,  0.0394, -0.0373, -0.0313,  0.0533,  0.0363,  0.0132,\n",
       "           0.0231,  0.0356,  0.0528,  0.0511, -0.0545, -0.0374,  0.0429, -0.0487,\n",
       "          -0.0192,  0.0433, -0.0408,  0.0258,  0.0236, -0.0090,  0.0126, -0.0239,\n",
       "          -0.0032,  0.0537, -0.0413, -0.0064, -0.0572,  0.0293,  0.0445, -0.0288],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1417],\n",
       "          [ 0.0366],\n",
       "          [-0.0723],\n",
       "          [ 0.0151],\n",
       "          [ 0.0242],\n",
       "          [ 0.1094],\n",
       "          [-0.0605],\n",
       "          [ 0.1356],\n",
       "          [-0.1345],\n",
       "          [-0.0999],\n",
       "          [-0.0688],\n",
       "          [-0.0522],\n",
       "          [ 0.0618],\n",
       "          [-0.1363],\n",
       "          [ 0.0639],\n",
       "          [ 0.1310],\n",
       "          [-0.0542],\n",
       "          [-0.0762],\n",
       "          [ 0.0753],\n",
       "          [-0.1487],\n",
       "          [-0.0170],\n",
       "          [-0.0991],\n",
       "          [ 0.0977],\n",
       "          [-0.0178],\n",
       "          [ 0.0018],\n",
       "          [ 0.1116],\n",
       "          [-0.0624],\n",
       "          [ 0.0580],\n",
       "          [ 0.0785],\n",
       "          [-0.0888],\n",
       "          [ 0.0669],\n",
       "          [ 0.1084],\n",
       "          [-0.0907],\n",
       "          [-0.0769],\n",
       "          [-0.0756],\n",
       "          [ 0.1085],\n",
       "          [-0.1012],\n",
       "          [-0.1408],\n",
       "          [-0.0887],\n",
       "          [ 0.1385],\n",
       "          [ 0.0518],\n",
       "          [-0.1520],\n",
       "          [-0.0481],\n",
       "          [ 0.0240],\n",
       "          [-0.0907],\n",
       "          [-0.0050],\n",
       "          [ 0.0226],\n",
       "          [-0.0798],\n",
       "          [ 0.1312],\n",
       "          [-0.0859],\n",
       "          [-0.0349],\n",
       "          [-0.0676],\n",
       "          [ 0.0703],\n",
       "          [-0.0032],\n",
       "          [ 0.0566],\n",
       "          [ 0.0853],\n",
       "          [ 0.0762],\n",
       "          [-0.0647],\n",
       "          [-0.1141],\n",
       "          [-0.0495],\n",
       "          [-0.0108],\n",
       "          [-0.1265],\n",
       "          [ 0.0918],\n",
       "          [ 0.1398],\n",
       "          [ 0.1261],\n",
       "          [ 0.1247],\n",
       "          [ 0.1500],\n",
       "          [-0.0274],\n",
       "          [-0.1191],\n",
       "          [-0.1520],\n",
       "          [ 0.1316],\n",
       "          [-0.0076],\n",
       "          [-0.1097],\n",
       "          [ 0.0954],\n",
       "          [-0.0380],\n",
       "          [-0.1507],\n",
       "          [ 0.1151],\n",
       "          [-0.1422],\n",
       "          [-0.1359],\n",
       "          [ 0.1422],\n",
       "          [ 0.0567],\n",
       "          [ 0.0795],\n",
       "          [-0.0550],\n",
       "          [-0.1489],\n",
       "          [ 0.0528],\n",
       "          [ 0.1194],\n",
       "          [-0.1393],\n",
       "          [-0.0316],\n",
       "          [ 0.0116],\n",
       "          [-0.0346],\n",
       "          [ 0.0077],\n",
       "          [ 0.1064],\n",
       "          [ 0.0353],\n",
       "          [-0.1114],\n",
       "          [-0.0305],\n",
       "          [-0.0850],\n",
       "          [-0.0109],\n",
       "          [ 0.1072],\n",
       "          [-0.1221],\n",
       "          [-0.1100],\n",
       "          [-0.1131],\n",
       "          [ 0.1477],\n",
       "          [ 0.0490],\n",
       "          [-0.0861],\n",
       "          [ 0.0635],\n",
       "          [ 0.0268],\n",
       "          [ 0.0547],\n",
       "          [-0.0601],\n",
       "          [ 0.1334],\n",
       "          [ 0.0010],\n",
       "          [-0.0448],\n",
       "          [-0.0668],\n",
       "          [ 0.0776],\n",
       "          [ 0.0997],\n",
       "          [-0.0913],\n",
       "          [-0.0980],\n",
       "          [-0.0043],\n",
       "          [-0.1361],\n",
       "          [ 0.0693],\n",
       "          [ 0.0303],\n",
       "          [ 0.0675],\n",
       "          [-0.1155],\n",
       "          [ 0.0588],\n",
       "          [ 0.0414],\n",
       "          [-0.0156],\n",
       "          [-0.0566],\n",
       "          [ 0.0244],\n",
       "          [ 0.1085],\n",
       "          [-0.0576],\n",
       "          [-0.0978],\n",
       "          [-0.1148],\n",
       "          [-0.0848],\n",
       "          [ 0.0810],\n",
       "          [ 0.1311],\n",
       "          [ 0.0299],\n",
       "          [-0.1450],\n",
       "          [-0.1366],\n",
       "          [-0.0831],\n",
       "          [-0.0469],\n",
       "          [-0.0005],\n",
       "          [-0.1094],\n",
       "          [-0.1122],\n",
       "          [ 0.0506],\n",
       "          [ 0.0737],\n",
       "          [-0.0058],\n",
       "          [-0.0789],\n",
       "          [ 0.0894],\n",
       "          [-0.0423],\n",
       "          [ 0.0985],\n",
       "          [-0.0951],\n",
       "          [ 0.1067],\n",
       "          [-0.0202],\n",
       "          [-0.1186],\n",
       "          [ 0.0576],\n",
       "          [-0.0149],\n",
       "          [ 0.0657],\n",
       "          [ 0.1216],\n",
       "          [-0.0915],\n",
       "          [-0.0081],\n",
       "          [-0.0959],\n",
       "          [ 0.0782],\n",
       "          [-0.0004],\n",
       "          [ 0.1185],\n",
       "          [-0.0930],\n",
       "          [-0.0297],\n",
       "          [-0.0632],\n",
       "          [-0.0574],\n",
       "          [-0.0913],\n",
       "          [ 0.1287],\n",
       "          [-0.0746],\n",
       "          [ 0.1297],\n",
       "          [-0.0928],\n",
       "          [-0.0936],\n",
       "          [-0.1197],\n",
       "          [-0.1515],\n",
       "          [ 0.0664],\n",
       "          [-0.0712],\n",
       "          [ 0.1068],\n",
       "          [-0.0644],\n",
       "          [ 0.1307],\n",
       "          [-0.0795],\n",
       "          [-0.0893],\n",
       "          [-0.0641],\n",
       "          [-0.0583],\n",
       "          [-0.0076],\n",
       "          [ 0.0485],\n",
       "          [ 0.0920],\n",
       "          [ 0.0791],\n",
       "          [-0.0404],\n",
       "          [ 0.0940],\n",
       "          [-0.0243],\n",
       "          [ 0.1146],\n",
       "          [ 0.0984],\n",
       "          [ 0.0850],\n",
       "          [ 0.1135],\n",
       "          [-0.0388],\n",
       "          [-0.0052],\n",
       "          [-0.1194],\n",
       "          [ 0.0668],\n",
       "          [ 0.0496],\n",
       "          [ 0.0372],\n",
       "          [ 0.0990],\n",
       "          [-0.0115],\n",
       "          [-0.0165],\n",
       "          [ 0.0963],\n",
       "          [-0.0238],\n",
       "          [ 0.0074],\n",
       "          [-0.0176],\n",
       "          [ 0.1424],\n",
       "          [ 0.0848],\n",
       "          [-0.0902],\n",
       "          [-0.0930],\n",
       "          [ 0.1401],\n",
       "          [ 0.1029],\n",
       "          [ 0.0077],\n",
       "          [ 0.0031],\n",
       "          [ 0.0674],\n",
       "          [ 0.0376],\n",
       "          [-0.0840],\n",
       "          [ 0.0284],\n",
       "          [ 0.0597],\n",
       "          [ 0.0495],\n",
       "          [-0.1356],\n",
       "          [-0.1475],\n",
       "          [-0.1458],\n",
       "          [ 0.0322],\n",
       "          [-0.1434],\n",
       "          [ 0.0168],\n",
       "          [ 0.0641],\n",
       "          [ 0.0320],\n",
       "          [-0.1333],\n",
       "          [ 0.0228],\n",
       "          [ 0.0891],\n",
       "          [ 0.0626],\n",
       "          [-0.0695],\n",
       "          [ 0.0959],\n",
       "          [-0.0363],\n",
       "          [-0.1156],\n",
       "          [-0.0440],\n",
       "          [-0.0496],\n",
       "          [ 0.1440],\n",
       "          [-0.0467],\n",
       "          [ 0.1525],\n",
       "          [ 0.0385],\n",
       "          [ 0.0317],\n",
       "          [ 0.0299],\n",
       "          [ 0.0273],\n",
       "          [ 0.0738],\n",
       "          [ 0.0379],\n",
       "          [ 0.0131],\n",
       "          [ 0.0016],\n",
       "          [-0.0221],\n",
       "          [ 0.1428],\n",
       "          [ 0.0473],\n",
       "          [-0.0496],\n",
       "          [-0.0792]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0200,  0.0335,  0.0103,  0.1302,  0.0255,  0.0801,  0.0218,\n",
       "             0.1145, -0.0863, -0.0181, -0.0587, -0.0206, -0.0191,  0.1315,\n",
       "             0.0927, -0.1174, -0.0435,  0.0026, -0.0592,  0.0172,  0.1315,\n",
       "            -0.1446, -0.0920,  0.0652, -0.1400, -0.0737, -0.0213, -0.1048,\n",
       "             0.0494, -0.0356, -0.1409, -0.0629,  0.1485,  0.1190,  0.1432,\n",
       "             0.0300,  0.0519,  0.1026,  0.1018, -0.0221, -0.1213,  0.0938,\n",
       "             0.1324, -0.1329, -0.0794, -0.0210, -0.0685, -0.1060,  0.1192,\n",
       "            -0.1313, -0.0311, -0.0292,  0.0917,  0.0030, -0.1464,  0.1508,\n",
       "             0.0654, -0.0411, -0.1095, -0.1267, -0.0921, -0.1515,  0.1446,\n",
       "             0.0429,  0.0443, -0.0678,  0.0006,  0.0788, -0.0442,  0.0086,\n",
       "            -0.0488, -0.0998, -0.0765,  0.0971, -0.1065,  0.1377, -0.1493,\n",
       "            -0.1408,  0.1459, -0.0481, -0.1191, -0.1450,  0.0868,  0.0668,\n",
       "             0.1019, -0.0496,  0.0304,  0.0687,  0.0451, -0.1004, -0.0484,\n",
       "             0.0603,  0.0033,  0.1341, -0.0932,  0.0037,  0.1356,  0.0060,\n",
       "             0.0132,  0.0712,  0.0899,  0.0646,  0.0602,  0.1139,  0.0914,\n",
       "            -0.0006, -0.1449,  0.0678,  0.0944,  0.1021, -0.0535,  0.0792,\n",
       "            -0.0422,  0.0030,  0.1401,  0.1353, -0.0558, -0.1065, -0.1083,\n",
       "             0.0070, -0.0180, -0.0346,  0.0977, -0.0152,  0.0721,  0.1480,\n",
       "             0.1271, -0.1346, -0.0555, -0.1356,  0.0812,  0.1159, -0.1121,\n",
       "            -0.0719,  0.1490, -0.0302,  0.1136,  0.0610, -0.0402, -0.0771,\n",
       "            -0.1459, -0.1472,  0.0403,  0.0441, -0.0691, -0.0815,  0.0386,\n",
       "             0.0457,  0.0258, -0.0387,  0.0279,  0.1367,  0.1463, -0.1453,\n",
       "            -0.0459,  0.0523, -0.0527, -0.1191, -0.0622, -0.0055,  0.0997,\n",
       "            -0.0528, -0.1347, -0.1380,  0.0963, -0.0650, -0.0464, -0.0016,\n",
       "             0.1113, -0.0155,  0.0832, -0.1290,  0.1054, -0.0351,  0.1185,\n",
       "             0.1473,  0.0862,  0.0792, -0.1094, -0.0501, -0.0468, -0.0883,\n",
       "             0.1031, -0.0312,  0.0262,  0.1274,  0.0284,  0.0965, -0.0532,\n",
       "            -0.0847, -0.1363,  0.1403,  0.0945, -0.0951,  0.0325,  0.1375,\n",
       "             0.0115, -0.1461, -0.0791,  0.0877,  0.0744, -0.1202, -0.0471,\n",
       "            -0.0898,  0.1150,  0.0293,  0.0453,  0.0781,  0.1067,  0.1124,\n",
       "             0.0273,  0.0810,  0.0431, -0.1068, -0.1007, -0.1366,  0.0268,\n",
       "            -0.0689,  0.1231, -0.0766,  0.0755, -0.0101,  0.1387,  0.0660,\n",
       "             0.1030,  0.1427, -0.0307,  0.0187, -0.0940, -0.1152,  0.0697,\n",
       "            -0.0502, -0.0506,  0.0776, -0.0652,  0.0788, -0.0489, -0.0499,\n",
       "            -0.0002,  0.0688,  0.0476,  0.0021, -0.0272, -0.0127,  0.0522,\n",
       "             0.1291,  0.1157,  0.0301, -0.1423,  0.0188,  0.0053,  0.0913,\n",
       "            -0.0818, -0.1383, -0.0635,  0.0301]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0365, -0.0044,  0.0374,  ...,  0.0447,  0.0720, -0.0298],\n",
       "          [ 0.0348, -0.0717, -0.0505,  ..., -0.0585, -0.0818,  0.0744],\n",
       "          [-0.0446,  0.0096, -0.1027,  ..., -0.0008, -0.0678,  0.0059],\n",
       "          ...,\n",
       "          [-0.0585, -0.0794, -0.0716,  ..., -0.0536,  0.0257,  0.0783],\n",
       "          [ 0.0629,  0.0268, -0.0784,  ..., -0.0467,  0.0997,  0.0138],\n",
       "          [-0.0050,  0.0768,  0.0006,  ..., -0.0718,  0.0735, -0.0258]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0564,  0.0374, -0.0565, -0.0403,  0.0398, -0.0226, -0.0226, -0.0339,\n",
       "           0.0056, -0.0437, -0.0230,  0.0278,  0.0006, -0.0120,  0.0544,  0.0453,\n",
       "          -0.0071,  0.0046, -0.0377,  0.0308, -0.0218, -0.0480,  0.0518, -0.0555,\n",
       "          -0.0513, -0.0231, -0.0289,  0.0106, -0.0129, -0.0421,  0.0088,  0.0374,\n",
       "          -0.0513,  0.0426, -0.0135,  0.0544, -0.0191, -0.0239,  0.0290,  0.0396,\n",
       "           0.0369, -0.0342, -0.0316,  0.0024, -0.0165, -0.0484,  0.0178, -0.0490,\n",
       "          -0.0310, -0.0459,  0.0478, -0.0159,  0.0296, -0.0068,  0.0340, -0.0246,\n",
       "           0.0382,  0.0411,  0.0180,  0.0176, -0.0194, -0.0238,  0.0565,  0.0474,\n",
       "          -0.0202, -0.0260, -0.0078, -0.0134, -0.0314,  0.0145,  0.0259, -0.0270,\n",
       "           0.0571, -0.0411,  0.0255,  0.0136, -0.0496,  0.0421, -0.0259,  0.0465,\n",
       "           0.0307, -0.0414,  0.0262,  0.0528,  0.0552, -0.0066, -0.0002, -0.0138,\n",
       "          -0.0312,  0.0327,  0.0199, -0.0231,  0.0242,  0.0210, -0.0042, -0.0490,\n",
       "           0.0115,  0.0352,  0.0142, -0.0556, -0.0343, -0.0570,  0.0202,  0.0102,\n",
       "           0.0106,  0.0065,  0.0048, -0.0020,  0.0431, -0.0090, -0.0103, -0.0192,\n",
       "          -0.0376, -0.0261,  0.0016,  0.0538, -0.0505, -0.0150, -0.0352, -0.0260,\n",
       "           0.0341, -0.0295, -0.0441,  0.0558, -0.0209,  0.0070,  0.0067, -0.0441,\n",
       "           0.0028, -0.0263,  0.0220,  0.0436,  0.0181, -0.0457, -0.0022, -0.0173,\n",
       "          -0.0350,  0.0064,  0.0235,  0.0483,  0.0435,  0.0284,  0.0380,  0.0205,\n",
       "           0.0190,  0.0473, -0.0188,  0.0326, -0.0126,  0.0223,  0.0487, -0.0338,\n",
       "          -0.0495,  0.0121, -0.0212, -0.0549, -0.0301, -0.0053,  0.0271, -0.0478,\n",
       "           0.0350,  0.0020,  0.0155,  0.0163, -0.0086, -0.0565,  0.0041, -0.0404,\n",
       "          -0.0180, -0.0236,  0.0374,  0.0563, -0.0349,  0.0446, -0.0097,  0.0273,\n",
       "           0.0309,  0.0367, -0.0340,  0.0459, -0.0262, -0.0136, -0.0208, -0.0527,\n",
       "           0.0305, -0.0257, -0.0556, -0.0364, -0.0017,  0.0205,  0.0507, -0.0446,\n",
       "          -0.0176, -0.0576,  0.0198, -0.0028,  0.0195, -0.0180,  0.0308,  0.0468,\n",
       "           0.0224,  0.0032,  0.0076,  0.0409,  0.0329, -0.0442,  0.0127, -0.0519,\n",
       "           0.0037,  0.0495,  0.0112,  0.0535,  0.0577,  0.0294,  0.0167,  0.0176,\n",
       "           0.0517, -0.0126, -0.0271,  0.0120, -0.0508, -0.0470, -0.0009,  0.0064,\n",
       "           0.0259,  0.0010,  0.0505,  0.0517, -0.0417, -0.0341, -0.0298,  0.0253,\n",
       "           0.0280, -0.0268, -0.0148,  0.0004, -0.0309,  0.0002,  0.0190,  0.0577,\n",
       "          -0.0447,  0.0144,  0.0159,  0.0248, -0.0295,  0.0216, -0.0246,  0.0321,\n",
       "          -0.0553, -0.0576, -0.0451, -0.0494,  0.0358,  0.0030, -0.0092,  0.0374],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0249, -0.0115, -0.0642,  ...,  0.0147, -0.0065, -0.0575],\n",
       "          [ 0.0708,  0.0296, -0.0935,  ...,  0.0081,  0.0051,  0.1012],\n",
       "          [-0.0703, -0.0519, -0.0942,  ...,  0.0823,  0.0633, -0.0469],\n",
       "          ...,\n",
       "          [-0.0871, -0.0548,  0.0464,  ...,  0.0388, -0.0517,  0.0068],\n",
       "          [-0.0816,  0.0633, -0.0865,  ..., -0.0538,  0.0129,  0.0427],\n",
       "          [-0.0292,  0.0716,  0.0712,  ..., -0.0403,  0.0879, -0.0478]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0279,  0.0088,  0.0394,  0.0265,  0.0031, -0.0203, -0.0445,  0.0448,\n",
       "           0.0023, -0.0030, -0.0421, -0.0356,  0.0553,  0.0294,  0.0309,  0.0567,\n",
       "           0.0057,  0.0114,  0.0364, -0.0145, -0.0082,  0.0541,  0.0474,  0.0214,\n",
       "          -0.0562,  0.0036, -0.0569, -0.0470, -0.0231,  0.0345, -0.0385, -0.0266,\n",
       "          -0.0096, -0.0190, -0.0043, -0.0237, -0.0174, -0.0406, -0.0187,  0.0392,\n",
       "           0.0397, -0.0075, -0.0282, -0.0308, -0.0516,  0.0464, -0.0098,  0.0069,\n",
       "          -0.0389, -0.0156,  0.0154,  0.0212,  0.0063, -0.0409,  0.0044, -0.0051,\n",
       "          -0.0076, -0.0434, -0.0071, -0.0081, -0.0482, -0.0322,  0.0307, -0.0030,\n",
       "           0.0555, -0.0533, -0.0433, -0.0238, -0.0563, -0.0453, -0.0191, -0.0497,\n",
       "           0.0087, -0.0293,  0.0100, -0.0351, -0.0559, -0.0465,  0.0541, -0.0363,\n",
       "          -0.0050, -0.0553,  0.0259,  0.0127, -0.0537,  0.0160,  0.0072,  0.0417,\n",
       "          -0.0542,  0.0217, -0.0019, -0.0023,  0.0295,  0.0409,  0.0282, -0.0121,\n",
       "           0.0541, -0.0564,  0.0266, -0.0077,  0.0229,  0.0022, -0.0314, -0.0119,\n",
       "          -0.0363,  0.0201, -0.0107, -0.0419, -0.0166, -0.0424,  0.0535,  0.0399,\n",
       "           0.0281,  0.0517,  0.0414,  0.0177, -0.0035, -0.0063,  0.0409,  0.0462,\n",
       "           0.0362,  0.0239, -0.0335, -0.0098, -0.0206,  0.0373, -0.0202,  0.0225,\n",
       "           0.0072, -0.0299,  0.0360,  0.0453, -0.0449, -0.0105,  0.0503, -0.0262,\n",
       "           0.0329, -0.0363, -0.0520, -0.0163, -0.0123,  0.0295,  0.0387,  0.0228,\n",
       "           0.0060, -0.0128,  0.0313,  0.0394, -0.0554, -0.0257,  0.0229,  0.0321,\n",
       "          -0.0359,  0.0093,  0.0413, -0.0230,  0.0079, -0.0388, -0.0240, -0.0068,\n",
       "           0.0404, -0.0229, -0.0411, -0.0288, -0.0435,  0.0500,  0.0362,  0.0089,\n",
       "           0.0486,  0.0407, -0.0135,  0.0387, -0.0502,  0.0377, -0.0099,  0.0175,\n",
       "          -0.0049,  0.0561, -0.0285, -0.0576,  0.0147,  0.0537, -0.0558,  0.0021,\n",
       "           0.0202,  0.0307,  0.0097,  0.0372, -0.0373, -0.0116, -0.0538,  0.0508,\n",
       "          -0.0511,  0.0269, -0.0185, -0.0445,  0.0142,  0.0382, -0.0299,  0.0090,\n",
       "          -0.0319,  0.0354, -0.0498, -0.0257,  0.0093, -0.0558, -0.0412,  0.0084,\n",
       "           0.0490,  0.0003, -0.0528,  0.0176, -0.0440, -0.0261,  0.0299,  0.0340,\n",
       "          -0.0203,  0.0360,  0.0292,  0.0298, -0.0439,  0.0349, -0.0411,  0.0052,\n",
       "           0.0483,  0.0550,  0.0170,  0.0477, -0.0038,  0.0090,  0.0430, -0.0107,\n",
       "          -0.0562,  0.0158,  0.0476, -0.0188, -0.0425,  0.0275, -0.0292, -0.0308,\n",
       "          -0.0045,  0.0382, -0.0042, -0.0343, -0.0107,  0.0332,  0.0388, -0.0420,\n",
       "           0.0104,  0.0368,  0.0069,  0.0464, -0.0475,  0.0071,  0.0165, -0.0470],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0846],\n",
       "          [ 0.0153],\n",
       "          [ 0.0844],\n",
       "          [ 0.0399],\n",
       "          [-0.0074],\n",
       "          [ 0.0638],\n",
       "          [-0.0765],\n",
       "          [ 0.0692],\n",
       "          [-0.1457],\n",
       "          [ 0.0401],\n",
       "          [ 0.0932],\n",
       "          [-0.1260],\n",
       "          [ 0.1025],\n",
       "          [-0.1464],\n",
       "          [-0.1345],\n",
       "          [-0.1291],\n",
       "          [ 0.0991],\n",
       "          [-0.1192],\n",
       "          [ 0.1282],\n",
       "          [-0.0005],\n",
       "          [-0.0485],\n",
       "          [-0.0502],\n",
       "          [-0.0893],\n",
       "          [-0.0718],\n",
       "          [ 0.0276],\n",
       "          [ 0.0629],\n",
       "          [ 0.0269],\n",
       "          [ 0.0798],\n",
       "          [ 0.1112],\n",
       "          [ 0.0373],\n",
       "          [ 0.0258],\n",
       "          [ 0.0019],\n",
       "          [ 0.0703],\n",
       "          [-0.1144],\n",
       "          [-0.0344],\n",
       "          [ 0.0023],\n",
       "          [ 0.0444],\n",
       "          [-0.1456],\n",
       "          [-0.1358],\n",
       "          [-0.0536],\n",
       "          [-0.1161],\n",
       "          [-0.0336],\n",
       "          [-0.1322],\n",
       "          [ 0.1461],\n",
       "          [ 0.0891],\n",
       "          [ 0.0962],\n",
       "          [-0.1111],\n",
       "          [-0.0737],\n",
       "          [ 0.1305],\n",
       "          [-0.1104],\n",
       "          [ 0.1000],\n",
       "          [-0.0064],\n",
       "          [ 0.0266],\n",
       "          [ 0.0334],\n",
       "          [ 0.0525],\n",
       "          [ 0.0874],\n",
       "          [ 0.0620],\n",
       "          [ 0.0909],\n",
       "          [ 0.0012],\n",
       "          [ 0.0122],\n",
       "          [ 0.0809],\n",
       "          [-0.1340],\n",
       "          [ 0.0940],\n",
       "          [ 0.0329],\n",
       "          [ 0.0824],\n",
       "          [-0.0082],\n",
       "          [ 0.0477],\n",
       "          [ 0.0251],\n",
       "          [-0.0973],\n",
       "          [ 0.1162],\n",
       "          [-0.0491],\n",
       "          [-0.0395],\n",
       "          [ 0.0414],\n",
       "          [-0.0047],\n",
       "          [ 0.0629],\n",
       "          [-0.0560],\n",
       "          [ 0.1087],\n",
       "          [-0.1374],\n",
       "          [-0.1483],\n",
       "          [-0.1288],\n",
       "          [-0.1008],\n",
       "          [-0.0080],\n",
       "          [ 0.0910],\n",
       "          [-0.1195],\n",
       "          [-0.0598],\n",
       "          [-0.0382],\n",
       "          [ 0.1483],\n",
       "          [ 0.0587],\n",
       "          [ 0.0494],\n",
       "          [-0.0760],\n",
       "          [-0.0411],\n",
       "          [ 0.0858],\n",
       "          [ 0.0799],\n",
       "          [ 0.1237],\n",
       "          [-0.0447],\n",
       "          [-0.0724],\n",
       "          [-0.0175],\n",
       "          [ 0.0818],\n",
       "          [ 0.1470],\n",
       "          [-0.0413],\n",
       "          [-0.0614],\n",
       "          [ 0.1486],\n",
       "          [-0.1277],\n",
       "          [-0.0893],\n",
       "          [-0.0746],\n",
       "          [ 0.0967],\n",
       "          [-0.1206],\n",
       "          [ 0.0672],\n",
       "          [ 0.1172],\n",
       "          [ 0.0013],\n",
       "          [-0.1332],\n",
       "          [ 0.0020],\n",
       "          [-0.0073],\n",
       "          [ 0.0979],\n",
       "          [-0.0575],\n",
       "          [ 0.1039],\n",
       "          [-0.1511],\n",
       "          [ 0.0571],\n",
       "          [-0.0703],\n",
       "          [ 0.0213],\n",
       "          [-0.0068],\n",
       "          [ 0.1177],\n",
       "          [-0.0592],\n",
       "          [-0.0291],\n",
       "          [ 0.1479],\n",
       "          [-0.0402],\n",
       "          [-0.0277],\n",
       "          [ 0.0154],\n",
       "          [ 0.1506],\n",
       "          [-0.0983],\n",
       "          [-0.1282],\n",
       "          [ 0.0788],\n",
       "          [ 0.0196],\n",
       "          [ 0.0147],\n",
       "          [ 0.1087],\n",
       "          [ 0.0050],\n",
       "          [ 0.0423],\n",
       "          [-0.1252],\n",
       "          [-0.0868],\n",
       "          [ 0.0626],\n",
       "          [ 0.0698],\n",
       "          [ 0.0159],\n",
       "          [ 0.0384],\n",
       "          [-0.0425],\n",
       "          [ 0.1233],\n",
       "          [ 0.1296],\n",
       "          [-0.0510],\n",
       "          [-0.1447],\n",
       "          [-0.0176],\n",
       "          [-0.0618],\n",
       "          [ 0.1195],\n",
       "          [ 0.0780],\n",
       "          [ 0.1013],\n",
       "          [-0.0526],\n",
       "          [-0.0303],\n",
       "          [ 0.1432],\n",
       "          [-0.0576],\n",
       "          [-0.0045],\n",
       "          [ 0.1338],\n",
       "          [ 0.1194],\n",
       "          [ 0.0606],\n",
       "          [-0.0056],\n",
       "          [-0.0527],\n",
       "          [ 0.1195],\n",
       "          [-0.1101],\n",
       "          [-0.0241],\n",
       "          [ 0.1439],\n",
       "          [ 0.1153],\n",
       "          [-0.0886],\n",
       "          [ 0.1248],\n",
       "          [ 0.1454],\n",
       "          [ 0.0690],\n",
       "          [-0.1488],\n",
       "          [ 0.0832],\n",
       "          [-0.0336],\n",
       "          [-0.0853],\n",
       "          [ 0.0824],\n",
       "          [ 0.0754],\n",
       "          [-0.1179],\n",
       "          [ 0.1215],\n",
       "          [ 0.0701],\n",
       "          [ 0.1293],\n",
       "          [ 0.1092],\n",
       "          [-0.0067],\n",
       "          [-0.0897],\n",
       "          [-0.1343],\n",
       "          [-0.0943],\n",
       "          [ 0.0898],\n",
       "          [ 0.1029],\n",
       "          [ 0.1414],\n",
       "          [-0.0391],\n",
       "          [ 0.0920],\n",
       "          [-0.1365],\n",
       "          [-0.1301],\n",
       "          [-0.0733],\n",
       "          [ 0.0152],\n",
       "          [-0.0131],\n",
       "          [-0.0714],\n",
       "          [ 0.0559],\n",
       "          [ 0.0582],\n",
       "          [ 0.0683],\n",
       "          [-0.0747],\n",
       "          [ 0.0160],\n",
       "          [ 0.0152],\n",
       "          [-0.1472],\n",
       "          [-0.0022],\n",
       "          [ 0.0093],\n",
       "          [ 0.0323],\n",
       "          [ 0.1235],\n",
       "          [-0.0745],\n",
       "          [ 0.0137],\n",
       "          [-0.0163],\n",
       "          [-0.0141],\n",
       "          [-0.1105],\n",
       "          [ 0.1217],\n",
       "          [-0.1480],\n",
       "          [-0.1028],\n",
       "          [ 0.1353],\n",
       "          [-0.1281],\n",
       "          [-0.0396],\n",
       "          [ 0.0043],\n",
       "          [ 0.0766],\n",
       "          [ 0.0372],\n",
       "          [-0.0877],\n",
       "          [ 0.0958],\n",
       "          [-0.1442],\n",
       "          [-0.1432],\n",
       "          [ 0.0439],\n",
       "          [ 0.1007],\n",
       "          [ 0.1216],\n",
       "          [ 0.0023],\n",
       "          [ 0.0057],\n",
       "          [-0.1288],\n",
       "          [ 0.0851],\n",
       "          [-0.1136],\n",
       "          [-0.0664],\n",
       "          [-0.1309],\n",
       "          [ 0.1210],\n",
       "          [ 0.1439],\n",
       "          [ 0.1214],\n",
       "          [-0.0467],\n",
       "          [-0.0207],\n",
       "          [-0.0791],\n",
       "          [ 0.0858],\n",
       "          [ 0.0942],\n",
       "          [ 0.0211],\n",
       "          [-0.0438],\n",
       "          [ 0.0785],\n",
       "          [ 0.0822],\n",
       "          [ 0.0834],\n",
       "          [-0.0967],\n",
       "          [ 0.0189],\n",
       "          [ 0.0373],\n",
       "          [ 0.1139],\n",
       "          [-0.0362],\n",
       "          [-0.1454]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3008, -0.2352,  0.3111, -0.1075, -0.3329, -0.2357,  0.0766,\n",
       "            -0.2914, -0.2891,  0.2938,  0.0834,  0.3777, -0.3902,  0.0478,\n",
       "            -0.0163, -0.0495, -0.3064, -0.0949, -0.4029,  0.1552, -0.2174,\n",
       "             0.1341, -0.0190, -0.3853, -0.1829, -0.1760, -0.2528, -0.3628,\n",
       "             0.1262, -0.0379,  0.2895,  0.3114],\n",
       "           [-0.0649, -0.2009,  0.0257, -0.3437,  0.1503,  0.1181, -0.0298,\n",
       "            -0.1202, -0.0127,  0.0504, -0.0691, -0.3948, -0.1886,  0.2101,\n",
       "             0.2732, -0.0557, -0.2040,  0.1887,  0.0369, -0.0883,  0.2437,\n",
       "            -0.1396, -0.1569, -0.3299,  0.1194, -0.0127, -0.3123, -0.1819,\n",
       "             0.0579, -0.0723, -0.3056, -0.0579],\n",
       "           [-0.3616,  0.2064,  0.1784,  0.3685, -0.2797,  0.1147, -0.3144,\n",
       "             0.1107,  0.1390, -0.3354,  0.4068, -0.0572, -0.0891, -0.1501,\n",
       "             0.2829, -0.1713,  0.3887, -0.3519,  0.1715,  0.2719,  0.3271,\n",
       "             0.1420,  0.1083, -0.3053, -0.2431,  0.0438, -0.1078, -0.2369,\n",
       "             0.2259, -0.1269,  0.0507, -0.3859],\n",
       "           [ 0.2775,  0.1409, -0.3753, -0.3248, -0.3585,  0.3696,  0.1145,\n",
       "            -0.3680, -0.3422,  0.1584,  0.2886,  0.2446,  0.2588,  0.1878,\n",
       "             0.2889, -0.3419,  0.0211,  0.1422, -0.0360,  0.2036,  0.3323,\n",
       "            -0.2973, -0.1346,  0.0176,  0.1835,  0.3811, -0.3785, -0.2356,\n",
       "             0.2535, -0.0118,  0.1306,  0.3588]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0544, -0.0185,  0.0342,  ...,  0.0276, -0.1099, -0.0327],\n",
       "          [-0.0908,  0.0999,  0.0075,  ..., -0.0178, -0.0235, -0.0547],\n",
       "          [ 0.0468,  0.0304, -0.1227,  ...,  0.1079,  0.0683,  0.0757],\n",
       "          ...,\n",
       "          [ 0.1045,  0.1011, -0.0854,  ..., -0.0427, -0.0160,  0.0916],\n",
       "          [-0.0361, -0.0555, -0.0041,  ..., -0.0221, -0.0110, -0.0961],\n",
       "          [-0.0123, -0.1236,  0.0199,  ..., -0.0985,  0.0757, -0.1199]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0165,  0.0369,  0.0244,  0.0153,  0.0108,  0.0591, -0.0594, -0.0180,\n",
       "           0.0203,  0.0444,  0.0072,  0.0426,  0.0338, -0.0414,  0.0559,  0.0490,\n",
       "          -0.0594,  0.0005,  0.0359, -0.0129,  0.0426, -0.0207,  0.0292,  0.0134,\n",
       "          -0.0591,  0.0003,  0.0518,  0.0512,  0.0065, -0.0158, -0.0248,  0.0157,\n",
       "           0.0032,  0.0412,  0.0103, -0.0485,  0.0247,  0.0002,  0.0141, -0.0326,\n",
       "          -0.0325,  0.0334,  0.0041,  0.0394,  0.0183, -0.0217,  0.0109, -0.0605,\n",
       "           0.0312, -0.0563, -0.0620,  0.0055,  0.0157,  0.0381,  0.0327,  0.0480,\n",
       "           0.0125,  0.0267,  0.0365, -0.0552,  0.0201, -0.0469, -0.0116, -0.0421,\n",
       "           0.0034,  0.0566,  0.0091,  0.0465,  0.0287,  0.0514, -0.0057, -0.0178,\n",
       "           0.0584, -0.0274, -0.0285, -0.0078,  0.0179,  0.0526,  0.0014,  0.0037,\n",
       "          -0.0573,  0.0044, -0.0537, -0.0303, -0.0008, -0.0428, -0.0020,  0.0139,\n",
       "          -0.0386, -0.0381,  0.0487, -0.0532, -0.0541, -0.0099,  0.0558, -0.0069,\n",
       "          -0.0456, -0.0293,  0.0580,  0.0110, -0.0177,  0.0351,  0.0470, -0.0082,\n",
       "           0.0271, -0.0513,  0.0610,  0.0062, -0.0004,  0.0403,  0.0600,  0.0191,\n",
       "          -0.0029,  0.0429,  0.0163, -0.0139,  0.0099,  0.0385,  0.0308,  0.0292,\n",
       "           0.0112,  0.0276,  0.0123, -0.0031,  0.0018, -0.0511,  0.0621, -0.0252],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0625, -0.0290,  0.1059,  ..., -0.1245,  0.0604,  0.0792],\n",
       "          [-0.0284,  0.0281,  0.0437,  ..., -0.1005,  0.0801, -0.0192],\n",
       "          [ 0.0469,  0.0740,  0.0258,  ..., -0.1088, -0.0481,  0.0801],\n",
       "          ...,\n",
       "          [-0.0748,  0.0726,  0.0978,  ..., -0.1150,  0.1196,  0.1064],\n",
       "          [-0.0202,  0.0426, -0.0367,  ...,  0.0158, -0.0532,  0.0015],\n",
       "          [-0.0716, -0.1134, -0.0361,  ..., -0.0042, -0.0435,  0.1159]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 2.2118e-02,  5.2835e-02,  5.3285e-02, -1.1410e-02, -2.4323e-02,\n",
       "           3.3181e-02, -1.0388e-02,  5.5569e-02, -4.9947e-02, -4.7093e-02,\n",
       "           4.5876e-02, -9.3385e-03,  4.2923e-02, -8.1284e-03, -9.6456e-03,\n",
       "           6.2416e-02,  3.1080e-02,  2.3060e-02,  1.1267e-03, -1.1972e-02,\n",
       "          -5.7452e-03, -1.1449e-02,  7.9728e-03, -4.2820e-02, -2.9579e-02,\n",
       "           3.0781e-02,  5.4018e-02, -9.4120e-03, -5.4205e-02, -3.8635e-02,\n",
       "           3.4037e-02,  4.8965e-02, -5.2075e-02, -1.8291e-02,  5.8281e-02,\n",
       "          -7.0522e-03, -3.4092e-02,  3.2336e-02,  1.3747e-02, -5.2140e-02,\n",
       "           2.6669e-02,  8.2083e-03, -3.7877e-02,  2.0207e-02,  4.6175e-02,\n",
       "           2.3198e-02,  4.3994e-02, -1.2092e-02, -4.9190e-02, -1.4788e-03,\n",
       "          -4.2161e-02, -2.3696e-02, -7.6174e-03, -6.6671e-04,  4.3200e-02,\n",
       "          -5.3606e-02,  1.7808e-02,  6.1724e-02, -3.3625e-02,  2.8193e-02,\n",
       "           3.0991e-02, -2.4430e-02, -2.4887e-03, -1.0219e-02, -4.0001e-02,\n",
       "           2.3580e-02,  8.6021e-04,  2.1430e-02,  5.4987e-02,  5.2671e-02,\n",
       "          -1.9537e-02, -2.9282e-02,  2.3041e-02,  3.6722e-02, -5.7986e-03,\n",
       "          -5.1217e-02, -5.7322e-02, -5.7088e-02,  1.5360e-02, -1.3166e-02,\n",
       "           5.9980e-03,  4.6070e-02,  5.8479e-02,  2.8044e-03, -2.2783e-02,\n",
       "           4.5618e-02, -4.1317e-02, -3.7663e-05, -4.5025e-03,  3.3520e-02,\n",
       "           4.9001e-02,  9.0558e-03,  7.3882e-03, -1.9333e-02,  2.6862e-03,\n",
       "           3.5874e-02, -3.8502e-02, -2.9562e-02, -1.6327e-02,  5.4355e-02,\n",
       "          -2.1239e-02,  4.9401e-02,  5.8673e-02,  3.8972e-02, -2.2046e-02,\n",
       "           3.1052e-02, -3.3328e-02, -2.9419e-02, -5.2175e-02, -5.8195e-02,\n",
       "           1.8262e-02,  5.4517e-02,  6.7291e-03,  2.2966e-02,  5.8634e-02,\n",
       "           1.1694e-02,  5.9998e-02, -2.6951e-02, -1.1777e-02,  4.6053e-02,\n",
       "           3.9992e-02,  5.9794e-02, -2.1033e-02,  3.8459e-02,  2.6930e-02,\n",
       "          -4.6748e-02,  5.5118e-02,  4.7914e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.1497e-01],\n",
       "          [ 3.7977e-03],\n",
       "          [ 1.4805e-01],\n",
       "          [ 8.9919e-02],\n",
       "          [ 1.1910e-01],\n",
       "          [ 2.7918e-02],\n",
       "          [-1.1297e-01],\n",
       "          [ 7.2707e-02],\n",
       "          [-1.7851e-01],\n",
       "          [ 5.4935e-02],\n",
       "          [-7.3413e-02],\n",
       "          [ 1.7452e-01],\n",
       "          [-1.9590e-01],\n",
       "          [ 1.8962e-01],\n",
       "          [-1.0671e-01],\n",
       "          [ 1.1270e-01],\n",
       "          [ 1.8444e-01],\n",
       "          [ 7.6649e-02],\n",
       "          [-2.1408e-01],\n",
       "          [ 1.2447e-01],\n",
       "          [-9.6043e-02],\n",
       "          [ 6.8374e-04],\n",
       "          [ 1.7860e-01],\n",
       "          [-1.6685e-01],\n",
       "          [-6.7270e-02],\n",
       "          [-1.4412e-01],\n",
       "          [-2.8191e-02],\n",
       "          [-1.5109e-01],\n",
       "          [-1.7139e-02],\n",
       "          [-1.8616e-01],\n",
       "          [-1.4355e-01],\n",
       "          [ 7.7322e-02],\n",
       "          [ 1.7772e-02],\n",
       "          [-1.8937e-01],\n",
       "          [ 5.0425e-02],\n",
       "          [-4.2599e-02],\n",
       "          [ 1.6352e-01],\n",
       "          [ 6.6411e-03],\n",
       "          [ 7.5609e-02],\n",
       "          [ 6.7098e-02],\n",
       "          [-1.8323e-01],\n",
       "          [ 1.6255e-01],\n",
       "          [-5.2304e-02],\n",
       "          [ 1.3945e-01],\n",
       "          [-1.0827e-01],\n",
       "          [-1.1599e-01],\n",
       "          [ 1.4666e-01],\n",
       "          [ 1.0457e-02],\n",
       "          [-1.2238e-01],\n",
       "          [ 1.6641e-02],\n",
       "          [ 1.2169e-02],\n",
       "          [-4.9272e-02],\n",
       "          [ 3.1071e-02],\n",
       "          [ 3.7247e-02],\n",
       "          [ 1.1305e-01],\n",
       "          [-1.5998e-01],\n",
       "          [-1.4523e-01],\n",
       "          [ 1.1574e-01],\n",
       "          [-1.6812e-01],\n",
       "          [-6.3338e-02],\n",
       "          [-1.4578e-01],\n",
       "          [ 2.1367e-02],\n",
       "          [ 1.8362e-01],\n",
       "          [ 1.7232e-01],\n",
       "          [ 1.2132e-01],\n",
       "          [ 1.2410e-02],\n",
       "          [-1.5787e-02],\n",
       "          [-1.7956e-01],\n",
       "          [-1.4951e-01],\n",
       "          [ 3.1559e-02],\n",
       "          [ 2.0854e-01],\n",
       "          [ 4.8983e-02],\n",
       "          [ 7.0943e-02],\n",
       "          [ 4.8436e-02],\n",
       "          [ 1.5045e-01],\n",
       "          [-2.1483e-01],\n",
       "          [ 1.3208e-01],\n",
       "          [ 1.2933e-01],\n",
       "          [-3.0557e-02],\n",
       "          [ 1.9751e-01],\n",
       "          [-1.8882e-01],\n",
       "          [ 1.5756e-01],\n",
       "          [ 1.8620e-01],\n",
       "          [ 3.7286e-02],\n",
       "          [-7.7559e-02],\n",
       "          [-9.8824e-02],\n",
       "          [-1.2208e-01],\n",
       "          [ 6.2827e-02],\n",
       "          [-1.2718e-01],\n",
       "          [-6.8051e-02],\n",
       "          [-1.9545e-02],\n",
       "          [ 9.0182e-02],\n",
       "          [ 8.8821e-02],\n",
       "          [ 5.5998e-02],\n",
       "          [-2.1521e-01],\n",
       "          [ 9.2292e-02],\n",
       "          [ 1.6341e-01],\n",
       "          [ 1.8818e-01],\n",
       "          [ 3.9387e-02],\n",
       "          [-1.8637e-01],\n",
       "          [-2.0723e-01],\n",
       "          [ 1.9629e-01],\n",
       "          [ 8.6068e-02],\n",
       "          [-7.5697e-02],\n",
       "          [ 1.4451e-01],\n",
       "          [-1.7080e-01],\n",
       "          [-1.6740e-01],\n",
       "          [-4.4096e-02],\n",
       "          [ 8.9809e-05],\n",
       "          [ 4.4306e-02],\n",
       "          [ 1.1393e-01],\n",
       "          [-1.8183e-01],\n",
       "          [-1.4595e-01],\n",
       "          [ 8.0718e-02],\n",
       "          [-1.3120e-01],\n",
       "          [-1.2461e-01],\n",
       "          [ 5.5107e-02],\n",
       "          [ 6.1095e-02],\n",
       "          [-9.1045e-02],\n",
       "          [-7.7831e-02],\n",
       "          [ 2.0737e-01],\n",
       "          [ 1.5231e-01],\n",
       "          [-7.7908e-02],\n",
       "          [ 5.3498e-02],\n",
       "          [ 2.0510e-01],\n",
       "          [ 2.7642e-02],\n",
       "          [ 1.8057e-01],\n",
       "          [-1.2083e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-1.6418e-01, -5.4290e-02, -3.2986e-02,  1.1669e-01,  1.3777e-01,\n",
       "             3.8522e-01, -3.7333e-01, -5.1196e-02, -3.7262e-01, -2.6894e-01,\n",
       "             3.4678e-01, -2.5270e-01,  2.3250e-01,  1.5455e-01,  3.8584e-01,\n",
       "             3.0269e-01, -3.9619e-02, -3.9963e-01, -2.5764e-01,  2.9363e-01,\n",
       "            -6.3183e-02, -3.8854e-01,  1.2348e-01,  3.9546e-01, -1.8129e-01,\n",
       "             1.6435e-01, -6.5020e-03, -1.4758e-01, -3.9836e-01, -3.7565e-01,\n",
       "             3.6333e-01, -2.7842e-01],\n",
       "           [-3.3315e-01,  3.1772e-01,  1.8060e-01, -1.4779e-01, -3.8252e-01,\n",
       "             2.5692e-01,  1.2366e-01, -2.8314e-01, -3.5646e-01, -2.0512e-01,\n",
       "             1.1366e-01, -3.9612e-01, -9.4884e-02, -1.0463e-01,  1.0151e-02,\n",
       "             2.3901e-01,  3.8503e-01, -3.9301e-01, -3.2731e-01, -2.5605e-01,\n",
       "             2.7781e-01, -3.0659e-01,  1.5739e-01,  1.5173e-01, -1.7282e-01,\n",
       "            -2.6391e-01, -3.8464e-01, -4.0726e-01,  3.6721e-01,  1.4798e-01,\n",
       "             1.6295e-01, -8.9312e-03],\n",
       "           [-2.8670e-01, -3.6838e-01, -1.5300e-01,  2.9119e-02, -4.0206e-01,\n",
       "             1.6584e-01, -2.1314e-01,  1.1055e-01,  3.1653e-01,  2.5626e-01,\n",
       "             3.3251e-01,  2.8874e-01,  1.8573e-01, -3.2722e-02,  1.3408e-04,\n",
       "            -2.7217e-01, -1.9775e-01, -1.7587e-01, -1.0181e-01,  4.0221e-02,\n",
       "             1.0557e-01,  2.8569e-01, -1.0937e-01,  1.7944e-01,  2.3095e-01,\n",
       "            -3.5202e-01, -1.3703e-01, -2.4067e-01, -1.2841e-01, -8.7442e-02,\n",
       "             1.2541e-01,  3.1249e-01],\n",
       "           [ 2.5272e-01, -3.8867e-01,  4.0523e-01, -2.1260e-01, -3.3371e-01,\n",
       "             2.4099e-01, -8.4293e-02,  1.8575e-01,  1.8240e-01, -2.3014e-01,\n",
       "             7.0030e-02,  2.7306e-02, -5.2220e-02,  1.9708e-01,  1.3796e-01,\n",
       "            -1.0948e-01,  2.7392e-01, -4.0339e-01, -3.7918e-01, -3.1086e-02,\n",
       "             2.0895e-01,  1.9563e-01, -4.0061e-01,  1.9141e-01, -2.5060e-01,\n",
       "            -3.1199e-01,  3.5437e-01,  1.0967e-01,  1.4607e-01,  2.4564e-03,\n",
       "             5.6302e-02,  7.3492e-02]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1245,  0.0779, -0.0921,  ..., -0.0672,  0.0097,  0.0995],\n",
       "          [ 0.0743, -0.1154, -0.0554,  ..., -0.0615, -0.1122, -0.0708],\n",
       "          [ 0.1211,  0.0297,  0.0086,  ..., -0.0576, -0.0673,  0.0514],\n",
       "          ...,\n",
       "          [-0.0551,  0.0554,  0.0444,  ...,  0.1201, -0.0512,  0.0555],\n",
       "          [-0.1208,  0.0484,  0.0118,  ..., -0.0340, -0.1050, -0.0334],\n",
       "          [-0.0383,  0.0467, -0.0272,  ..., -0.0690,  0.1058,  0.0260]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0335, -0.0045,  0.0540, -0.0146, -0.0221,  0.0430, -0.0500,  0.0249,\n",
       "          -0.0085, -0.0318, -0.0242, -0.0510, -0.0013, -0.0537,  0.0591, -0.0298,\n",
       "          -0.0596, -0.0425,  0.0262, -0.0523,  0.0096, -0.0561,  0.0584, -0.0572,\n",
       "          -0.0277,  0.0128, -0.0293, -0.0400, -0.0020,  0.0563,  0.0010,  0.0063,\n",
       "           0.0390,  0.0070,  0.0018,  0.0048, -0.0284,  0.0420,  0.0314, -0.0412,\n",
       "           0.0170,  0.0109, -0.0433, -0.0594, -0.0291,  0.0424, -0.0383, -0.0086,\n",
       "          -0.0024,  0.0155,  0.0499, -0.0247,  0.0220,  0.0161, -0.0557, -0.0296,\n",
       "          -0.0541,  0.0304, -0.0340,  0.0282,  0.0549,  0.0430, -0.0088, -0.0403,\n",
       "           0.0018,  0.0107, -0.0119, -0.0095,  0.0540,  0.0519, -0.0199, -0.0402,\n",
       "           0.0296,  0.0403,  0.0248,  0.0140,  0.0407, -0.0299,  0.0273,  0.0326,\n",
       "           0.0206, -0.0570,  0.0233, -0.0225, -0.0167, -0.0229, -0.0065,  0.0383,\n",
       "           0.0304, -0.0231, -0.0040,  0.0545, -0.0434, -0.0489, -0.0539,  0.0507,\n",
       "           0.0388, -0.0226, -0.0173,  0.0438, -0.0138,  0.0505,  0.0221, -0.0034,\n",
       "           0.0080,  0.0064,  0.0603,  0.0558, -0.0310, -0.0428,  0.0194, -0.0407,\n",
       "          -0.0359,  0.0268,  0.0104,  0.0443,  0.0073,  0.0169,  0.0513,  0.0608,\n",
       "          -0.0278,  0.0461,  0.0550, -0.0454,  0.0264,  0.0187, -0.0410,  0.0008],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0762,  0.0773, -0.0531,  ...,  0.0615, -0.1056, -0.0343],\n",
       "          [ 0.0338, -0.1074, -0.0330,  ..., -0.0642,  0.0317, -0.0934],\n",
       "          [-0.0771, -0.0297, -0.1109,  ..., -0.0096,  0.1145,  0.0395],\n",
       "          ...,\n",
       "          [-0.0276, -0.0673, -0.0905,  ...,  0.0020, -0.0367,  0.0849],\n",
       "          [-0.0754,  0.1227,  0.0015,  ..., -0.0447,  0.1113,  0.0660],\n",
       "          [-0.0647,  0.0230,  0.0519,  ...,  0.0493,  0.0016, -0.1062]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0370,  0.0117,  0.0069,  0.0515,  0.0179,  0.0479,  0.0370,  0.0481,\n",
       "           0.0252,  0.0557,  0.0155, -0.0303, -0.0202, -0.0192,  0.0518, -0.0272,\n",
       "           0.0004,  0.0322, -0.0157, -0.0465,  0.0537, -0.0194, -0.0288, -0.0496,\n",
       "          -0.0343, -0.0102,  0.0462, -0.0301,  0.0168,  0.0297,  0.0483,  0.0311,\n",
       "           0.0375,  0.0266,  0.0406,  0.0387,  0.0383,  0.0083, -0.0098, -0.0454,\n",
       "           0.0236,  0.0606,  0.0297, -0.0008,  0.0422, -0.0381, -0.0441,  0.0179,\n",
       "           0.0417, -0.0609, -0.0540,  0.0237, -0.0547, -0.0074, -0.0114,  0.0130,\n",
       "          -0.0164, -0.0307, -0.0435,  0.0204,  0.0317,  0.0072,  0.0049, -0.0327,\n",
       "           0.0050,  0.0349,  0.0378,  0.0481,  0.0277,  0.0555, -0.0364, -0.0389,\n",
       "           0.0557,  0.0358, -0.0485,  0.0461, -0.0247, -0.0010,  0.0255,  0.0216,\n",
       "           0.0060, -0.0365,  0.0568, -0.0345, -0.0010, -0.0170,  0.0543, -0.0559,\n",
       "          -0.0314,  0.0188,  0.0331, -0.0548,  0.0369,  0.0348, -0.0206,  0.0322,\n",
       "          -0.0532,  0.0298,  0.0187,  0.0559, -0.0013,  0.0151,  0.0546,  0.0178,\n",
       "          -0.0055, -0.0007,  0.0229, -0.0111,  0.0569, -0.0302, -0.0551, -0.0589,\n",
       "           0.0279,  0.0478,  0.0402, -0.0202,  0.0030, -0.0528, -0.0219, -0.0144,\n",
       "          -0.0131, -0.0319,  0.0087,  0.0375,  0.0310, -0.0340, -0.0389,  0.0248],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0604],\n",
       "          [ 0.0935],\n",
       "          [ 0.0025],\n",
       "          [-0.1914],\n",
       "          [-0.1798],\n",
       "          [ 0.0034],\n",
       "          [ 0.0215],\n",
       "          [-0.0128],\n",
       "          [-0.0464],\n",
       "          [ 0.1489],\n",
       "          [-0.0316],\n",
       "          [-0.0676],\n",
       "          [-0.0336],\n",
       "          [ 0.0505],\n",
       "          [-0.0774],\n",
       "          [-0.0343],\n",
       "          [-0.0066],\n",
       "          [ 0.0656],\n",
       "          [-0.0686],\n",
       "          [-0.0815],\n",
       "          [-0.1931],\n",
       "          [-0.0680],\n",
       "          [-0.1226],\n",
       "          [ 0.0346],\n",
       "          [ 0.0788],\n",
       "          [ 0.1228],\n",
       "          [ 0.1751],\n",
       "          [ 0.1585],\n",
       "          [ 0.0648],\n",
       "          [ 0.0912],\n",
       "          [ 0.1365],\n",
       "          [ 0.1415],\n",
       "          [ 0.0421],\n",
       "          [ 0.1088],\n",
       "          [ 0.1969],\n",
       "          [-0.1048],\n",
       "          [-0.0249],\n",
       "          [ 0.0894],\n",
       "          [-0.0024],\n",
       "          [ 0.0386],\n",
       "          [-0.0414],\n",
       "          [ 0.0773],\n",
       "          [ 0.1461],\n",
       "          [-0.0638],\n",
       "          [-0.1946],\n",
       "          [ 0.1210],\n",
       "          [ 0.1036],\n",
       "          [-0.0987],\n",
       "          [-0.1363],\n",
       "          [ 0.1501],\n",
       "          [-0.1469],\n",
       "          [ 0.0685],\n",
       "          [ 0.0930],\n",
       "          [-0.1162],\n",
       "          [-0.0800],\n",
       "          [ 0.1038],\n",
       "          [-0.1825],\n",
       "          [-0.1095],\n",
       "          [ 0.1951],\n",
       "          [-0.1241],\n",
       "          [ 0.0878],\n",
       "          [-0.0861],\n",
       "          [-0.1894],\n",
       "          [-0.2025],\n",
       "          [ 0.2072],\n",
       "          [ 0.0792],\n",
       "          [ 0.1706],\n",
       "          [ 0.0470],\n",
       "          [ 0.0478],\n",
       "          [-0.1039],\n",
       "          [-0.0320],\n",
       "          [-0.2064],\n",
       "          [-0.2081],\n",
       "          [-0.1893],\n",
       "          [-0.0346],\n",
       "          [-0.1329],\n",
       "          [-0.0380],\n",
       "          [-0.0844],\n",
       "          [-0.0971],\n",
       "          [ 0.0073],\n",
       "          [ 0.2048],\n",
       "          [-0.0297],\n",
       "          [ 0.1842],\n",
       "          [ 0.0475],\n",
       "          [-0.1811],\n",
       "          [ 0.1454],\n",
       "          [-0.1613],\n",
       "          [-0.1922],\n",
       "          [ 0.1735],\n",
       "          [ 0.1883],\n",
       "          [ 0.0850],\n",
       "          [-0.0159],\n",
       "          [-0.0492],\n",
       "          [-0.1976],\n",
       "          [ 0.1118],\n",
       "          [ 0.0958],\n",
       "          [-0.1981],\n",
       "          [-0.1591],\n",
       "          [-0.2067],\n",
       "          [-0.0140],\n",
       "          [ 0.1642],\n",
       "          [ 0.1814],\n",
       "          [ 0.1497],\n",
       "          [ 0.1758],\n",
       "          [-0.1306],\n",
       "          [ 0.0351],\n",
       "          [-0.0761],\n",
       "          [-0.0016],\n",
       "          [ 0.1839],\n",
       "          [-0.1877],\n",
       "          [ 0.0692],\n",
       "          [ 0.0677],\n",
       "          [-0.0115],\n",
       "          [ 0.1545],\n",
       "          [ 0.1470],\n",
       "          [-0.0736],\n",
       "          [ 0.0053],\n",
       "          [-0.0840],\n",
       "          [-0.0360],\n",
       "          [-0.0773],\n",
       "          [-0.0685],\n",
       "          [-0.1557],\n",
       "          [-0.0586],\n",
       "          [-0.0352],\n",
       "          [-0.0931],\n",
       "          [-0.0906],\n",
       "          [ 0.1205],\n",
       "          [ 0.0298]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2711, -0.2116, -0.2082,  0.2691,  0.3802, -0.1360,  0.1251,\n",
       "             0.1804, -0.3702, -0.1804,  0.2962, -0.2757, -0.2075,  0.0747,\n",
       "            -0.3747, -0.1801,  0.0605, -0.3641,  0.2725,  0.1228, -0.1571,\n",
       "             0.2100,  0.2144, -0.0951, -0.4080, -0.2782, -0.0081, -0.1732,\n",
       "             0.1171, -0.3169,  0.1532, -0.1288],\n",
       "           [-0.3239,  0.0630,  0.0070,  0.0698, -0.2392, -0.3178, -0.0230,\n",
       "             0.1080,  0.3148, -0.0893, -0.1344, -0.1378, -0.3641,  0.3104,\n",
       "            -0.0087,  0.3105,  0.2574, -0.3389, -0.0719, -0.1630, -0.2236,\n",
       "             0.1049, -0.0223,  0.1578,  0.2608, -0.3506, -0.1565, -0.0708,\n",
       "            -0.3448, -0.3263,  0.0460, -0.2761],\n",
       "           [ 0.2520, -0.4064, -0.1345,  0.0602,  0.2700, -0.1916,  0.3455,\n",
       "             0.1499,  0.1749, -0.0654, -0.0729,  0.2302,  0.1702,  0.3009,\n",
       "             0.3492, -0.3634, -0.3143,  0.1570,  0.3825, -0.2770,  0.1200,\n",
       "             0.0925, -0.3307,  0.0997, -0.1839, -0.0268,  0.0780, -0.2779,\n",
       "            -0.3644,  0.3536,  0.0960, -0.0229],\n",
       "           [ 0.0668,  0.1631, -0.3007,  0.3181, -0.1746,  0.0620,  0.2583,\n",
       "             0.3882,  0.2154, -0.3115, -0.1330,  0.4062, -0.1838, -0.1213,\n",
       "             0.1929,  0.3753, -0.2803,  0.0301, -0.2532, -0.3859,  0.3417,\n",
       "             0.2224, -0.0073,  0.3661,  0.1391,  0.2901,  0.0798,  0.2366,\n",
       "             0.1749,  0.0685,  0.2611, -0.3261]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1123,  0.0403, -0.0043,  ..., -0.1051, -0.0073, -0.1070],\n",
       "          [ 0.0161,  0.0690,  0.1160,  ...,  0.0461, -0.0549, -0.0230],\n",
       "          [-0.1183, -0.0939, -0.0887,  ...,  0.0652,  0.1199, -0.1166],\n",
       "          ...,\n",
       "          [-0.0453,  0.0129,  0.1228,  ..., -0.1188,  0.0035, -0.1197],\n",
       "          [-0.1045, -0.0992, -0.1065,  ..., -0.0224,  0.0248, -0.0397],\n",
       "          [ 0.0862,  0.1043,  0.0652,  ...,  0.1050, -0.0417, -0.0696]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0324,  0.0534,  0.0071,  0.0227, -0.0107,  0.0092,  0.0303, -0.0321,\n",
       "          -0.0096, -0.0106,  0.0467, -0.0073,  0.0250,  0.0573,  0.0108,  0.0614,\n",
       "           0.0105,  0.0432,  0.0579,  0.0002, -0.0453,  0.0224,  0.0108,  0.0136,\n",
       "           0.0562,  0.0109,  0.0289,  0.0144,  0.0157,  0.0362, -0.0613,  0.0403,\n",
       "          -0.0371,  0.0328,  0.0298, -0.0236,  0.0587,  0.0308, -0.0230, -0.0064,\n",
       "           0.0430,  0.0530, -0.0282,  0.0536,  0.0324,  0.0379, -0.0023,  0.0432,\n",
       "          -0.0059,  0.0465,  0.0446, -0.0525,  0.0188, -0.0551,  0.0013, -0.0120,\n",
       "           0.0295,  0.0133, -0.0535, -0.0128, -0.0564,  0.0612, -0.0482, -0.0346,\n",
       "           0.0133,  0.0397,  0.0589, -0.0589, -0.0319,  0.0302, -0.0518, -0.0134,\n",
       "          -0.0474,  0.0468, -0.0220, -0.0311, -0.0452,  0.0212, -0.0532,  0.0409,\n",
       "          -0.0581,  0.0197,  0.0220, -0.0206,  0.0336,  0.0497,  0.0275,  0.0047,\n",
       "           0.0130,  0.0441, -0.0367,  0.0300, -0.0421, -0.0370,  0.0424,  0.0175,\n",
       "           0.0034, -0.0311, -0.0198,  0.0283,  0.0484, -0.0110, -0.0486, -0.0206,\n",
       "          -0.0166,  0.0299,  0.0277, -0.0604, -0.0555, -0.0100,  0.0126,  0.0160,\n",
       "          -0.0198,  0.0341,  0.0097,  0.0360, -0.0200,  0.0302,  0.0304,  0.0222,\n",
       "           0.0470,  0.0110, -0.0576,  0.0562,  0.0413, -0.0054,  0.0014,  0.0161],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1193, -0.0701, -0.0368,  ...,  0.1097, -0.1221,  0.1219],\n",
       "          [ 0.0247, -0.0510,  0.0430,  ...,  0.0809, -0.0208, -0.0864],\n",
       "          [ 0.0205, -0.0920,  0.1097,  ...,  0.0968, -0.0658,  0.0635],\n",
       "          ...,\n",
       "          [-0.0916, -0.0226, -0.1106,  ..., -0.0304, -0.0601, -0.1114],\n",
       "          [-0.1147,  0.0871, -0.0230,  ...,  0.0282, -0.0355, -0.0812],\n",
       "          [-0.1163,  0.0343,  0.1198,  ..., -0.0105,  0.0070, -0.0847]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0545,  0.0533,  0.0619, -0.0061,  0.0330,  0.0176, -0.0235,  0.0603,\n",
       "          -0.0587,  0.0532, -0.0621, -0.0433, -0.0012,  0.0487,  0.0511, -0.0187,\n",
       "           0.0378, -0.0098, -0.0240,  0.0559, -0.0573,  0.0463,  0.0492,  0.0008,\n",
       "           0.0231, -0.0015,  0.0189, -0.0011, -0.0120, -0.0258,  0.0015, -0.0590,\n",
       "           0.0012,  0.0370,  0.0439, -0.0474, -0.0433,  0.0205, -0.0416, -0.0313,\n",
       "           0.0162,  0.0192,  0.0606, -0.0450,  0.0492, -0.0601,  0.0228, -0.0565,\n",
       "          -0.0440,  0.0572, -0.0341, -0.0163,  0.0291, -0.0439, -0.0145, -0.0106,\n",
       "           0.0018, -0.0347,  0.0123, -0.0009,  0.0614, -0.0029,  0.0332,  0.0577,\n",
       "           0.0329, -0.0161, -0.0456,  0.0349,  0.0366,  0.0457, -0.0459,  0.0455,\n",
       "          -0.0482, -0.0046, -0.0015, -0.0034, -0.0617, -0.0335,  0.0315,  0.0079,\n",
       "          -0.0167,  0.0066, -0.0373,  0.0620,  0.0492,  0.0120,  0.0076,  0.0070,\n",
       "           0.0367,  0.0510, -0.0509, -0.0508,  0.0156, -0.0065,  0.0413,  0.0452,\n",
       "          -0.0462,  0.0050,  0.0367, -0.0376, -0.0306,  0.0485,  0.0385, -0.0412,\n",
       "          -0.0559,  0.0286, -0.0090, -0.0439,  0.0092,  0.0101, -0.0130,  0.0100,\n",
       "          -0.0504, -0.0343, -0.0561,  0.0430, -0.0030,  0.0390, -0.0426, -0.0266,\n",
       "          -0.0136, -0.0009, -0.0206, -0.0334, -0.0260, -0.0170,  0.0315, -0.0580],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0151],\n",
       "          [ 0.1186],\n",
       "          [ 0.0228],\n",
       "          [-0.0610],\n",
       "          [ 0.0923],\n",
       "          [-0.0724],\n",
       "          [ 0.1665],\n",
       "          [ 0.1169],\n",
       "          [ 0.0106],\n",
       "          [-0.1666],\n",
       "          [ 0.1382],\n",
       "          [ 0.0068],\n",
       "          [-0.2055],\n",
       "          [ 0.1402],\n",
       "          [-0.1240],\n",
       "          [ 0.0821],\n",
       "          [-0.0659],\n",
       "          [ 0.0380],\n",
       "          [-0.1338],\n",
       "          [-0.1227],\n",
       "          [-0.1654],\n",
       "          [-0.1929],\n",
       "          [ 0.0936],\n",
       "          [ 0.0023],\n",
       "          [ 0.0456],\n",
       "          [-0.1014],\n",
       "          [ 0.0833],\n",
       "          [-0.0736],\n",
       "          [ 0.0805],\n",
       "          [ 0.0310],\n",
       "          [ 0.1426],\n",
       "          [-0.1555],\n",
       "          [ 0.1487],\n",
       "          [ 0.1917],\n",
       "          [-0.0429],\n",
       "          [-0.0607],\n",
       "          [-0.0025],\n",
       "          [ 0.0606],\n",
       "          [-0.0005],\n",
       "          [ 0.0489],\n",
       "          [-0.0961],\n",
       "          [-0.1691],\n",
       "          [-0.0137],\n",
       "          [ 0.0525],\n",
       "          [ 0.1920],\n",
       "          [-0.0442],\n",
       "          [ 0.0542],\n",
       "          [-0.0783],\n",
       "          [-0.0024],\n",
       "          [-0.0687],\n",
       "          [-0.0945],\n",
       "          [ 0.0915],\n",
       "          [ 0.1358],\n",
       "          [ 0.1115],\n",
       "          [ 0.0963],\n",
       "          [ 0.1407],\n",
       "          [-0.1510],\n",
       "          [-0.1899],\n",
       "          [ 0.1274],\n",
       "          [ 0.1377],\n",
       "          [-0.1767],\n",
       "          [-0.0978],\n",
       "          [ 0.0315],\n",
       "          [-0.0156],\n",
       "          [ 0.0509],\n",
       "          [-0.1666],\n",
       "          [ 0.1460],\n",
       "          [-0.0653],\n",
       "          [ 0.0344],\n",
       "          [ 0.0366],\n",
       "          [-0.1121],\n",
       "          [-0.1848],\n",
       "          [ 0.0983],\n",
       "          [-0.1115],\n",
       "          [-0.0282],\n",
       "          [-0.1059],\n",
       "          [-0.1546],\n",
       "          [ 0.0774],\n",
       "          [ 0.1587],\n",
       "          [-0.0227],\n",
       "          [-0.1992],\n",
       "          [ 0.1960],\n",
       "          [-0.0034],\n",
       "          [-0.0242],\n",
       "          [-0.0476],\n",
       "          [-0.1007],\n",
       "          [-0.1542],\n",
       "          [ 0.1894],\n",
       "          [ 0.0858],\n",
       "          [ 0.2154],\n",
       "          [ 0.1268],\n",
       "          [-0.1585],\n",
       "          [-0.0909],\n",
       "          [ 0.1242],\n",
       "          [ 0.1603],\n",
       "          [-0.2014],\n",
       "          [ 0.1825],\n",
       "          [ 0.2088],\n",
       "          [-0.1846],\n",
       "          [-0.0056],\n",
       "          [ 0.0543],\n",
       "          [-0.1249],\n",
       "          [ 0.1008],\n",
       "          [-0.1106],\n",
       "          [ 0.1772],\n",
       "          [-0.1160],\n",
       "          [-0.0745],\n",
       "          [ 0.0686],\n",
       "          [-0.1701],\n",
       "          [-0.1849],\n",
       "          [ 0.0031],\n",
       "          [-0.1518],\n",
       "          [-0.0020],\n",
       "          [ 0.1898],\n",
       "          [ 0.1703],\n",
       "          [-0.0792],\n",
       "          [-0.0589],\n",
       "          [-0.0882],\n",
       "          [-0.0841],\n",
       "          [-0.1545],\n",
       "          [ 0.0881],\n",
       "          [-0.0909],\n",
       "          [ 0.0332],\n",
       "          [-0.1944],\n",
       "          [ 0.2112],\n",
       "          [-0.1698],\n",
       "          [ 0.2030],\n",
       "          [-0.0779]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.3511,  0.2154, -0.3435,  0.0769,  0.3607, -0.3587,  0.3337,\n",
       "             0.2608,  0.3220, -0.0763, -0.1195,  0.3912, -0.1770,  0.1907,\n",
       "            -0.2827, -0.1062,  0.0208, -0.0758,  0.3855, -0.1375, -0.1747,\n",
       "             0.1064,  0.1655, -0.2808, -0.0340, -0.3226,  0.4065,  0.2889,\n",
       "            -0.3278,  0.1165,  0.0866, -0.1259],\n",
       "           [-0.3133,  0.3149,  0.1939, -0.2216,  0.0800, -0.0904,  0.2936,\n",
       "            -0.1424,  0.0123, -0.1035,  0.3935, -0.2194,  0.2744, -0.2073,\n",
       "             0.1879,  0.3568, -0.2598,  0.2518,  0.3479, -0.3057, -0.2952,\n",
       "             0.2436, -0.2060,  0.1746, -0.1973,  0.0006, -0.1200,  0.0790,\n",
       "             0.0796, -0.3979, -0.0953, -0.0566],\n",
       "           [-0.0808,  0.1424,  0.4028,  0.0438,  0.3302,  0.3027, -0.0881,\n",
       "            -0.1208, -0.3620,  0.1892, -0.2166, -0.0902,  0.2297, -0.2254,\n",
       "             0.1631,  0.0834, -0.1880,  0.1939,  0.1358, -0.2069, -0.3705,\n",
       "            -0.2195,  0.2927,  0.0797, -0.3983, -0.2761,  0.2139, -0.0522,\n",
       "            -0.0711,  0.2356, -0.1765,  0.3019],\n",
       "           [ 0.1918,  0.2671,  0.2146, -0.0611, -0.2112, -0.1136, -0.0455,\n",
       "            -0.2343, -0.0790,  0.3156, -0.2173, -0.3477, -0.1967, -0.2569,\n",
       "             0.0016, -0.0291, -0.2093, -0.0146,  0.0373,  0.2428, -0.2519,\n",
       "             0.3000,  0.2746,  0.4058, -0.0619,  0.3816,  0.3596, -0.1737,\n",
       "            -0.0945, -0.0386, -0.0118, -0.1502]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0168, -0.0040, -0.1099,  ...,  0.0152,  0.0178, -0.1102],\n",
       "          [ 0.0717, -0.0004, -0.0430,  ..., -0.1159,  0.1210, -0.0052],\n",
       "          [-0.0849,  0.0098,  0.1141,  ..., -0.0840,  0.0305,  0.0833],\n",
       "          ...,\n",
       "          [-0.0235,  0.0567,  0.0014,  ..., -0.0207, -0.0966, -0.0654],\n",
       "          [ 0.1166,  0.0872,  0.0773,  ..., -0.1182,  0.0834,  0.0297],\n",
       "          [-0.0970, -0.0526, -0.1030,  ...,  0.0777,  0.0782,  0.0381]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0141,  0.0624, -0.0341,  0.0026, -0.0048,  0.0134,  0.0398,  0.0377,\n",
       "          -0.0311, -0.0149,  0.0449,  0.0094,  0.0244, -0.0042,  0.0039,  0.0062,\n",
       "          -0.0561, -0.0167,  0.0083,  0.0596, -0.0129, -0.0592,  0.0103,  0.0204,\n",
       "          -0.0368,  0.0356, -0.0095, -0.0588,  0.0476, -0.0451,  0.0616, -0.0245,\n",
       "           0.0539, -0.0609,  0.0433,  0.0477,  0.0061,  0.0464, -0.0251,  0.0304,\n",
       "          -0.0622,  0.0467, -0.0589,  0.0243, -0.0055, -0.0329, -0.0583, -0.0543,\n",
       "          -0.0185,  0.0217,  0.0430,  0.0435, -0.0168,  0.0394, -0.0260,  0.0004,\n",
       "          -0.0306, -0.0474,  0.0252,  0.0260,  0.0106,  0.0336, -0.0614,  0.0402,\n",
       "           0.0175,  0.0395, -0.0253, -0.0367,  0.0534, -0.0222,  0.0005,  0.0463,\n",
       "           0.0305,  0.0148,  0.0522,  0.0068, -0.0544,  0.0095,  0.0388, -0.0332,\n",
       "           0.0482,  0.0069,  0.0328,  0.0388, -0.0598,  0.0124,  0.0419, -0.0342,\n",
       "          -0.0332,  0.0522,  0.0595, -0.0168, -0.0264,  0.0143, -0.0356,  0.0169,\n",
       "           0.0059, -0.0514, -0.0404,  0.0302, -0.0230,  0.0219, -0.0478, -0.0226,\n",
       "           0.0171, -0.0165, -0.0007,  0.0038, -0.0424,  0.0192,  0.0155, -0.0416,\n",
       "           0.0161,  0.0007,  0.0555, -0.0525, -0.0113, -0.0502,  0.0033, -0.0513,\n",
       "           0.0243,  0.0225, -0.0244,  0.0064, -0.0298, -0.0011,  0.0386,  0.0488],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0282, -0.1103,  0.0347,  ...,  0.1058,  0.0335,  0.1208],\n",
       "          [ 0.0034,  0.0852, -0.0981,  ...,  0.0886,  0.0714,  0.0450],\n",
       "          [ 0.0080, -0.0092,  0.1153,  ...,  0.0992,  0.0540, -0.0968],\n",
       "          ...,\n",
       "          [-0.1140,  0.1162, -0.0985,  ..., -0.0015,  0.0067, -0.0855],\n",
       "          [-0.1004, -0.0223, -0.1114,  ..., -0.1111,  0.0682, -0.1110],\n",
       "          [-0.0587, -0.0706,  0.0823,  ..., -0.0962,  0.0167,  0.0475]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0607, -0.0272,  0.0318,  0.0418, -0.0063,  0.0424, -0.0557, -0.0468,\n",
       "          -0.0476, -0.0325,  0.0486,  0.0541, -0.0074, -0.0608, -0.0272,  0.0100,\n",
       "          -0.0272,  0.0083,  0.0288,  0.0458,  0.0230,  0.0078,  0.0553, -0.0355,\n",
       "          -0.0505, -0.0453,  0.0555,  0.0416, -0.0057,  0.0442,  0.0265,  0.0030,\n",
       "          -0.0339,  0.0345,  0.0586, -0.0541, -0.0481, -0.0563, -0.0523,  0.0526,\n",
       "           0.0286, -0.0385, -0.0174,  0.0095,  0.0490,  0.0276,  0.0136,  0.0047,\n",
       "          -0.0255,  0.0389, -0.0033,  0.0278,  0.0051,  0.0541, -0.0155,  0.0139,\n",
       "          -0.0510, -0.0514,  0.0025, -0.0186,  0.0499, -0.0184,  0.0043,  0.0365,\n",
       "           0.0581, -0.0557,  0.0123,  0.0590, -0.0048,  0.0296,  0.0076, -0.0499,\n",
       "          -0.0109,  0.0446,  0.0314,  0.0310, -0.0017,  0.0521,  0.0158, -0.0544,\n",
       "           0.0371, -0.0198, -0.0607, -0.0007, -0.0306, -0.0139, -0.0377, -0.0402,\n",
       "          -0.0181,  0.0332,  0.0191, -0.0089,  0.0330,  0.0365,  0.0214,  0.0453,\n",
       "           0.0461, -0.0346,  0.0525, -0.0619, -0.0309, -0.0555, -0.0092,  0.0333,\n",
       "           0.0329, -0.0573,  0.0467,  0.0595,  0.0351, -0.0136, -0.0169,  0.0603,\n",
       "           0.0014, -0.0617,  0.0493, -0.0117, -0.0370,  0.0103,  0.0227, -0.0471,\n",
       "          -0.0515,  0.0330, -0.0158,  0.0533,  0.0414, -0.0475,  0.0112, -0.0403],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.3911e-01],\n",
       "          [-1.0837e-01],\n",
       "          [ 1.6659e-01],\n",
       "          [-1.7661e-01],\n",
       "          [ 9.0487e-03],\n",
       "          [ 4.8750e-02],\n",
       "          [-7.2225e-02],\n",
       "          [-9.2908e-02],\n",
       "          [ 7.0020e-02],\n",
       "          [ 7.4615e-02],\n",
       "          [ 1.8926e-01],\n",
       "          [ 1.3847e-01],\n",
       "          [-6.8849e-02],\n",
       "          [-7.8877e-02],\n",
       "          [ 1.3969e-01],\n",
       "          [-8.7694e-02],\n",
       "          [ 7.7982e-02],\n",
       "          [-9.1804e-02],\n",
       "          [-1.4199e-01],\n",
       "          [-1.6547e-02],\n",
       "          [-1.9344e-01],\n",
       "          [ 1.8438e-01],\n",
       "          [ 1.3454e-01],\n",
       "          [ 2.4284e-02],\n",
       "          [ 4.2648e-02],\n",
       "          [ 3.6204e-02],\n",
       "          [ 1.9594e-01],\n",
       "          [-1.2259e-01],\n",
       "          [ 1.6315e-01],\n",
       "          [ 1.2810e-01],\n",
       "          [ 7.7284e-02],\n",
       "          [-2.0199e-01],\n",
       "          [-1.1068e-01],\n",
       "          [ 9.0746e-02],\n",
       "          [ 1.0688e-01],\n",
       "          [ 1.1811e-01],\n",
       "          [ 1.2436e-01],\n",
       "          [-1.8282e-01],\n",
       "          [ 6.1500e-02],\n",
       "          [-1.7168e-01],\n",
       "          [-7.4918e-02],\n",
       "          [ 5.7581e-02],\n",
       "          [-1.1483e-01],\n",
       "          [-5.2079e-03],\n",
       "          [ 1.9455e-01],\n",
       "          [ 2.6814e-02],\n",
       "          [ 2.3884e-02],\n",
       "          [-4.0382e-03],\n",
       "          [-1.4585e-01],\n",
       "          [-1.2469e-01],\n",
       "          [-3.8190e-02],\n",
       "          [-1.3494e-01],\n",
       "          [ 1.1455e-01],\n",
       "          [-1.4307e-01],\n",
       "          [ 1.9287e-02],\n",
       "          [ 1.4534e-01],\n",
       "          [ 1.7047e-01],\n",
       "          [-2.0700e-01],\n",
       "          [ 1.3490e-01],\n",
       "          [ 1.6318e-01],\n",
       "          [ 8.5994e-02],\n",
       "          [-2.1455e-01],\n",
       "          [-1.6700e-02],\n",
       "          [-2.0497e-01],\n",
       "          [ 4.5524e-02],\n",
       "          [ 1.0980e-01],\n",
       "          [ 1.9078e-01],\n",
       "          [ 2.3717e-02],\n",
       "          [-1.2313e-01],\n",
       "          [-2.1264e-01],\n",
       "          [-1.9641e-01],\n",
       "          [ 2.1026e-02],\n",
       "          [-6.5747e-02],\n",
       "          [ 1.0684e-01],\n",
       "          [ 1.5122e-01],\n",
       "          [-1.5473e-01],\n",
       "          [ 1.5509e-01],\n",
       "          [ 3.4177e-02],\n",
       "          [ 1.4563e-01],\n",
       "          [-1.1162e-01],\n",
       "          [-8.9832e-02],\n",
       "          [-7.0307e-02],\n",
       "          [-1.6189e-01],\n",
       "          [-1.9310e-01],\n",
       "          [ 1.1582e-01],\n",
       "          [-1.7980e-01],\n",
       "          [-2.1298e-01],\n",
       "          [ 1.2007e-01],\n",
       "          [ 1.9377e-02],\n",
       "          [ 1.3644e-04],\n",
       "          [ 1.3128e-01],\n",
       "          [-1.1751e-01],\n",
       "          [-5.3953e-02],\n",
       "          [-1.8963e-01],\n",
       "          [ 1.7221e-01],\n",
       "          [ 1.0610e-01],\n",
       "          [ 1.6459e-01],\n",
       "          [-1.1421e-01],\n",
       "          [-1.9836e-01],\n",
       "          [ 3.9462e-02],\n",
       "          [ 8.7546e-02],\n",
       "          [ 8.7075e-02],\n",
       "          [ 1.9241e-01],\n",
       "          [-1.2418e-02],\n",
       "          [ 1.0236e-01],\n",
       "          [-1.7597e-01],\n",
       "          [-1.1294e-01],\n",
       "          [ 2.0673e-01],\n",
       "          [-4.7215e-02],\n",
       "          [-4.2568e-02],\n",
       "          [ 1.9327e-02],\n",
       "          [ 7.8675e-02],\n",
       "          [ 1.3423e-01],\n",
       "          [ 9.7466e-02],\n",
       "          [ 6.3894e-02],\n",
       "          [-1.7579e-01],\n",
       "          [-5.3159e-02],\n",
       "          [ 3.2000e-02],\n",
       "          [-2.2104e-02],\n",
       "          [ 2.0672e-01],\n",
       "          [-3.6246e-02],\n",
       "          [ 6.6013e-02],\n",
       "          [-6.3145e-02],\n",
       "          [ 1.4251e-02],\n",
       "          [ 4.1208e-02],\n",
       "          [ 9.1452e-03],\n",
       "          [ 1.6828e-01],\n",
       "          [-1.0391e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2542,  0.2987,  0.2341,  0.2782, -0.2093, -0.0310, -0.0332,\n",
       "            -0.1307, -0.0975, -0.0844,  0.3038,  0.1442,  0.3141,  0.2340,\n",
       "            -0.2422,  0.3524, -0.0908, -0.1283,  0.1126, -0.2678,  0.0786,\n",
       "            -0.2831,  0.2939, -0.0149,  0.3286,  0.0501, -0.0774,  0.0025,\n",
       "            -0.2729, -0.2882, -0.2348, -0.1214],\n",
       "           [-0.0971, -0.1147,  0.3257, -0.4054, -0.3272,  0.3130, -0.1746,\n",
       "             0.0656, -0.0860,  0.0728,  0.0402, -0.1427, -0.2823, -0.1807,\n",
       "             0.0050, -0.1939, -0.0938, -0.3103,  0.1511,  0.1337,  0.0317,\n",
       "             0.1737,  0.3718, -0.3547,  0.3573,  0.2007,  0.3249, -0.3895,\n",
       "            -0.0774,  0.0359, -0.2852, -0.0251],\n",
       "           [-0.0931,  0.3796,  0.0320,  0.0779,  0.0863, -0.0233,  0.1803,\n",
       "            -0.3483, -0.1504,  0.2814,  0.0137, -0.0825,  0.1961,  0.3105,\n",
       "            -0.1977,  0.0098, -0.3092, -0.1359,  0.2423, -0.0972,  0.1519,\n",
       "            -0.3307,  0.2414, -0.1124, -0.2034,  0.0828,  0.2207, -0.3214,\n",
       "             0.3661,  0.0156, -0.2820, -0.0176],\n",
       "           [-0.2651, -0.0069,  0.1232, -0.2163, -0.1387,  0.1783,  0.1879,\n",
       "            -0.1150, -0.0887, -0.3110, -0.2764,  0.2027, -0.2913,  0.1602,\n",
       "             0.1616,  0.3960,  0.3225,  0.0805, -0.3042,  0.1260,  0.1998,\n",
       "             0.0824,  0.0481,  0.0908, -0.4003, -0.3968,  0.0236, -0.0008,\n",
       "             0.2637, -0.4060,  0.2536,  0.2759]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1110,  0.0739, -0.0372,  ..., -0.0319,  0.0464, -0.0645],\n",
       "          [-0.0309,  0.1120, -0.0244,  ..., -0.1076,  0.0458,  0.1143],\n",
       "          [-0.0292, -0.1031, -0.0778,  ..., -0.0408, -0.0288, -0.0630],\n",
       "          ...,\n",
       "          [ 0.0185,  0.0865, -0.0728,  ...,  0.0444,  0.0806, -0.0935],\n",
       "          [ 0.1030,  0.0147, -0.0002,  ...,  0.1025,  0.1221, -0.0846],\n",
       "          [-0.1004, -0.0617, -0.0480,  ...,  0.0358,  0.0195, -0.1088]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0498, -0.0008, -0.0321,  0.0618, -0.0478,  0.0302,  0.0454, -0.0366,\n",
       "          -0.0335,  0.0394, -0.0202,  0.0306,  0.0299,  0.0323,  0.0221,  0.0622,\n",
       "           0.0443, -0.0169,  0.0392, -0.0053, -0.0272, -0.0542,  0.0338, -0.0349,\n",
       "          -0.0263, -0.0282, -0.0345, -0.0414, -0.0335, -0.0440, -0.0346, -0.0133,\n",
       "          -0.0389, -0.0456, -0.0410, -0.0261, -0.0130,  0.0058,  0.0165, -0.0081,\n",
       "           0.0063,  0.0251, -0.0524,  0.0353,  0.0434,  0.0459,  0.0102, -0.0544,\n",
       "           0.0467, -0.0147, -0.0181, -0.0245, -0.0518, -0.0579,  0.0172, -0.0225,\n",
       "           0.0178,  0.0522,  0.0583,  0.0093, -0.0537, -0.0429,  0.0018, -0.0381,\n",
       "          -0.0332, -0.0198, -0.0231, -0.0332,  0.0608, -0.0201,  0.0574, -0.0443,\n",
       "           0.0203,  0.0252, -0.0355,  0.0590, -0.0359, -0.0516, -0.0402, -0.0293,\n",
       "           0.0472, -0.0426, -0.0529,  0.0121, -0.0388, -0.0216, -0.0335,  0.0086,\n",
       "           0.0393, -0.0086, -0.0327,  0.0076,  0.0596, -0.0321, -0.0575,  0.0084,\n",
       "          -0.0485,  0.0093,  0.0347,  0.0586,  0.0156,  0.0208,  0.0049,  0.0150,\n",
       "          -0.0418,  0.0564,  0.0254,  0.0330, -0.0593, -0.0278, -0.0137,  0.0281,\n",
       "           0.0312, -0.0323,  0.0352, -0.0017,  0.0040, -0.0143,  0.0224, -0.0085,\n",
       "          -0.0607,  0.0255,  0.0344,  0.0256,  0.0058, -0.0061, -0.0567,  0.0014],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0145, -0.0716, -0.0820,  ...,  0.0332, -0.0205, -0.0867],\n",
       "          [-0.0858,  0.0201,  0.0946,  ...,  0.0925,  0.0773,  0.0466],\n",
       "          [ 0.1012,  0.1147, -0.1206,  ..., -0.1076, -0.0873,  0.0868],\n",
       "          ...,\n",
       "          [-0.0086, -0.0146,  0.0594,  ..., -0.0900,  0.0434,  0.0654],\n",
       "          [ 0.0542,  0.0473, -0.0298,  ...,  0.0786, -0.0512,  0.0011],\n",
       "          [-0.0267, -0.1061,  0.0186,  ..., -0.0464, -0.0037,  0.1056]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0180,  0.0054, -0.0419, -0.0174, -0.0411,  0.0521,  0.0310, -0.0244,\n",
       "          -0.0027, -0.0580,  0.0395,  0.0212, -0.0055, -0.0280, -0.0389, -0.0508,\n",
       "          -0.0598, -0.0122,  0.0137,  0.0432,  0.0027,  0.0345,  0.0560,  0.0554,\n",
       "           0.0441, -0.0587, -0.0115, -0.0457,  0.0207, -0.0160, -0.0083,  0.0296,\n",
       "           0.0465,  0.0530,  0.0391,  0.0289,  0.0222,  0.0452,  0.0410,  0.0420,\n",
       "           0.0514, -0.0385, -0.0328,  0.0351, -0.0188, -0.0611, -0.0274, -0.0505,\n",
       "           0.0421, -0.0430,  0.0258,  0.0389, -0.0203,  0.0507, -0.0614, -0.0266,\n",
       "          -0.0540,  0.0522, -0.0066,  0.0484, -0.0104, -0.0452, -0.0244,  0.0290,\n",
       "           0.0165,  0.0387,  0.0524, -0.0593, -0.0587, -0.0439, -0.0537,  0.0430,\n",
       "           0.0556,  0.0295, -0.0490, -0.0013, -0.0315,  0.0368,  0.0378,  0.0201,\n",
       "           0.0128,  0.0083,  0.0385, -0.0279, -0.0463,  0.0207, -0.0114, -0.0406,\n",
       "          -0.0063, -0.0610,  0.0112, -0.0443,  0.0572, -0.0024,  0.0096, -0.0451,\n",
       "          -0.0050, -0.0568,  0.0071,  0.0545, -0.0009,  0.0104,  0.0399,  0.0487,\n",
       "          -0.0564,  0.0390,  0.0388,  0.0567, -0.0544, -0.0491, -0.0146, -0.0578,\n",
       "           0.0617, -0.0476,  0.0339,  0.0106,  0.0185,  0.0264,  0.0553,  0.0297,\n",
       "           0.0109, -0.0122, -0.0589,  0.0182,  0.0601, -0.0481, -0.0296, -0.0333],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0822],\n",
       "          [-0.1212],\n",
       "          [-0.1573],\n",
       "          [ 0.1053],\n",
       "          [ 0.1612],\n",
       "          [-0.0319],\n",
       "          [ 0.1896],\n",
       "          [ 0.1900],\n",
       "          [ 0.0176],\n",
       "          [-0.1914],\n",
       "          [-0.0015],\n",
       "          [ 0.1085],\n",
       "          [-0.1018],\n",
       "          [ 0.1237],\n",
       "          [ 0.1260],\n",
       "          [ 0.0280],\n",
       "          [-0.0660],\n",
       "          [ 0.0072],\n",
       "          [-0.0877],\n",
       "          [ 0.0068],\n",
       "          [ 0.1357],\n",
       "          [-0.1971],\n",
       "          [ 0.1524],\n",
       "          [ 0.1638],\n",
       "          [ 0.0006],\n",
       "          [ 0.1651],\n",
       "          [-0.0495],\n",
       "          [ 0.0628],\n",
       "          [ 0.0313],\n",
       "          [-0.0373],\n",
       "          [-0.0949],\n",
       "          [ 0.0403],\n",
       "          [-0.0593],\n",
       "          [-0.1812],\n",
       "          [ 0.0628],\n",
       "          [ 0.1237],\n",
       "          [ 0.0072],\n",
       "          [-0.1884],\n",
       "          [ 0.0051],\n",
       "          [-0.0516],\n",
       "          [ 0.1726],\n",
       "          [-0.0131],\n",
       "          [ 0.1775],\n",
       "          [-0.0758],\n",
       "          [ 0.1057],\n",
       "          [ 0.0623],\n",
       "          [ 0.0097],\n",
       "          [-0.1837],\n",
       "          [-0.1964],\n",
       "          [-0.1033],\n",
       "          [-0.0800],\n",
       "          [ 0.0799],\n",
       "          [ 0.0571],\n",
       "          [-0.1682],\n",
       "          [ 0.0918],\n",
       "          [ 0.1389],\n",
       "          [-0.0028],\n",
       "          [ 0.1575],\n",
       "          [ 0.0395],\n",
       "          [ 0.1567],\n",
       "          [-0.0013],\n",
       "          [ 0.0378],\n",
       "          [ 0.2041],\n",
       "          [-0.0444],\n",
       "          [ 0.2092],\n",
       "          [-0.0110],\n",
       "          [ 0.0964],\n",
       "          [-0.1645],\n",
       "          [-0.1092],\n",
       "          [ 0.0428],\n",
       "          [ 0.1180],\n",
       "          [-0.1473],\n",
       "          [ 0.1318],\n",
       "          [ 0.1147],\n",
       "          [-0.1705],\n",
       "          [ 0.1882],\n",
       "          [-0.0092],\n",
       "          [ 0.1631],\n",
       "          [-0.0390],\n",
       "          [-0.1401],\n",
       "          [ 0.0729],\n",
       "          [-0.0344],\n",
       "          [-0.0234],\n",
       "          [-0.0062],\n",
       "          [ 0.1555],\n",
       "          [ 0.1651],\n",
       "          [ 0.0280],\n",
       "          [ 0.1507],\n",
       "          [ 0.1476],\n",
       "          [-0.0323],\n",
       "          [-0.0572],\n",
       "          [-0.0893],\n",
       "          [ 0.0855],\n",
       "          [-0.0317],\n",
       "          [ 0.1700],\n",
       "          [-0.1235],\n",
       "          [-0.1454],\n",
       "          [-0.0017],\n",
       "          [ 0.1151],\n",
       "          [ 0.0794],\n",
       "          [-0.1170],\n",
       "          [ 0.0950],\n",
       "          [ 0.0941],\n",
       "          [ 0.0654],\n",
       "          [ 0.1199],\n",
       "          [-0.1988],\n",
       "          [-0.1277],\n",
       "          [ 0.1585],\n",
       "          [ 0.0580],\n",
       "          [ 0.0408],\n",
       "          [-0.0045],\n",
       "          [ 0.1323],\n",
       "          [ 0.0839],\n",
       "          [ 0.2040],\n",
       "          [ 0.1402],\n",
       "          [ 0.0484],\n",
       "          [ 0.1019],\n",
       "          [-0.0699],\n",
       "          [ 0.1601],\n",
       "          [ 0.1593],\n",
       "          [-0.0612],\n",
       "          [ 0.1166],\n",
       "          [ 0.0115],\n",
       "          [-0.0513],\n",
       "          [ 0.1164],\n",
       "          [-0.1666],\n",
       "          [ 0.0588],\n",
       "          [ 0.0981]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2694,  0.3976, -0.3768, -0.1136, -0.2365,  0.2873,  0.2766,\n",
       "            -0.1791,  0.2546,  0.0211,  0.2645, -0.1166, -0.2984,  0.1525,\n",
       "             0.1005,  0.2492,  0.1996, -0.3768, -0.0175, -0.1601,  0.0818,\n",
       "            -0.3483, -0.3151,  0.0174, -0.0014, -0.0215, -0.1800,  0.0944,\n",
       "             0.1114,  0.3037,  0.1700,  0.0922],\n",
       "           [-0.2372, -0.3456,  0.0526,  0.0738, -0.0688, -0.3546,  0.3261,\n",
       "             0.3693,  0.3394, -0.1124,  0.0843,  0.2108, -0.3902,  0.1035,\n",
       "            -0.0563, -0.2141, -0.0266, -0.2718, -0.2725, -0.1449,  0.3406,\n",
       "            -0.3985, -0.1698,  0.2166, -0.1517, -0.0686, -0.2328, -0.3343,\n",
       "             0.1506, -0.1261, -0.2059, -0.0212],\n",
       "           [-0.3119,  0.0521, -0.3075, -0.2295,  0.0086, -0.1315,  0.3006,\n",
       "            -0.3767, -0.0052,  0.0752,  0.2735,  0.0214,  0.3824,  0.2531,\n",
       "             0.2916,  0.3712,  0.1915,  0.3169, -0.1088,  0.1734,  0.1116,\n",
       "             0.3195,  0.2991,  0.2647, -0.2870, -0.0082,  0.2664,  0.0987,\n",
       "             0.1347,  0.1178, -0.1784, -0.3299],\n",
       "           [-0.1587,  0.2742,  0.2919, -0.0067,  0.4034,  0.1070,  0.3886,\n",
       "             0.1613, -0.3691, -0.3315,  0.1763,  0.2972, -0.0642, -0.3354,\n",
       "             0.1213,  0.2266,  0.4052, -0.1003,  0.2908,  0.3355,  0.0342,\n",
       "             0.0944, -0.1166,  0.3795,  0.1018,  0.1279, -0.0052,  0.0153,\n",
       "             0.4011, -0.1204, -0.2600, -0.0187]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0693, -0.0652,  0.1160,  ...,  0.1197,  0.0910,  0.0874],\n",
       "          [-0.0202, -0.0056,  0.0597,  ...,  0.1239, -0.0599, -0.0550],\n",
       "          [ 0.1027,  0.0204, -0.1079,  ..., -0.0913, -0.0388, -0.0057],\n",
       "          ...,\n",
       "          [ 0.0623,  0.0038, -0.0476,  ...,  0.1242, -0.0099,  0.0775],\n",
       "          [ 0.0369, -0.1059,  0.0323,  ..., -0.0257,  0.0176, -0.0262],\n",
       "          [-0.0229,  0.0750, -0.0803,  ..., -0.0650, -0.0630,  0.0609]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0368,  0.0213,  0.0484,  0.0242, -0.0281,  0.0499,  0.0056,  0.0619,\n",
       "          -0.0094, -0.0461, -0.0393,  0.0615,  0.0361, -0.0098, -0.0555, -0.0603,\n",
       "           0.0295, -0.0154, -0.0002,  0.0576,  0.0059, -0.0588, -0.0556, -0.0567,\n",
       "           0.0611, -0.0253,  0.0469, -0.0173,  0.0264,  0.0158, -0.0081,  0.0333,\n",
       "          -0.0100,  0.0377,  0.0318, -0.0186,  0.0364, -0.0358, -0.0234, -0.0607,\n",
       "           0.0029, -0.0280, -0.0584, -0.0453, -0.0004,  0.0051,  0.0353, -0.0613,\n",
       "           0.0064,  0.0443,  0.0318, -0.0003,  0.0610,  0.0146, -0.0195,  0.0128,\n",
       "          -0.0146, -0.0587, -0.0208, -0.0152,  0.0412, -0.0163,  0.0463, -0.0608,\n",
       "           0.0503,  0.0021, -0.0483, -0.0395, -0.0013, -0.0029, -0.0323, -0.0040,\n",
       "          -0.0409,  0.0405, -0.0223,  0.0455,  0.0076, -0.0475,  0.0199, -0.0040,\n",
       "           0.0060, -0.0396,  0.0512,  0.0558,  0.0061, -0.0593, -0.0364, -0.0330,\n",
       "          -0.0095, -0.0602, -0.0262, -0.0410,  0.0367, -0.0384, -0.0382,  0.0227,\n",
       "           0.0049,  0.0097, -0.0446,  0.0207,  0.0224,  0.0495, -0.0599,  0.0190,\n",
       "          -0.0072,  0.0337,  0.0611,  0.0153, -0.0033,  0.0084, -0.0383, -0.0353,\n",
       "           0.0392, -0.0219,  0.0144, -0.0624,  0.0621, -0.0617, -0.0302, -0.0082,\n",
       "           0.0263,  0.0134,  0.0042, -0.0060,  0.0299, -0.0070,  0.0476,  0.0622],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0768,  0.0694, -0.0635,  ...,  0.0847, -0.0945,  0.0984],\n",
       "          [ 0.0308, -0.0882,  0.0250,  ..., -0.0280,  0.1212, -0.0099],\n",
       "          [-0.0491, -0.0057,  0.0721,  ...,  0.0959, -0.0172,  0.0362],\n",
       "          ...,\n",
       "          [-0.0576, -0.0498,  0.1237,  ..., -0.0786, -0.0752, -0.1232],\n",
       "          [ 0.0913,  0.0695,  0.0224,  ..., -0.0636, -0.0978,  0.0287],\n",
       "          [-0.0943,  0.1091, -0.0482,  ...,  0.0365,  0.0657,  0.0767]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.9594e-02, -2.2985e-02,  3.2152e-02, -3.0007e-02, -4.4357e-02,\n",
       "           6.1241e-02, -2.4153e-02, -9.5199e-03,  3.6193e-02,  3.3570e-02,\n",
       "          -2.6737e-02, -1.2173e-02,  5.4023e-02, -2.5439e-02,  2.0288e-02,\n",
       "          -5.0007e-02, -4.6238e-02,  3.3079e-02,  3.8825e-02,  3.7889e-02,\n",
       "          -5.6892e-02,  5.8160e-02,  5.9359e-02,  4.8013e-02, -3.2891e-02,\n",
       "           5.3275e-02,  1.2736e-02,  2.1103e-02,  3.9508e-02, -2.3121e-02,\n",
       "          -5.5850e-02, -9.7922e-04, -5.5216e-02, -2.3513e-02, -4.1910e-02,\n",
       "           3.3005e-03,  3.8565e-02, -9.9162e-03,  3.9721e-02, -4.5159e-02,\n",
       "           2.4233e-02,  3.4164e-02, -5.4843e-02,  3.1965e-03,  2.2508e-02,\n",
       "           8.1342e-03,  2.4304e-03,  1.7185e-02, -2.3961e-02, -3.4343e-02,\n",
       "          -8.5499e-03, -4.3031e-02, -6.0667e-02, -3.2250e-02,  1.4331e-02,\n",
       "           2.3759e-04,  4.1846e-02, -5.6005e-02, -3.5418e-02,  5.3826e-02,\n",
       "           1.3980e-03,  1.8875e-02, -3.2356e-02, -1.0849e-02,  3.1807e-02,\n",
       "           4.3966e-03, -5.5247e-02,  3.6877e-02,  4.8334e-02, -8.4435e-03,\n",
       "           2.0314e-02, -3.3479e-02,  2.6354e-02, -6.1608e-02, -5.9952e-02,\n",
       "          -4.4490e-02, -1.2828e-02,  4.9598e-02, -2.8995e-02, -1.1194e-02,\n",
       "          -1.7247e-02,  3.0326e-02,  2.4983e-02,  1.6847e-02,  1.9998e-02,\n",
       "           5.2314e-02, -5.4602e-02,  3.9729e-02,  4.2581e-02, -1.9486e-02,\n",
       "           6.0972e-02, -8.1636e-05,  1.3485e-02,  4.3258e-02, -4.4615e-02,\n",
       "           1.3707e-02, -5.9084e-02,  3.2134e-02, -2.4642e-03,  1.7150e-02,\n",
       "           4.5694e-02, -2.3765e-02,  4.8091e-02, -2.8578e-02, -3.3445e-02,\n",
       "           5.5313e-02,  9.7534e-03,  2.5375e-02, -2.5423e-02, -5.7433e-02,\n",
       "           4.9067e-02, -2.8484e-02, -4.6821e-02,  1.2993e-02,  4.5375e-02,\n",
       "           1.4912e-03, -3.5938e-02, -6.2090e-02,  1.3925e-02, -3.5740e-02,\n",
       "          -3.3894e-02, -1.8203e-02,  2.6636e-02,  8.3248e-03,  5.2390e-02,\n",
       "          -9.3007e-03, -4.6934e-02, -3.5032e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1810],\n",
       "          [ 0.0071],\n",
       "          [ 0.1484],\n",
       "          [ 0.0026],\n",
       "          [ 0.2148],\n",
       "          [ 0.1599],\n",
       "          [-0.1837],\n",
       "          [-0.1048],\n",
       "          [-0.2098],\n",
       "          [-0.0541],\n",
       "          [ 0.1612],\n",
       "          [ 0.1622],\n",
       "          [ 0.0887],\n",
       "          [-0.1848],\n",
       "          [ 0.1714],\n",
       "          [ 0.1893],\n",
       "          [ 0.0066],\n",
       "          [-0.1416],\n",
       "          [ 0.1441],\n",
       "          [ 0.1184],\n",
       "          [ 0.0050],\n",
       "          [ 0.1458],\n",
       "          [ 0.0087],\n",
       "          [ 0.0372],\n",
       "          [ 0.1627],\n",
       "          [ 0.0984],\n",
       "          [-0.1298],\n",
       "          [-0.1847],\n",
       "          [-0.2086],\n",
       "          [ 0.1968],\n",
       "          [-0.0215],\n",
       "          [ 0.0596],\n",
       "          [-0.1201],\n",
       "          [-0.0409],\n",
       "          [-0.0369],\n",
       "          [-0.0070],\n",
       "          [-0.1133],\n",
       "          [ 0.0057],\n",
       "          [-0.2002],\n",
       "          [-0.1866],\n",
       "          [-0.1321],\n",
       "          [-0.2107],\n",
       "          [ 0.0709],\n",
       "          [-0.1968],\n",
       "          [ 0.0444],\n",
       "          [-0.1397],\n",
       "          [-0.1629],\n",
       "          [ 0.0389],\n",
       "          [-0.0506],\n",
       "          [-0.0956],\n",
       "          [ 0.1211],\n",
       "          [-0.0090],\n",
       "          [-0.0333],\n",
       "          [ 0.1552],\n",
       "          [ 0.0563],\n",
       "          [ 0.0684],\n",
       "          [-0.2147],\n",
       "          [-0.0483],\n",
       "          [ 0.1442],\n",
       "          [-0.1787],\n",
       "          [ 0.1587],\n",
       "          [ 0.0323],\n",
       "          [ 0.1017],\n",
       "          [-0.2033],\n",
       "          [ 0.0717],\n",
       "          [-0.1422],\n",
       "          [ 0.0836],\n",
       "          [ 0.0566],\n",
       "          [ 0.2020],\n",
       "          [ 0.0031],\n",
       "          [-0.0422],\n",
       "          [-0.1887],\n",
       "          [-0.1966],\n",
       "          [ 0.1617],\n",
       "          [-0.1124],\n",
       "          [ 0.0932],\n",
       "          [ 0.0019],\n",
       "          [ 0.0726],\n",
       "          [ 0.0848],\n",
       "          [-0.1420],\n",
       "          [-0.0113],\n",
       "          [-0.0706],\n",
       "          [ 0.2087],\n",
       "          [ 0.1187],\n",
       "          [-0.0861],\n",
       "          [-0.0767],\n",
       "          [-0.1975],\n",
       "          [ 0.0289],\n",
       "          [ 0.0345],\n",
       "          [ 0.0072],\n",
       "          [-0.1703],\n",
       "          [-0.0769],\n",
       "          [ 0.1923],\n",
       "          [ 0.1849],\n",
       "          [-0.0279],\n",
       "          [ 0.1445],\n",
       "          [-0.1200],\n",
       "          [ 0.2074],\n",
       "          [-0.1257],\n",
       "          [-0.2067],\n",
       "          [ 0.1187],\n",
       "          [ 0.1674],\n",
       "          [-0.0040],\n",
       "          [ 0.1325],\n",
       "          [ 0.2111],\n",
       "          [ 0.0873],\n",
       "          [ 0.1561],\n",
       "          [-0.1326],\n",
       "          [-0.0355],\n",
       "          [ 0.1445],\n",
       "          [-0.1565],\n",
       "          [-0.0587],\n",
       "          [ 0.0112],\n",
       "          [ 0.1631],\n",
       "          [-0.1625],\n",
       "          [-0.1896],\n",
       "          [ 0.0273],\n",
       "          [ 0.1087],\n",
       "          [ 0.1715],\n",
       "          [ 0.0180],\n",
       "          [-0.0600],\n",
       "          [ 0.1102],\n",
       "          [-0.2027],\n",
       "          [-0.1150],\n",
       "          [-0.1317],\n",
       "          [ 0.1927],\n",
       "          [-0.0077],\n",
       "          [ 0.2021]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1341, -0.2907,  0.2373, -0.0049,  0.1184, -0.2837, -0.1443,\n",
       "            -0.1117, -0.2426,  0.0751,  0.1790, -0.1915,  0.0560, -0.2684,\n",
       "            -0.2120,  0.0403,  0.0012, -0.2292,  0.0691, -0.3711, -0.1255,\n",
       "             0.0417, -0.0431,  0.2842, -0.4036,  0.0038,  0.1250, -0.1780,\n",
       "             0.2973, -0.0377,  0.0565,  0.3875],\n",
       "           [ 0.0024, -0.0209, -0.0176,  0.3614, -0.1764,  0.0717,  0.0357,\n",
       "            -0.0946, -0.3134, -0.2059,  0.0683, -0.3995, -0.3090,  0.2480,\n",
       "             0.3776,  0.2385, -0.0596,  0.3396, -0.3743, -0.2733,  0.2750,\n",
       "            -0.3641,  0.2528, -0.2816,  0.0273, -0.0123, -0.3954,  0.0881,\n",
       "             0.3034, -0.1719, -0.1590, -0.1363],\n",
       "           [-0.1990,  0.0669,  0.2749, -0.3245, -0.3855, -0.1440,  0.1215,\n",
       "             0.3508,  0.2942,  0.2739,  0.2485, -0.1827,  0.0715, -0.3481,\n",
       "            -0.1308, -0.2909,  0.0530, -0.3627,  0.2547, -0.0379,  0.0360,\n",
       "            -0.2362, -0.3290,  0.3410,  0.1837, -0.2389, -0.3118, -0.3150,\n",
       "             0.2774,  0.2603, -0.1027,  0.1656],\n",
       "           [-0.1507, -0.1115,  0.0804,  0.1627,  0.2859,  0.0805,  0.2252,\n",
       "             0.3497, -0.3875, -0.2523, -0.1255,  0.2962,  0.3412, -0.3808,\n",
       "             0.1071,  0.2433, -0.1066,  0.2977,  0.3307,  0.2019, -0.4042,\n",
       "            -0.2777, -0.1117, -0.0931, -0.1440,  0.1985,  0.2493,  0.0686,\n",
       "             0.2338, -0.1811,  0.3105, -0.0156]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0856,  0.0977, -0.0250,  ...,  0.0415,  0.0704, -0.1236],\n",
       "          [-0.0998,  0.0451,  0.0368,  ..., -0.0801, -0.0577, -0.0924],\n",
       "          [-0.0175,  0.0913,  0.0661,  ...,  0.0411,  0.0964, -0.1040],\n",
       "          ...,\n",
       "          [-0.0712, -0.0723, -0.0891,  ..., -0.0438,  0.0354,  0.0675],\n",
       "          [-0.0447, -0.0907, -0.0762,  ...,  0.1006,  0.0647,  0.0051],\n",
       "          [ 0.0627, -0.0197,  0.0076,  ...,  0.0940, -0.1237,  0.0893]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0593,  0.0286,  0.0170, -0.0106,  0.0505, -0.0296, -0.0414,  0.0034,\n",
       "           0.0527,  0.0556, -0.0385, -0.0096,  0.0060, -0.0435, -0.0145,  0.0361,\n",
       "          -0.0540,  0.0126, -0.0475, -0.0045, -0.0482,  0.0079, -0.0362,  0.0454,\n",
       "           0.0402,  0.0500, -0.0053, -0.0227, -0.0239, -0.0345, -0.0064, -0.0452,\n",
       "          -0.0525, -0.0553, -0.0441,  0.0038,  0.0242,  0.0219, -0.0320, -0.0155,\n",
       "          -0.0064, -0.0045,  0.0187,  0.0026, -0.0436,  0.0572,  0.0390, -0.0026,\n",
       "          -0.0366, -0.0434,  0.0048, -0.0244,  0.0312, -0.0563, -0.0095,  0.0216,\n",
       "          -0.0324, -0.0380, -0.0489,  0.0219,  0.0511, -0.0185, -0.0311,  0.0436,\n",
       "          -0.0570, -0.0345,  0.0311, -0.0532,  0.0272,  0.0522, -0.0114,  0.0107,\n",
       "          -0.0016, -0.0384, -0.0382, -0.0407, -0.0366, -0.0582,  0.0522,  0.0101,\n",
       "           0.0255,  0.0602, -0.0580,  0.0602, -0.0057,  0.0181,  0.0263, -0.0050,\n",
       "           0.0250, -0.0503,  0.0076,  0.0450, -0.0040,  0.0119, -0.0075,  0.0247,\n",
       "          -0.0140,  0.0417, -0.0320, -0.0579, -0.0318, -0.0131,  0.0298,  0.0050,\n",
       "          -0.0539, -0.0357, -0.0043,  0.0474, -0.0148,  0.0577, -0.0207, -0.0597,\n",
       "           0.0337,  0.0473,  0.0516, -0.0410,  0.0236,  0.0390,  0.0054, -0.0021,\n",
       "          -0.0526, -0.0609,  0.0447, -0.0133,  0.0094,  0.0091, -0.0611,  0.0215],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1019,  0.0477, -0.1077,  ...,  0.0590,  0.0785,  0.0698],\n",
       "          [-0.0844, -0.0732,  0.1069,  ..., -0.0149, -0.0969,  0.0099],\n",
       "          [ 0.0357, -0.0472, -0.0056,  ..., -0.0150, -0.0579, -0.1116],\n",
       "          ...,\n",
       "          [-0.0021, -0.1195,  0.1042,  ...,  0.1116, -0.0973,  0.0871],\n",
       "          [-0.1208,  0.0904,  0.0223,  ...,  0.1097,  0.0784, -0.0384],\n",
       "          [ 0.0888, -0.0368,  0.0316,  ..., -0.0871,  0.0542, -0.0729]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0445, -0.0145, -0.0060, -0.0557,  0.0156,  0.0385,  0.0258,  0.0434,\n",
       "          -0.0046,  0.0105, -0.0133,  0.0437, -0.0277,  0.0267,  0.0156,  0.0200,\n",
       "          -0.0613,  0.0537, -0.0622,  0.0102,  0.0146,  0.0505, -0.0419, -0.0287,\n",
       "          -0.0577,  0.0110, -0.0465, -0.0487,  0.0010, -0.0363,  0.0247,  0.0577,\n",
       "          -0.0095,  0.0279, -0.0480,  0.0595, -0.0241,  0.0173,  0.0586,  0.0483,\n",
       "           0.0221,  0.0395, -0.0373,  0.0435,  0.0042, -0.0107, -0.0441,  0.0125,\n",
       "           0.0519,  0.0213,  0.0482, -0.0543,  0.0213,  0.0434,  0.0231,  0.0209,\n",
       "          -0.0541,  0.0418,  0.0442, -0.0259, -0.0237, -0.0612,  0.0008,  0.0480,\n",
       "           0.0337, -0.0386, -0.0405,  0.0602,  0.0538,  0.0040, -0.0111, -0.0030,\n",
       "           0.0286, -0.0002, -0.0435,  0.0576, -0.0337, -0.0371,  0.0362,  0.0610,\n",
       "          -0.0190,  0.0481, -0.0408,  0.0566, -0.0262,  0.0168,  0.0577, -0.0269,\n",
       "          -0.0399,  0.0512,  0.0150,  0.0068,  0.0464, -0.0554,  0.0622, -0.0566,\n",
       "          -0.0288, -0.0547, -0.0547,  0.0619, -0.0498, -0.0339,  0.0522, -0.0545,\n",
       "          -0.0386,  0.0509, -0.0132,  0.0008,  0.0255,  0.0087,  0.0024,  0.0538,\n",
       "           0.0192, -0.0105,  0.0290,  0.0453, -0.0387,  0.0254,  0.0090,  0.0151,\n",
       "           0.0254, -0.0120, -0.0621, -0.0115,  0.0160,  0.0081,  0.0445, -0.0621],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.7754e-02],\n",
       "          [ 1.0558e-02],\n",
       "          [-4.3854e-02],\n",
       "          [-1.1334e-01],\n",
       "          [-1.5674e-01],\n",
       "          [ 1.1096e-01],\n",
       "          [-6.8117e-02],\n",
       "          [-1.7460e-02],\n",
       "          [ 1.2999e-01],\n",
       "          [ 7.3124e-02],\n",
       "          [-1.6888e-01],\n",
       "          [-1.1849e-01],\n",
       "          [ 2.6314e-02],\n",
       "          [ 5.7637e-02],\n",
       "          [-5.0301e-02],\n",
       "          [-2.1382e-01],\n",
       "          [ 1.1159e-01],\n",
       "          [-5.5345e-02],\n",
       "          [ 1.3318e-01],\n",
       "          [ 1.9134e-01],\n",
       "          [ 3.5084e-02],\n",
       "          [-2.9763e-03],\n",
       "          [-1.2583e-01],\n",
       "          [-9.8838e-02],\n",
       "          [-1.6350e-01],\n",
       "          [ 8.3313e-02],\n",
       "          [-4.7468e-03],\n",
       "          [-3.8484e-02],\n",
       "          [ 5.3796e-02],\n",
       "          [-5.9746e-02],\n",
       "          [-8.6047e-02],\n",
       "          [ 3.2015e-02],\n",
       "          [-1.1524e-01],\n",
       "          [ 1.4223e-01],\n",
       "          [-9.6637e-02],\n",
       "          [-9.6908e-02],\n",
       "          [ 1.9588e-01],\n",
       "          [ 1.1511e-01],\n",
       "          [-1.3260e-01],\n",
       "          [-1.5932e-01],\n",
       "          [ 1.9019e-01],\n",
       "          [ 1.3563e-01],\n",
       "          [-7.6177e-02],\n",
       "          [ 1.5743e-01],\n",
       "          [ 2.1025e-01],\n",
       "          [ 1.0283e-01],\n",
       "          [-6.9535e-02],\n",
       "          [-7.0896e-03],\n",
       "          [ 1.5089e-01],\n",
       "          [-1.9486e-02],\n",
       "          [-8.6242e-02],\n",
       "          [ 1.3783e-01],\n",
       "          [ 7.1138e-02],\n",
       "          [ 3.9150e-02],\n",
       "          [ 3.9954e-02],\n",
       "          [-1.9979e-01],\n",
       "          [-9.3041e-02],\n",
       "          [ 8.1615e-02],\n",
       "          [ 4.2485e-02],\n",
       "          [-1.4404e-01],\n",
       "          [ 1.0007e-01],\n",
       "          [ 7.3297e-02],\n",
       "          [-2.1004e-01],\n",
       "          [-5.2296e-02],\n",
       "          [-3.5432e-02],\n",
       "          [-1.7953e-01],\n",
       "          [-1.8176e-01],\n",
       "          [-1.2134e-01],\n",
       "          [-1.9703e-01],\n",
       "          [-1.8673e-01],\n",
       "          [ 1.9833e-01],\n",
       "          [-7.5269e-02],\n",
       "          [ 1.0131e-01],\n",
       "          [-1.1583e-01],\n",
       "          [-1.8707e-01],\n",
       "          [-7.4628e-02],\n",
       "          [ 9.6025e-02],\n",
       "          [-2.0649e-01],\n",
       "          [ 1.5378e-05],\n",
       "          [-8.5004e-02],\n",
       "          [ 6.8493e-02],\n",
       "          [-1.1554e-01],\n",
       "          [-2.2698e-03],\n",
       "          [-1.4211e-01],\n",
       "          [ 3.7865e-02],\n",
       "          [ 1.7515e-01],\n",
       "          [-1.6479e-01],\n",
       "          [-4.8734e-02],\n",
       "          [ 1.5679e-01],\n",
       "          [-1.1100e-01],\n",
       "          [-7.5115e-02],\n",
       "          [ 5.1865e-02],\n",
       "          [ 1.5232e-01],\n",
       "          [ 1.2866e-02],\n",
       "          [ 2.0392e-01],\n",
       "          [ 1.8114e-01],\n",
       "          [ 4.5072e-02],\n",
       "          [-2.7589e-02],\n",
       "          [ 1.9611e-01],\n",
       "          [ 1.0457e-01],\n",
       "          [ 1.0226e-01],\n",
       "          [-5.9451e-03],\n",
       "          [-6.3381e-02],\n",
       "          [-1.0001e-01],\n",
       "          [-1.4862e-01],\n",
       "          [ 1.3495e-01],\n",
       "          [-1.6948e-01],\n",
       "          [-1.5868e-01],\n",
       "          [ 1.6498e-01],\n",
       "          [-7.3766e-02],\n",
       "          [-1.4668e-01],\n",
       "          [-9.5319e-03],\n",
       "          [ 1.8407e-02],\n",
       "          [-1.0430e-01],\n",
       "          [-1.5836e-01],\n",
       "          [ 1.1361e-01],\n",
       "          [-1.5198e-01],\n",
       "          [ 1.0077e-01],\n",
       "          [-8.5037e-02],\n",
       "          [ 1.3410e-01],\n",
       "          [-1.7311e-01],\n",
       "          [ 1.0301e-01],\n",
       "          [ 1.8164e-01],\n",
       "          [ 3.1661e-02],\n",
       "          [ 5.5125e-02],\n",
       "          [-6.0621e-02],\n",
       "          [ 9.2025e-02],\n",
       "          [ 1.1069e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 2.7646e-01,  7.9293e-02, -1.4193e-01,  2.2132e-01,  2.2018e-01,\n",
       "             2.5074e-01, -3.5152e-01,  2.4731e-01,  3.8592e-01,  1.8786e-01,\n",
       "            -3.1282e-01, -4.0199e-01, -7.6685e-02,  3.1023e-01,  2.6139e-01,\n",
       "             1.0614e-01, -1.6902e-01,  6.4182e-03, -3.8719e-01,  2.6950e-01,\n",
       "            -8.1508e-02, -3.4412e-01,  1.0335e-01,  5.5858e-02,  1.6147e-01,\n",
       "             2.4012e-01, -4.0552e-01,  1.8029e-01, -1.1903e-01,  3.0677e-01,\n",
       "            -2.0478e-01, -2.8681e-02],\n",
       "           [ 2.0264e-01, -3.2259e-02,  1.4665e-01,  2.6218e-01, -2.2073e-01,\n",
       "             1.7210e-01,  6.7425e-02, -1.3518e-01,  1.4826e-01, -7.4432e-02,\n",
       "            -1.2680e-01,  5.6162e-02, -1.3900e-01, -7.6822e-02,  7.8680e-02,\n",
       "            -1.7235e-01, -2.8789e-01,  2.0959e-01, -2.7620e-01,  1.8039e-02,\n",
       "             1.0580e-01,  3.3073e-01,  3.0610e-01, -1.3079e-01, -1.6150e-01,\n",
       "            -3.4617e-01, -1.0474e-01,  1.2814e-01,  8.5707e-02,  3.9744e-01,\n",
       "            -1.1637e-01,  2.5831e-02],\n",
       "           [ 2.7344e-01, -2.7721e-01,  3.7640e-02,  2.4263e-01,  2.3047e-01,\n",
       "             7.9177e-02,  3.3392e-01,  3.5703e-01, -5.2015e-02, -4.6465e-02,\n",
       "            -3.3039e-03, -3.4586e-01,  2.3947e-01,  1.4646e-01, -1.5158e-01,\n",
       "             3.0142e-01,  3.8440e-01, -3.2886e-01, -7.7053e-02,  3.7587e-01,\n",
       "             8.9364e-02, -2.8263e-01, -1.4441e-01,  2.6902e-02, -1.9194e-01,\n",
       "            -3.2190e-01, -2.9079e-01, -3.8897e-02,  3.0890e-01, -2.2018e-01,\n",
       "            -1.6973e-01, -2.5381e-01],\n",
       "           [-2.0600e-01,  1.1376e-01,  2.9090e-01, -4.8396e-02,  1.7064e-01,\n",
       "             4.0742e-01,  2.7195e-02,  1.3467e-01, -3.0350e-01, -8.4987e-02,\n",
       "            -3.8811e-01, -2.2229e-01,  2.4328e-01,  2.7561e-01, -3.4161e-01,\n",
       "             2.1358e-01, -3.5109e-01, -2.9132e-04,  9.8973e-02, -1.6254e-02,\n",
       "            -2.6067e-01, -1.7437e-01,  2.2177e-01,  2.5327e-01,  8.4026e-02,\n",
       "            -2.3334e-01,  3.8139e-01, -1.0335e-01, -1.6652e-01,  8.2974e-03,\n",
       "            -8.7751e-02, -3.3524e-01]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0430,  0.0611,  0.0271,  ...,  0.0436, -0.0521, -0.0934],\n",
       "          [ 0.0260,  0.0126,  0.0494,  ..., -0.0901, -0.0935,  0.0725],\n",
       "          [ 0.0120, -0.0341,  0.0338,  ..., -0.0124,  0.0633, -0.0787],\n",
       "          ...,\n",
       "          [ 0.0869, -0.0248, -0.0478,  ...,  0.0391,  0.0821, -0.0006],\n",
       "          [ 0.1085,  0.0073, -0.0579,  ..., -0.1073,  0.0953,  0.0992],\n",
       "          [ 0.0743,  0.0624,  0.0322,  ...,  0.0853,  0.1121,  0.0334]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0058,  0.0269, -0.0297,  0.0024, -0.0317,  0.0402, -0.0016, -0.0282,\n",
       "           0.0130,  0.0468,  0.0298, -0.0392, -0.0222,  0.0129, -0.0335,  0.0414,\n",
       "          -0.0084,  0.0396, -0.0277,  0.0519,  0.0383, -0.0250, -0.0446,  0.0255,\n",
       "          -0.0472, -0.0536,  0.0500,  0.0292,  0.0059,  0.0065,  0.0388,  0.0438,\n",
       "           0.0043, -0.0593, -0.0130,  0.0149, -0.0548,  0.0510, -0.0599, -0.0600,\n",
       "          -0.0410, -0.0263,  0.0022, -0.0105, -0.0109, -0.0076,  0.0148, -0.0603,\n",
       "          -0.0613, -0.0359,  0.0452,  0.0522, -0.0161, -0.0118, -0.0553, -0.0388,\n",
       "           0.0190, -0.0578,  0.0464, -0.0112,  0.0610, -0.0032,  0.0499, -0.0468,\n",
       "           0.0176,  0.0336, -0.0399, -0.0096,  0.0314, -0.0037,  0.0164,  0.0537,\n",
       "           0.0598,  0.0282,  0.0471, -0.0596, -0.0163, -0.0501,  0.0040, -0.0364,\n",
       "           0.0333, -0.0216,  0.0488, -0.0250,  0.0524,  0.0101,  0.0235,  0.0143,\n",
       "           0.0407,  0.0435, -0.0258, -0.0498, -0.0364, -0.0130, -0.0160,  0.0482,\n",
       "          -0.0441, -0.0442, -0.0381, -0.0327, -0.0235, -0.0214, -0.0559,  0.0412,\n",
       "           0.0367, -0.0454,  0.0368, -0.0460,  0.0025, -0.0624,  0.0195, -0.0021,\n",
       "          -0.0322, -0.0242, -0.0488,  0.0256, -0.0148, -0.0323,  0.0608, -0.0593,\n",
       "          -0.0369, -0.0116, -0.0317,  0.0323,  0.0556,  0.0289,  0.0149, -0.0223],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0914,  0.0771, -0.0124,  ...,  0.0787,  0.1135,  0.1103],\n",
       "          [-0.1199,  0.1211, -0.1056,  ..., -0.1202, -0.1198, -0.0822],\n",
       "          [-0.0213, -0.0624, -0.0220,  ...,  0.1164,  0.0082,  0.1150],\n",
       "          ...,\n",
       "          [ 0.0926, -0.0590,  0.0617,  ..., -0.1029, -0.1234, -0.0956],\n",
       "          [ 0.0742, -0.0768,  0.0242,  ...,  0.0963, -0.1247, -0.0634],\n",
       "          [-0.0093, -0.1136,  0.0366,  ..., -0.0212, -0.0441, -0.0504]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.6148e-02,  5.2215e-02,  6.1617e-02,  5.3692e-02, -3.6698e-02,\n",
       "           5.9050e-02,  4.4734e-02,  3.2319e-02, -2.1508e-02, -2.2447e-03,\n",
       "           2.0822e-03, -4.2309e-02, -3.7209e-02,  5.2169e-02, -9.7324e-03,\n",
       "           8.9208e-03, -5.7783e-02, -6.1541e-02, -1.6575e-02,  4.1454e-02,\n",
       "          -4.6619e-02, -6.0443e-03, -5.1629e-02,  6.1305e-03,  1.1200e-02,\n",
       "          -3.9865e-02, -1.0997e-02, -4.4400e-02,  4.7523e-02, -2.9862e-02,\n",
       "          -6.0242e-02,  1.2960e-02,  5.1502e-02,  1.2321e-02, -3.3719e-02,\n",
       "           4.3617e-02, -7.2240e-03,  2.9487e-02,  3.3955e-02, -2.7139e-02,\n",
       "           6.2356e-02, -8.0638e-03,  6.0564e-02,  5.9553e-02, -6.1991e-02,\n",
       "          -4.3982e-02,  1.3310e-02,  4.8422e-02, -4.5097e-02, -5.4266e-02,\n",
       "           2.4059e-02,  5.9271e-02,  9.8705e-03, -2.7204e-03, -2.3795e-02,\n",
       "           6.0535e-02,  5.5642e-02, -1.7987e-02, -5.8245e-02,  1.7485e-02,\n",
       "           1.4655e-02,  3.0341e-02,  1.2256e-02, -4.0137e-02, -4.8351e-02,\n",
       "           4.8024e-02,  1.4677e-02, -1.0002e-02, -5.0246e-02,  5.1654e-02,\n",
       "           3.3323e-02,  7.8868e-03, -8.6795e-03, -2.6980e-02,  6.1637e-02,\n",
       "           5.4045e-02,  6.1960e-02,  3.0125e-02, -1.9496e-02, -2.2458e-02,\n",
       "          -1.1761e-02, -3.3195e-02, -1.4644e-02, -2.5758e-02, -3.7536e-02,\n",
       "           4.0532e-02,  2.9298e-02,  5.0459e-02, -4.5147e-02,  5.6676e-03,\n",
       "           3.9838e-02, -2.0400e-02,  6.0369e-02, -2.1825e-02, -2.6350e-02,\n",
       "           2.5100e-02, -5.9520e-02,  2.3791e-02, -4.7135e-02,  1.8364e-02,\n",
       "           2.9113e-02, -1.2114e-02, -2.0352e-02,  5.6555e-02, -1.2175e-02,\n",
       "           4.2106e-02, -1.8837e-02, -1.5582e-03,  1.9636e-03,  2.7469e-02,\n",
       "          -3.3759e-02,  4.1675e-02, -5.1929e-02, -1.3429e-02,  2.6938e-02,\n",
       "          -4.6889e-02,  4.2631e-02, -5.3205e-02,  8.4495e-03,  6.0708e-02,\n",
       "           4.8501e-03,  5.8684e-02,  4.9818e-02,  5.5677e-02, -1.9560e-02,\n",
       "          -2.4751e-03,  8.5331e-05, -5.9054e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1607],\n",
       "          [ 0.1750],\n",
       "          [ 0.1151],\n",
       "          [ 0.1825],\n",
       "          [ 0.0639],\n",
       "          [-0.2103],\n",
       "          [-0.1051],\n",
       "          [-0.1550],\n",
       "          [-0.0577],\n",
       "          [ 0.1430],\n",
       "          [-0.2119],\n",
       "          [ 0.0212],\n",
       "          [-0.0986],\n",
       "          [-0.2147],\n",
       "          [ 0.0812],\n",
       "          [-0.1099],\n",
       "          [-0.1964],\n",
       "          [-0.0426],\n",
       "          [-0.1630],\n",
       "          [ 0.1254],\n",
       "          [ 0.1229],\n",
       "          [-0.0633],\n",
       "          [ 0.0409],\n",
       "          [ 0.1895],\n",
       "          [-0.1487],\n",
       "          [ 0.1760],\n",
       "          [-0.1687],\n",
       "          [-0.2005],\n",
       "          [ 0.2087],\n",
       "          [ 0.1046],\n",
       "          [ 0.1844],\n",
       "          [ 0.1539],\n",
       "          [ 0.2023],\n",
       "          [ 0.1235],\n",
       "          [ 0.1310],\n",
       "          [-0.1380],\n",
       "          [-0.2022],\n",
       "          [ 0.1993],\n",
       "          [ 0.0513],\n",
       "          [-0.1873],\n",
       "          [-0.1667],\n",
       "          [ 0.0022],\n",
       "          [ 0.1483],\n",
       "          [-0.0302],\n",
       "          [ 0.0894],\n",
       "          [ 0.1995],\n",
       "          [-0.1621],\n",
       "          [-0.0330],\n",
       "          [-0.0448],\n",
       "          [-0.2020],\n",
       "          [-0.2018],\n",
       "          [ 0.1761],\n",
       "          [-0.0013],\n",
       "          [ 0.1931],\n",
       "          [-0.0320],\n",
       "          [-0.1627],\n",
       "          [-0.0136],\n",
       "          [ 0.0925],\n",
       "          [ 0.1073],\n",
       "          [ 0.2011],\n",
       "          [-0.1817],\n",
       "          [ 0.0008],\n",
       "          [-0.1523],\n",
       "          [-0.1034],\n",
       "          [ 0.0412],\n",
       "          [ 0.1235],\n",
       "          [-0.0733],\n",
       "          [ 0.1260],\n",
       "          [ 0.1214],\n",
       "          [-0.1641],\n",
       "          [-0.1379],\n",
       "          [-0.0154],\n",
       "          [-0.1342],\n",
       "          [ 0.0867],\n",
       "          [ 0.0866],\n",
       "          [ 0.1211],\n",
       "          [ 0.1250],\n",
       "          [ 0.0633],\n",
       "          [ 0.0226],\n",
       "          [ 0.1965],\n",
       "          [ 0.0601],\n",
       "          [ 0.1546],\n",
       "          [-0.1325],\n",
       "          [-0.0220],\n",
       "          [-0.2113],\n",
       "          [-0.2060],\n",
       "          [ 0.0167],\n",
       "          [ 0.0554],\n",
       "          [-0.0258],\n",
       "          [ 0.1697],\n",
       "          [-0.1974],\n",
       "          [-0.1626],\n",
       "          [ 0.1502],\n",
       "          [-0.1105],\n",
       "          [-0.2130],\n",
       "          [ 0.1195],\n",
       "          [ 0.1504],\n",
       "          [-0.1731],\n",
       "          [ 0.2075],\n",
       "          [-0.1321],\n",
       "          [ 0.0882],\n",
       "          [ 0.0273],\n",
       "          [ 0.0245],\n",
       "          [-0.1509],\n",
       "          [-0.0780],\n",
       "          [-0.0283],\n",
       "          [ 0.0261],\n",
       "          [-0.1876],\n",
       "          [ 0.1536],\n",
       "          [-0.1859],\n",
       "          [-0.0973],\n",
       "          [ 0.0984],\n",
       "          [-0.1187],\n",
       "          [ 0.1962],\n",
       "          [-0.2055],\n",
       "          [ 0.0650],\n",
       "          [-0.0848],\n",
       "          [-0.0106],\n",
       "          [-0.1545],\n",
       "          [-0.1194],\n",
       "          [ 0.1898],\n",
       "          [ 0.0581],\n",
       "          [ 0.1170],\n",
       "          [-0.1843],\n",
       "          [ 0.2067],\n",
       "          [ 0.1102],\n",
       "          [ 0.0127],\n",
       "          [ 0.0767]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0743, -0.2166,  0.3293,  0.2891, -0.1661,  0.0435, -0.1430,\n",
       "             0.1105, -0.3153,  0.3179,  0.0687,  0.1091,  0.3332,  0.0479,\n",
       "            -0.0636,  0.3991, -0.0210,  0.4026,  0.0878,  0.2501,  0.1392,\n",
       "             0.1770, -0.1876,  0.1468,  0.2052, -0.3173,  0.3240,  0.3347,\n",
       "             0.3748, -0.1090, -0.1819, -0.0809],\n",
       "           [-0.2338, -0.2787, -0.2371,  0.1372, -0.0188,  0.0142,  0.1180,\n",
       "            -0.3538, -0.2306,  0.3128,  0.2116, -0.1237,  0.0329,  0.3258,\n",
       "             0.0753,  0.1710,  0.3534,  0.1015,  0.2387, -0.0485,  0.0011,\n",
       "            -0.3611,  0.3405, -0.1731,  0.2482,  0.3259, -0.1542, -0.3142,\n",
       "             0.1697,  0.0231, -0.3174, -0.3241],\n",
       "           [-0.0749, -0.1177, -0.0009,  0.2575,  0.0365, -0.3759, -0.0835,\n",
       "            -0.0271,  0.2150,  0.3399, -0.0771,  0.0601, -0.0225, -0.1298,\n",
       "             0.0785,  0.3250, -0.3854,  0.2563,  0.1994, -0.0719, -0.4059,\n",
       "            -0.2523,  0.1150,  0.3238, -0.2612, -0.1176, -0.0429,  0.0392,\n",
       "            -0.3724,  0.2971, -0.1036, -0.1372],\n",
       "           [-0.3191,  0.2338, -0.3145, -0.0433,  0.1492, -0.1281, -0.3940,\n",
       "             0.3105,  0.1095, -0.3566,  0.1908,  0.2341,  0.0667,  0.0293,\n",
       "            -0.1380, -0.1042, -0.1941, -0.2810,  0.0035,  0.3646, -0.3876,\n",
       "             0.3102,  0.2020, -0.3337, -0.1408, -0.1255,  0.2513, -0.1915,\n",
       "            -0.1748, -0.2308, -0.1799, -0.1334]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0459, -0.0778,  0.0988,  ..., -0.0088, -0.1040, -0.0165],\n",
       "          [ 0.1147,  0.0048, -0.0168,  ...,  0.0657, -0.1137, -0.0093],\n",
       "          [-0.0695, -0.0339, -0.0023,  ...,  0.0312, -0.0422, -0.0863],\n",
       "          ...,\n",
       "          [-0.0102,  0.0126, -0.0026,  ..., -0.1120, -0.0381, -0.0745],\n",
       "          [-0.0049, -0.0253, -0.1017,  ..., -0.0519, -0.0734, -0.0129],\n",
       "          [ 0.0289, -0.0628,  0.0789,  ...,  0.0754,  0.0040, -0.0677]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0329,  0.0266,  0.0401,  0.0501, -0.0469, -0.0105, -0.0026, -0.0393,\n",
       "           0.0221,  0.0575,  0.0443,  0.0604,  0.0337, -0.0472,  0.0353, -0.0084,\n",
       "           0.0383, -0.0344,  0.0451,  0.0186, -0.0077,  0.0012,  0.0132,  0.0442,\n",
       "           0.0618,  0.0473,  0.0125, -0.0027, -0.0018,  0.0152,  0.0261, -0.0416,\n",
       "           0.0073, -0.0006,  0.0308, -0.0596, -0.0081,  0.0534, -0.0429,  0.0111,\n",
       "          -0.0154,  0.0019,  0.0078,  0.0250, -0.0560, -0.0066,  0.0073,  0.0221,\n",
       "          -0.0172, -0.0410, -0.0072, -0.0304, -0.0306,  0.0584,  0.0331,  0.0075,\n",
       "          -0.0096, -0.0503,  0.0284, -0.0578, -0.0094, -0.0419,  0.0381, -0.0237,\n",
       "          -0.0404, -0.0566, -0.0565, -0.0388, -0.0192, -0.0107,  0.0331, -0.0217,\n",
       "           0.0204,  0.0048,  0.0515,  0.0438,  0.0427,  0.0081, -0.0076, -0.0524,\n",
       "          -0.0093,  0.0418,  0.0515,  0.0091,  0.0045, -0.0427, -0.0336,  0.0505,\n",
       "          -0.0523,  0.0224, -0.0111, -0.0006, -0.0568, -0.0356, -0.0335,  0.0109,\n",
       "          -0.0369,  0.0159,  0.0395, -0.0532,  0.0612, -0.0004, -0.0264,  0.0304,\n",
       "           0.0625,  0.0533,  0.0233, -0.0564,  0.0130,  0.0620, -0.0339, -0.0375,\n",
       "           0.0288,  0.0578, -0.0368, -0.0483,  0.0333,  0.0594,  0.0491, -0.0138,\n",
       "          -0.0199, -0.0252, -0.0052, -0.0250,  0.0003, -0.0501,  0.0502,  0.0525],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1080, -0.0132,  0.0794,  ..., -0.0110,  0.0062, -0.0374],\n",
       "          [ 0.0401,  0.0638, -0.0852,  ...,  0.0072, -0.1050, -0.0830],\n",
       "          [ 0.0431,  0.0804, -0.1183,  ...,  0.0709, -0.0801,  0.0577],\n",
       "          ...,\n",
       "          [ 0.1128,  0.0374,  0.0179,  ...,  0.0839,  0.1250,  0.0263],\n",
       "          [ 0.0271,  0.0989, -0.0778,  ...,  0.0903, -0.1200, -0.0827],\n",
       "          [ 0.0060, -0.0740, -0.0567,  ..., -0.0957,  0.1137,  0.1205]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0142, -0.0307, -0.0254,  0.0062, -0.0423,  0.0227, -0.0535, -0.0215,\n",
       "          -0.0133,  0.0556,  0.0385, -0.0064,  0.0185, -0.0568, -0.0565, -0.0504,\n",
       "          -0.0173, -0.0309, -0.0335,  0.0046,  0.0241, -0.0509,  0.0448, -0.0251,\n",
       "           0.0239,  0.0078,  0.0308,  0.0241,  0.0151,  0.0125, -0.0278,  0.0416,\n",
       "          -0.0032, -0.0610,  0.0045,  0.0540,  0.0233, -0.0337,  0.0128,  0.0108,\n",
       "           0.0360,  0.0468, -0.0101, -0.0075, -0.0455, -0.0158, -0.0221,  0.0530,\n",
       "           0.0456,  0.0565, -0.0532,  0.0282,  0.0321,  0.0531, -0.0205,  0.0386,\n",
       "          -0.0069, -0.0324, -0.0566, -0.0328,  0.0150,  0.0093, -0.0573, -0.0294,\n",
       "          -0.0053,  0.0481,  0.0506,  0.0196,  0.0166, -0.0554, -0.0275,  0.0256,\n",
       "           0.0337,  0.0345,  0.0284,  0.0275,  0.0115, -0.0548,  0.0540,  0.0362,\n",
       "          -0.0468, -0.0400, -0.0130,  0.0175, -0.0116,  0.0206, -0.0353,  0.0366,\n",
       "          -0.0155, -0.0079,  0.0003, -0.0051, -0.0494, -0.0327, -0.0355, -0.0367,\n",
       "          -0.0163, -0.0617,  0.0074, -0.0044,  0.0262, -0.0421,  0.0241, -0.0362,\n",
       "          -0.0166, -0.0565, -0.0508, -0.0385,  0.0166,  0.0463, -0.0333,  0.0446,\n",
       "          -0.0120,  0.0284,  0.0094,  0.0433, -0.0044,  0.0536,  0.0343, -0.0007,\n",
       "           0.0544, -0.0547, -0.0159,  0.0157,  0.0429,  0.0008,  0.0557, -0.0586],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0396],\n",
       "          [-0.0726],\n",
       "          [ 0.0143],\n",
       "          [-0.1496],\n",
       "          [ 0.0448],\n",
       "          [-0.1231],\n",
       "          [-0.0303],\n",
       "          [-0.1760],\n",
       "          [-0.0701],\n",
       "          [ 0.1320],\n",
       "          [ 0.0433],\n",
       "          [ 0.1187],\n",
       "          [ 0.1786],\n",
       "          [ 0.0758],\n",
       "          [ 0.2050],\n",
       "          [ 0.0530],\n",
       "          [ 0.0038],\n",
       "          [-0.0279],\n",
       "          [-0.0158],\n",
       "          [ 0.0222],\n",
       "          [-0.0709],\n",
       "          [ 0.2006],\n",
       "          [ 0.1939],\n",
       "          [ 0.2011],\n",
       "          [ 0.1554],\n",
       "          [-0.0464],\n",
       "          [ 0.1401],\n",
       "          [ 0.0164],\n",
       "          [ 0.2148],\n",
       "          [ 0.1209],\n",
       "          [-0.2060],\n",
       "          [ 0.0177],\n",
       "          [ 0.1793],\n",
       "          [-0.0850],\n",
       "          [-0.1783],\n",
       "          [ 0.1735],\n",
       "          [ 0.1203],\n",
       "          [-0.1152],\n",
       "          [-0.0088],\n",
       "          [-0.1109],\n",
       "          [-0.0535],\n",
       "          [-0.1739],\n",
       "          [ 0.1710],\n",
       "          [ 0.2130],\n",
       "          [-0.0559],\n",
       "          [-0.0921],\n",
       "          [ 0.1617],\n",
       "          [-0.1572],\n",
       "          [ 0.0165],\n",
       "          [-0.0787],\n",
       "          [-0.0641],\n",
       "          [-0.1451],\n",
       "          [ 0.1480],\n",
       "          [-0.1512],\n",
       "          [ 0.1873],\n",
       "          [ 0.0724],\n",
       "          [-0.0716],\n",
       "          [ 0.0612],\n",
       "          [-0.1386],\n",
       "          [-0.1261],\n",
       "          [ 0.1079],\n",
       "          [ 0.1949],\n",
       "          [-0.2006],\n",
       "          [ 0.0427],\n",
       "          [-0.0369],\n",
       "          [-0.0956],\n",
       "          [-0.1921],\n",
       "          [-0.1980],\n",
       "          [ 0.0416],\n",
       "          [-0.0707],\n",
       "          [ 0.1081],\n",
       "          [-0.1859],\n",
       "          [-0.0836],\n",
       "          [-0.1661],\n",
       "          [-0.0850],\n",
       "          [ 0.1852],\n",
       "          [ 0.1459],\n",
       "          [ 0.1029],\n",
       "          [-0.0109],\n",
       "          [ 0.0825],\n",
       "          [ 0.1837],\n",
       "          [-0.1848],\n",
       "          [-0.0586],\n",
       "          [ 0.0561],\n",
       "          [ 0.1968],\n",
       "          [ 0.0247],\n",
       "          [-0.0142],\n",
       "          [ 0.2099],\n",
       "          [-0.1395],\n",
       "          [ 0.1335],\n",
       "          [-0.0425],\n",
       "          [ 0.2138],\n",
       "          [ 0.0891],\n",
       "          [ 0.0366],\n",
       "          [ 0.1747],\n",
       "          [ 0.1140],\n",
       "          [ 0.1563],\n",
       "          [-0.1171],\n",
       "          [ 0.0490],\n",
       "          [-0.0057],\n",
       "          [ 0.1830],\n",
       "          [ 0.1760],\n",
       "          [-0.0621],\n",
       "          [-0.0177],\n",
       "          [ 0.1277],\n",
       "          [ 0.1263],\n",
       "          [-0.1007],\n",
       "          [ 0.0149],\n",
       "          [ 0.1796],\n",
       "          [-0.1377],\n",
       "          [-0.1747],\n",
       "          [-0.1457],\n",
       "          [ 0.0902],\n",
       "          [-0.0493],\n",
       "          [-0.0330],\n",
       "          [ 0.0739],\n",
       "          [-0.0736],\n",
       "          [ 0.1287],\n",
       "          [-0.2074],\n",
       "          [ 0.1929],\n",
       "          [ 0.0714],\n",
       "          [-0.1981],\n",
       "          [ 0.1688],\n",
       "          [-0.1911],\n",
       "          [ 0.1820],\n",
       "          [ 0.1200],\n",
       "          [ 0.2142],\n",
       "          [ 0.1699]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1121, -0.3374,  0.0694, -0.0792,  0.3856,  0.3200,  0.1856,\n",
       "             0.3819, -0.3074, -0.0428,  0.2646,  0.1188,  0.0021,  0.3883,\n",
       "            -0.1078,  0.2937,  0.1367,  0.1807, -0.1635, -0.3760,  0.3895,\n",
       "            -0.1014, -0.0769, -0.2747,  0.3936,  0.2627,  0.3400, -0.2108,\n",
       "             0.0154, -0.2037, -0.1782,  0.4167],\n",
       "           [-0.2715, -0.0032, -0.1583,  0.3152, -0.0768,  0.0646, -0.2237,\n",
       "             0.1622, -0.0459, -0.2043, -0.0242, -0.2497,  0.2812,  0.2633,\n",
       "            -0.2356, -0.2014,  0.3493,  0.3618,  0.2816, -0.4186, -0.0952,\n",
       "            -0.3239, -0.2222,  0.0295,  0.1008,  0.0042,  0.3941, -0.2017,\n",
       "            -0.2639, -0.3733, -0.4176,  0.3501]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0440,  0.0379, -0.1284,  ...,  0.1722,  0.0440, -0.1517],\n",
       "          [ 0.0137,  0.1673,  0.0441,  ...,  0.1171, -0.1767,  0.0451],\n",
       "          [ 0.1618,  0.1060, -0.1228,  ..., -0.0954,  0.0255,  0.0068],\n",
       "          ...,\n",
       "          [ 0.0877, -0.0579, -0.0984,  ..., -0.1658, -0.0743,  0.1567],\n",
       "          [ 0.1622,  0.1157, -0.1198,  ..., -0.0945,  0.1427, -0.1392],\n",
       "          [ 0.1746, -0.1518, -0.0370,  ..., -0.1712, -0.1284, -0.1382]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0848, -0.0113,  0.0243, -0.0881, -0.0393, -0.0576,  0.0596, -0.0289,\n",
       "           0.0432,  0.0625, -0.0234, -0.0346, -0.0794,  0.0423,  0.0116,  0.0428,\n",
       "           0.0073, -0.0679,  0.0158,  0.0877,  0.0412,  0.0244, -0.0291,  0.0695,\n",
       "          -0.0322,  0.0395, -0.0054, -0.0784,  0.0080, -0.0858, -0.0501, -0.0292,\n",
       "           0.0316,  0.0615, -0.0810, -0.0619, -0.0847,  0.0394,  0.0647, -0.0592,\n",
       "          -0.0295,  0.0411,  0.0466, -0.0260, -0.0606,  0.0523,  0.0658,  0.0558,\n",
       "           0.0563,  0.0509, -0.0376,  0.0243,  0.0113,  0.0702,  0.0446,  0.0538,\n",
       "           0.0677,  0.0151, -0.0688,  0.0060,  0.0243,  0.0380, -0.0662,  0.0370],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0837,  0.1539,  0.1179,  ...,  0.1458,  0.0113,  0.1194],\n",
       "          [ 0.0356,  0.1463, -0.0345,  ..., -0.0635,  0.1112,  0.1200],\n",
       "          [ 0.0985,  0.1515, -0.0565,  ..., -0.1607, -0.1106, -0.1652],\n",
       "          ...,\n",
       "          [-0.1752,  0.0841, -0.0651,  ..., -0.0368,  0.0246, -0.1277],\n",
       "          [-0.1671,  0.0330,  0.1238,  ..., -0.0657,  0.0033,  0.1679],\n",
       "          [ 0.1495, -0.1688,  0.1081,  ...,  0.1723, -0.0068,  0.1127]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0727, -0.0311, -0.0277,  0.0469,  0.0545, -0.0251, -0.0628,  0.0503,\n",
       "           0.0258,  0.0721,  0.0231, -0.0354,  0.0681,  0.0312, -0.0174,  0.0552,\n",
       "           0.0525,  0.0185,  0.0445,  0.0311, -0.0843,  0.0763,  0.0267,  0.0026,\n",
       "          -0.0287,  0.0844, -0.0188, -0.0593,  0.0111,  0.0273, -0.0561, -0.0624,\n",
       "          -0.0514, -0.0314,  0.0256,  0.0851, -0.0623, -0.0440, -0.0699, -0.0142,\n",
       "          -0.0007, -0.0153,  0.0281,  0.0223,  0.0641, -0.0650,  0.0481,  0.0797,\n",
       "          -0.0344,  0.0765,  0.0439,  0.0731,  0.0883, -0.0011,  0.0819,  0.0812,\n",
       "           0.0287,  0.0791, -0.0017, -0.0488,  0.0693, -0.0099, -0.0741,  0.0298],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2496],\n",
       "          [ 0.1675],\n",
       "          [ 0.0303],\n",
       "          [ 0.0487],\n",
       "          [-0.1151],\n",
       "          [ 0.1809],\n",
       "          [ 0.0636],\n",
       "          [-0.0914],\n",
       "          [-0.0591],\n",
       "          [ 0.2585],\n",
       "          [ 0.2826],\n",
       "          [-0.0355],\n",
       "          [-0.0688],\n",
       "          [ 0.1190],\n",
       "          [-0.3015],\n",
       "          [-0.1877],\n",
       "          [-0.0599],\n",
       "          [ 0.1160],\n",
       "          [ 0.1720],\n",
       "          [-0.2089],\n",
       "          [-0.0717],\n",
       "          [ 0.0350],\n",
       "          [ 0.1168],\n",
       "          [ 0.1849],\n",
       "          [ 0.0550],\n",
       "          [ 0.1449],\n",
       "          [ 0.1288],\n",
       "          [ 0.0804],\n",
       "          [ 0.2714],\n",
       "          [ 0.2240],\n",
       "          [ 0.2659],\n",
       "          [-0.1979],\n",
       "          [-0.0741],\n",
       "          [ 0.2999],\n",
       "          [-0.1323],\n",
       "          [-0.1906],\n",
       "          [ 0.2200],\n",
       "          [ 0.1413],\n",
       "          [ 0.0734],\n",
       "          [ 0.2553],\n",
       "          [ 0.0258],\n",
       "          [-0.2943],\n",
       "          [ 0.2536],\n",
       "          [ 0.2745],\n",
       "          [-0.1570],\n",
       "          [ 0.0403],\n",
       "          [-0.0372],\n",
       "          [-0.1910],\n",
       "          [-0.2702],\n",
       "          [-0.2894],\n",
       "          [ 0.1513],\n",
       "          [ 0.2534],\n",
       "          [ 0.0302],\n",
       "          [ 0.2004],\n",
       "          [ 0.2703],\n",
       "          [ 0.0568],\n",
       "          [-0.3000],\n",
       "          [-0.2395],\n",
       "          [-0.0285],\n",
       "          [ 0.2174],\n",
       "          [-0.1819],\n",
       "          [ 0.0074],\n",
       "          [-0.1199],\n",
       "          [ 0.1076]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-3.0545e-02, -1.2721e-01,  1.7900e-01, -5.6084e-02,  1.4432e-01,\n",
       "             1.6904e-01, -3.3352e-04,  1.0793e-01,  1.6962e-01,  2.8032e-01,\n",
       "             4.1231e-02,  1.4671e-01, -6.2095e-02, -3.3961e-01, -2.9591e-02,\n",
       "             2.2636e-01, -3.3481e-01, -4.0834e-01, -1.5850e-01, -5.0826e-02,\n",
       "             3.1723e-01, -1.9054e-01, -1.3262e-01, -2.8724e-01,  2.7800e-01,\n",
       "             2.5730e-02,  1.1094e-01, -4.0081e-01,  3.9269e-01,  3.1725e-01,\n",
       "            -2.0150e-01, -1.1443e-01],\n",
       "           [-2.8380e-01, -2.6677e-01,  1.6121e-01, -3.8857e-03, -2.6690e-01,\n",
       "             8.9493e-02, -1.7363e-01,  2.0785e-01,  1.0194e-01,  3.8185e-01,\n",
       "             2.5250e-02,  8.7135e-02, -1.6801e-01,  2.5233e-02, -3.8646e-01,\n",
       "            -1.1646e-02, -3.3037e-01,  2.7318e-01, -4.3036e-02,  1.8932e-01,\n",
       "            -1.6259e-01, -2.8232e-01,  3.2934e-01, -8.2760e-02, -2.8317e-01,\n",
       "            -1.8831e-01, -3.9938e-02,  5.3332e-03,  1.3970e-01,  2.1089e-01,\n",
       "             3.8460e-01,  3.9574e-02]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0070,  0.1460,  0.0522,  ..., -0.1728, -0.1719,  0.0707],\n",
       "          [-0.0356, -0.0689,  0.0181,  ..., -0.0744,  0.1687, -0.0047],\n",
       "          [-0.0260,  0.0776, -0.0676,  ..., -0.0091, -0.0994,  0.0709],\n",
       "          ...,\n",
       "          [ 0.0029,  0.0477, -0.1139,  ..., -0.1392, -0.1195, -0.0644],\n",
       "          [-0.0236,  0.0594,  0.0633,  ..., -0.0913, -0.0347, -0.1565],\n",
       "          [ 0.1136,  0.0862, -0.0882,  ..., -0.0345, -0.1497, -0.0085]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0536,  0.0610,  0.0470,  0.0864,  0.0549, -0.0765,  0.0213,  0.0199,\n",
       "          -0.0562, -0.0101, -0.0464, -0.0634,  0.0476,  0.0691, -0.0783,  0.0068,\n",
       "          -0.0136, -0.0245,  0.0509, -0.0429, -0.0641,  0.0537, -0.0202, -0.0184,\n",
       "           0.0252, -0.0061,  0.0070, -0.0348, -0.0865, -0.0171, -0.0198, -0.0830,\n",
       "           0.0453,  0.0059, -0.0833,  0.0832, -0.0396, -0.0221, -0.0414, -0.0168,\n",
       "          -0.0271,  0.0146, -0.0014,  0.0101,  0.0173,  0.0434,  0.0476,  0.0518,\n",
       "          -0.0017,  0.0051,  0.0637,  0.0259,  0.0762,  0.0305, -0.0123,  0.0082,\n",
       "          -0.0169,  0.0390, -0.0742, -0.0788,  0.0589,  0.0836,  0.0621,  0.0259],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0992,  0.1736, -0.0400,  ...,  0.1478, -0.0635, -0.1653],\n",
       "          [ 0.0548, -0.0539, -0.0329,  ...,  0.1000,  0.0593, -0.1097],\n",
       "          [-0.0057,  0.1105,  0.1088,  ...,  0.0310, -0.1385,  0.1285],\n",
       "          ...,\n",
       "          [ 0.0410,  0.0072, -0.1336,  ..., -0.0503,  0.0011, -0.0142],\n",
       "          [-0.1335,  0.1599,  0.0673,  ..., -0.0501,  0.1573, -0.1254],\n",
       "          [ 0.0471,  0.0220,  0.0743,  ..., -0.0435,  0.1095,  0.0368]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0130,  0.0517,  0.0875,  0.0107,  0.0463,  0.0373, -0.0264,  0.0659,\n",
       "          -0.0724,  0.0497,  0.0582, -0.0096, -0.0155, -0.0295,  0.0546, -0.0241,\n",
       "          -0.0053,  0.0017, -0.0768, -0.0324, -0.0133,  0.0746, -0.0767, -0.0761,\n",
       "           0.0394,  0.0685,  0.0457, -0.0819,  0.0354,  0.0755, -0.0323, -0.0412,\n",
       "          -0.0141, -0.0751, -0.0716,  0.0523, -0.0564, -0.0797, -0.0656, -0.0442,\n",
       "           0.0156,  0.0362, -0.0066, -0.0642, -0.0249, -0.0421, -0.0279,  0.0612,\n",
       "           0.0867, -0.0662,  0.0524, -0.0424, -0.0021,  0.0076,  0.0654,  0.0843,\n",
       "          -0.0434,  0.0417,  0.0123, -0.0561, -0.0753,  0.0628, -0.0825, -0.0238],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1977],\n",
       "          [-0.0659],\n",
       "          [-0.1918],\n",
       "          [ 0.2763],\n",
       "          [ 0.2077],\n",
       "          [ 0.0936],\n",
       "          [-0.1805],\n",
       "          [ 0.2265],\n",
       "          [-0.0204],\n",
       "          [-0.1006],\n",
       "          [-0.1089],\n",
       "          [ 0.1218],\n",
       "          [-0.1398],\n",
       "          [ 0.3002],\n",
       "          [ 0.0551],\n",
       "          [ 0.1842],\n",
       "          [-0.2765],\n",
       "          [-0.2731],\n",
       "          [-0.0112],\n",
       "          [ 0.0937],\n",
       "          [-0.2360],\n",
       "          [ 0.1678],\n",
       "          [-0.0402],\n",
       "          [ 0.2603],\n",
       "          [ 0.1488],\n",
       "          [-0.1781],\n",
       "          [-0.2253],\n",
       "          [-0.2615],\n",
       "          [-0.1431],\n",
       "          [-0.2610],\n",
       "          [-0.1955],\n",
       "          [ 0.2861],\n",
       "          [ 0.1783],\n",
       "          [ 0.2219],\n",
       "          [-0.0157],\n",
       "          [ 0.0337],\n",
       "          [-0.1412],\n",
       "          [ 0.1957],\n",
       "          [-0.1027],\n",
       "          [-0.0222],\n",
       "          [ 0.0128],\n",
       "          [ 0.0397],\n",
       "          [ 0.2931],\n",
       "          [ 0.1792],\n",
       "          [-0.2350],\n",
       "          [-0.2388],\n",
       "          [ 0.1256],\n",
       "          [ 0.0836],\n",
       "          [-0.0573],\n",
       "          [ 0.1583],\n",
       "          [-0.0823],\n",
       "          [-0.2097],\n",
       "          [-0.1813],\n",
       "          [-0.0788],\n",
       "          [-0.2813],\n",
       "          [ 0.0748],\n",
       "          [ 0.0543],\n",
       "          [ 0.2721],\n",
       "          [ 0.2457],\n",
       "          [ 0.1834],\n",
       "          [ 0.1556],\n",
       "          [-0.0398],\n",
       "          [ 0.1882],\n",
       "          [ 0.0431]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-1.1450e-01, -3.4967e-02, -6.7753e-02, -2.9963e-02,  3.0591e-01,\n",
       "            -1.5468e-01, -2.6987e-01, -2.9350e-01,  3.9746e-02,  2.9686e-01,\n",
       "            -9.6217e-02,  5.4181e-02, -3.2622e-03, -3.9177e-02,  1.4415e-01,\n",
       "            -7.9542e-02,  1.3088e-01,  2.9533e-01, -2.8871e-01,  2.3181e-01,\n",
       "            -3.5538e-01,  1.6985e-01,  4.2960e-02,  8.0879e-02, -2.6232e-01,\n",
       "             3.4181e-01, -1.4479e-01,  2.4776e-01,  2.1643e-01, -1.2209e-01,\n",
       "             1.3559e-01,  2.7320e-02],\n",
       "           [ 1.3786e-01, -3.4947e-01, -3.8615e-01, -3.3278e-01,  1.1165e-01,\n",
       "            -6.0721e-02,  2.3194e-01, -2.5805e-01, -2.6281e-01,  3.0937e-01,\n",
       "             4.4080e-02, -3.8388e-01, -4.0698e-04, -3.3961e-01,  3.9244e-01,\n",
       "            -2.7655e-01,  3.2084e-01,  3.9206e-01,  2.0429e-01,  1.4918e-01,\n",
       "            -3.2867e-01, -4.0337e-01, -2.4665e-01, -2.3064e-01, -2.9505e-01,\n",
       "             4.0501e-01, -1.3263e-01, -2.2367e-01,  1.7961e-01,  1.8509e-01,\n",
       "            -3.5391e-02,  4.1947e-01]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0861,  0.0948, -0.0589,  ...,  0.1540,  0.1019, -0.0291],\n",
       "          [-0.1624,  0.0444, -0.0272,  ..., -0.1007,  0.1431, -0.1576],\n",
       "          [ 0.0343, -0.1290,  0.1736,  ..., -0.0089, -0.0614, -0.1338],\n",
       "          ...,\n",
       "          [ 0.0845, -0.1631, -0.0307,  ..., -0.0113,  0.0446,  0.1497],\n",
       "          [-0.1257,  0.1163,  0.0092,  ...,  0.0840,  0.0572, -0.1697],\n",
       "          [ 0.0321,  0.0340, -0.0688,  ..., -0.0862,  0.0485,  0.1251]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 4.6845e-02, -8.1649e-02,  4.5422e-02, -7.0158e-02, -8.5387e-02,\n",
       "           5.4560e-02, -3.3903e-03, -6.3250e-02,  4.9978e-02,  3.7933e-02,\n",
       "          -4.8133e-02, -5.5519e-02, -5.8600e-02,  7.0284e-02, -8.3921e-02,\n",
       "          -7.3194e-02,  6.5661e-02, -6.2550e-02,  1.9078e-02, -4.7663e-02,\n",
       "           8.4099e-02,  7.7839e-02,  5.6832e-02, -7.3339e-02, -1.9670e-03,\n",
       "           7.1699e-02, -2.5932e-02,  2.8520e-02, -4.9769e-02, -7.3674e-02,\n",
       "           6.4196e-03, -1.7454e-02, -4.1051e-02,  4.7414e-03, -2.0714e-03,\n",
       "          -8.5208e-02, -6.8236e-03,  4.1407e-02, -6.7462e-02, -6.1139e-02,\n",
       "           4.6940e-02,  8.4833e-02, -1.6186e-02,  6.9393e-02, -4.1576e-02,\n",
       "          -8.3665e-02, -5.3053e-02,  2.2497e-02,  4.9330e-02, -1.9168e-02,\n",
       "          -6.8753e-02,  6.0468e-02,  7.7694e-02,  2.7983e-02,  5.2473e-02,\n",
       "          -2.0776e-02,  7.9608e-02, -8.1686e-02,  1.7923e-02, -3.0813e-02,\n",
       "           1.0818e-02, -2.5287e-05,  3.2790e-02,  5.3879e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0493,  0.0665, -0.1060,  ...,  0.1325, -0.1399, -0.1171],\n",
       "          [ 0.0721, -0.1311, -0.0584,  ..., -0.1057,  0.0214,  0.0229],\n",
       "          [-0.1127,  0.1642, -0.1320,  ...,  0.0734, -0.0607,  0.0740],\n",
       "          ...,\n",
       "          [ 0.0460, -0.0903,  0.0762,  ...,  0.1280, -0.1227, -0.1504],\n",
       "          [ 0.1358,  0.0340,  0.1174,  ...,  0.1616, -0.0476,  0.0306],\n",
       "          [-0.0802,  0.1079,  0.1404,  ..., -0.1524, -0.1573, -0.0767]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0162,  0.0166,  0.0120, -0.0062,  0.0732,  0.0751, -0.0450,  0.0024,\n",
       "          -0.0555, -0.0360,  0.0256, -0.0436,  0.0630, -0.0434, -0.0091,  0.0627,\n",
       "          -0.0089, -0.0173, -0.0045, -0.0046, -0.0134, -0.0667,  0.0829, -0.0481,\n",
       "          -0.0559, -0.0227, -0.0835, -0.0601,  0.0286,  0.0088, -0.0762, -0.0458,\n",
       "           0.0079,  0.0832,  0.0048,  0.0524,  0.0356,  0.0370, -0.0108,  0.0260,\n",
       "           0.0418, -0.0774, -0.0117,  0.0100,  0.0594,  0.0255,  0.0845,  0.0787,\n",
       "           0.0051, -0.0383,  0.0777, -0.0266,  0.0431,  0.0396, -0.0745,  0.0031,\n",
       "           0.0694,  0.0851, -0.0460,  0.0002,  0.0823,  0.0657, -0.0142, -0.0107],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1310],\n",
       "          [-0.2872],\n",
       "          [-0.1876],\n",
       "          [-0.0452],\n",
       "          [ 0.2722],\n",
       "          [-0.2069],\n",
       "          [-0.0111],\n",
       "          [ 0.1420],\n",
       "          [ 0.0942],\n",
       "          [ 0.0099],\n",
       "          [ 0.0865],\n",
       "          [ 0.2257],\n",
       "          [-0.0884],\n",
       "          [-0.1345],\n",
       "          [ 0.1406],\n",
       "          [-0.2426],\n",
       "          [-0.1610],\n",
       "          [-0.0763],\n",
       "          [ 0.1678],\n",
       "          [-0.0466],\n",
       "          [-0.2537],\n",
       "          [-0.0963],\n",
       "          [-0.0801],\n",
       "          [-0.0139],\n",
       "          [ 0.2817],\n",
       "          [ 0.0490],\n",
       "          [ 0.1968],\n",
       "          [-0.1675],\n",
       "          [-0.0778],\n",
       "          [ 0.2992],\n",
       "          [-0.1766],\n",
       "          [ 0.2508],\n",
       "          [ 0.2634],\n",
       "          [-0.0737],\n",
       "          [ 0.1622],\n",
       "          [ 0.0738],\n",
       "          [-0.1605],\n",
       "          [-0.2950],\n",
       "          [ 0.2252],\n",
       "          [ 0.2725],\n",
       "          [ 0.2202],\n",
       "          [-0.0869],\n",
       "          [ 0.2058],\n",
       "          [ 0.0679],\n",
       "          [-0.2869],\n",
       "          [ 0.0063],\n",
       "          [-0.1876],\n",
       "          [ 0.0177],\n",
       "          [ 0.1098],\n",
       "          [-0.1456],\n",
       "          [ 0.0804],\n",
       "          [-0.1081],\n",
       "          [-0.1642],\n",
       "          [-0.1345],\n",
       "          [ 0.2752],\n",
       "          [ 0.2632],\n",
       "          [ 0.1416],\n",
       "          [-0.0182],\n",
       "          [-0.2983],\n",
       "          [ 0.2311],\n",
       "          [-0.1003],\n",
       "          [-0.2599],\n",
       "          [ 0.1645],\n",
       "          [-0.1834]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.3612, -0.2133, -0.0380,  0.3139,  0.2238, -0.2311, -0.2818,\n",
       "            -0.1071,  0.3994, -0.4117,  0.2537, -0.1206, -0.2695,  0.2603,\n",
       "             0.1587,  0.0293, -0.1878, -0.2149, -0.0326, -0.2186,  0.0788,\n",
       "            -0.4034, -0.3999,  0.0744,  0.0564,  0.0614, -0.1680,  0.0893,\n",
       "            -0.2863,  0.0280, -0.3524, -0.2497],\n",
       "           [ 0.1182,  0.2104, -0.2357,  0.3737, -0.4153,  0.0088, -0.2176,\n",
       "             0.0182,  0.3911, -0.1846, -0.1627, -0.1058, -0.0375, -0.3694,\n",
       "             0.3345, -0.2656, -0.0581,  0.2173, -0.1902,  0.2910, -0.2406,\n",
       "            -0.1111,  0.0302,  0.3602, -0.2988,  0.3893, -0.3617, -0.3051,\n",
       "             0.3425, -0.3441, -0.1123,  0.0279]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1291, -0.0286, -0.0686,  ..., -0.1701,  0.0961,  0.1394],\n",
       "          [-0.0135,  0.0994,  0.1506,  ...,  0.1082, -0.1453,  0.1540],\n",
       "          [ 0.1033, -0.1516,  0.0763,  ..., -0.1146, -0.0908,  0.0814],\n",
       "          ...,\n",
       "          [-0.0136, -0.1217, -0.0077,  ..., -0.1217, -0.0126,  0.0668],\n",
       "          [-0.1189, -0.0990,  0.1736,  ..., -0.0310,  0.0051, -0.0459],\n",
       "          [ 0.0832,  0.0483,  0.0795,  ...,  0.1085, -0.1123,  0.1673]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0240,  0.0189, -0.0578,  0.0209,  0.0261,  0.0306, -0.0500,  0.0178,\n",
       "           0.0788, -0.0131,  0.0014, -0.0456, -0.0843, -0.0628,  0.0347, -0.0524,\n",
       "          -0.0719, -0.0864,  0.0162,  0.0378, -0.0862, -0.0107, -0.0797, -0.0094,\n",
       "          -0.0248,  0.0737,  0.0557,  0.0565,  0.0083,  0.0816, -0.0240, -0.0173,\n",
       "           0.0706, -0.0616,  0.0153,  0.0388, -0.0483, -0.0279, -0.0395,  0.0126,\n",
       "           0.0126, -0.0840,  0.0650, -0.0050, -0.0425, -0.0035,  0.0633,  0.0027,\n",
       "          -0.0281,  0.0294,  0.0504, -0.0682, -0.0013, -0.0609, -0.0011,  0.0608,\n",
       "           0.0213,  0.0758,  0.0689, -0.0319,  0.0860, -0.0742, -0.0600, -0.0566],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0386,  0.1661, -0.0542,  ..., -0.0777, -0.0981, -0.0334],\n",
       "          [ 0.1750,  0.1549,  0.0623,  ..., -0.1463, -0.0262,  0.1367],\n",
       "          [-0.1536, -0.0043,  0.1675,  ..., -0.1677, -0.1516,  0.0008],\n",
       "          ...,\n",
       "          [-0.0440, -0.0723, -0.0856,  ..., -0.0814, -0.1506, -0.0459],\n",
       "          [ 0.0799, -0.1557,  0.1055,  ..., -0.0099,  0.0087,  0.0183],\n",
       "          [ 0.0347, -0.0741, -0.1560,  ..., -0.0466, -0.0974, -0.0229]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0292,  0.0335,  0.0035, -0.0169,  0.0611, -0.0683,  0.0438, -0.0859,\n",
       "           0.0748, -0.0255, -0.0012,  0.0667, -0.0793, -0.0356,  0.0280, -0.0565,\n",
       "           0.0864, -0.0546,  0.0328, -0.0314,  0.0438,  0.0245, -0.0774,  0.0623,\n",
       "          -0.0534, -0.0455,  0.0824,  0.0603,  0.0797, -0.0740, -0.0323,  0.0744,\n",
       "          -0.0314,  0.0869, -0.0106,  0.0670, -0.0044, -0.0046,  0.0842, -0.0030,\n",
       "          -0.0204, -0.0241, -0.0421, -0.0755, -0.0624,  0.0412, -0.0062,  0.0775,\n",
       "           0.0740,  0.0415, -0.0743,  0.0429,  0.0824, -0.0087,  0.0027, -0.0755,\n",
       "           0.0658, -0.0142,  0.0526, -0.0090, -0.0857, -0.0020, -0.0430,  0.0589],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0269],\n",
       "          [ 0.1848],\n",
       "          [-0.0690],\n",
       "          [ 0.0228],\n",
       "          [ 0.1148],\n",
       "          [ 0.2814],\n",
       "          [ 0.1209],\n",
       "          [ 0.1383],\n",
       "          [ 0.0676],\n",
       "          [ 0.2208],\n",
       "          [ 0.1445],\n",
       "          [-0.0229],\n",
       "          [-0.1289],\n",
       "          [-0.2420],\n",
       "          [-0.2436],\n",
       "          [-0.2068],\n",
       "          [ 0.1770],\n",
       "          [ 0.1036],\n",
       "          [-0.1471],\n",
       "          [-0.0397],\n",
       "          [ 0.0578],\n",
       "          [ 0.0896],\n",
       "          [-0.2075],\n",
       "          [ 0.0949],\n",
       "          [ 0.2434],\n",
       "          [-0.1826],\n",
       "          [-0.2904],\n",
       "          [ 0.0569],\n",
       "          [-0.2311],\n",
       "          [-0.0219],\n",
       "          [ 0.1760],\n",
       "          [ 0.2496],\n",
       "          [-0.0104],\n",
       "          [-0.0273],\n",
       "          [ 0.1468],\n",
       "          [-0.2100],\n",
       "          [-0.1744],\n",
       "          [-0.1052],\n",
       "          [-0.0232],\n",
       "          [ 0.0812],\n",
       "          [-0.0725],\n",
       "          [-0.0584],\n",
       "          [-0.0776],\n",
       "          [-0.0426],\n",
       "          [-0.1231],\n",
       "          [-0.0528],\n",
       "          [-0.2008],\n",
       "          [ 0.0676],\n",
       "          [-0.2851],\n",
       "          [ 0.0135],\n",
       "          [ 0.1596],\n",
       "          [-0.0151],\n",
       "          [-0.0140],\n",
       "          [-0.1188],\n",
       "          [-0.1701],\n",
       "          [ 0.0496],\n",
       "          [-0.1104],\n",
       "          [ 0.1152],\n",
       "          [ 0.0596],\n",
       "          [-0.2185],\n",
       "          [ 0.2992],\n",
       "          [ 0.2733],\n",
       "          [ 0.1737],\n",
       "          [-0.1491]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1522, -0.1890, -0.2149, -0.2907, -0.2945, -0.3364,  0.1704,\n",
       "             0.3306,  0.3623, -0.2768,  0.1185,  0.3504,  0.1745,  0.2285,\n",
       "             0.1926, -0.0126,  0.1021,  0.1103,  0.3352,  0.2462,  0.2134,\n",
       "             0.2050, -0.2463,  0.1671, -0.3089,  0.1809, -0.4076, -0.0766,\n",
       "            -0.3062, -0.2102, -0.0447, -0.3281],\n",
       "           [ 0.1330, -0.2524,  0.0307,  0.1887, -0.1472, -0.3255, -0.2580,\n",
       "             0.3181,  0.2685,  0.3862, -0.3934, -0.2069,  0.2435,  0.0734,\n",
       "            -0.1657, -0.2474,  0.2891,  0.1644, -0.3541,  0.3700,  0.2774,\n",
       "            -0.0539,  0.1531,  0.4050, -0.0832,  0.0913, -0.0388, -0.2333,\n",
       "            -0.3830, -0.2019, -0.1857, -0.1996]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0631, -0.0509, -0.0215,  ..., -0.1357,  0.1339,  0.0600],\n",
       "          [ 0.1765,  0.1162, -0.0273,  ..., -0.0497, -0.1499, -0.1441],\n",
       "          [ 0.1423,  0.0781,  0.0852,  ..., -0.0358,  0.1399,  0.0146],\n",
       "          ...,\n",
       "          [ 0.0068, -0.0779,  0.1224,  ..., -0.1422, -0.0115, -0.1518],\n",
       "          [-0.0787,  0.0718,  0.1030,  ..., -0.1606,  0.1219,  0.1338],\n",
       "          [-0.1497, -0.0310,  0.0015,  ..., -0.0372, -0.0261, -0.0838]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0725, -0.0402, -0.0414,  0.0539,  0.0066, -0.0202, -0.0418,  0.0575,\n",
       "          -0.0356, -0.0176, -0.0576,  0.0872,  0.0480, -0.0057,  0.0525, -0.0045,\n",
       "           0.0126, -0.0443,  0.0725, -0.0243, -0.0424, -0.0656, -0.0445,  0.0457,\n",
       "          -0.0067, -0.0030,  0.0601,  0.0759, -0.0241, -0.0335,  0.0430, -0.0017,\n",
       "           0.0386, -0.0142,  0.0263, -0.0290, -0.0725, -0.0140, -0.0698, -0.0128,\n",
       "          -0.0003,  0.0039,  0.0639,  0.0266, -0.0106,  0.0792, -0.0100,  0.0311,\n",
       "           0.0327, -0.0782, -0.0335,  0.0388, -0.0294,  0.0051,  0.0412,  0.0129,\n",
       "          -0.0308, -0.0690,  0.0509, -0.0141, -0.0437, -0.0310, -0.0504,  0.0158],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1417,  0.0778, -0.0794,  ..., -0.1671, -0.0899,  0.0262],\n",
       "          [-0.0707,  0.1434,  0.1553,  ..., -0.0535, -0.1008, -0.1535],\n",
       "          [-0.0409,  0.0356, -0.1238,  ..., -0.0009,  0.0235, -0.1033],\n",
       "          ...,\n",
       "          [ 0.0315,  0.0952, -0.0791,  ...,  0.0491, -0.1213, -0.0442],\n",
       "          [ 0.1227,  0.1725,  0.0589,  ...,  0.0558,  0.0259,  0.0130],\n",
       "          [-0.1594, -0.0785, -0.1639,  ..., -0.1080, -0.1572,  0.1253]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0202,  0.0086, -0.0609,  0.0613, -0.0370,  0.0454,  0.0044, -0.0862,\n",
       "          -0.0190, -0.0590, -0.0554,  0.0373, -0.0549,  0.0848, -0.0140, -0.0153,\n",
       "          -0.0078,  0.0619, -0.0839,  0.0856, -0.0306, -0.0044,  0.0421, -0.0035,\n",
       "           0.0209,  0.0491,  0.0123, -0.0371, -0.0589,  0.0774,  0.0388,  0.0748,\n",
       "          -0.0061,  0.0337, -0.0469,  0.0782, -0.0839,  0.0523,  0.0855, -0.0771,\n",
       "           0.0583, -0.0863,  0.0341,  0.0624,  0.0276, -0.0847, -0.0645, -0.0451,\n",
       "           0.0033, -0.0187, -0.0232,  0.0464,  0.0522,  0.0043,  0.0414, -0.0594,\n",
       "           0.0515,  0.0315,  0.0675,  0.0515,  0.0792, -0.0341,  0.0687,  0.0740],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1068],\n",
       "          [-0.2869],\n",
       "          [ 0.1572],\n",
       "          [ 0.1325],\n",
       "          [-0.0220],\n",
       "          [ 0.2740],\n",
       "          [ 0.0413],\n",
       "          [-0.0806],\n",
       "          [-0.1301],\n",
       "          [ 0.2156],\n",
       "          [ 0.1376],\n",
       "          [ 0.1448],\n",
       "          [ 0.0785],\n",
       "          [ 0.0782],\n",
       "          [-0.2291],\n",
       "          [-0.2737],\n",
       "          [-0.0046],\n",
       "          [ 0.2161],\n",
       "          [ 0.2881],\n",
       "          [ 0.0580],\n",
       "          [-0.2797],\n",
       "          [-0.0180],\n",
       "          [ 0.0105],\n",
       "          [-0.0595],\n",
       "          [ 0.1292],\n",
       "          [ 0.2535],\n",
       "          [ 0.2173],\n",
       "          [-0.0259],\n",
       "          [-0.1694],\n",
       "          [-0.0072],\n",
       "          [ 0.2486],\n",
       "          [-0.2371],\n",
       "          [ 0.0407],\n",
       "          [ 0.1133],\n",
       "          [-0.0647],\n",
       "          [ 0.0494],\n",
       "          [-0.2733],\n",
       "          [-0.2920],\n",
       "          [ 0.2395],\n",
       "          [ 0.1595],\n",
       "          [-0.1382],\n",
       "          [ 0.1033],\n",
       "          [ 0.2605],\n",
       "          [-0.0392],\n",
       "          [-0.1540],\n",
       "          [ 0.1143],\n",
       "          [-0.2871],\n",
       "          [ 0.0510],\n",
       "          [-0.0748],\n",
       "          [-0.2222],\n",
       "          [ 0.2897],\n",
       "          [ 0.2210],\n",
       "          [-0.1836],\n",
       "          [ 0.1314],\n",
       "          [ 0.2102],\n",
       "          [-0.2910],\n",
       "          [ 0.0416],\n",
       "          [-0.2035],\n",
       "          [ 0.1379],\n",
       "          [ 0.2018],\n",
       "          [ 0.2378],\n",
       "          [ 0.0006],\n",
       "          [ 0.2842],\n",
       "          [-0.1463]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0815,  0.3681, -0.0113, -0.3165,  0.0225, -0.3564,  0.2134,\n",
       "            -0.0851, -0.2962, -0.2906, -0.1219,  0.3842,  0.3388, -0.2865,\n",
       "             0.2724,  0.3571, -0.1210, -0.3862, -0.3685, -0.3839,  0.3112,\n",
       "             0.1454,  0.1801, -0.2523,  0.1547, -0.4151,  0.0393,  0.0420,\n",
       "             0.0438, -0.3436,  0.2668,  0.2065],\n",
       "           [-0.0239,  0.3833,  0.1541, -0.1764,  0.2422,  0.1243, -0.4078,\n",
       "            -0.1040, -0.2459, -0.4084,  0.3191,  0.0077,  0.3890, -0.3488,\n",
       "             0.0417,  0.2389, -0.3173, -0.2020, -0.0889, -0.1159, -0.2357,\n",
       "            -0.3612,  0.2063,  0.0411,  0.2274,  0.1102,  0.1430, -0.4101,\n",
       "            -0.3567,  0.2113,  0.1149, -0.0381]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0013,  0.1076,  0.0646,  ...,  0.1239,  0.1581,  0.1348],\n",
       "          [ 0.0040,  0.1722, -0.0037,  ...,  0.0080, -0.1760, -0.0918],\n",
       "          [-0.1359,  0.1478,  0.1512,  ...,  0.1131, -0.1615,  0.0521],\n",
       "          ...,\n",
       "          [-0.0343, -0.0787, -0.1566,  ...,  0.1299, -0.0916,  0.0382],\n",
       "          [ 0.1002,  0.1359, -0.1024,  ..., -0.0713, -0.0173,  0.1061],\n",
       "          [ 0.1169,  0.0849, -0.0669,  ..., -0.0082, -0.0716,  0.0766]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0071,  0.0061,  0.0580, -0.0035,  0.0252, -0.0331,  0.0581, -0.0243,\n",
       "          -0.0032,  0.0394, -0.0246, -0.0871,  0.0242,  0.0418,  0.0288,  0.0819,\n",
       "           0.0103, -0.0061, -0.0212,  0.0663, -0.0793, -0.0052,  0.0628, -0.0635,\n",
       "          -0.0230,  0.0378,  0.0781,  0.0375,  0.0604,  0.0473,  0.0527, -0.0525,\n",
       "           0.0010, -0.0541, -0.0244,  0.0008, -0.0080, -0.0501, -0.0025, -0.0875,\n",
       "          -0.0476,  0.0446, -0.0567,  0.0643, -0.0393,  0.0224,  0.0571,  0.0325,\n",
       "           0.0246,  0.0179, -0.0695,  0.0494, -0.0129, -0.0666, -0.0402,  0.0250,\n",
       "           0.0616,  0.0537,  0.0438, -0.0520,  0.0394, -0.0791,  0.0802, -0.0616],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0889, -0.0932, -0.0439,  ...,  0.0693,  0.0551,  0.1381],\n",
       "          [-0.0771, -0.0053,  0.0611,  ...,  0.0175, -0.0697, -0.0708],\n",
       "          [-0.0527, -0.1046,  0.0322,  ...,  0.0787,  0.1159,  0.0839],\n",
       "          ...,\n",
       "          [ 0.1708,  0.0151,  0.1337,  ..., -0.1692,  0.0496, -0.1030],\n",
       "          [-0.0863,  0.0062, -0.0069,  ...,  0.0476,  0.1589, -0.1103],\n",
       "          [ 0.0299,  0.0437,  0.1686,  ...,  0.1404,  0.1156, -0.0639]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.2148e-02,  1.2309e-02, -6.1792e-02, -3.6509e-02, -1.8890e-02,\n",
       "           7.7243e-02, -3.5785e-02,  2.2918e-02, -5.0792e-02, -2.7716e-02,\n",
       "          -5.4924e-02, -6.1226e-02, -8.9254e-03, -1.7754e-02,  5.6925e-02,\n",
       "          -4.1801e-03, -4.1851e-02,  8.1765e-02,  6.0342e-03, -3.2841e-03,\n",
       "           4.7621e-03, -3.4666e-02,  2.1078e-02, -4.7700e-02, -7.8649e-02,\n",
       "          -6.3239e-03,  8.4178e-02, -7.3081e-03, -4.7713e-02,  2.9965e-02,\n",
       "           8.7231e-02,  2.3567e-02,  9.8581e-03,  3.3956e-02,  5.6741e-02,\n",
       "          -4.5723e-02, -8.6259e-02, -6.8422e-02,  8.0377e-03,  7.9582e-02,\n",
       "           6.6285e-02, -7.7987e-02,  2.4355e-02, -6.7756e-02, -1.0868e-03,\n",
       "          -6.4146e-02, -1.2412e-02,  2.2750e-02,  2.2055e-03,  4.6203e-02,\n",
       "           4.1686e-02,  1.4665e-02, -4.0400e-02,  3.6097e-02, -6.4987e-03,\n",
       "          -5.3817e-02,  2.9144e-02,  6.5430e-02, -2.3879e-05, -6.1464e-03,\n",
       "           2.4383e-02,  6.1102e-02, -2.6052e-02, -6.5349e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0830],\n",
       "          [ 0.1454],\n",
       "          [-0.2877],\n",
       "          [ 0.1223],\n",
       "          [-0.2399],\n",
       "          [-0.1985],\n",
       "          [-0.2455],\n",
       "          [ 0.2417],\n",
       "          [ 0.0379],\n",
       "          [-0.0082],\n",
       "          [-0.1742],\n",
       "          [ 0.1921],\n",
       "          [ 0.0320],\n",
       "          [-0.0936],\n",
       "          [ 0.1490],\n",
       "          [-0.1930],\n",
       "          [ 0.2995],\n",
       "          [ 0.0309],\n",
       "          [-0.2940],\n",
       "          [ 0.1429],\n",
       "          [ 0.0338],\n",
       "          [-0.2250],\n",
       "          [ 0.2999],\n",
       "          [ 0.0945],\n",
       "          [ 0.2186],\n",
       "          [ 0.1893],\n",
       "          [-0.2989],\n",
       "          [-0.2004],\n",
       "          [ 0.1360],\n",
       "          [ 0.1550],\n",
       "          [-0.1205],\n",
       "          [-0.2927],\n",
       "          [ 0.2288],\n",
       "          [-0.1526],\n",
       "          [ 0.0288],\n",
       "          [ 0.0486],\n",
       "          [-0.0057],\n",
       "          [ 0.2500],\n",
       "          [-0.2541],\n",
       "          [ 0.1497],\n",
       "          [ 0.0450],\n",
       "          [-0.0718],\n",
       "          [-0.2495],\n",
       "          [ 0.1007],\n",
       "          [-0.0674],\n",
       "          [-0.0316],\n",
       "          [-0.1194],\n",
       "          [ 0.0898],\n",
       "          [ 0.2766],\n",
       "          [ 0.2363],\n",
       "          [-0.1790],\n",
       "          [-0.1840],\n",
       "          [-0.0133],\n",
       "          [-0.1076],\n",
       "          [-0.2238],\n",
       "          [-0.0230],\n",
       "          [ 0.0060],\n",
       "          [-0.0351],\n",
       "          [-0.1238],\n",
       "          [ 0.0353],\n",
       "          [ 0.1196],\n",
       "          [-0.1645],\n",
       "          [ 0.1380],\n",
       "          [-0.2367]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1257, -0.3604,  0.0878,  0.2864, -0.2291, -0.0722, -0.0404,\n",
       "            -0.1418,  0.1958,  0.3413,  0.0521, -0.0439, -0.1717, -0.2044,\n",
       "            -0.1614, -0.3091,  0.3792, -0.0982, -0.0657, -0.0405,  0.0912,\n",
       "            -0.3631,  0.1330, -0.1337,  0.1444, -0.0760, -0.1117,  0.1370,\n",
       "            -0.2237, -0.0953, -0.3904,  0.1619],\n",
       "           [ 0.3908,  0.3335,  0.1646,  0.1796, -0.3940, -0.1485,  0.0321,\n",
       "            -0.3823, -0.1907, -0.0981,  0.1490,  0.3914,  0.1099,  0.1131,\n",
       "             0.2484, -0.1864, -0.0341, -0.2094,  0.1861,  0.4076, -0.0730,\n",
       "            -0.0822,  0.1287, -0.1603,  0.0310, -0.2876,  0.2067, -0.1321,\n",
       "            -0.2971,  0.3731,  0.0355, -0.0682]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0758, -0.0602, -0.0575,  ...,  0.0040,  0.1586, -0.0350],\n",
       "          [-0.1151, -0.0268, -0.0721,  ..., -0.0813, -0.0111,  0.1308],\n",
       "          [ 0.0983,  0.1369, -0.0141,  ..., -0.0713, -0.1129, -0.1740],\n",
       "          ...,\n",
       "          [-0.0648, -0.1295, -0.1096,  ..., -0.1616, -0.1352, -0.0955],\n",
       "          [ 0.0975,  0.0347, -0.1014,  ...,  0.0893,  0.1187,  0.0912],\n",
       "          [-0.1608, -0.0189,  0.1118,  ..., -0.0721,  0.0756,  0.0950]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0442, -0.0269,  0.0208,  0.0266, -0.0830,  0.0163, -0.0441, -0.0871,\n",
       "          -0.0408, -0.0338, -0.0410,  0.0236, -0.0156,  0.0646, -0.0531, -0.0428,\n",
       "           0.0589,  0.0305, -0.0612, -0.0195,  0.0326, -0.0660,  0.0722,  0.0629,\n",
       "           0.0057,  0.0575, -0.0707,  0.0454,  0.0223,  0.0462, -0.0504, -0.0290,\n",
       "           0.0342,  0.0272,  0.0142, -0.0582, -0.0394, -0.0293,  0.0845,  0.0788,\n",
       "           0.0825,  0.0564, -0.0797, -0.0695, -0.0501, -0.0367, -0.0783, -0.0534,\n",
       "          -0.0796,  0.0780, -0.0811, -0.0782, -0.0197, -0.0655, -0.0009,  0.0689,\n",
       "           0.0776, -0.0598, -0.0554,  0.0259,  0.0338,  0.0112,  0.0680,  0.0344],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1759,  0.0483,  0.0396,  ...,  0.1385,  0.1669, -0.1401],\n",
       "          [ 0.1733,  0.0352, -0.0312,  ...,  0.0866, -0.0320,  0.0226],\n",
       "          [-0.0611, -0.1725,  0.0602,  ...,  0.1623,  0.1515,  0.0091],\n",
       "          ...,\n",
       "          [ 0.1314,  0.0949,  0.0615,  ...,  0.1250, -0.0892,  0.1737],\n",
       "          [ 0.0389,  0.1203,  0.1378,  ..., -0.0179,  0.0083,  0.0219],\n",
       "          [ 0.1304,  0.1585, -0.1145,  ..., -0.0224,  0.0924, -0.0540]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0370,  0.0338,  0.0281,  0.0682,  0.0094, -0.0782, -0.0367,  0.0145,\n",
       "           0.0431, -0.0843, -0.0493,  0.0021,  0.0538,  0.0335, -0.0584, -0.0610,\n",
       "          -0.0636, -0.0090, -0.0277, -0.0284,  0.0236, -0.0490,  0.0022, -0.0442,\n",
       "           0.0590,  0.0806, -0.0151,  0.0082,  0.0165,  0.0562, -0.0498,  0.0182,\n",
       "           0.0431,  0.0340, -0.0492, -0.0621, -0.0314, -0.0736,  0.0410,  0.0123,\n",
       "           0.0699, -0.0767,  0.0350, -0.0846,  0.0238,  0.0576,  0.0832,  0.0593,\n",
       "          -0.0734, -0.0060, -0.0588,  0.0509, -0.0010,  0.0778, -0.0844,  0.0265,\n",
       "           0.0539, -0.0334,  0.0306,  0.0606, -0.0049,  0.0819, -0.0719,  0.0297],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2697],\n",
       "          [-0.1861],\n",
       "          [ 0.0457],\n",
       "          [-0.2612],\n",
       "          [-0.1835],\n",
       "          [ 0.1911],\n",
       "          [-0.2717],\n",
       "          [-0.2309],\n",
       "          [ 0.2706],\n",
       "          [ 0.1306],\n",
       "          [ 0.0118],\n",
       "          [ 0.0188],\n",
       "          [-0.2951],\n",
       "          [-0.2125],\n",
       "          [ 0.2406],\n",
       "          [ 0.2929],\n",
       "          [ 0.2690],\n",
       "          [-0.0715],\n",
       "          [ 0.1945],\n",
       "          [ 0.0178],\n",
       "          [-0.0333],\n",
       "          [-0.2698],\n",
       "          [-0.0196],\n",
       "          [-0.2355],\n",
       "          [ 0.2408],\n",
       "          [-0.2418],\n",
       "          [ 0.1256],\n",
       "          [ 0.2198],\n",
       "          [-0.2408],\n",
       "          [-0.1234],\n",
       "          [ 0.0318],\n",
       "          [-0.0527],\n",
       "          [-0.0465],\n",
       "          [-0.1183],\n",
       "          [ 0.2023],\n",
       "          [-0.1258],\n",
       "          [ 0.0382],\n",
       "          [-0.0327],\n",
       "          [-0.2250],\n",
       "          [ 0.2052],\n",
       "          [ 0.2577],\n",
       "          [ 0.0484],\n",
       "          [-0.0730],\n",
       "          [ 0.2644],\n",
       "          [-0.1123],\n",
       "          [ 0.2129],\n",
       "          [ 0.2588],\n",
       "          [ 0.1791],\n",
       "          [-0.0131],\n",
       "          [-0.2111],\n",
       "          [ 0.0651],\n",
       "          [ 0.1311],\n",
       "          [-0.2349],\n",
       "          [-0.1205],\n",
       "          [-0.2863],\n",
       "          [ 0.2212],\n",
       "          [-0.2431],\n",
       "          [-0.1514],\n",
       "          [-0.2640],\n",
       "          [-0.2903],\n",
       "          [-0.1833],\n",
       "          [-0.1589],\n",
       "          [-0.0405],\n",
       "          [-0.2548]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.4149, -0.3954, -0.2894,  0.3526, -0.2013, -0.0467, -0.2416,\n",
       "             0.3481, -0.4004,  0.0325,  0.1956, -0.0389, -0.0811,  0.3204,\n",
       "             0.0969, -0.0050,  0.2270, -0.2276,  0.3921, -0.3171,  0.1371,\n",
       "             0.0386,  0.2617, -0.2746, -0.0404, -0.2081,  0.0588,  0.4191,\n",
       "            -0.3391,  0.0903, -0.1803, -0.3897],\n",
       "           [-0.1686, -0.0265,  0.0311,  0.2982, -0.1102,  0.3956,  0.2524,\n",
       "             0.2413,  0.0933,  0.0164,  0.0933, -0.0206,  0.3666,  0.0461,\n",
       "            -0.2207, -0.0746, -0.4022, -0.0790, -0.3296, -0.1117, -0.0005,\n",
       "             0.2379, -0.3775, -0.3682,  0.0713,  0.1760, -0.3097,  0.1976,\n",
       "            -0.2436,  0.1240,  0.3264, -0.2135]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1365,  0.1585,  0.1134,  ...,  0.1066, -0.1654,  0.0339],\n",
       "          [-0.1360, -0.1539, -0.1176,  ...,  0.1758, -0.0657, -0.0729],\n",
       "          [-0.0232, -0.0449, -0.0516,  ..., -0.1059, -0.0618, -0.0910],\n",
       "          ...,\n",
       "          [ 0.0719, -0.0077, -0.0675,  ...,  0.0305,  0.1039, -0.1394],\n",
       "          [-0.0309,  0.1203,  0.1063,  ..., -0.1270,  0.0930, -0.0793],\n",
       "          [-0.0120, -0.0781, -0.0401,  ...,  0.1663, -0.1587,  0.0134]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0715,  0.0629, -0.0399,  0.0053,  0.0742, -0.0323, -0.0248,  0.0402,\n",
       "          -0.0746, -0.0406,  0.0694,  0.0154, -0.0070,  0.0163,  0.0519,  0.0058,\n",
       "           0.0582,  0.0472, -0.0512,  0.0488,  0.0835, -0.0530, -0.0299,  0.0043,\n",
       "           0.0248, -0.0350,  0.0114,  0.0568, -0.0275, -0.0443, -0.0181,  0.0479,\n",
       "           0.0042, -0.0400,  0.0666, -0.0881,  0.0222,  0.0259, -0.0357,  0.0672,\n",
       "          -0.0371,  0.0089, -0.0708,  0.0105, -0.0589, -0.0058,  0.0720,  0.0815,\n",
       "          -0.0808, -0.0188,  0.0830, -0.0102, -0.0246,  0.0420,  0.0193, -0.0867,\n",
       "          -0.0345,  0.0692,  0.0777, -0.0694,  0.0680, -0.0523, -0.0036,  0.0616],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1487, -0.0277,  0.0231,  ..., -0.0030, -0.0274, -0.0184],\n",
       "          [ 0.0273,  0.1734, -0.1743,  ..., -0.1453, -0.0441,  0.1228],\n",
       "          [ 0.0056,  0.1191,  0.1349,  ..., -0.1644, -0.0618,  0.0035],\n",
       "          ...,\n",
       "          [ 0.0325, -0.1634,  0.1664,  ..., -0.0924,  0.0283, -0.0745],\n",
       "          [-0.0868, -0.0185, -0.0492,  ...,  0.0531,  0.1546,  0.0849],\n",
       "          [ 0.0552,  0.1035,  0.0774,  ...,  0.1475, -0.0860,  0.0009]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0614,  0.0748, -0.0708,  0.0536, -0.0569, -0.0455,  0.0610,  0.0753,\n",
       "           0.0253, -0.0872,  0.0793,  0.0381, -0.0194, -0.0132,  0.0413, -0.0605,\n",
       "           0.0162,  0.0464,  0.0152,  0.0221,  0.0191, -0.0233,  0.0090,  0.0373,\n",
       "          -0.0554,  0.0471,  0.0675, -0.0626, -0.0208,  0.0213, -0.0252, -0.0051,\n",
       "          -0.0760, -0.0227,  0.0221,  0.0648,  0.0472,  0.0345, -0.0388, -0.0583,\n",
       "           0.0834,  0.0051, -0.0517, -0.0791, -0.0606,  0.0677,  0.0172, -0.0269,\n",
       "           0.0839, -0.0136,  0.0363, -0.0376,  0.0399, -0.0186, -0.0211,  0.0551,\n",
       "           0.0812,  0.0290,  0.0446, -0.0054,  0.0774, -0.0288, -0.0807,  0.0272],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0675],\n",
       "          [-0.1925],\n",
       "          [ 0.3011],\n",
       "          [-0.2619],\n",
       "          [-0.1725],\n",
       "          [ 0.2970],\n",
       "          [ 0.0840],\n",
       "          [ 0.0995],\n",
       "          [-0.0034],\n",
       "          [ 0.0878],\n",
       "          [ 0.0932],\n",
       "          [-0.1684],\n",
       "          [-0.0177],\n",
       "          [-0.2027],\n",
       "          [ 0.1403],\n",
       "          [-0.2778],\n",
       "          [ 0.0195],\n",
       "          [ 0.0942],\n",
       "          [ 0.0110],\n",
       "          [ 0.2161],\n",
       "          [ 0.2228],\n",
       "          [-0.2212],\n",
       "          [ 0.1028],\n",
       "          [ 0.2938],\n",
       "          [-0.3026],\n",
       "          [ 0.2279],\n",
       "          [ 0.2662],\n",
       "          [-0.0497],\n",
       "          [ 0.2328],\n",
       "          [-0.1811],\n",
       "          [ 0.0544],\n",
       "          [ 0.2573],\n",
       "          [-0.2669],\n",
       "          [-0.0936],\n",
       "          [-0.2367],\n",
       "          [-0.2336],\n",
       "          [ 0.2339],\n",
       "          [-0.0527],\n",
       "          [ 0.1807],\n",
       "          [-0.0408],\n",
       "          [ 0.2181],\n",
       "          [ 0.1475],\n",
       "          [ 0.2108],\n",
       "          [-0.1250],\n",
       "          [ 0.2986],\n",
       "          [-0.1029],\n",
       "          [-0.0353],\n",
       "          [-0.1034],\n",
       "          [ 0.3020],\n",
       "          [-0.0915],\n",
       "          [-0.0767],\n",
       "          [-0.2125],\n",
       "          [ 0.2331],\n",
       "          [ 0.0985],\n",
       "          [-0.1247],\n",
       "          [ 0.0959],\n",
       "          [-0.2971],\n",
       "          [-0.0675],\n",
       "          [ 0.1500],\n",
       "          [ 0.2683],\n",
       "          [-0.1966],\n",
       "          [-0.0434],\n",
       "          [ 0.0958],\n",
       "          [ 0.1246]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1131,  0.3715, -0.1021,  0.2135, -0.1963,  0.3322, -0.3212,\n",
       "             0.2998, -0.2546,  0.3653, -0.3046,  0.1354, -0.2791,  0.1906,\n",
       "            -0.0865,  0.2976, -0.3386,  0.4025,  0.3733, -0.2745,  0.0384,\n",
       "            -0.2535, -0.1302,  0.2647, -0.4059,  0.2600, -0.3149,  0.3415,\n",
       "             0.2652,  0.1715, -0.0331, -0.0832],\n",
       "           [-0.0934,  0.2522, -0.0504, -0.2688, -0.2738,  0.3826, -0.3487,\n",
       "            -0.1572, -0.4024,  0.2715, -0.1925, -0.3157, -0.0516, -0.2370,\n",
       "            -0.2801, -0.1553, -0.0567,  0.0614, -0.3218, -0.0691,  0.2155,\n",
       "             0.3061, -0.1877, -0.1436,  0.2292,  0.0521,  0.1547,  0.1897,\n",
       "            -0.3102, -0.3005,  0.1753, -0.2403]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1298, -0.1342,  0.0559,  ...,  0.1413,  0.0594,  0.0157],\n",
       "          [-0.0324, -0.1478, -0.0076,  ..., -0.1390, -0.0043, -0.1597],\n",
       "          [ 0.1207,  0.0622,  0.0564,  ...,  0.1467,  0.0449,  0.0979],\n",
       "          ...,\n",
       "          [ 0.1390, -0.0073,  0.0443,  ...,  0.0927, -0.0235,  0.1335],\n",
       "          [ 0.0163, -0.1478, -0.0630,  ...,  0.0849,  0.1576, -0.1468],\n",
       "          [-0.0737,  0.0052, -0.0140,  ...,  0.1647,  0.1674,  0.0735]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0862, -0.0589, -0.0252,  0.0373,  0.0100, -0.0250,  0.0785, -0.0821,\n",
       "           0.0338,  0.0246, -0.0310, -0.0572, -0.0491, -0.0723, -0.0855, -0.0282,\n",
       "           0.0303, -0.0402,  0.0050,  0.0860,  0.0641, -0.0604, -0.0314, -0.0492,\n",
       "          -0.0739,  0.0235,  0.0624, -0.0214, -0.0295, -0.0605, -0.0533, -0.0507,\n",
       "           0.0194, -0.0281, -0.0625, -0.0802, -0.0387,  0.0659,  0.0089,  0.0043,\n",
       "          -0.0028,  0.0720, -0.0105,  0.0602, -0.0644,  0.0776,  0.0037,  0.0198,\n",
       "           0.0098, -0.0159,  0.0638, -0.0826, -0.0710,  0.0690, -0.0698,  0.0079,\n",
       "          -0.0572, -0.0374,  0.0135,  0.0815,  0.0086, -0.0389,  0.0797, -0.0128],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0813, -0.0215,  0.0800,  ..., -0.0519,  0.1712, -0.1241],\n",
       "          [ 0.0718,  0.0768, -0.0757,  ..., -0.1694, -0.1460,  0.1297],\n",
       "          [ 0.0018,  0.1510, -0.0515,  ...,  0.0579, -0.0582, -0.1368],\n",
       "          ...,\n",
       "          [-0.1367,  0.0391, -0.0321,  ..., -0.1650,  0.1477, -0.1278],\n",
       "          [ 0.1113,  0.0643, -0.1708,  ...,  0.1555,  0.0565, -0.1294],\n",
       "          [-0.0470,  0.0381, -0.1078,  ..., -0.1635, -0.0087, -0.0950]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.6022e-02, -7.2972e-02, -6.7134e-02,  1.8706e-02, -1.9816e-03,\n",
       "          -8.6116e-02,  2.5481e-02, -8.1801e-02, -1.7925e-02,  7.5504e-02,\n",
       "           4.3801e-02,  1.8037e-02, -1.2118e-02, -2.4378e-05,  5.1446e-02,\n",
       "           6.2082e-02, -3.0481e-02,  3.8595e-04, -7.7405e-02,  5.6090e-04,\n",
       "           6.6782e-02,  4.9850e-02,  8.8027e-02,  7.3883e-03,  7.2629e-02,\n",
       "           7.3154e-02, -5.6368e-03, -7.3949e-02, -2.0812e-02, -6.8705e-02,\n",
       "          -6.4895e-02, -1.7720e-02, -1.8253e-02,  4.6312e-02, -3.6640e-02,\n",
       "           4.2656e-02, -2.5880e-02,  5.4103e-02,  5.4600e-02, -9.2678e-03,\n",
       "          -4.8872e-02,  8.2546e-02, -6.1789e-02, -3.5268e-02, -2.2439e-02,\n",
       "          -5.1863e-02, -1.3256e-02,  7.3743e-03, -4.0756e-02, -7.4419e-02,\n",
       "          -8.3118e-02, -1.5498e-03,  2.4629e-02, -4.9277e-02,  2.3753e-02,\n",
       "          -6.0546e-03,  2.3882e-02,  4.4421e-02, -2.9659e-02, -1.3291e-02,\n",
       "          -1.8056e-02,  6.1096e-03,  5.1234e-02, -5.8687e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2048],\n",
       "          [-0.0291],\n",
       "          [ 0.0921],\n",
       "          [ 0.1059],\n",
       "          [ 0.2197],\n",
       "          [ 0.2039],\n",
       "          [-0.1512],\n",
       "          [-0.0454],\n",
       "          [ 0.2329],\n",
       "          [-0.0861],\n",
       "          [ 0.0962],\n",
       "          [-0.0247],\n",
       "          [-0.0548],\n",
       "          [ 0.1040],\n",
       "          [-0.1110],\n",
       "          [ 0.1887],\n",
       "          [ 0.1605],\n",
       "          [ 0.0349],\n",
       "          [-0.1204],\n",
       "          [-0.2110],\n",
       "          [-0.1427],\n",
       "          [ 0.1838],\n",
       "          [-0.0171],\n",
       "          [ 0.0990],\n",
       "          [ 0.1447],\n",
       "          [-0.1788],\n",
       "          [ 0.1870],\n",
       "          [-0.2566],\n",
       "          [ 0.2591],\n",
       "          [ 0.1584],\n",
       "          [-0.2552],\n",
       "          [-0.2529],\n",
       "          [ 0.0189],\n",
       "          [ 0.0682],\n",
       "          [ 0.0096],\n",
       "          [ 0.1939],\n",
       "          [ 0.2121],\n",
       "          [ 0.1784],\n",
       "          [ 0.1406],\n",
       "          [ 0.0066],\n",
       "          [-0.2724],\n",
       "          [ 0.2433],\n",
       "          [-0.2877],\n",
       "          [-0.1545],\n",
       "          [ 0.1277],\n",
       "          [-0.2443],\n",
       "          [-0.0022],\n",
       "          [ 0.1846],\n",
       "          [ 0.2912],\n",
       "          [-0.0382],\n",
       "          [-0.2207],\n",
       "          [-0.1175],\n",
       "          [ 0.1784],\n",
       "          [ 0.1259],\n",
       "          [-0.2006],\n",
       "          [-0.2960],\n",
       "          [-0.0271],\n",
       "          [-0.2425],\n",
       "          [-0.2884],\n",
       "          [-0.0936],\n",
       "          [-0.2810],\n",
       "          [ 0.1080],\n",
       "          [-0.1420],\n",
       "          [ 0.1983]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1606,  0.3714,  0.0291, -0.0115,  0.3987,  0.2774, -0.4193,\n",
       "             0.1799,  0.2706, -0.4192,  0.0729, -0.0736, -0.1384,  0.0629,\n",
       "             0.0287, -0.4098,  0.2276, -0.4013,  0.0087,  0.0285, -0.1433,\n",
       "             0.0741,  0.0337, -0.1001,  0.0533,  0.3411,  0.3009,  0.2967,\n",
       "             0.0825,  0.3502, -0.2537, -0.1028],\n",
       "           [-0.3900, -0.0300,  0.0103,  0.2092, -0.1211,  0.3327, -0.3931,\n",
       "            -0.0371,  0.1154, -0.2682, -0.2081, -0.0223, -0.1238, -0.1252,\n",
       "             0.4023,  0.0552, -0.3147, -0.2915,  0.1498,  0.3176,  0.2258,\n",
       "            -0.3252,  0.0774,  0.4194,  0.1009,  0.4198,  0.2417, -0.0326,\n",
       "            -0.2644,  0.1607,  0.3440,  0.4131]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1161, -0.1536,  0.0385,  ..., -0.0589, -0.1163, -0.1780],\n",
       "          [ 0.0265,  0.0652,  0.0503,  ...,  0.0300, -0.0512, -0.1755],\n",
       "          [ 0.1390, -0.0401, -0.2008,  ..., -0.0762, -0.0019,  0.1702],\n",
       "          ...,\n",
       "          [ 0.0286,  0.1249, -0.0123,  ...,  0.2117,  0.0837,  0.1622],\n",
       "          [ 0.0717,  0.0519,  0.0375,  ..., -0.2023,  0.2051,  0.1532],\n",
       "          [ 0.1061, -0.1632, -0.0830,  ...,  0.0917, -0.1600, -0.1806]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0995, -0.1083,  0.1042,  0.0004, -0.0898, -0.0519,  0.1067, -0.0559,\n",
       "           0.0955, -0.0764, -0.0677,  0.0586, -0.0306, -0.0203,  0.0467,  0.0712,\n",
       "          -0.1135, -0.1226, -0.0231,  0.0657,  0.0927, -0.0215,  0.0301, -0.0434,\n",
       "          -0.0357, -0.0400, -0.0178,  0.0056,  0.0223, -0.0344,  0.1209,  0.0650,\n",
       "           0.1139,  0.0407,  0.1012, -0.1009,  0.0595,  0.0588, -0.1127, -0.1157,\n",
       "           0.0397, -0.0805, -0.0480,  0.1167,  0.0833, -0.0516,  0.0056,  0.0431,\n",
       "           0.0273, -0.0940, -0.1145,  0.0265,  0.0032, -0.0170, -0.0034,  0.0151,\n",
       "           0.0470,  0.0264, -0.0259,  0.0127,  0.0378,  0.1026,  0.0128, -0.0714],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2113,  0.0289, -0.1312,  ..., -0.1335, -0.0513,  0.0507],\n",
       "          [-0.0596,  0.0118,  0.2067,  ..., -0.1407, -0.0143,  0.0230],\n",
       "          [ 0.0755,  0.1410, -0.0921,  ...,  0.1783, -0.1574, -0.1865],\n",
       "          ...,\n",
       "          [-0.1857, -0.1075,  0.1020,  ...,  0.0186,  0.0230, -0.1248],\n",
       "          [ 0.0398, -0.1707, -0.0443,  ..., -0.2062,  0.1857,  0.1324],\n",
       "          [ 0.0899, -0.0708, -0.0331,  ..., -0.0548,  0.0707, -0.1797]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0151, -0.0559,  0.1143, -0.0678, -0.0955, -0.0340,  0.0335, -0.0413,\n",
       "           0.1025, -0.0349,  0.0061, -0.0228, -0.1101,  0.1001, -0.0668, -0.0928,\n",
       "          -0.0285,  0.0102,  0.0553,  0.0551, -0.0471, -0.0926, -0.0487,  0.0126,\n",
       "           0.0997, -0.0904,  0.1135, -0.0027,  0.0536,  0.0276, -0.0824,  0.1211,\n",
       "           0.0530,  0.0921, -0.0052, -0.0988,  0.0205, -0.0665,  0.1067,  0.0109,\n",
       "          -0.0842, -0.0745, -0.0173,  0.0614,  0.1142,  0.1204, -0.0612,  0.0824,\n",
       "           0.0116,  0.0051,  0.1010,  0.0904,  0.0986, -0.0263, -0.0596, -0.0492,\n",
       "          -0.0233, -0.0765,  0.0104, -0.0380, -0.1047,  0.0203,  0.0183,  0.1044],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0632],\n",
       "          [ 0.1743],\n",
       "          [ 0.0617],\n",
       "          [ 0.0895],\n",
       "          [ 0.0710],\n",
       "          [-0.0702],\n",
       "          [ 0.2553],\n",
       "          [-0.2665],\n",
       "          [ 0.0154],\n",
       "          [ 0.2293],\n",
       "          [-0.0759],\n",
       "          [-0.3016],\n",
       "          [-0.1317],\n",
       "          [-0.2850],\n",
       "          [ 0.1439],\n",
       "          [-0.1296],\n",
       "          [-0.2747],\n",
       "          [ 0.0395],\n",
       "          [-0.1494],\n",
       "          [ 0.2860],\n",
       "          [ 0.0946],\n",
       "          [ 0.2454],\n",
       "          [-0.2616],\n",
       "          [-0.2676],\n",
       "          [-0.1464],\n",
       "          [-0.0920],\n",
       "          [-0.1920],\n",
       "          [-0.0817],\n",
       "          [-0.0603],\n",
       "          [-0.2945],\n",
       "          [-0.3024],\n",
       "          [ 0.1672],\n",
       "          [-0.1638],\n",
       "          [ 0.3001],\n",
       "          [-0.0696],\n",
       "          [-0.1140],\n",
       "          [-0.0936],\n",
       "          [-0.0911],\n",
       "          [ 0.2901],\n",
       "          [ 0.0771],\n",
       "          [ 0.0462],\n",
       "          [ 0.2671],\n",
       "          [-0.0412],\n",
       "          [ 0.0971],\n",
       "          [-0.1238],\n",
       "          [ 0.2849],\n",
       "          [ 0.1271],\n",
       "          [-0.1771],\n",
       "          [ 0.0985],\n",
       "          [ 0.0409],\n",
       "          [-0.1151],\n",
       "          [-0.1987],\n",
       "          [-0.1562],\n",
       "          [ 0.2971],\n",
       "          [ 0.0626],\n",
       "          [ 0.0431],\n",
       "          [-0.0233],\n",
       "          [ 0.2094],\n",
       "          [-0.0654],\n",
       "          [ 0.2097],\n",
       "          [ 0.0624],\n",
       "          [ 0.0867],\n",
       "          [-0.2536],\n",
       "          [-0.1455]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0312,  0.3485,  0.2986,  0.0815, -0.0058,  0.2569, -0.1298,\n",
       "             0.0220,  0.2316,  0.1575, -0.0344,  0.1490,  0.0862,  0.1101,\n",
       "            -0.3529,  0.1973, -0.3551,  0.0016, -0.3431, -0.0871,  0.2662,\n",
       "             0.3932,  0.1859, -0.1348, -0.1974, -0.1164,  0.1567,  0.3280,\n",
       "             0.1714,  0.2491,  0.2741, -0.1807],\n",
       "           [-0.3635, -0.2897, -0.3257,  0.2891, -0.3957,  0.0781,  0.2021,\n",
       "             0.4184,  0.0856, -0.1103, -0.0538,  0.1140,  0.3111,  0.1242,\n",
       "             0.0041, -0.3206, -0.3927,  0.2330,  0.2790, -0.1570,  0.2510,\n",
       "             0.4137, -0.1824, -0.1268,  0.3120, -0.2090, -0.1934,  0.2511,\n",
       "            -0.0975,  0.2234,  0.1427, -0.2129]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0199, -0.2150,  0.0957,  ...,  0.1646, -0.0849,  0.1013],\n",
       "          [-0.1656,  0.1792,  0.1542,  ...,  0.0846,  0.0703,  0.2153],\n",
       "          [-0.0781,  0.1609, -0.0578,  ..., -0.1898,  0.0274,  0.1046],\n",
       "          ...,\n",
       "          [ 0.1944,  0.0904, -0.1909,  ..., -0.0735, -0.0354, -0.0109],\n",
       "          [ 0.0007,  0.0190, -0.0548,  ...,  0.1863,  0.1795,  0.0289],\n",
       "          [ 0.0973,  0.1602, -0.1571,  ..., -0.1987,  0.0118, -0.0634]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0859, -0.0918, -0.0608, -0.0217,  0.0096, -0.1181,  0.0079, -0.0194,\n",
       "          -0.1189, -0.1034, -0.1174, -0.1189, -0.0998,  0.1034,  0.0680,  0.0873,\n",
       "          -0.0594, -0.0552,  0.1119,  0.0395,  0.0405,  0.1148,  0.0678,  0.0532,\n",
       "          -0.0874, -0.1081,  0.0122, -0.1209, -0.0509, -0.0245, -0.0459,  0.0638,\n",
       "          -0.0815, -0.0376,  0.0892,  0.0947, -0.0012, -0.0901, -0.0886,  0.0054,\n",
       "          -0.0043,  0.0206, -0.0793, -0.0132,  0.0935, -0.0016, -0.0892, -0.0961,\n",
       "           0.0248,  0.0859,  0.1014, -0.1173, -0.0993, -0.0411, -0.1205, -0.0174,\n",
       "          -0.0184,  0.1114,  0.0300,  0.0257,  0.1025,  0.1211, -0.1229,  0.1196],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1569,  0.0481,  0.1717,  ...,  0.1476,  0.0089, -0.1117],\n",
       "          [-0.0994,  0.0854,  0.1992,  ..., -0.1620,  0.0880, -0.0381],\n",
       "          [ 0.2008, -0.0708,  0.0683,  ...,  0.1493,  0.1422,  0.2004],\n",
       "          ...,\n",
       "          [ 0.0397, -0.0704,  0.0204,  ..., -0.0233, -0.1857, -0.1846],\n",
       "          [-0.1997, -0.1616,  0.0973,  ...,  0.1688, -0.0529, -0.1164],\n",
       "          [ 0.1449, -0.1511,  0.0777,  ...,  0.0889,  0.0774,  0.1837]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0712, -0.0856, -0.0069, -0.0158,  0.0972, -0.0393, -0.0596,  0.1052,\n",
       "          -0.0633, -0.1238, -0.1211, -0.0748, -0.0165, -0.1123,  0.0666, -0.0730,\n",
       "           0.0996, -0.0180,  0.0397,  0.0033, -0.0016, -0.0877, -0.0671, -0.0959,\n",
       "          -0.0958, -0.1191, -0.0727,  0.0391, -0.0930, -0.0924, -0.0352, -0.0977,\n",
       "           0.0233,  0.0860, -0.0129, -0.1044, -0.1181,  0.0236,  0.1090,  0.0940,\n",
       "           0.0804,  0.0388,  0.0993,  0.0592,  0.0072,  0.1146,  0.0620,  0.0731,\n",
       "           0.0855, -0.1079,  0.1248, -0.0818,  0.0241,  0.1156, -0.0705,  0.0710,\n",
       "           0.1199,  0.1097, -0.0223,  0.0986,  0.1023, -0.0205, -0.0289,  0.1022],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1891],\n",
       "          [-0.2538],\n",
       "          [ 0.1156],\n",
       "          [ 0.0729],\n",
       "          [ 0.0357],\n",
       "          [ 0.2972],\n",
       "          [-0.1024],\n",
       "          [ 0.1772],\n",
       "          [ 0.1092],\n",
       "          [-0.0053],\n",
       "          [ 0.1312],\n",
       "          [-0.2723],\n",
       "          [ 0.2937],\n",
       "          [-0.1050],\n",
       "          [-0.2950],\n",
       "          [-0.1048],\n",
       "          [ 0.1133],\n",
       "          [ 0.0116],\n",
       "          [ 0.2610],\n",
       "          [-0.1721],\n",
       "          [ 0.0786],\n",
       "          [-0.2014],\n",
       "          [-0.1801],\n",
       "          [ 0.2911],\n",
       "          [ 0.2051],\n",
       "          [ 0.2768],\n",
       "          [-0.0103],\n",
       "          [-0.0131],\n",
       "          [-0.2611],\n",
       "          [ 0.1686],\n",
       "          [ 0.0029],\n",
       "          [ 0.1790],\n",
       "          [ 0.1986],\n",
       "          [-0.0922],\n",
       "          [-0.1198],\n",
       "          [-0.2102],\n",
       "          [-0.2336],\n",
       "          [-0.2823],\n",
       "          [-0.2377],\n",
       "          [ 0.1599],\n",
       "          [ 0.2721],\n",
       "          [-0.2591],\n",
       "          [-0.1670],\n",
       "          [-0.2896],\n",
       "          [-0.1814],\n",
       "          [-0.1628],\n",
       "          [-0.0480],\n",
       "          [ 0.2870],\n",
       "          [-0.2884],\n",
       "          [-0.1612],\n",
       "          [ 0.1451],\n",
       "          [ 0.2799],\n",
       "          [ 0.2935],\n",
       "          [ 0.0364],\n",
       "          [ 0.0781],\n",
       "          [ 0.0061],\n",
       "          [ 0.1861],\n",
       "          [-0.1637],\n",
       "          [ 0.0125],\n",
       "          [-0.2044],\n",
       "          [ 0.0987],\n",
       "          [-0.1547],\n",
       "          [ 0.0392],\n",
       "          [-0.2389]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1195, -0.2929,  0.3527, -0.3854,  0.2523, -0.1661, -0.3780,\n",
       "            -0.3477, -0.0856, -0.2382,  0.3039, -0.3862,  0.2756,  0.0147,\n",
       "             0.2153, -0.3701,  0.3431,  0.1960, -0.1690, -0.0499,  0.2400,\n",
       "             0.1814,  0.3812, -0.1924,  0.0137, -0.3358, -0.2968,  0.2981,\n",
       "             0.3565,  0.1848, -0.2937,  0.0579],\n",
       "           [-0.0210, -0.0073,  0.3512, -0.1874,  0.2880, -0.1935,  0.0870,\n",
       "            -0.2484,  0.2941,  0.4087,  0.3026, -0.0402, -0.0146,  0.2949,\n",
       "             0.2338, -0.0192, -0.1607, -0.1538,  0.0209, -0.1189, -0.0625,\n",
       "            -0.0899, -0.3519,  0.0785, -0.3109, -0.0858, -0.0072, -0.3346,\n",
       "            -0.1945, -0.0975, -0.0142, -0.3626]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1084,  0.1322,  0.2065,  ..., -0.0898, -0.0439,  0.1219],\n",
       "          [ 0.1781, -0.1632, -0.0778,  ..., -0.0438, -0.0322, -0.0268],\n",
       "          [-0.2033, -0.0702, -0.0267,  ...,  0.2106, -0.1699, -0.2055],\n",
       "          ...,\n",
       "          [ 0.0088,  0.2035,  0.1454,  ...,  0.0361,  0.1051, -0.0412],\n",
       "          [-0.0422,  0.0634,  0.1457,  ...,  0.0427, -0.1985, -0.0054],\n",
       "          [ 0.1569, -0.0607,  0.0067,  ...,  0.0315, -0.1614, -0.1189]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0984, -0.0646,  0.0939,  0.1109,  0.0755, -0.1133, -0.1014, -0.0937,\n",
       "          -0.0599, -0.0969,  0.0722, -0.1249,  0.0775,  0.0122,  0.0649,  0.0315,\n",
       "           0.0037, -0.0849, -0.0293, -0.0761, -0.0961, -0.0448,  0.1135, -0.0954,\n",
       "           0.0280, -0.0648, -0.0338,  0.0811,  0.0580, -0.0257, -0.0228,  0.0164,\n",
       "          -0.1028,  0.0406,  0.0389, -0.0664, -0.0153, -0.0221, -0.0015, -0.1141,\n",
       "           0.0034, -0.0938, -0.0471, -0.0124,  0.1052, -0.0895,  0.0909, -0.0087,\n",
       "          -0.0387,  0.0377,  0.0342,  0.1231, -0.0071, -0.0632, -0.0305, -0.0677,\n",
       "           0.0557, -0.0766, -0.1035,  0.0960,  0.0980, -0.0124, -0.0690,  0.0554],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1035, -0.0659, -0.1535,  ..., -0.2001, -0.1689, -0.1299],\n",
       "          [ 0.1757,  0.1549, -0.0247,  ..., -0.1009,  0.1396,  0.1214],\n",
       "          [-0.1957,  0.1765,  0.0580,  ..., -0.2136,  0.1607, -0.0563],\n",
       "          ...,\n",
       "          [-0.0091,  0.0581,  0.0959,  ..., -0.1444,  0.0070, -0.0192],\n",
       "          [ 0.0900, -0.0866, -0.0230,  ..., -0.0902, -0.0336, -0.0358],\n",
       "          [ 0.0062,  0.1157, -0.0003,  ...,  0.1134,  0.0364, -0.0091]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0424,  0.1125, -0.0911,  0.1103,  0.0142,  0.0227,  0.1209, -0.1064,\n",
       "           0.1244, -0.1178,  0.0438,  0.0315,  0.0801, -0.1004,  0.0342, -0.1009,\n",
       "           0.0105,  0.1107, -0.1186,  0.0783, -0.0206,  0.0779,  0.0245, -0.0704,\n",
       "           0.0411,  0.0731,  0.0426, -0.0219, -0.0654, -0.1222, -0.0487, -0.1215,\n",
       "           0.0744,  0.0046, -0.0717,  0.0978, -0.0194,  0.0025,  0.0441,  0.0520,\n",
       "           0.0970,  0.0061,  0.0956, -0.0631,  0.0496,  0.0312, -0.0591,  0.1177,\n",
       "          -0.0513, -0.0758,  0.0086, -0.0353, -0.0662, -0.0435,  0.0739, -0.0965,\n",
       "           0.0457, -0.0736,  0.0774,  0.1036, -0.1066,  0.0861, -0.1189,  0.1038],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0030],\n",
       "          [-0.0301],\n",
       "          [-0.0515],\n",
       "          [-0.2820],\n",
       "          [ 0.2992],\n",
       "          [-0.0706],\n",
       "          [ 0.2632],\n",
       "          [ 0.1897],\n",
       "          [ 0.0538],\n",
       "          [-0.2823],\n",
       "          [-0.1519],\n",
       "          [-0.2121],\n",
       "          [-0.1183],\n",
       "          [ 0.0300],\n",
       "          [ 0.1028],\n",
       "          [ 0.0170],\n",
       "          [-0.0876],\n",
       "          [ 0.2474],\n",
       "          [-0.1415],\n",
       "          [ 0.0545],\n",
       "          [-0.1497],\n",
       "          [ 0.0363],\n",
       "          [-0.1398],\n",
       "          [ 0.0083],\n",
       "          [-0.2653],\n",
       "          [ 0.0053],\n",
       "          [ 0.0948],\n",
       "          [-0.2346],\n",
       "          [ 0.2630],\n",
       "          [-0.0483],\n",
       "          [ 0.0007],\n",
       "          [ 0.2209],\n",
       "          [ 0.0304],\n",
       "          [ 0.0429],\n",
       "          [ 0.2783],\n",
       "          [-0.0755],\n",
       "          [-0.2558],\n",
       "          [-0.0973],\n",
       "          [ 0.0479],\n",
       "          [ 0.3024],\n",
       "          [ 0.1761],\n",
       "          [ 0.1644],\n",
       "          [-0.1180],\n",
       "          [-0.0998],\n",
       "          [-0.1966],\n",
       "          [-0.1731],\n",
       "          [-0.2253],\n",
       "          [ 0.1515],\n",
       "          [ 0.2717],\n",
       "          [-0.0430],\n",
       "          [-0.0298],\n",
       "          [ 0.0866],\n",
       "          [ 0.1173],\n",
       "          [ 0.1025],\n",
       "          [ 0.1208],\n",
       "          [-0.1990],\n",
       "          [ 0.2997],\n",
       "          [-0.0963],\n",
       "          [-0.2044],\n",
       "          [ 0.2640],\n",
       "          [ 0.1190],\n",
       "          [-0.0873],\n",
       "          [ 0.2940],\n",
       "          [ 0.1702]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1205,  0.0733,  0.3220,  0.0906,  0.3017,  0.0103, -0.4166,\n",
       "            -0.0868,  0.2212, -0.0515,  0.2143,  0.0675, -0.3865,  0.3147,\n",
       "            -0.0339, -0.3097, -0.2882,  0.0665, -0.1138, -0.3022, -0.3070,\n",
       "            -0.3367,  0.3996,  0.3592,  0.2525,  0.4122,  0.3210, -0.2089,\n",
       "            -0.3482, -0.3120, -0.0715, -0.3034],\n",
       "           [-0.2137, -0.1128, -0.0452,  0.2494, -0.1972, -0.3131, -0.4175,\n",
       "             0.3537,  0.3365, -0.0192, -0.3269, -0.2831,  0.1788,  0.3392,\n",
       "            -0.1252, -0.0502,  0.1976, -0.3106, -0.0243,  0.2231,  0.2184,\n",
       "            -0.3628,  0.1067,  0.2518, -0.3876,  0.3257, -0.2233,  0.1523,\n",
       "             0.3836,  0.2166, -0.3212, -0.0676]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1804, -0.1092, -0.1320,  ...,  0.1224,  0.1832, -0.0678],\n",
       "          [-0.0305,  0.0213, -0.0207,  ..., -0.0182, -0.0820,  0.0224],\n",
       "          [-0.1130, -0.1471,  0.1001,  ...,  0.1370, -0.1740, -0.0137],\n",
       "          ...,\n",
       "          [-0.1583,  0.1042,  0.1741,  ..., -0.1274, -0.0672, -0.1180],\n",
       "          [ 0.0543,  0.2052,  0.0347,  ...,  0.1281, -0.2134,  0.1538],\n",
       "          [ 0.1638, -0.0855, -0.0760,  ...,  0.1964,  0.1856, -0.1873]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1055,  0.0865, -0.0838,  0.0332,  0.0452,  0.0817, -0.0158, -0.1074,\n",
       "           0.0734,  0.0967, -0.0819,  0.1079,  0.1198,  0.0301, -0.0200, -0.0773,\n",
       "           0.1245, -0.0365, -0.0214,  0.0589,  0.0209,  0.0077, -0.0334,  0.0589,\n",
       "           0.0535, -0.0472, -0.0854,  0.0723,  0.1051, -0.1018,  0.1179,  0.0723,\n",
       "           0.0890, -0.0967, -0.0206, -0.0940, -0.0763,  0.0742,  0.0649, -0.1195,\n",
       "           0.0911,  0.0375, -0.0600,  0.1226, -0.0474,  0.0150,  0.0102, -0.0561,\n",
       "          -0.0334,  0.1214, -0.1164, -0.1071,  0.0458, -0.0518,  0.0540, -0.1249,\n",
       "           0.1167,  0.0423, -0.0150,  0.0376, -0.0634, -0.0732,  0.0426,  0.0112],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1700, -0.1156,  0.0754,  ..., -0.0404, -0.1151,  0.0191],\n",
       "          [-0.2143, -0.1678, -0.0317,  ..., -0.0914, -0.1865,  0.1919],\n",
       "          [-0.1725,  0.1049, -0.1834,  ..., -0.0827,  0.1456, -0.1102],\n",
       "          ...,\n",
       "          [-0.2046, -0.0799, -0.1531,  ..., -0.2055,  0.0771,  0.0216],\n",
       "          [-0.0370,  0.0824,  0.2004,  ...,  0.0239, -0.1440,  0.1957],\n",
       "          [-0.1564, -0.1073, -0.0031,  ...,  0.1524,  0.2160, -0.0278]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0843,  0.0405,  0.1210,  0.0681, -0.0731,  0.0988,  0.0139,  0.0448,\n",
       "           0.0782, -0.1221,  0.0969, -0.0908, -0.1137,  0.0275,  0.0698,  0.0526,\n",
       "           0.0264,  0.0723, -0.0049, -0.0627,  0.0458,  0.1108,  0.0204, -0.0043,\n",
       "          -0.0997,  0.0820, -0.0906, -0.0643,  0.0976, -0.0060,  0.1116,  0.0337,\n",
       "           0.0092, -0.1186, -0.1219,  0.1211, -0.0085,  0.0798,  0.0538,  0.0094,\n",
       "          -0.0349, -0.0349,  0.0252,  0.0260,  0.0722,  0.1101,  0.0505, -0.0462,\n",
       "           0.0940,  0.0613, -0.1020,  0.0646,  0.1222, -0.1232, -0.0469, -0.0461,\n",
       "           0.1047, -0.0712,  0.0913,  0.0715, -0.0540,  0.1140, -0.0242,  0.0674],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0179],\n",
       "          [ 0.1502],\n",
       "          [-0.0316],\n",
       "          [ 0.2738],\n",
       "          [-0.1986],\n",
       "          [-0.1505],\n",
       "          [ 0.2253],\n",
       "          [-0.1595],\n",
       "          [-0.0024],\n",
       "          [-0.3011],\n",
       "          [ 0.1980],\n",
       "          [ 0.1134],\n",
       "          [ 0.1619],\n",
       "          [ 0.0857],\n",
       "          [ 0.1592],\n",
       "          [-0.2753],\n",
       "          [-0.2179],\n",
       "          [ 0.1838],\n",
       "          [ 0.1119],\n",
       "          [ 0.1154],\n",
       "          [ 0.0589],\n",
       "          [-0.0282],\n",
       "          [-0.2332],\n",
       "          [-0.0106],\n",
       "          [ 0.2297],\n",
       "          [ 0.1135],\n",
       "          [-0.0259],\n",
       "          [ 0.1555],\n",
       "          [-0.0274],\n",
       "          [ 0.1486],\n",
       "          [ 0.3023],\n",
       "          [ 0.2471],\n",
       "          [-0.1210],\n",
       "          [ 0.2531],\n",
       "          [-0.0238],\n",
       "          [ 0.2799],\n",
       "          [ 0.2717],\n",
       "          [ 0.1551],\n",
       "          [ 0.2582],\n",
       "          [-0.0041],\n",
       "          [ 0.1551],\n",
       "          [ 0.1449],\n",
       "          [ 0.0788],\n",
       "          [ 0.0041],\n",
       "          [ 0.2085],\n",
       "          [ 0.0421],\n",
       "          [-0.1616],\n",
       "          [-0.2511],\n",
       "          [ 0.1772],\n",
       "          [ 0.1794],\n",
       "          [ 0.0797],\n",
       "          [-0.1428],\n",
       "          [ 0.0580],\n",
       "          [-0.1226],\n",
       "          [ 0.0208],\n",
       "          [-0.0521],\n",
       "          [-0.0290],\n",
       "          [-0.1543],\n",
       "          [ 0.0937],\n",
       "          [-0.2312],\n",
       "          [-0.2149],\n",
       "          [-0.1458],\n",
       "          [-0.0299],\n",
       "          [-0.0270]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.3021, -0.3304,  0.3586,  0.0033,  0.4187,  0.1028, -0.1581,\n",
       "             0.3881, -0.0036,  0.2609,  0.3473, -0.1282,  0.1434, -0.3168,\n",
       "             0.0342,  0.4189,  0.1420,  0.1798,  0.1056,  0.2468, -0.2099,\n",
       "            -0.3044, -0.2601, -0.1809,  0.0030,  0.2016,  0.3144,  0.3778,\n",
       "            -0.0413,  0.1849, -0.0167, -0.3315],\n",
       "           [-0.1180,  0.1788, -0.2283, -0.0591,  0.1272, -0.1045,  0.2227,\n",
       "             0.2532, -0.4006, -0.0822, -0.1175,  0.0248,  0.1607,  0.2890,\n",
       "             0.0997,  0.2908,  0.2902, -0.3129, -0.2467,  0.1440,  0.3088,\n",
       "             0.0386, -0.0143,  0.2165, -0.3894, -0.1767, -0.0588, -0.2241,\n",
       "            -0.0384,  0.0274, -0.3748, -0.0305]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0755,  0.1571,  0.1910,  ..., -0.2156,  0.1666,  0.0435],\n",
       "          [-0.0552,  0.2050, -0.2059,  ...,  0.1855, -0.0416,  0.1030],\n",
       "          [-0.0824, -0.1891,  0.2148,  ..., -0.1973,  0.0026,  0.0782],\n",
       "          ...,\n",
       "          [-0.1981, -0.1168, -0.0894,  ..., -0.1248,  0.1744,  0.0697],\n",
       "          [-0.0624,  0.1309,  0.0662,  ...,  0.0606,  0.0713, -0.0089],\n",
       "          [ 0.0569,  0.0004,  0.2144,  ...,  0.1261,  0.0088,  0.1363]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0580, -0.0885,  0.0826,  0.1049, -0.0757, -0.0757, -0.0627,  0.0788,\n",
       "          -0.0604, -0.0881, -0.1098,  0.0148, -0.0195, -0.0406, -0.0154,  0.0105,\n",
       "           0.0740, -0.0359,  0.1043, -0.0287, -0.0126,  0.0548,  0.0909,  0.0050,\n",
       "           0.0869, -0.0661,  0.1142, -0.0783,  0.0063, -0.0120,  0.0153,  0.0132,\n",
       "          -0.0065, -0.0870,  0.1219,  0.1210,  0.0524,  0.0827,  0.1050,  0.0341,\n",
       "           0.1172, -0.1213,  0.0766,  0.1066, -0.0498,  0.0024,  0.1002,  0.1005,\n",
       "          -0.0155,  0.0177,  0.0085,  0.0604,  0.0930, -0.1047,  0.0467, -0.0260,\n",
       "          -0.0716, -0.1249, -0.0521,  0.0800, -0.0865, -0.0984,  0.0864, -0.0155],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1700,  0.1991, -0.0095,  ...,  0.1151, -0.2149, -0.0302],\n",
       "          [ 0.0378,  0.0523,  0.1505,  ...,  0.1908, -0.0133, -0.0487],\n",
       "          [ 0.0500, -0.1872,  0.0020,  ...,  0.0597,  0.1744, -0.1849],\n",
       "          ...,\n",
       "          [-0.1333,  0.0076,  0.0675,  ...,  0.0665, -0.0082, -0.1779],\n",
       "          [ 0.0424, -0.1719, -0.1105,  ..., -0.0607,  0.0520,  0.2128],\n",
       "          [ 0.1232,  0.0810,  0.1321,  ...,  0.0618, -0.0486,  0.0109]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0504,  0.0179, -0.1113, -0.0303, -0.0852,  0.0789, -0.1027,  0.1087,\n",
       "           0.0420, -0.1206,  0.0664, -0.0148, -0.0686, -0.0150, -0.1172, -0.1136,\n",
       "          -0.0263, -0.0816, -0.0519,  0.0659,  0.0106,  0.0436,  0.0978,  0.0387,\n",
       "           0.0765,  0.0099, -0.0806, -0.0098,  0.0569,  0.1069,  0.0427, -0.1115,\n",
       "           0.0996,  0.0527,  0.0692,  0.0052,  0.0485,  0.1020, -0.0742,  0.0791,\n",
       "          -0.0961,  0.0616,  0.0573, -0.0618,  0.0413,  0.0738,  0.1097, -0.0027,\n",
       "          -0.0488, -0.0273,  0.0318, -0.1028, -0.0749, -0.0657,  0.0975,  0.0889,\n",
       "          -0.0705,  0.0086, -0.0776,  0.0144, -0.0290, -0.0933,  0.0189, -0.0454],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0495],\n",
       "          [ 0.0745],\n",
       "          [-0.0233],\n",
       "          [-0.0942],\n",
       "          [-0.2025],\n",
       "          [ 0.1105],\n",
       "          [ 0.0892],\n",
       "          [ 0.2903],\n",
       "          [-0.3005],\n",
       "          [-0.0483],\n",
       "          [-0.0861],\n",
       "          [-0.0659],\n",
       "          [ 0.1757],\n",
       "          [ 0.0728],\n",
       "          [-0.2375],\n",
       "          [-0.2091],\n",
       "          [ 0.0636],\n",
       "          [-0.1082],\n",
       "          [-0.1540],\n",
       "          [-0.2598],\n",
       "          [-0.2424],\n",
       "          [-0.3035],\n",
       "          [-0.3019],\n",
       "          [ 0.2354],\n",
       "          [ 0.1618],\n",
       "          [ 0.1064],\n",
       "          [ 0.2785],\n",
       "          [ 0.0851],\n",
       "          [ 0.2378],\n",
       "          [-0.0567],\n",
       "          [-0.2257],\n",
       "          [ 0.2094],\n",
       "          [-0.1786],\n",
       "          [ 0.2466],\n",
       "          [-0.1272],\n",
       "          [ 0.0109],\n",
       "          [ 0.2543],\n",
       "          [ 0.0024],\n",
       "          [ 0.2002],\n",
       "          [-0.0377],\n",
       "          [ 0.0996],\n",
       "          [-0.1512],\n",
       "          [-0.0210],\n",
       "          [ 0.2188],\n",
       "          [-0.1103],\n",
       "          [ 0.1607],\n",
       "          [ 0.0083],\n",
       "          [ 0.2106],\n",
       "          [ 0.1539],\n",
       "          [-0.0442],\n",
       "          [ 0.2820],\n",
       "          [ 0.0397],\n",
       "          [ 0.3003],\n",
       "          [-0.1832],\n",
       "          [-0.2804],\n",
       "          [ 0.0071],\n",
       "          [-0.1548],\n",
       "          [ 0.2797],\n",
       "          [-0.2886],\n",
       "          [ 0.0010],\n",
       "          [-0.1598],\n",
       "          [ 0.2694],\n",
       "          [-0.1046],\n",
       "          [ 0.1651]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1968, -0.2411,  0.1480, -0.1417, -0.3346,  0.3051, -0.1588,\n",
       "            -0.2246, -0.0580,  0.2954,  0.3255,  0.2299,  0.0133, -0.2588,\n",
       "             0.2384,  0.0796, -0.2702, -0.0898, -0.2025, -0.3420, -0.2741,\n",
       "             0.3466,  0.0067,  0.1126, -0.1820,  0.1566, -0.3060,  0.0440,\n",
       "            -0.1240, -0.3639,  0.2761, -0.0330],\n",
       "           [-0.1677, -0.1899,  0.0785,  0.1017,  0.0991,  0.2913,  0.0235,\n",
       "             0.0813,  0.3970, -0.1377, -0.1104, -0.3576, -0.1658, -0.2071,\n",
       "             0.0215, -0.3165, -0.2838, -0.1660,  0.2429,  0.1669, -0.0191,\n",
       "            -0.2359,  0.3806,  0.4034,  0.3255, -0.3140,  0.0551, -0.1688,\n",
       "            -0.0255,  0.1769,  0.0126, -0.1420]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0867,  0.1957, -0.0779,  ...,  0.0195, -0.1962, -0.2097],\n",
       "          [ 0.0449,  0.1157,  0.1509,  ...,  0.1845,  0.0720, -0.0091],\n",
       "          [-0.0921,  0.2058, -0.1386,  ...,  0.1844,  0.1004,  0.1113],\n",
       "          ...,\n",
       "          [ 0.0517,  0.0179,  0.1972,  ..., -0.2086,  0.0617,  0.1597],\n",
       "          [-0.1058, -0.2140,  0.1190,  ...,  0.0758,  0.2048,  0.0912],\n",
       "          [ 0.0596, -0.0586, -0.0230,  ...,  0.1562,  0.0289, -0.0304]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0714, -0.0854,  0.1013, -0.0600,  0.0629,  0.0573,  0.0918,  0.0906,\n",
       "           0.0912,  0.0472,  0.0917, -0.0022, -0.0785, -0.0321,  0.0361, -0.1203,\n",
       "          -0.0677,  0.0673, -0.0513,  0.0083, -0.0809, -0.0874, -0.1250,  0.0840,\n",
       "          -0.0941, -0.1242, -0.0974, -0.0885, -0.1142, -0.0127, -0.0138, -0.0641,\n",
       "           0.0540,  0.0979, -0.0064, -0.0412,  0.0812,  0.0020,  0.0706, -0.0773,\n",
       "           0.0676,  0.0634,  0.1109,  0.1008, -0.0488, -0.1005, -0.0614, -0.1221,\n",
       "           0.0547, -0.0638,  0.0490,  0.0086,  0.0810, -0.0242,  0.0543, -0.0171,\n",
       "           0.0911,  0.0241,  0.0538, -0.0339,  0.1006, -0.0988, -0.0630,  0.0177],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0218, -0.0980, -0.1092,  ..., -0.0408, -0.1479,  0.0334],\n",
       "          [ 0.0946, -0.0588,  0.1532,  ..., -0.1059,  0.1989, -0.0568],\n",
       "          [-0.1251, -0.0512, -0.0664,  ...,  0.0875, -0.0508, -0.0105],\n",
       "          ...,\n",
       "          [ 0.0657, -0.1868, -0.1144,  ..., -0.0828,  0.1120,  0.0877],\n",
       "          [-0.0578,  0.1692,  0.1530,  ...,  0.1583,  0.1216,  0.2023],\n",
       "          [-0.1332,  0.1114, -0.0790,  ...,  0.1909,  0.0076,  0.0694]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0525,  0.0125, -0.0468, -0.0957, -0.0212, -0.1230,  0.1108,  0.0475,\n",
       "           0.0664,  0.0377,  0.0393,  0.0641, -0.0827, -0.0744, -0.0396,  0.0948,\n",
       "           0.0904,  0.0064,  0.0221,  0.0149,  0.0240, -0.1085,  0.0632,  0.1222,\n",
       "           0.1126,  0.1098,  0.1186,  0.1004,  0.0775,  0.0584,  0.0032,  0.0498,\n",
       "          -0.0986,  0.0919, -0.0501,  0.1059, -0.0951, -0.0675,  0.0492, -0.0989,\n",
       "           0.0090, -0.0685, -0.0031,  0.1128,  0.1183, -0.0330, -0.0892,  0.0138,\n",
       "           0.1198, -0.0054,  0.0637,  0.0305, -0.0340,  0.0650,  0.0949, -0.1135,\n",
       "           0.0404, -0.0402,  0.0843, -0.0126, -0.0793, -0.0163,  0.0273,  0.0159],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1504],\n",
       "          [-0.2644],\n",
       "          [-0.1801],\n",
       "          [ 0.2645],\n",
       "          [-0.1902],\n",
       "          [-0.1104],\n",
       "          [ 0.1613],\n",
       "          [-0.2107],\n",
       "          [-0.2219],\n",
       "          [-0.1140],\n",
       "          [ 0.2264],\n",
       "          [-0.2436],\n",
       "          [ 0.1085],\n",
       "          [ 0.0537],\n",
       "          [-0.3030],\n",
       "          [ 0.0262],\n",
       "          [-0.3007],\n",
       "          [ 0.2120],\n",
       "          [ 0.0625],\n",
       "          [ 0.0755],\n",
       "          [-0.2542],\n",
       "          [ 0.0382],\n",
       "          [-0.0382],\n",
       "          [-0.0078],\n",
       "          [ 0.1944],\n",
       "          [-0.0808],\n",
       "          [-0.1591],\n",
       "          [-0.1072],\n",
       "          [ 0.1842],\n",
       "          [ 0.1861],\n",
       "          [-0.2208],\n",
       "          [-0.2822],\n",
       "          [-0.2468],\n",
       "          [-0.2508],\n",
       "          [-0.0823],\n",
       "          [-0.2922],\n",
       "          [-0.0161],\n",
       "          [ 0.2349],\n",
       "          [ 0.0331],\n",
       "          [ 0.0628],\n",
       "          [-0.2126],\n",
       "          [-0.2266],\n",
       "          [ 0.1600],\n",
       "          [-0.1822],\n",
       "          [-0.2213],\n",
       "          [-0.2089],\n",
       "          [ 0.1972],\n",
       "          [-0.1231],\n",
       "          [-0.2376],\n",
       "          [-0.0443],\n",
       "          [ 0.1257],\n",
       "          [-0.2305],\n",
       "          [-0.2496],\n",
       "          [ 0.1560],\n",
       "          [ 0.2887],\n",
       "          [-0.0841],\n",
       "          [ 0.2782],\n",
       "          [-0.2873],\n",
       "          [ 0.0157],\n",
       "          [-0.1527],\n",
       "          [-0.0467],\n",
       "          [ 0.0325],\n",
       "          [-0.0400],\n",
       "          [-0.1123]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0488,  0.0393,  0.0537, -0.1420, -0.4129,  0.3358,  0.2832,\n",
       "             0.3956,  0.1152, -0.0227, -0.3928, -0.2366,  0.1011,  0.2055,\n",
       "            -0.3898, -0.0062,  0.2801,  0.0159, -0.2454,  0.3637, -0.0919,\n",
       "            -0.3116,  0.0640,  0.1238, -0.2133, -0.1097, -0.1393, -0.2021,\n",
       "            -0.0592,  0.3710, -0.2582,  0.1608],\n",
       "           [ 0.3282, -0.2821,  0.3484, -0.2978,  0.1524,  0.0624,  0.0043,\n",
       "            -0.0418, -0.2129, -0.1576,  0.1279,  0.2842,  0.2517,  0.0581,\n",
       "             0.3341,  0.1335, -0.1626, -0.1005, -0.2271, -0.1105, -0.1005,\n",
       "             0.0415,  0.4162,  0.3339,  0.1334, -0.0563, -0.3539,  0.1156,\n",
       "             0.0165,  0.1089,  0.3194,  0.3026]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1201,  0.0905,  0.1949,  ...,  0.1751,  0.1907, -0.2143],\n",
       "          [-0.1380,  0.0844,  0.0044,  ..., -0.1349,  0.0432, -0.1069],\n",
       "          [-0.0138, -0.0160,  0.0774,  ..., -0.1028,  0.2141, -0.0130],\n",
       "          ...,\n",
       "          [-0.1655, -0.2058, -0.0882,  ...,  0.0768,  0.1467,  0.0203],\n",
       "          [-0.1992,  0.1085,  0.0426,  ...,  0.0835, -0.1813,  0.1209],\n",
       "          [-0.1205, -0.1159, -0.1969,  ..., -0.0515, -0.0730, -0.0920]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0195, -0.0872,  0.1158,  0.1250, -0.0288, -0.1247,  0.0029, -0.0048,\n",
       "           0.0335, -0.0154,  0.1033, -0.0364, -0.1235,  0.0732,  0.0999,  0.1008,\n",
       "           0.0320,  0.0098,  0.0074,  0.0417,  0.1026,  0.0645,  0.0712,  0.0603,\n",
       "          -0.0631,  0.0900,  0.0543,  0.0802, -0.0959, -0.1241, -0.0599, -0.0912,\n",
       "          -0.0538, -0.1150,  0.0764,  0.0379, -0.1120,  0.0214, -0.0289,  0.0357,\n",
       "           0.0232,  0.0301, -0.1226, -0.0457, -0.1215, -0.0748,  0.0147, -0.0228,\n",
       "          -0.0075,  0.1083, -0.0124,  0.1067,  0.0169,  0.0094,  0.0091, -0.0781,\n",
       "          -0.1071, -0.0784, -0.0690, -0.0146, -0.1110,  0.0922, -0.0560,  0.0534],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0373, -0.2067, -0.0061,  ...,  0.1414, -0.0856,  0.1341],\n",
       "          [ 0.0106,  0.1845, -0.1032,  ...,  0.1652,  0.1617, -0.1554],\n",
       "          [ 0.1477, -0.0035,  0.0125,  ..., -0.0687,  0.1911,  0.0511],\n",
       "          ...,\n",
       "          [-0.2106,  0.1302,  0.1110,  ...,  0.1557, -0.0679,  0.1757],\n",
       "          [-0.1467,  0.1022, -0.1689,  ...,  0.1256, -0.0654,  0.0932],\n",
       "          [-0.0194, -0.0074, -0.1812,  ..., -0.1870,  0.1123, -0.1087]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0325,  0.0749,  0.0705, -0.1033,  0.1144,  0.1229,  0.0529,  0.0266,\n",
       "          -0.0229, -0.1189, -0.0921, -0.1188, -0.1064,  0.1235, -0.0540,  0.1152,\n",
       "           0.1162,  0.0132,  0.0511,  0.0402,  0.1184,  0.0262, -0.0028, -0.0113,\n",
       "           0.1158, -0.1172, -0.0126,  0.0924,  0.1209, -0.0819,  0.0238,  0.0785,\n",
       "          -0.0818,  0.0334, -0.0726, -0.1057, -0.0286,  0.0479,  0.0697,  0.0822,\n",
       "           0.1061, -0.0888, -0.0884, -0.0771,  0.0678,  0.1097,  0.1073,  0.0550,\n",
       "           0.1049,  0.1237, -0.0927,  0.0648,  0.0192, -0.1144,  0.0716, -0.0662,\n",
       "           0.0045,  0.0536,  0.0810, -0.0079, -0.0621, -0.0791,  0.0413,  0.0436],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0455],\n",
       "          [ 0.1413],\n",
       "          [ 0.1853],\n",
       "          [-0.1010],\n",
       "          [-0.2222],\n",
       "          [-0.2107],\n",
       "          [-0.1791],\n",
       "          [ 0.1115],\n",
       "          [-0.1090],\n",
       "          [ 0.1894],\n",
       "          [ 0.0501],\n",
       "          [-0.2674],\n",
       "          [ 0.2333],\n",
       "          [-0.1156],\n",
       "          [ 0.0123],\n",
       "          [-0.2814],\n",
       "          [-0.1326],\n",
       "          [-0.2914],\n",
       "          [ 0.0005],\n",
       "          [-0.0455],\n",
       "          [ 0.1662],\n",
       "          [ 0.0586],\n",
       "          [-0.2222],\n",
       "          [ 0.1870],\n",
       "          [ 0.0124],\n",
       "          [ 0.2233],\n",
       "          [ 0.2996],\n",
       "          [-0.1967],\n",
       "          [ 0.0842],\n",
       "          [-0.1001],\n",
       "          [-0.2810],\n",
       "          [-0.0066],\n",
       "          [-0.0966],\n",
       "          [ 0.2745],\n",
       "          [ 0.0526],\n",
       "          [ 0.2934],\n",
       "          [ 0.2812],\n",
       "          [-0.1887],\n",
       "          [ 0.0062],\n",
       "          [ 0.2989],\n",
       "          [ 0.0487],\n",
       "          [ 0.2555],\n",
       "          [-0.2318],\n",
       "          [ 0.2157],\n",
       "          [-0.1429],\n",
       "          [ 0.1727],\n",
       "          [-0.2374],\n",
       "          [-0.0834],\n",
       "          [-0.2203],\n",
       "          [-0.1166],\n",
       "          [-0.1649],\n",
       "          [ 0.0611],\n",
       "          [ 0.1769],\n",
       "          [ 0.0603],\n",
       "          [ 0.2617],\n",
       "          [ 0.1652],\n",
       "          [ 0.0591],\n",
       "          [ 0.0133],\n",
       "          [ 0.2914],\n",
       "          [ 0.1512],\n",
       "          [ 0.1108],\n",
       "          [-0.2632],\n",
       "          [-0.0341],\n",
       "          [ 0.2666]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0779, -0.4066,  0.2855,  0.3360, -0.1081,  0.0930,  0.1555,\n",
       "            -0.2712,  0.3555,  0.3810, -0.2590, -0.1636,  0.3370, -0.0460,\n",
       "             0.1997,  0.3929, -0.3666,  0.3025, -0.1843,  0.3627, -0.4200,\n",
       "             0.1321, -0.3491, -0.2128,  0.0970, -0.2131, -0.2838, -0.1288,\n",
       "             0.1127,  0.1497, -0.0942, -0.1292],\n",
       "           [ 0.1009,  0.4121,  0.3788,  0.2695,  0.0795,  0.0773,  0.1171,\n",
       "            -0.3909, -0.2108, -0.1033,  0.4067,  0.2345,  0.2654, -0.0654,\n",
       "             0.3323,  0.1176, -0.0875, -0.2657, -0.1058,  0.3661,  0.2126,\n",
       "             0.1903, -0.3624, -0.1311, -0.2465, -0.1674, -0.3552,  0.0331,\n",
       "            -0.2121,  0.3093, -0.2040,  0.3369]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0093, -0.2100,  0.1341,  ...,  0.1793, -0.1980, -0.0397],\n",
       "          [ 0.1520,  0.1864,  0.2123,  ...,  0.0057,  0.0232, -0.0918],\n",
       "          [ 0.0039, -0.0385, -0.0921,  ...,  0.0826, -0.1457,  0.1246],\n",
       "          ...,\n",
       "          [-0.1928, -0.1069, -0.1488,  ..., -0.0708,  0.0096, -0.1390],\n",
       "          [-0.0544, -0.0368, -0.0296,  ...,  0.0545,  0.1589,  0.0489],\n",
       "          [ 0.1409, -0.0028, -0.0274,  ..., -0.1613,  0.1969,  0.0179]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0562,  0.0670, -0.0910,  0.0803,  0.1120,  0.0857, -0.0398,  0.0973,\n",
       "          -0.0372,  0.0878,  0.0731,  0.0970,  0.1118,  0.0490,  0.1187,  0.1108,\n",
       "          -0.0794,  0.0221, -0.0451,  0.0338,  0.0653, -0.0010,  0.0024, -0.0792,\n",
       "          -0.1244, -0.0791, -0.0725, -0.0180,  0.0335,  0.0986,  0.0725, -0.1086,\n",
       "           0.1211, -0.0550, -0.0777,  0.1120,  0.0459, -0.0229,  0.0862, -0.0859,\n",
       "          -0.1147, -0.1131,  0.0845, -0.0116,  0.1130, -0.0506,  0.0260, -0.0140,\n",
       "          -0.1022,  0.0833, -0.1078,  0.0957,  0.0691,  0.0397, -0.0842,  0.0283,\n",
       "           0.0078, -0.0534, -0.0528, -0.0360,  0.1070, -0.0345,  0.0708, -0.0718],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1223, -0.2104,  0.2065,  ..., -0.1125, -0.2165,  0.1151],\n",
       "          [ 0.0850, -0.1817, -0.2085,  ..., -0.0385, -0.1826,  0.0322],\n",
       "          [-0.0038, -0.0172, -0.0475,  ...,  0.0602,  0.0906,  0.1228],\n",
       "          ...,\n",
       "          [ 0.0404, -0.1942, -0.1085,  ...,  0.0127, -0.0273, -0.1402],\n",
       "          [ 0.0915, -0.0629, -0.0564,  ..., -0.1822, -0.1754,  0.0165],\n",
       "          [-0.0136,  0.1975, -0.1377,  ...,  0.1299, -0.0390,  0.2159]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1045,  0.0745, -0.0684, -0.0841,  0.0924,  0.0792,  0.0403,  0.0156,\n",
       "           0.0130,  0.0527,  0.0099, -0.0222,  0.0708,  0.1180,  0.1003,  0.0517,\n",
       "           0.0936, -0.0339,  0.0508,  0.0388,  0.0554,  0.0396, -0.0566, -0.0721,\n",
       "           0.0234, -0.0044, -0.1139, -0.1149,  0.0706, -0.0232,  0.1036,  0.0805,\n",
       "          -0.0840,  0.0672, -0.1112,  0.0522,  0.1176,  0.0951, -0.0159,  0.1056,\n",
       "          -0.0715, -0.0244, -0.0563, -0.0936, -0.0556,  0.1127, -0.1139,  0.0599,\n",
       "           0.0128, -0.0563, -0.0019,  0.0764,  0.0242,  0.0161,  0.0043, -0.0960,\n",
       "           0.0842,  0.0718, -0.0946,  0.0275,  0.0164,  0.0304,  0.0080,  0.0948],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0821],\n",
       "          [ 0.0814],\n",
       "          [ 0.2580],\n",
       "          [-0.2440],\n",
       "          [ 0.1210],\n",
       "          [-0.0220],\n",
       "          [-0.0249],\n",
       "          [ 0.0221],\n",
       "          [-0.0633],\n",
       "          [-0.2169],\n",
       "          [ 0.0118],\n",
       "          [ 0.0568],\n",
       "          [ 0.0047],\n",
       "          [-0.2049],\n",
       "          [ 0.0784],\n",
       "          [ 0.2167],\n",
       "          [ 0.2274],\n",
       "          [-0.2211],\n",
       "          [-0.1338],\n",
       "          [ 0.0467],\n",
       "          [ 0.2084],\n",
       "          [-0.0752],\n",
       "          [ 0.0579],\n",
       "          [ 0.2824],\n",
       "          [ 0.2045],\n",
       "          [-0.0438],\n",
       "          [ 0.1142],\n",
       "          [-0.2213],\n",
       "          [-0.1443],\n",
       "          [-0.1357],\n",
       "          [ 0.1818],\n",
       "          [ 0.2332],\n",
       "          [ 0.1578],\n",
       "          [ 0.2192],\n",
       "          [-0.0308],\n",
       "          [ 0.0337],\n",
       "          [-0.2122],\n",
       "          [ 0.0700],\n",
       "          [-0.0236],\n",
       "          [-0.0163],\n",
       "          [ 0.1619],\n",
       "          [-0.2136],\n",
       "          [ 0.0633],\n",
       "          [ 0.0476],\n",
       "          [ 0.0576],\n",
       "          [-0.2134],\n",
       "          [-0.1736],\n",
       "          [-0.2364],\n",
       "          [ 0.2716],\n",
       "          [ 0.0100],\n",
       "          [-0.0634],\n",
       "          [-0.1875],\n",
       "          [-0.1354],\n",
       "          [-0.0492],\n",
       "          [-0.1386],\n",
       "          [-0.2780],\n",
       "          [ 0.2820],\n",
       "          [-0.2305],\n",
       "          [-0.1528],\n",
       "          [-0.2131],\n",
       "          [-0.2095],\n",
       "          [ 0.2762],\n",
       "          [ 0.0884],\n",
       "          [ 0.0669]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2262, -0.1522,  0.0465,  0.1460,  0.1503, -0.2598,  0.2541,\n",
       "             0.0143,  0.3607,  0.3354,  0.2235,  0.0116, -0.3545,  0.2822,\n",
       "             0.3018, -0.2035, -0.3511,  0.2314, -0.2227, -0.3500,  0.3368,\n",
       "             0.3172,  0.2261, -0.1763,  0.3973, -0.4108,  0.3934,  0.2225,\n",
       "            -0.4119,  0.1685, -0.0173,  0.3968],\n",
       "           [-0.0715, -0.3178, -0.2297,  0.3038,  0.2074,  0.1723,  0.0096,\n",
       "             0.1689,  0.3095, -0.1626, -0.0912, -0.4061, -0.1532, -0.2129,\n",
       "            -0.0753,  0.1661, -0.2310, -0.1806, -0.3064, -0.1189, -0.3472,\n",
       "            -0.2420,  0.2119,  0.1218, -0.0739, -0.1054,  0.0879,  0.3885,\n",
       "             0.2844,  0.3176,  0.0031,  0.0835]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2111, -0.0935, -0.0898,  ...,  0.0601,  0.2074, -0.1211],\n",
       "          [-0.0894,  0.1208, -0.0156,  ..., -0.1324, -0.1947, -0.0294],\n",
       "          [ 0.0455, -0.0399,  0.0113,  ..., -0.0820, -0.0475,  0.0082],\n",
       "          ...,\n",
       "          [ 0.2029, -0.0377,  0.1030,  ..., -0.1492,  0.1243, -0.1361],\n",
       "          [ 0.1096,  0.2148,  0.0260,  ...,  0.1329, -0.0578,  0.0897],\n",
       "          [-0.0968, -0.0322, -0.1210,  ..., -0.1667, -0.1722, -0.1402]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.0205e-01,  8.1453e-02, -2.1431e-02,  1.7808e-02, -5.4732e-02,\n",
       "          -4.0235e-02, -4.7119e-02,  1.2231e-01, -3.1364e-02,  1.0988e-01,\n",
       "          -3.7106e-02, -9.5991e-02, -1.0456e-01, -1.3800e-02,  5.5649e-02,\n",
       "          -9.2188e-02, -1.7767e-02, -7.4521e-05,  9.8367e-02,  2.4549e-02,\n",
       "           9.8365e-02, -1.0040e-01, -2.6554e-02, -4.6865e-02,  2.3927e-03,\n",
       "          -7.4474e-02, -2.6721e-02, -5.5733e-02, -1.1740e-01, -3.0165e-02,\n",
       "           1.0611e-01,  1.0294e-01,  1.0261e-01, -4.4665e-02,  2.2085e-02,\n",
       "          -6.2490e-02,  7.7038e-02,  8.4906e-02, -6.3316e-02, -1.0247e-01,\n",
       "           4.9844e-02,  8.7881e-02, -1.0129e-01,  4.1229e-02, -4.1080e-02,\n",
       "           8.2499e-02,  4.1341e-02,  2.9589e-02, -6.0664e-02,  4.2249e-02,\n",
       "          -4.7339e-02,  8.8496e-02, -4.6195e-04,  1.5803e-02, -2.8977e-02,\n",
       "           7.8352e-02,  3.8551e-02,  3.0576e-02,  9.5880e-02, -6.4336e-03,\n",
       "           1.2471e-01,  9.5676e-02,  3.9960e-03, -5.0039e-02],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1565, -0.1035, -0.0187,  ..., -0.1091, -0.0444,  0.1729],\n",
       "          [-0.1330,  0.1634,  0.1218,  ...,  0.0398, -0.1395, -0.0819],\n",
       "          [ 0.1160, -0.2078, -0.0706,  ...,  0.0524,  0.0506, -0.0627],\n",
       "          ...,\n",
       "          [-0.0779, -0.2013, -0.1132,  ...,  0.0896, -0.1292,  0.0578],\n",
       "          [-0.0480,  0.1458,  0.0609,  ...,  0.2143, -0.0671,  0.0764],\n",
       "          [ 0.1745, -0.0536, -0.1285,  ...,  0.0987, -0.1255, -0.0219]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0114,  0.0038,  0.0204, -0.1145, -0.0078, -0.0887, -0.0896,  0.0667,\n",
       "           0.0879,  0.0371,  0.0080, -0.0972, -0.0880,  0.0675,  0.1192, -0.0014,\n",
       "           0.0712, -0.0529, -0.0808, -0.0602, -0.0387, -0.0176, -0.1182, -0.0957,\n",
       "          -0.0202,  0.0124,  0.1125, -0.1214, -0.0313,  0.0792, -0.0524,  0.0725,\n",
       "          -0.0908,  0.1122,  0.0125,  0.0881, -0.0951, -0.0538, -0.1155,  0.0628,\n",
       "           0.0085,  0.0665,  0.0556,  0.0337,  0.1048, -0.0162,  0.0834,  0.0488,\n",
       "          -0.1198,  0.0987,  0.0131,  0.0427, -0.1208, -0.0719, -0.0368,  0.1213,\n",
       "          -0.0390, -0.0633, -0.0498, -0.0484, -0.1200,  0.0868,  0.0192, -0.0162],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1712],\n",
       "          [-0.2242],\n",
       "          [-0.2013],\n",
       "          [ 0.1948],\n",
       "          [-0.0269],\n",
       "          [-0.2893],\n",
       "          [-0.0981],\n",
       "          [ 0.1022],\n",
       "          [ 0.2436],\n",
       "          [ 0.0173],\n",
       "          [-0.1234],\n",
       "          [-0.1162],\n",
       "          [ 0.1449],\n",
       "          [-0.0256],\n",
       "          [ 0.2765],\n",
       "          [-0.1668],\n",
       "          [ 0.0800],\n",
       "          [-0.2286],\n",
       "          [ 0.1977],\n",
       "          [ 0.2937],\n",
       "          [-0.2539],\n",
       "          [-0.1296],\n",
       "          [-0.1747],\n",
       "          [-0.2570],\n",
       "          [ 0.2157],\n",
       "          [-0.2694],\n",
       "          [ 0.1254],\n",
       "          [ 0.0770],\n",
       "          [ 0.1726],\n",
       "          [ 0.2585],\n",
       "          [ 0.2052],\n",
       "          [-0.0519],\n",
       "          [ 0.1751],\n",
       "          [ 0.1606],\n",
       "          [ 0.1990],\n",
       "          [ 0.2780],\n",
       "          [ 0.1549],\n",
       "          [-0.2332],\n",
       "          [-0.0180],\n",
       "          [-0.1632],\n",
       "          [ 0.1856],\n",
       "          [ 0.0583],\n",
       "          [-0.0828],\n",
       "          [-0.2139],\n",
       "          [ 0.2555],\n",
       "          [ 0.0667],\n",
       "          [-0.0299],\n",
       "          [ 0.2953],\n",
       "          [ 0.2854],\n",
       "          [ 0.2768],\n",
       "          [ 0.0849],\n",
       "          [-0.1762],\n",
       "          [ 0.1253],\n",
       "          [-0.1653],\n",
       "          [ 0.0984],\n",
       "          [-0.0915],\n",
       "          [-0.2496],\n",
       "          [-0.2794],\n",
       "          [-0.3031],\n",
       "          [-0.1391],\n",
       "          [-0.1073],\n",
       "          [ 0.2297],\n",
       "          [ 0.1390],\n",
       "          [ 0.0830]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3125, -0.3520,  0.2128, -0.3659, -0.1152, -0.0836,  0.2414,\n",
       "            -0.0152,  0.3712,  0.1922,  0.0938,  0.4081, -0.0619, -0.0136,\n",
       "             0.1478,  0.3035, -0.1767,  0.2403, -0.3005,  0.2040,  0.3527,\n",
       "            -0.2435, -0.3652, -0.3259, -0.1149, -0.1355,  0.2748,  0.3190,\n",
       "            -0.3253, -0.2107, -0.2267, -0.1266]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0682, -0.0111,  0.0819,  ..., -0.0665, -0.0480, -0.0168],\n",
       "          [-0.2071, -0.0634,  0.1541,  ..., -0.1249, -0.2285,  0.0884],\n",
       "          [-0.2306,  0.0281, -0.0954,  ...,  0.1277, -0.0661, -0.1465],\n",
       "          ...,\n",
       "          [-0.1787, -0.0160,  0.0017,  ..., -0.0589,  0.2448, -0.0601],\n",
       "          [-0.0787, -0.2422, -0.0158,  ..., -0.0460, -0.2047, -0.1216],\n",
       "          [ 0.0502,  0.2053, -0.2152,  ..., -0.1705,  0.0726,  0.0704]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0530,  0.0029, -0.0002,  0.1053,  0.1136,  0.0604,  0.0762, -0.1248,\n",
       "          -0.0802, -0.0298,  0.0088,  0.0064,  0.0702,  0.1214, -0.0809,  0.0546,\n",
       "           0.1200,  0.0653,  0.0186, -0.0854, -0.1124, -0.1186, -0.0148, -0.0301,\n",
       "          -0.0187,  0.0411, -0.1040,  0.0701, -0.1124, -0.0181, -0.0026,  0.0795],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1098, -0.2004,  0.2021,  ...,  0.1233,  0.0514,  0.1384],\n",
       "          [-0.1784, -0.1730, -0.0387,  ...,  0.0038,  0.2427, -0.1149],\n",
       "          [-0.1548, -0.1175, -0.0638,  ...,  0.1200,  0.0434, -0.1872],\n",
       "          ...,\n",
       "          [-0.1464,  0.0811, -0.2311,  ..., -0.2287, -0.2180, -0.1256],\n",
       "          [-0.1807, -0.2006, -0.1627,  ...,  0.0892,  0.0353,  0.2307],\n",
       "          [ 0.2180, -0.2015, -0.1540,  ..., -0.2032, -0.0738, -0.0429]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0144,  0.0646, -0.1224,  0.0431,  0.0996,  0.0072,  0.0712, -0.0437,\n",
       "          -0.0186,  0.0964,  0.0284, -0.0303,  0.0086, -0.0833, -0.0266, -0.0860,\n",
       "          -0.0422, -0.0170, -0.1057, -0.0782, -0.1225, -0.0651,  0.1219,  0.0431,\n",
       "           0.0025,  0.1217, -0.1070,  0.1186,  0.0592, -0.0591, -0.0623,  0.0733],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3213],\n",
       "          [-0.2024],\n",
       "          [ 0.3015],\n",
       "          [ 0.0578],\n",
       "          [-0.1868],\n",
       "          [-0.0871],\n",
       "          [ 0.3939],\n",
       "          [ 0.2354],\n",
       "          [ 0.0306],\n",
       "          [ 0.1146],\n",
       "          [ 0.3196],\n",
       "          [-0.2734],\n",
       "          [ 0.4080],\n",
       "          [ 0.2737],\n",
       "          [ 0.3204],\n",
       "          [ 0.1719],\n",
       "          [-0.2945],\n",
       "          [ 0.2317],\n",
       "          [ 0.3538],\n",
       "          [-0.4064],\n",
       "          [-0.0027],\n",
       "          [-0.3211],\n",
       "          [-0.2083],\n",
       "          [ 0.0224],\n",
       "          [-0.3943],\n",
       "          [ 0.0236],\n",
       "          [-0.3469],\n",
       "          [-0.3082],\n",
       "          [ 0.1442],\n",
       "          [-0.3304],\n",
       "          [-0.4206],\n",
       "          [-0.3795]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1584, -0.0640,  0.1089,  0.1209,  0.0562,  0.0293, -0.0442,\n",
       "             0.1179, -0.0636, -0.1741,  0.2528, -0.2596,  0.3403,  0.2717,\n",
       "             0.0793, -0.4203, -0.2676,  0.0187,  0.4071, -0.3880, -0.4073,\n",
       "             0.1955, -0.4038,  0.3168, -0.4179, -0.2788,  0.0856,  0.0197,\n",
       "            -0.2083,  0.1590, -0.0616, -0.1128]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0321, -0.1821, -0.2203,  ..., -0.0514, -0.0010,  0.0428],\n",
       "          [-0.0553, -0.0121,  0.2388,  ..., -0.1592, -0.1372, -0.0901],\n",
       "          [-0.0228,  0.1427, -0.1997,  ...,  0.1278,  0.0694,  0.0885],\n",
       "          ...,\n",
       "          [ 0.1898,  0.0225,  0.1388,  ...,  0.1975,  0.2048, -0.1843],\n",
       "          [ 0.0803,  0.0394, -0.1513,  ...,  0.2248,  0.1480, -0.0715],\n",
       "          [ 0.0787,  0.1276,  0.2199,  ...,  0.1326,  0.0671,  0.0593]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.8003e-02,  7.4186e-02,  2.1117e-02, -1.4052e-02, -9.4042e-02,\n",
       "           1.2204e-01,  8.9956e-02, -3.6582e-05,  6.4803e-02,  7.9321e-02,\n",
       "          -1.2403e-01, -9.6108e-02,  1.0987e-01,  1.2149e-01, -4.0691e-02,\n",
       "          -7.6679e-02,  3.5806e-02,  1.8241e-02,  2.4513e-02,  1.1519e-01,\n",
       "          -7.0705e-02,  5.5579e-03,  6.3641e-02, -1.0297e-01, -5.9049e-04,\n",
       "          -9.6722e-03, -7.0056e-02,  4.4421e-02,  1.1589e-01,  4.8303e-02,\n",
       "           1.1778e-01, -4.9817e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2102, -0.1676,  0.1182,  ...,  0.0258,  0.0155,  0.2261],\n",
       "          [ 0.0587, -0.1389, -0.0505,  ...,  0.1810,  0.0426, -0.2038],\n",
       "          [ 0.1720,  0.1512, -0.2047,  ..., -0.1936, -0.2065, -0.0261],\n",
       "          ...,\n",
       "          [ 0.1987,  0.0178, -0.1131,  ..., -0.1635, -0.1552, -0.0120],\n",
       "          [ 0.0004,  0.2111,  0.2162,  ..., -0.1432, -0.1932,  0.0618],\n",
       "          [-0.0163, -0.1083, -0.0728,  ...,  0.0078, -0.1596, -0.1401]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0813, -0.1079, -0.1123, -0.0601, -0.0422, -0.0801, -0.0996, -0.0161,\n",
       "          -0.0935, -0.0591,  0.0386,  0.0960,  0.0786,  0.1235,  0.0278, -0.0541,\n",
       "           0.0220, -0.0804,  0.0748,  0.1101,  0.0695, -0.0075,  0.0990,  0.1060,\n",
       "          -0.0804,  0.0646,  0.0944,  0.1035,  0.0825,  0.0685, -0.0491,  0.1044],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2815],\n",
       "          [ 0.1361],\n",
       "          [-0.3080],\n",
       "          [ 0.2584],\n",
       "          [ 0.3808],\n",
       "          [-0.2069],\n",
       "          [-0.3632],\n",
       "          [ 0.4214],\n",
       "          [ 0.0772],\n",
       "          [ 0.2402],\n",
       "          [ 0.3106],\n",
       "          [ 0.0635],\n",
       "          [-0.4221],\n",
       "          [-0.0096],\n",
       "          [ 0.2939],\n",
       "          [ 0.2452],\n",
       "          [ 0.1994],\n",
       "          [-0.1503],\n",
       "          [-0.2125],\n",
       "          [ 0.1760],\n",
       "          [-0.3048],\n",
       "          [-0.1187],\n",
       "          [-0.0298],\n",
       "          [ 0.1959],\n",
       "          [ 0.2396],\n",
       "          [ 0.2403],\n",
       "          [ 0.4101],\n",
       "          [ 0.3099],\n",
       "          [ 0.0383],\n",
       "          [ 0.1356],\n",
       "          [-0.0493],\n",
       "          [ 0.4094]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0017, -0.3676,  0.3435, -0.2681, -0.4259, -0.1915,  0.2741,\n",
       "             0.1808,  0.3017,  0.3928,  0.3658, -0.1049, -0.0306,  0.1058,\n",
       "            -0.3259,  0.0451,  0.1007,  0.1861,  0.0588, -0.4127,  0.2083,\n",
       "             0.2603, -0.0934,  0.0196,  0.2797, -0.0767, -0.0849, -0.0886,\n",
       "            -0.1719, -0.2861,  0.4185, -0.0070]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-1.4299e-01,  4.9010e-02,  2.3977e-01,  ...,  1.8940e-01,\n",
       "            1.3541e-01, -2.3713e-01],\n",
       "          [-1.8321e-01, -2.1417e-01,  2.4796e-01,  ...,  2.2084e-04,\n",
       "            2.3608e-01,  2.2462e-01],\n",
       "          [-7.8177e-02,  1.1914e-01,  1.9587e-01,  ..., -1.7632e-01,\n",
       "           -1.1323e-01,  1.3258e-01],\n",
       "          ...,\n",
       "          [ 1.8115e-01,  1.4337e-01, -3.7774e-04,  ..., -1.0463e-02,\n",
       "            1.1578e-01,  2.5146e-02],\n",
       "          [-9.0366e-03, -6.1869e-02, -1.1805e-01,  ..., -8.3703e-02,\n",
       "            2.0815e-01,  1.1678e-01],\n",
       "          [ 1.9474e-01, -6.8862e-02,  1.3067e-02,  ...,  1.8728e-01,\n",
       "           -8.3529e-03,  2.4474e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0639, -0.0787, -0.0877, -0.0655,  0.0829, -0.0953, -0.0612, -0.0356,\n",
       "           0.0801,  0.0548, -0.1231, -0.0818,  0.0681,  0.0953,  0.0758, -0.1134,\n",
       "           0.0818, -0.1090,  0.0810,  0.0317,  0.1079,  0.0831,  0.1038,  0.1193,\n",
       "          -0.1161, -0.0239,  0.1013,  0.0154, -0.0262,  0.0815,  0.0576,  0.0391],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1075,  0.2485, -0.1929,  ..., -0.0343,  0.0920, -0.1249],\n",
       "          [-0.1167, -0.2130, -0.0384,  ..., -0.1094, -0.1097, -0.1596],\n",
       "          [-0.0880, -0.0563,  0.1293,  ..., -0.1095, -0.0525,  0.0060],\n",
       "          ...,\n",
       "          [ 0.0933,  0.1495,  0.1864,  ...,  0.2480,  0.1120, -0.2148],\n",
       "          [-0.1195,  0.2193,  0.0470,  ...,  0.0454, -0.0301,  0.1188],\n",
       "          [ 0.2319, -0.1194, -0.1457,  ...,  0.1319,  0.0102,  0.0918]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0058, -0.0812, -0.0279,  0.0455, -0.0055,  0.0781, -0.0545,  0.0302,\n",
       "          -0.1227,  0.0484,  0.0791, -0.0497, -0.0732, -0.1100, -0.0504,  0.0053,\n",
       "           0.0390,  0.0485,  0.0887,  0.0324,  0.0471,  0.0036, -0.0085, -0.0600,\n",
       "          -0.0867,  0.0719,  0.0185,  0.0283,  0.0469,  0.0275,  0.0789,  0.0604],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.3709],\n",
       "          [-0.3207],\n",
       "          [-0.4111],\n",
       "          [ 0.3238],\n",
       "          [-0.3667],\n",
       "          [ 0.4144],\n",
       "          [-0.0936],\n",
       "          [-0.0374],\n",
       "          [-0.0679],\n",
       "          [-0.0209],\n",
       "          [-0.1934],\n",
       "          [-0.4053],\n",
       "          [-0.1316],\n",
       "          [ 0.2065],\n",
       "          [-0.3934],\n",
       "          [ 0.2206],\n",
       "          [ 0.1349],\n",
       "          [ 0.0823],\n",
       "          [ 0.2974],\n",
       "          [ 0.2349],\n",
       "          [-0.1193],\n",
       "          [ 0.0074],\n",
       "          [-0.1885],\n",
       "          [ 0.2622],\n",
       "          [-0.0194],\n",
       "          [ 0.3364],\n",
       "          [-0.3031],\n",
       "          [-0.3811],\n",
       "          [ 0.0459],\n",
       "          [-0.1105],\n",
       "          [ 0.1468],\n",
       "          [-0.1338]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2065,  0.3916, -0.1847,  0.3579, -0.2552,  0.2855, -0.3734,\n",
       "             0.3917,  0.1422,  0.1752, -0.4018,  0.2875,  0.1815, -0.0150,\n",
       "            -0.3071, -0.3821, -0.3172,  0.0548,  0.2403,  0.3057, -0.2724,\n",
       "            -0.0522,  0.1130,  0.3755, -0.2403,  0.4150,  0.3806, -0.1237,\n",
       "            -0.2519,  0.0310, -0.2580,  0.2976]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2097, -0.1622,  0.0026,  ...,  0.2064, -0.1926,  0.1162],\n",
       "          [-0.0960, -0.0021, -0.1508,  ..., -0.2311,  0.1344, -0.2288],\n",
       "          [-0.0481, -0.0055, -0.1113,  ..., -0.0529,  0.0975,  0.1467],\n",
       "          ...,\n",
       "          [-0.2460, -0.0545,  0.2052,  ..., -0.2226,  0.2417, -0.1899],\n",
       "          [-0.2471,  0.1948, -0.0393,  ..., -0.0220,  0.0690, -0.0541],\n",
       "          [ 0.0580,  0.1427, -0.1090,  ..., -0.1297,  0.0371,  0.0947]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0057, -0.0358,  0.1056,  0.0298, -0.0049,  0.0588, -0.0929, -0.0510,\n",
       "           0.0323, -0.0043, -0.0683,  0.0594,  0.1029,  0.1234, -0.1124,  0.0058,\n",
       "           0.1233, -0.0428,  0.0989, -0.0911, -0.0244, -0.0776, -0.0774, -0.0154,\n",
       "           0.0262,  0.0366,  0.1218, -0.0440, -0.0401,  0.1127,  0.0555, -0.0497],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0494, -0.1158,  0.1359,  ...,  0.0557,  0.1838, -0.2190],\n",
       "          [-0.1199,  0.1149, -0.0021,  ..., -0.0683, -0.2186, -0.0728],\n",
       "          [ 0.0614, -0.0719,  0.1782,  ...,  0.0057,  0.2388,  0.1461],\n",
       "          ...,\n",
       "          [ 0.0716,  0.0306, -0.2180,  ..., -0.0137, -0.2031,  0.0212],\n",
       "          [ 0.1525, -0.1378, -0.0799,  ..., -0.0907, -0.0353, -0.2008],\n",
       "          [ 0.0543, -0.2000,  0.0384,  ...,  0.0059, -0.2047, -0.0130]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0146, -0.0659, -0.0895,  0.0115, -0.0676,  0.0137,  0.0513, -0.0647,\n",
       "          -0.0112, -0.0853,  0.0501, -0.0299, -0.1097, -0.0676,  0.1230,  0.0788,\n",
       "           0.1179,  0.1037,  0.1100,  0.0483,  0.1169,  0.0625, -0.0921, -0.0869,\n",
       "           0.0044,  0.0643,  0.0549,  0.1227,  0.0566, -0.0698, -0.0512, -0.0926],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1016],\n",
       "          [ 0.2638],\n",
       "          [ 0.3139],\n",
       "          [ 0.2020],\n",
       "          [-0.2823],\n",
       "          [-0.2192],\n",
       "          [-0.0831],\n",
       "          [ 0.1303],\n",
       "          [ 0.2614],\n",
       "          [-0.0190],\n",
       "          [ 0.2009],\n",
       "          [-0.0661],\n",
       "          [-0.3986],\n",
       "          [-0.1036],\n",
       "          [ 0.3228],\n",
       "          [ 0.4264],\n",
       "          [ 0.4169],\n",
       "          [-0.0444],\n",
       "          [-0.0886],\n",
       "          [ 0.2420],\n",
       "          [ 0.2657],\n",
       "          [ 0.2463],\n",
       "          [ 0.2373],\n",
       "          [ 0.2756],\n",
       "          [-0.0812],\n",
       "          [ 0.3117],\n",
       "          [-0.0866],\n",
       "          [-0.2304],\n",
       "          [-0.1659],\n",
       "          [ 0.1073],\n",
       "          [-0.3207],\n",
       "          [ 0.1244]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1403, -0.0031,  0.0914, -0.0955,  0.1891, -0.0240, -0.3590,\n",
       "             0.2591, -0.3131, -0.0532,  0.3544,  0.3608,  0.0550,  0.1368,\n",
       "             0.1710, -0.0827,  0.0007,  0.4180,  0.1161,  0.1030,  0.2431,\n",
       "            -0.0250,  0.2287,  0.3750, -0.1150,  0.1317, -0.0425,  0.0633,\n",
       "             0.2971,  0.0937,  0.1568,  0.4084]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0495,  0.0597, -0.2249,  ..., -0.0040, -0.2088, -0.0010],\n",
       "          [ 0.1562,  0.1122,  0.2175,  ..., -0.2357, -0.1695,  0.1744],\n",
       "          [-0.1669,  0.1444,  0.1766,  ...,  0.1606, -0.1706, -0.1848],\n",
       "          ...,\n",
       "          [ 0.0603,  0.1660, -0.2107,  ...,  0.1968,  0.1436, -0.0844],\n",
       "          [-0.2161,  0.1317,  0.2316,  ...,  0.1959, -0.2213, -0.0252],\n",
       "          [ 0.2243, -0.0995,  0.2293,  ..., -0.2270, -0.1015,  0.0556]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1162, -0.0551,  0.0484,  0.1063,  0.0045,  0.0932,  0.1089,  0.0960,\n",
       "           0.0560, -0.0861,  0.1107,  0.1249, -0.0965,  0.0053,  0.1136,  0.0851,\n",
       "          -0.0356,  0.0558, -0.0653, -0.0085,  0.1169, -0.0995, -0.1248, -0.0858,\n",
       "           0.1032,  0.0231, -0.0387,  0.0387, -0.0724, -0.1085,  0.1153,  0.0632],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0896, -0.2084,  0.1980,  ..., -0.1752,  0.0524, -0.1360],\n",
       "          [-0.2221,  0.1482,  0.1065,  ...,  0.1119, -0.0639,  0.1102],\n",
       "          [ 0.1511, -0.1249,  0.0776,  ...,  0.0748,  0.1287,  0.0965],\n",
       "          ...,\n",
       "          [-0.2036,  0.2172, -0.0331,  ..., -0.0566, -0.1718,  0.1415],\n",
       "          [-0.1970,  0.1576,  0.0606,  ..., -0.1502, -0.1780, -0.2485],\n",
       "          [ 0.1411, -0.0920, -0.0140,  ...,  0.0811, -0.1573, -0.2444]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1107,  0.0202,  0.0864, -0.0651, -0.0047,  0.1040,  0.0233,  0.0471,\n",
       "          -0.0905,  0.0578, -0.0735,  0.0813,  0.0810,  0.0857, -0.0384, -0.0235,\n",
       "          -0.0820, -0.0456,  0.0803, -0.0300, -0.0790,  0.0423,  0.0289,  0.1011,\n",
       "          -0.0485,  0.0403, -0.0409, -0.0154, -0.0727,  0.0940, -0.1112,  0.0829],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0009],\n",
       "          [ 0.4156],\n",
       "          [-0.1480],\n",
       "          [-0.1788],\n",
       "          [-0.2344],\n",
       "          [-0.0875],\n",
       "          [ 0.2802],\n",
       "          [-0.3592],\n",
       "          [ 0.3280],\n",
       "          [ 0.1584],\n",
       "          [ 0.1939],\n",
       "          [-0.2650],\n",
       "          [-0.3703],\n",
       "          [-0.1716],\n",
       "          [-0.3299],\n",
       "          [ 0.3696],\n",
       "          [-0.0321],\n",
       "          [-0.3287],\n",
       "          [ 0.3950],\n",
       "          [-0.2340],\n",
       "          [-0.4059],\n",
       "          [ 0.2250],\n",
       "          [ 0.2099],\n",
       "          [-0.1617],\n",
       "          [ 0.2647],\n",
       "          [ 0.1277],\n",
       "          [ 0.3342],\n",
       "          [-0.0733],\n",
       "          [-0.3380],\n",
       "          [ 0.3202],\n",
       "          [-0.1749],\n",
       "          [-0.4094]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0430,  0.3113,  0.0272, -0.0639,  0.0786, -0.1738,  0.2989,\n",
       "            -0.1627, -0.0610, -0.3816,  0.0979, -0.1338,  0.2009, -0.3092,\n",
       "            -0.1430, -0.1187, -0.4216, -0.0329,  0.2116,  0.3043, -0.0477,\n",
       "             0.0920, -0.3396,  0.3519, -0.2813,  0.4050, -0.3991,  0.4111,\n",
       "             0.1811, -0.1683,  0.3715, -0.0100]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0310,  0.0272,  0.0302,  ...,  0.0408, -0.1630, -0.2088],\n",
       "          [-0.1815,  0.2367,  0.0551,  ..., -0.2085,  0.1128,  0.0197],\n",
       "          [ 0.2029, -0.0952,  0.0681,  ..., -0.0988, -0.1260,  0.0598],\n",
       "          ...,\n",
       "          [-0.2119, -0.1731, -0.0762,  ..., -0.0993,  0.0386, -0.2272],\n",
       "          [-0.0607, -0.0948,  0.1367,  ...,  0.1703,  0.1695,  0.1220],\n",
       "          [-0.1325, -0.0598, -0.1115,  ...,  0.0884,  0.0031,  0.1454]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 4.1474e-02, -1.1049e-01,  1.1902e-01,  3.7880e-02,  1.0599e-01,\n",
       "          -9.5386e-02,  5.3532e-02,  1.1242e-01, -1.0131e-01,  1.1338e-01,\n",
       "          -9.3258e-02, -6.7751e-02,  6.9461e-02, -1.0343e-01, -1.0709e-01,\n",
       "          -5.6506e-02,  8.8381e-02, -9.6938e-02, -9.2625e-02,  4.4707e-02,\n",
       "          -9.0837e-02,  2.2658e-02, -6.9473e-02, -1.1389e-01, -1.2454e-01,\n",
       "           1.0843e-01, -1.2447e-01,  8.5950e-05, -1.0351e-01,  1.1553e-01,\n",
       "          -8.9102e-02,  1.3440e-02], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0058,  0.1016,  0.0707,  ..., -0.1475,  0.2290, -0.0275],\n",
       "          [ 0.0317, -0.0462,  0.1904,  ..., -0.1216, -0.0731, -0.0155],\n",
       "          [ 0.0979, -0.2191,  0.2032,  ..., -0.1991, -0.0784, -0.1309],\n",
       "          ...,\n",
       "          [ 0.1385,  0.0477,  0.0186,  ...,  0.0931, -0.0190,  0.2238],\n",
       "          [ 0.1980, -0.1060,  0.1458,  ...,  0.1201,  0.1742, -0.1228],\n",
       "          [-0.1592, -0.1892, -0.1866,  ...,  0.0877, -0.2301, -0.1441]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-3.1450e-02, -9.5845e-02, -1.3489e-02, -2.5891e-02,  3.7258e-03,\n",
       "          -7.7799e-02,  2.7030e-02,  2.1426e-02, -9.1646e-03,  9.0266e-02,\n",
       "           9.8547e-02,  4.8071e-03,  3.8111e-02,  1.1175e-01, -4.3062e-02,\n",
       "           6.7776e-02, -3.0454e-04,  3.9795e-02, -1.1231e-04,  1.1143e-01,\n",
       "           8.7797e-02, -1.0049e-01,  6.9395e-02,  9.4526e-02,  1.9849e-02,\n",
       "           9.9225e-02,  8.3326e-02,  1.1976e-01,  7.8257e-02,  1.2466e-01,\n",
       "          -1.4121e-02,  4.5384e-04], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1419],\n",
       "          [ 0.1079],\n",
       "          [-0.1799],\n",
       "          [ 0.1546],\n",
       "          [ 0.1270],\n",
       "          [-0.1913],\n",
       "          [-0.3772],\n",
       "          [-0.3386],\n",
       "          [-0.3837],\n",
       "          [-0.2073],\n",
       "          [ 0.0147],\n",
       "          [-0.2703],\n",
       "          [ 0.3316],\n",
       "          [ 0.3936],\n",
       "          [-0.0951],\n",
       "          [-0.3279],\n",
       "          [-0.1116],\n",
       "          [-0.3096],\n",
       "          [ 0.2481],\n",
       "          [ 0.1201],\n",
       "          [-0.0822],\n",
       "          [ 0.0322],\n",
       "          [ 0.0255],\n",
       "          [ 0.3726],\n",
       "          [-0.4088],\n",
       "          [ 0.1900],\n",
       "          [ 0.3812],\n",
       "          [ 0.3851],\n",
       "          [-0.0545],\n",
       "          [-0.3418],\n",
       "          [-0.1864],\n",
       "          [-0.1486]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1433, -0.3661,  0.3052, -0.3897, -0.1439, -0.3423, -0.1859,\n",
       "            -0.3868,  0.1054,  0.4039,  0.0937,  0.3259,  0.1309, -0.3161,\n",
       "             0.1886,  0.2712,  0.0343, -0.1052,  0.0107,  0.3567,  0.2370,\n",
       "             0.3645,  0.3216,  0.1402,  0.0260, -0.0990,  0.0020, -0.0583,\n",
       "             0.1093,  0.3518,  0.0100, -0.1317]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1306, -0.1662, -0.1980,  ...,  0.1019, -0.2335, -0.1793],\n",
       "          [-0.1374, -0.1240, -0.2078,  ...,  0.0315, -0.1107, -0.1244],\n",
       "          [-0.1610, -0.2068,  0.1608,  ..., -0.2422, -0.0487, -0.1757],\n",
       "          ...,\n",
       "          [ 0.1182, -0.0578, -0.1699,  ...,  0.2418,  0.0179, -0.0327],\n",
       "          [ 0.0781, -0.2106, -0.1513,  ..., -0.1658,  0.1542, -0.1046],\n",
       "          [ 0.0946, -0.1706, -0.1312,  ..., -0.2146,  0.0611,  0.1258]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0745, -0.0485,  0.0007,  0.0852, -0.0610,  0.0124,  0.1197,  0.1247,\n",
       "           0.1219, -0.0814, -0.0350, -0.0867, -0.0739,  0.0871, -0.0757, -0.0734,\n",
       "          -0.0604, -0.0262, -0.1223, -0.1120,  0.0710, -0.0900,  0.1074, -0.0919,\n",
       "           0.0785, -0.0192, -0.0052,  0.0350, -0.0467,  0.1134, -0.0594,  0.0451],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2389, -0.1474, -0.0295,  ...,  0.1212,  0.1298, -0.0964],\n",
       "          [ 0.1576, -0.0244, -0.1790,  ...,  0.1147, -0.1023,  0.1577],\n",
       "          [ 0.2081,  0.0355, -0.0804,  ...,  0.1869, -0.0353, -0.1057],\n",
       "          ...,\n",
       "          [ 0.0841, -0.1821,  0.0586,  ..., -0.2147, -0.1070,  0.2090],\n",
       "          [ 0.0335,  0.1355, -0.1725,  ...,  0.1249,  0.1393, -0.2265],\n",
       "          [-0.0821,  0.2308, -0.0316,  ..., -0.1020, -0.2011,  0.1708]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0144, -0.0895, -0.0213, -0.0158,  0.0428,  0.0917, -0.0236, -0.1004,\n",
       "           0.0280, -0.0390, -0.0517,  0.0065, -0.0894,  0.1162, -0.0277,  0.0120,\n",
       "          -0.0468, -0.0225, -0.1184, -0.0682,  0.1003, -0.0440,  0.0048,  0.0624,\n",
       "           0.0236,  0.0452, -0.0863,  0.1081,  0.0021, -0.0260, -0.0619,  0.0546],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0495],\n",
       "          [ 0.2975],\n",
       "          [ 0.3439],\n",
       "          [-0.0057],\n",
       "          [ 0.2425],\n",
       "          [-0.0118],\n",
       "          [ 0.0047],\n",
       "          [-0.3292],\n",
       "          [-0.0367],\n",
       "          [ 0.3232],\n",
       "          [-0.2174],\n",
       "          [ 0.3574],\n",
       "          [ 0.0964],\n",
       "          [-0.0546],\n",
       "          [-0.0505],\n",
       "          [-0.3425],\n",
       "          [-0.2213],\n",
       "          [-0.2779],\n",
       "          [ 0.3300],\n",
       "          [ 0.2219],\n",
       "          [ 0.2453],\n",
       "          [-0.0822],\n",
       "          [ 0.1512],\n",
       "          [-0.4239],\n",
       "          [-0.4012],\n",
       "          [-0.2910],\n",
       "          [ 0.2064],\n",
       "          [-0.3883],\n",
       "          [ 0.1752],\n",
       "          [ 0.0150],\n",
       "          [-0.0660],\n",
       "          [ 0.2640]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3411,  0.3002, -0.1063,  0.3128, -0.3470,  0.2194,  0.3474,\n",
       "             0.1170, -0.2632,  0.0185,  0.3636, -0.4103, -0.1731, -0.1309,\n",
       "             0.0748, -0.2279,  0.3384, -0.3070,  0.2141,  0.0488, -0.0587,\n",
       "            -0.2162,  0.0787,  0.2536,  0.0265,  0.3841, -0.1057, -0.3963,\n",
       "            -0.1926,  0.1628, -0.1681,  0.3209]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1252, -0.1906, -0.0020,  ..., -0.1016, -0.1697, -0.2286],\n",
       "          [-0.2169, -0.1886,  0.1402,  ..., -0.2138, -0.0040, -0.1037],\n",
       "          [-0.0722,  0.1154, -0.0817,  ...,  0.0654,  0.1562,  0.2187],\n",
       "          ...,\n",
       "          [-0.0741,  0.1046, -0.2296,  ..., -0.1409, -0.1243, -0.2496],\n",
       "          [-0.2316,  0.0905,  0.0543,  ...,  0.0299, -0.1637, -0.2295],\n",
       "          [-0.1619,  0.0501, -0.0426,  ...,  0.1111, -0.0241, -0.1671]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0248,  0.1112, -0.0327,  0.1222,  0.0949, -0.0157, -0.0233, -0.0467,\n",
       "          -0.1160,  0.0486, -0.1154, -0.0299, -0.0410,  0.0621, -0.1206, -0.1148,\n",
       "          -0.0458,  0.0477, -0.0798,  0.0829,  0.0011, -0.0246, -0.1146, -0.0009,\n",
       "          -0.1142, -0.1212, -0.0146, -0.0541,  0.1058,  0.0725,  0.0565, -0.0029],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1750,  0.2397, -0.1911,  ..., -0.2363, -0.1227,  0.0217],\n",
       "          [-0.1321,  0.0759, -0.0864,  ...,  0.2385,  0.2303,  0.0740],\n",
       "          [-0.0748,  0.2182,  0.1226,  ...,  0.1496, -0.1879,  0.2152],\n",
       "          ...,\n",
       "          [-0.0875,  0.0571,  0.0245,  ..., -0.0211,  0.1554,  0.0444],\n",
       "          [ 0.0094, -0.1491,  0.1408,  ..., -0.1051, -0.2029, -0.0788],\n",
       "          [ 0.2058,  0.1007,  0.0782,  ..., -0.0303, -0.1217, -0.1366]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0719,  0.1151, -0.0182, -0.0721,  0.0031, -0.0733, -0.0510, -0.0493,\n",
       "          -0.1060, -0.0340, -0.1187, -0.1247,  0.0389, -0.0631,  0.0664,  0.0203,\n",
       "           0.0946,  0.0419,  0.1015, -0.0994, -0.0894, -0.0374, -0.0879, -0.0420,\n",
       "          -0.0004,  0.0760,  0.0326,  0.0908, -0.0267,  0.0037,  0.0473,  0.0769],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.4111],\n",
       "          [ 0.2931],\n",
       "          [ 0.1247],\n",
       "          [-0.3737],\n",
       "          [ 0.0391],\n",
       "          [-0.2221],\n",
       "          [-0.0887],\n",
       "          [ 0.0797],\n",
       "          [ 0.1545],\n",
       "          [-0.0108],\n",
       "          [ 0.0361],\n",
       "          [ 0.3804],\n",
       "          [-0.4248],\n",
       "          [ 0.1933],\n",
       "          [-0.3021],\n",
       "          [ 0.2223],\n",
       "          [-0.2171],\n",
       "          [-0.3480],\n",
       "          [ 0.3878],\n",
       "          [ 0.3402],\n",
       "          [ 0.3826],\n",
       "          [ 0.0626],\n",
       "          [-0.1773],\n",
       "          [ 0.2271],\n",
       "          [ 0.1283],\n",
       "          [ 0.1494],\n",
       "          [ 0.3224],\n",
       "          [-0.3096],\n",
       "          [ 0.1686],\n",
       "          [-0.1162],\n",
       "          [-0.4227],\n",
       "          [ 0.1642]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3081, -0.2681,  0.1048,  0.0843,  0.1153, -0.2827,  0.2999,\n",
       "             0.2374, -0.0820, -0.3009, -0.1668, -0.2551, -0.1674, -0.1579,\n",
       "             0.3916,  0.0667,  0.3321, -0.2632,  0.4087, -0.3389,  0.4013,\n",
       "            -0.3484,  0.3089, -0.1347,  0.2042, -0.1100,  0.2677,  0.2981,\n",
       "             0.3013, -0.3320, -0.1027,  0.4173]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2025, -0.1288, -0.2207,  ..., -0.1723, -0.1015, -0.0330],\n",
       "          [-0.0332,  0.1116,  0.0417,  ..., -0.0552,  0.1137,  0.0591],\n",
       "          [ 0.1114, -0.2055,  0.1798,  ..., -0.0956, -0.0731,  0.1994],\n",
       "          ...,\n",
       "          [ 0.0715,  0.0132, -0.0453,  ..., -0.1563, -0.1886,  0.2257],\n",
       "          [-0.0147, -0.1161,  0.1796,  ..., -0.2086,  0.0818,  0.0365],\n",
       "          [-0.1103,  0.0510,  0.1455,  ...,  0.1281, -0.0158, -0.1000]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0157, -0.0339,  0.1052, -0.1136, -0.0788,  0.0517, -0.0260, -0.0426,\n",
       "          -0.1000, -0.0406,  0.0363,  0.0412, -0.0900,  0.0500,  0.1202, -0.0877,\n",
       "          -0.0782,  0.0626,  0.0401, -0.0899, -0.0034,  0.0531, -0.0365,  0.0736,\n",
       "           0.1226,  0.1107, -0.1009,  0.0902, -0.0097, -0.1162,  0.1175, -0.0648],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2338,  0.0983,  0.0595,  ..., -0.1439, -0.0646,  0.1551],\n",
       "          [ 0.0750,  0.1426,  0.0106,  ...,  0.2199,  0.1774, -0.0150],\n",
       "          [ 0.1782,  0.1571, -0.0339,  ..., -0.0804, -0.2281, -0.0787],\n",
       "          ...,\n",
       "          [ 0.1564,  0.2171, -0.0852,  ..., -0.2429, -0.1115, -0.1413],\n",
       "          [ 0.0296, -0.2396,  0.0225,  ...,  0.0484,  0.1814, -0.1532],\n",
       "          [ 0.2333, -0.0514, -0.0345,  ..., -0.1310,  0.1066,  0.0597]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0342,  0.0684,  0.0799, -0.0124, -0.0434,  0.0237, -0.0476,  0.1109,\n",
       "           0.1010,  0.1229,  0.1117,  0.0755,  0.0201,  0.0701,  0.0267, -0.0210,\n",
       "           0.1143, -0.1214, -0.0366, -0.1200,  0.0329,  0.0748,  0.0966,  0.0077,\n",
       "           0.0812,  0.0456, -0.0552,  0.0879,  0.0548,  0.0646,  0.1061,  0.0028],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1625],\n",
       "          [-0.0230],\n",
       "          [ 0.1137],\n",
       "          [ 0.2213],\n",
       "          [ 0.1047],\n",
       "          [ 0.0131],\n",
       "          [-0.0761],\n",
       "          [ 0.1642],\n",
       "          [-0.1466],\n",
       "          [-0.2522],\n",
       "          [-0.2841],\n",
       "          [-0.2343],\n",
       "          [ 0.1224],\n",
       "          [-0.1120],\n",
       "          [-0.2122],\n",
       "          [-0.1214],\n",
       "          [ 0.0220],\n",
       "          [-0.3545],\n",
       "          [ 0.3719],\n",
       "          [ 0.1403],\n",
       "          [ 0.3899],\n",
       "          [-0.0950],\n",
       "          [ 0.1556],\n",
       "          [-0.3901],\n",
       "          [ 0.0927],\n",
       "          [ 0.1619],\n",
       "          [ 0.2365],\n",
       "          [-0.3889],\n",
       "          [ 0.3758],\n",
       "          [ 0.3977],\n",
       "          [ 0.3871],\n",
       "          [-0.0847]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2015, -0.3575, -0.0566,  0.2215, -0.3442,  0.2051, -0.2590,\n",
       "             0.3239,  0.3354, -0.2465,  0.1211,  0.2849, -0.2912, -0.1720,\n",
       "             0.1751, -0.0607,  0.1181, -0.2737, -0.3937,  0.0929, -0.3022,\n",
       "            -0.0087, -0.1768, -0.3896,  0.2576, -0.0125,  0.3523,  0.4068,\n",
       "             0.0338, -0.2888,  0.0892, -0.3216]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2396, -0.0015,  0.0879,  ...,  0.0948, -0.1350, -0.2006],\n",
       "          [-0.2543,  0.0233, -0.2146,  ..., -0.0296,  0.1568, -0.2913],\n",
       "          [ 0.2770, -0.2186, -0.2727,  ...,  0.1045,  0.0554,  0.0571],\n",
       "          ...,\n",
       "          [ 0.0127,  0.2864, -0.0516,  ..., -0.1525, -0.1123,  0.2945],\n",
       "          [-0.0046, -0.1902,  0.2590,  ..., -0.2530, -0.1092,  0.0025],\n",
       "          [-0.0194, -0.0846,  0.2762,  ...,  0.1808, -0.1887,  0.0494]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0844,  0.0378,  0.0271,  0.1413,  0.1526, -0.1763, -0.1630,  0.1408,\n",
       "           0.0109, -0.1168, -0.1376,  0.1181,  0.0458, -0.0014, -0.0922, -0.0773,\n",
       "           0.0133, -0.1135, -0.0878,  0.1128,  0.0572,  0.1378, -0.1341, -0.1271,\n",
       "          -0.0822, -0.0532,  0.0108,  0.0886, -0.0258, -0.0458,  0.1147,  0.0565],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1525, -0.1213,  0.1140,  ..., -0.1486,  0.1992,  0.2726],\n",
       "          [ 0.1537,  0.2398, -0.1520,  ..., -0.1848,  0.0949,  0.0347],\n",
       "          [-0.0704,  0.2729,  0.3056,  ..., -0.2687, -0.0055, -0.2122],\n",
       "          ...,\n",
       "          [-0.1401, -0.2063, -0.0098,  ..., -0.2818,  0.0147,  0.2544],\n",
       "          [ 0.0005, -0.1922,  0.1059,  ...,  0.2220, -0.2293,  0.0871],\n",
       "          [ 0.2501,  0.0720, -0.2686,  ..., -0.0220,  0.0861, -0.1753]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0012, -0.1086, -0.1063,  0.0420, -0.0463, -0.1268, -0.0235,  0.0666,\n",
       "          -0.0716,  0.1696,  0.0140,  0.0159,  0.1008,  0.1621, -0.0066,  0.0584,\n",
       "           0.0535,  0.0095,  0.1222, -0.1090, -0.1429, -0.0416, -0.0192, -0.0996,\n",
       "           0.0800,  0.0465, -0.1116,  0.1638,  0.0800, -0.0048,  0.0798,  0.1605],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0773],\n",
       "          [-0.0300],\n",
       "          [ 0.0283],\n",
       "          [ 0.1026],\n",
       "          [-0.0342],\n",
       "          [-0.0320],\n",
       "          [-0.0917],\n",
       "          [-0.1017],\n",
       "          [ 0.3411],\n",
       "          [-0.0787],\n",
       "          [-0.3091],\n",
       "          [ 0.3005],\n",
       "          [ 0.3818],\n",
       "          [-0.0293],\n",
       "          [ 0.3189],\n",
       "          [-0.2975],\n",
       "          [-0.2903],\n",
       "          [-0.3942],\n",
       "          [-0.2757],\n",
       "          [ 0.4231],\n",
       "          [ 0.2114],\n",
       "          [-0.3134],\n",
       "          [-0.0811],\n",
       "          [-0.1468],\n",
       "          [ 0.1914],\n",
       "          [-0.2877],\n",
       "          [ 0.1915],\n",
       "          [ 0.0527],\n",
       "          [ 0.0083],\n",
       "          [ 0.3167],\n",
       "          [ 0.1877],\n",
       "          [-0.2987]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.2603, -0.1144, -0.2173, -0.2128, -0.2104,  0.2532, -0.2914,\n",
       "            -0.3810,  0.0524, -0.1408, -0.0176, -0.3897, -0.4244, -0.3459,\n",
       "            -0.2349, -0.2539,  0.0049, -0.2285,  0.1570,  0.4222,  0.0886,\n",
       "            -0.4241, -0.2769, -0.0728, -0.0903, -0.0218,  0.3678, -0.0877,\n",
       "            -0.2041, -0.1376, -0.0532,  0.1084]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1989,  0.1712,  0.2244,  ..., -0.1385, -0.1051, -0.0631],\n",
       "          [-0.1229, -0.1012,  0.2736,  ..., -0.1664, -0.2509,  0.0612],\n",
       "          [ 0.1608, -0.2133, -0.0367,  ...,  0.0175,  0.1938,  0.1707],\n",
       "          ...,\n",
       "          [-0.2628,  0.2121,  0.1179,  ..., -0.1268,  0.2795,  0.1361],\n",
       "          [ 0.2943,  0.1961,  0.0277,  ...,  0.0658,  0.1153,  0.0867],\n",
       "          [-0.2427,  0.0035,  0.0982,  ..., -0.3037,  0.2512,  0.1219]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1105,  0.0055,  0.1665, -0.1499, -0.0744, -0.1046,  0.0749, -0.0456,\n",
       "          -0.0368,  0.1259, -0.0529, -0.0150,  0.1570, -0.1535,  0.0444,  0.1097,\n",
       "          -0.0114,  0.1582,  0.1582, -0.0875, -0.0136,  0.1321,  0.0542,  0.1435,\n",
       "          -0.1038, -0.1755,  0.1064,  0.0254,  0.1053,  0.0533, -0.0321,  0.1122],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1561, -0.0326,  0.0331,  ..., -0.0959, -0.2544, -0.1759],\n",
       "          [-0.2791,  0.1370,  0.1966,  ..., -0.1016,  0.1299, -0.1190],\n",
       "          [ 0.1426,  0.2798, -0.0718,  ..., -0.0256,  0.2048,  0.0336],\n",
       "          ...,\n",
       "          [-0.1623,  0.1980,  0.0780,  ..., -0.1493,  0.1517, -0.1674],\n",
       "          [-0.1897, -0.0560,  0.2903,  ..., -0.1623,  0.2157, -0.1473],\n",
       "          [-0.0148,  0.1625,  0.2117,  ...,  0.0414,  0.2521,  0.0713]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1416,  0.1154,  0.1126,  0.0531,  0.0310,  0.0924, -0.1279,  0.0099,\n",
       "          -0.0434, -0.1425, -0.0556, -0.0424,  0.0888,  0.0718,  0.0292, -0.1183,\n",
       "          -0.0501,  0.0718,  0.1167, -0.0919,  0.0112,  0.1033, -0.1142, -0.0381,\n",
       "           0.1580, -0.0883,  0.0380, -0.0702, -0.1672,  0.0210,  0.1081, -0.0086],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0082],\n",
       "          [ 0.3953],\n",
       "          [-0.4062],\n",
       "          [-0.1744],\n",
       "          [-0.2570],\n",
       "          [-0.0288],\n",
       "          [ 0.4077],\n",
       "          [-0.1590],\n",
       "          [ 0.2947],\n",
       "          [ 0.0529],\n",
       "          [-0.2233],\n",
       "          [-0.2139],\n",
       "          [-0.0794],\n",
       "          [-0.0697],\n",
       "          [-0.0999],\n",
       "          [-0.3238],\n",
       "          [-0.3145],\n",
       "          [-0.2812],\n",
       "          [ 0.2227],\n",
       "          [-0.2495],\n",
       "          [-0.3299],\n",
       "          [-0.1592],\n",
       "          [ 0.1584],\n",
       "          [-0.0208],\n",
       "          [ 0.3633],\n",
       "          [ 0.3240],\n",
       "          [ 0.1037],\n",
       "          [-0.0940],\n",
       "          [ 0.3055],\n",
       "          [-0.0945],\n",
       "          [-0.2295],\n",
       "          [ 0.2898]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.2636, -0.2759,  0.2830, -0.2893,  0.0319,  0.3740,  0.2963,\n",
       "             0.3120,  0.1317,  0.4116, -0.0462,  0.3249, -0.4057,  0.1237,\n",
       "            -0.0829,  0.2462, -0.0024, -0.1635, -0.1822,  0.3167,  0.1426,\n",
       "            -0.1879,  0.1185,  0.1415,  0.3961,  0.0888,  0.0980,  0.0192,\n",
       "            -0.3368,  0.0145,  0.2106, -0.3118]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1219,  0.2492, -0.1742,  ..., -0.0181,  0.0300, -0.2503],\n",
       "          [-0.0209,  0.1070, -0.2434,  ..., -0.2611,  0.0135, -0.2398],\n",
       "          [-0.0678,  0.3028,  0.1869,  ..., -0.2857,  0.0474, -0.0985],\n",
       "          ...,\n",
       "          [ 0.1810, -0.0475, -0.1377,  ..., -0.2509,  0.2038,  0.2167],\n",
       "          [-0.2773,  0.1866, -0.2234,  ...,  0.0111,  0.1380, -0.2488],\n",
       "          [-0.1592,  0.1570, -0.3060,  ...,  0.0764,  0.2011,  0.2019]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1761, -0.0716, -0.0807, -0.1087,  0.0264, -0.0811,  0.0941,  0.1262,\n",
       "           0.0268,  0.1033, -0.1200, -0.1119,  0.0538, -0.0983,  0.0911,  0.0860,\n",
       "           0.1644,  0.0159,  0.0431,  0.0490, -0.1440, -0.1376, -0.0756, -0.0953,\n",
       "           0.0836, -0.0953, -0.1167,  0.1514,  0.0996, -0.0541,  0.1588, -0.1492],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1361, -0.0625,  0.2969,  ...,  0.2776,  0.1210,  0.1290],\n",
       "          [ 0.1824,  0.0867, -0.0717,  ..., -0.0673, -0.1491, -0.0746],\n",
       "          [-0.3027, -0.1483, -0.0092,  ..., -0.1570, -0.0290,  0.1119],\n",
       "          ...,\n",
       "          [ 0.2419, -0.1394, -0.0288,  ..., -0.1145, -0.1531, -0.2931],\n",
       "          [-0.0955, -0.2131,  0.0613,  ..., -0.0234,  0.2139, -0.0217],\n",
       "          [-0.1883,  0.2028, -0.0515,  ...,  0.1317,  0.1341,  0.0586]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0252, -0.0731,  0.1598, -0.1563, -0.1100,  0.0309,  0.0546,  0.0140,\n",
       "           0.1153, -0.0322,  0.0587, -0.0319, -0.1505,  0.1018, -0.0966, -0.0391,\n",
       "           0.1652, -0.1708, -0.1660,  0.1418, -0.0914,  0.1682,  0.1410, -0.1402,\n",
       "          -0.1272, -0.1196, -0.0278, -0.1266, -0.1299,  0.0174,  0.0595, -0.1764],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.3930],\n",
       "          [-0.0258],\n",
       "          [ 0.3462],\n",
       "          [ 0.1075],\n",
       "          [-0.0266],\n",
       "          [ 0.2843],\n",
       "          [-0.2119],\n",
       "          [-0.1749],\n",
       "          [-0.2912],\n",
       "          [-0.3945],\n",
       "          [-0.2394],\n",
       "          [ 0.1114],\n",
       "          [ 0.2514],\n",
       "          [ 0.3012],\n",
       "          [ 0.1656],\n",
       "          [ 0.1074],\n",
       "          [-0.1898],\n",
       "          [-0.3013],\n",
       "          [-0.3550],\n",
       "          [ 0.2958],\n",
       "          [-0.1838],\n",
       "          [ 0.2410],\n",
       "          [ 0.3766],\n",
       "          [-0.3156],\n",
       "          [-0.0698],\n",
       "          [-0.4186],\n",
       "          [ 0.3549],\n",
       "          [ 0.4114],\n",
       "          [-0.0410],\n",
       "          [ 0.0497],\n",
       "          [-0.1189],\n",
       "          [ 0.1383]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 3.1827e-01,  3.2615e-01, -3.9687e-01, -2.0862e-02,  8.1002e-02,\n",
       "             4.3094e-05,  1.5301e-01, -1.0763e-01,  2.5576e-01,  7.1324e-02,\n",
       "            -2.1941e-01, -3.4499e-01, -2.1078e-01,  2.9884e-01, -2.9797e-01,\n",
       "            -3.9498e-01, -3.0385e-01,  8.0233e-03,  1.7335e-01, -3.0270e-01,\n",
       "             3.6634e-01, -2.7870e-01,  2.2548e-01, -1.0652e-01,  3.0419e-02,\n",
       "            -3.1931e-01,  1.4887e-01, -7.0535e-03,  2.7159e-01,  4.1729e-01,\n",
       "             1.3152e-01,  5.1701e-02]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2582, -0.1920,  0.1369,  ..., -0.1228, -0.2139, -0.1628],\n",
       "          [ 0.1695,  0.0501, -0.1604,  ..., -0.0522, -0.2192, -0.0806],\n",
       "          [ 0.2761, -0.2165,  0.1889,  ...,  0.1393,  0.2234, -0.1585],\n",
       "          ...,\n",
       "          [ 0.3034, -0.2316, -0.2386,  ..., -0.2352, -0.2828,  0.2569],\n",
       "          [-0.2398,  0.2382,  0.1273,  ..., -0.1454, -0.2514,  0.2386],\n",
       "          [ 0.2527,  0.2988,  0.1523,  ...,  0.0477, -0.0220, -0.0386]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0928, -0.0454,  0.1130, -0.0346,  0.0424,  0.1451,  0.1049,  0.0952,\n",
       "           0.0849, -0.0149,  0.1009,  0.1152,  0.0396, -0.0167, -0.0623, -0.1559,\n",
       "          -0.0476, -0.0561,  0.0774,  0.1728,  0.0619,  0.0810,  0.1151, -0.0084,\n",
       "           0.1337,  0.1506, -0.0802, -0.0731, -0.0819,  0.0164, -0.0347,  0.0985],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0266, -0.1302, -0.0623,  ...,  0.1582, -0.2993,  0.2493],\n",
       "          [-0.2071, -0.2065,  0.0379,  ..., -0.2067, -0.1108, -0.2931],\n",
       "          [-0.0788, -0.1233,  0.0346,  ..., -0.0369, -0.2152, -0.1936],\n",
       "          ...,\n",
       "          [ 0.0914,  0.2528, -0.1762,  ...,  0.1609,  0.0046,  0.0163],\n",
       "          [ 0.2569, -0.0326,  0.2160,  ...,  0.0722,  0.2697,  0.0161],\n",
       "          [ 0.0530, -0.1701,  0.2745,  ..., -0.2625, -0.2804, -0.2128]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0643,  0.0959,  0.1503, -0.0718, -0.0184, -0.1403, -0.1300, -0.1693,\n",
       "          -0.1407,  0.1167, -0.1464,  0.0212,  0.1003, -0.1219,  0.1735, -0.1717,\n",
       "           0.1409, -0.1171, -0.0363, -0.0144, -0.0541,  0.1205, -0.0668, -0.1708,\n",
       "          -0.0092,  0.1366,  0.1019,  0.0401, -0.1434,  0.0791,  0.1638, -0.1167],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3389],\n",
       "          [-0.0067],\n",
       "          [ 0.2330],\n",
       "          [ 0.2036],\n",
       "          [-0.2173],\n",
       "          [ 0.3594],\n",
       "          [ 0.2939],\n",
       "          [ 0.4160],\n",
       "          [ 0.2818],\n",
       "          [ 0.0471],\n",
       "          [-0.2074],\n",
       "          [-0.3890],\n",
       "          [-0.0114],\n",
       "          [ 0.1282],\n",
       "          [-0.3640],\n",
       "          [-0.3519],\n",
       "          [-0.0360],\n",
       "          [ 0.1087],\n",
       "          [ 0.1594],\n",
       "          [-0.2731],\n",
       "          [-0.1469],\n",
       "          [-0.4110],\n",
       "          [ 0.1294],\n",
       "          [-0.3613],\n",
       "          [ 0.0543],\n",
       "          [-0.3976],\n",
       "          [-0.1597],\n",
       "          [ 0.3432],\n",
       "          [-0.4008],\n",
       "          [ 0.1026],\n",
       "          [ 0.4132],\n",
       "          [ 0.1656]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3546, -0.0995,  0.1921, -0.1925, -0.1293,  0.3427, -0.2468,\n",
       "            -0.0072, -0.0476, -0.0517, -0.0990,  0.4228,  0.3820, -0.4188,\n",
       "            -0.3854, -0.2550, -0.3143,  0.1711,  0.0155,  0.0558, -0.4183,\n",
       "             0.3588, -0.2660, -0.0332, -0.0431, -0.0662, -0.0151, -0.3302,\n",
       "             0.4107,  0.1259, -0.3430,  0.1126]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0582,  0.0599,  0.2110,  ..., -0.0470, -0.2077, -0.0080],\n",
       "          [-0.2944, -0.1049,  0.2071,  ...,  0.0249, -0.0783, -0.2778],\n",
       "          [-0.0657,  0.0389,  0.3027,  ..., -0.0328, -0.1103,  0.1914],\n",
       "          ...,\n",
       "          [-0.1895,  0.0969,  0.1935,  ...,  0.2275, -0.2675, -0.1710],\n",
       "          [ 0.0742, -0.1271,  0.0546,  ..., -0.1640,  0.0321, -0.0614],\n",
       "          [-0.1092, -0.1485, -0.0588,  ...,  0.0916,  0.0817,  0.1318]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0466,  0.1562, -0.0425, -0.0178,  0.0165, -0.0351, -0.0305,  0.0744,\n",
       "           0.0872, -0.1149, -0.0732, -0.0790, -0.1491, -0.0731,  0.0336, -0.1269,\n",
       "           0.1183,  0.0851,  0.1015, -0.1379, -0.0964,  0.1739,  0.1322,  0.0500,\n",
       "           0.0669,  0.0810, -0.0905, -0.1280, -0.0839,  0.1624,  0.0041, -0.0136],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1993, -0.1505,  0.2504,  ..., -0.1823, -0.1647, -0.2825],\n",
       "          [-0.1651, -0.0521, -0.2715,  ..., -0.1865, -0.0807, -0.1189],\n",
       "          [-0.0789, -0.1860, -0.0686,  ..., -0.1960, -0.0858,  0.1048],\n",
       "          ...,\n",
       "          [-0.0789,  0.2722,  0.2178,  ..., -0.2774,  0.2208,  0.1310],\n",
       "          [-0.0255,  0.0014, -0.1380,  ...,  0.1393, -0.1209, -0.0760],\n",
       "          [-0.1842,  0.2696, -0.0348,  ...,  0.2374, -0.1639,  0.2090]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0315, -0.1193, -0.1118, -0.1092,  0.1446, -0.0835, -0.1032, -0.1252,\n",
       "          -0.1030,  0.0597,  0.1667, -0.0576, -0.0874,  0.1592, -0.0151, -0.0482,\n",
       "          -0.0539,  0.0648, -0.0358,  0.0248,  0.0709, -0.1432, -0.1599, -0.1109,\n",
       "           0.0970,  0.0725, -0.0353, -0.1012, -0.0543, -0.0353, -0.0949, -0.1642],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1600],\n",
       "          [-0.3190],\n",
       "          [ 0.3959],\n",
       "          [-0.4090],\n",
       "          [ 0.3841],\n",
       "          [-0.1504],\n",
       "          [ 0.2882],\n",
       "          [-0.1413],\n",
       "          [ 0.3065],\n",
       "          [-0.2028],\n",
       "          [ 0.3978],\n",
       "          [ 0.2868],\n",
       "          [-0.2317],\n",
       "          [-0.2030],\n",
       "          [-0.1238],\n",
       "          [ 0.3093],\n",
       "          [-0.2460],\n",
       "          [-0.1914],\n",
       "          [-0.0759],\n",
       "          [-0.3339],\n",
       "          [-0.1045],\n",
       "          [-0.0763],\n",
       "          [-0.4214],\n",
       "          [-0.4212],\n",
       "          [ 0.0737],\n",
       "          [ 0.1906],\n",
       "          [-0.2375],\n",
       "          [ 0.1399],\n",
       "          [ 0.3590],\n",
       "          [-0.2404],\n",
       "          [-0.2459],\n",
       "          [ 0.4205]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1917,  0.1955,  0.4220, -0.2590, -0.2510, -0.0970,  0.1236,\n",
       "             0.3901, -0.1696, -0.1284, -0.1272, -0.2074, -0.2317, -0.3816,\n",
       "             0.2289, -0.0666, -0.3739,  0.2577,  0.0791,  0.2524,  0.4240,\n",
       "             0.2282, -0.0295,  0.2418, -0.0329,  0.0384, -0.1918, -0.0012,\n",
       "             0.0322, -0.2022, -0.4230,  0.0811]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0143,  0.0235,  0.1858,  ..., -0.0408, -0.0979, -0.0255],\n",
       "          [-0.0811, -0.1858,  0.0007,  ..., -0.1253,  0.2601, -0.2963],\n",
       "          [ 0.0383, -0.2880,  0.0304,  ..., -0.1913, -0.2430,  0.1172],\n",
       "          ...,\n",
       "          [ 0.2853,  0.1709,  0.1405,  ..., -0.1973,  0.2318,  0.2892],\n",
       "          [-0.3042, -0.1370,  0.0454,  ..., -0.2833, -0.1154, -0.1830],\n",
       "          [-0.1898,  0.1695, -0.1875,  ...,  0.0307, -0.0169,  0.0995]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1091, -0.1673, -0.0665, -0.0629,  0.0518,  0.0261, -0.0225,  0.0305,\n",
       "           0.1619, -0.0998,  0.1052, -0.1433, -0.1644, -0.1626,  0.1084,  0.0087,\n",
       "          -0.0060, -0.1269, -0.0221, -0.0734, -0.0459,  0.0724, -0.0969, -0.1688,\n",
       "           0.0972,  0.0838,  0.1076,  0.1299,  0.0093,  0.0072,  0.1120,  0.0232],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0584,  0.0701,  0.1802,  ..., -0.0649, -0.0229, -0.1722],\n",
       "          [ 0.0333,  0.1225, -0.0770,  ...,  0.2170,  0.2643, -0.0303],\n",
       "          [ 0.2481, -0.2327,  0.0625,  ..., -0.2432,  0.2690,  0.0216],\n",
       "          ...,\n",
       "          [-0.0803,  0.0735, -0.1073,  ..., -0.1360, -0.0201,  0.0747],\n",
       "          [ 0.2140, -0.1415, -0.1035,  ...,  0.2028,  0.1588, -0.2396],\n",
       "          [-0.2421,  0.0887,  0.2447,  ..., -0.0028, -0.0753, -0.2733]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1707, -0.0447, -0.0317,  0.0162, -0.0917, -0.1166, -0.1059,  0.1033,\n",
       "           0.0307,  0.0143, -0.1115,  0.1516,  0.1324, -0.0052,  0.0081,  0.0409,\n",
       "           0.0165,  0.0846, -0.0897, -0.0097, -0.0266,  0.0215,  0.0677, -0.1128,\n",
       "          -0.0372,  0.1750, -0.1393, -0.0347,  0.0288, -0.1377, -0.0523,  0.0879],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0508],\n",
       "          [-0.0848],\n",
       "          [-0.3859],\n",
       "          [-0.1145],\n",
       "          [-0.1132],\n",
       "          [-0.3054],\n",
       "          [-0.3596],\n",
       "          [-0.1536],\n",
       "          [-0.4053],\n",
       "          [ 0.3826],\n",
       "          [ 0.0223],\n",
       "          [ 0.2857],\n",
       "          [-0.1091],\n",
       "          [-0.3959],\n",
       "          [-0.2857],\n",
       "          [-0.0130],\n",
       "          [-0.2337],\n",
       "          [-0.3974],\n",
       "          [-0.3525],\n",
       "          [-0.2940],\n",
       "          [-0.1784],\n",
       "          [ 0.1317],\n",
       "          [-0.1422],\n",
       "          [ 0.2107],\n",
       "          [ 0.1990],\n",
       "          [ 0.2504],\n",
       "          [-0.3669],\n",
       "          [-0.0990],\n",
       "          [ 0.1668],\n",
       "          [ 0.1809],\n",
       "          [-0.3272],\n",
       "          [-0.0856]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.4064, -0.4012, -0.3089,  0.3750, -0.2622,  0.2838, -0.0065,\n",
       "             0.2881, -0.2549,  0.1593,  0.1583,  0.1684,  0.1165, -0.0340,\n",
       "             0.0111, -0.2701, -0.0629, -0.3467,  0.3460, -0.0217, -0.3959,\n",
       "             0.2909,  0.2253,  0.3156, -0.2185, -0.3264,  0.0867,  0.0939,\n",
       "             0.0131,  0.2815,  0.3805,  0.0093]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2028, -0.1747,  0.1827,  ...,  0.0859, -0.0762,  0.2406],\n",
       "          [-0.2477,  0.1350, -0.0071,  ..., -0.1903,  0.1313,  0.1962],\n",
       "          [-0.2916, -0.1331,  0.1118,  ..., -0.1264,  0.2950,  0.0537],\n",
       "          ...,\n",
       "          [-0.1604, -0.2172,  0.0065,  ...,  0.2700, -0.1934, -0.0797],\n",
       "          [-0.2730, -0.1387, -0.0213,  ..., -0.2011,  0.1767, -0.1217],\n",
       "          [ 0.0956,  0.1890,  0.2638,  ...,  0.0800,  0.0600,  0.0724]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1724, -0.0972, -0.1178, -0.0821, -0.1653,  0.1395, -0.1470, -0.0124,\n",
       "           0.1391,  0.0638, -0.0891,  0.1177,  0.1738, -0.1542, -0.1161, -0.1467,\n",
       "           0.1602, -0.0989,  0.0100,  0.1609, -0.0150,  0.1517, -0.0652, -0.0059,\n",
       "          -0.1754,  0.1573,  0.0272,  0.0403,  0.0396, -0.0560, -0.1432,  0.0201],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0592, -0.1068, -0.1378,  ...,  0.0521,  0.2613,  0.1244],\n",
       "          [-0.0797, -0.2870,  0.0437,  ...,  0.0989,  0.0124, -0.0568],\n",
       "          [-0.0148, -0.1427, -0.1203,  ...,  0.1972,  0.0004, -0.1426],\n",
       "          ...,\n",
       "          [ 0.2269, -0.0997,  0.1364,  ..., -0.2844, -0.1100,  0.2615],\n",
       "          [ 0.2518, -0.2787,  0.2187,  ...,  0.1541,  0.0351,  0.2032],\n",
       "          [-0.0638, -0.2005,  0.1961,  ...,  0.1143,  0.2620,  0.1551]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0965, -0.0334,  0.0787,  0.1713,  0.0684, -0.0466, -0.0688, -0.1356,\n",
       "          -0.0829,  0.1273, -0.0922,  0.1192,  0.0274,  0.1437,  0.1431,  0.0641,\n",
       "           0.0620, -0.1531, -0.1722, -0.0258,  0.0692, -0.1440, -0.0103,  0.0850,\n",
       "           0.0783,  0.0943,  0.0885,  0.0718,  0.0551, -0.0353,  0.0028, -0.1506],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3921],\n",
       "          [ 0.3706],\n",
       "          [ 0.4157],\n",
       "          [ 0.3281],\n",
       "          [-0.0527],\n",
       "          [ 0.2588],\n",
       "          [ 0.2426],\n",
       "          [-0.1677],\n",
       "          [ 0.2868],\n",
       "          [ 0.2939],\n",
       "          [-0.0861],\n",
       "          [ 0.1867],\n",
       "          [-0.3929],\n",
       "          [-0.0343],\n",
       "          [ 0.1087],\n",
       "          [ 0.1145],\n",
       "          [ 0.0455],\n",
       "          [ 0.2144],\n",
       "          [ 0.0071],\n",
       "          [ 0.3253],\n",
       "          [ 0.0466],\n",
       "          [ 0.0990],\n",
       "          [-0.1751],\n",
       "          [ 0.4259],\n",
       "          [-0.0891],\n",
       "          [ 0.2459],\n",
       "          [ 0.0940],\n",
       "          [ 0.2758],\n",
       "          [ 0.3123],\n",
       "          [ 0.3878],\n",
       "          [ 0.0107],\n",
       "          [ 0.1966]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1588, -0.2743, -0.3850, -0.2343, -0.2121,  0.3962, -0.1692,\n",
       "            -0.1655, -0.0548, -0.0399, -0.2684, -0.0690,  0.2755,  0.1890,\n",
       "            -0.3453,  0.0075,  0.0326, -0.2563,  0.3665, -0.0804,  0.0111,\n",
       "            -0.1916,  0.3049,  0.1959,  0.2590,  0.2306, -0.1747, -0.2154,\n",
       "            -0.3795,  0.2991,  0.1112,  0.2995]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0418,  0.1913, -0.1426,  ...,  0.3047, -0.2391,  0.0335],\n",
       "          [-0.1575,  0.0406,  0.0758,  ..., -0.0204, -0.1441, -0.1550],\n",
       "          [-0.1244, -0.2130,  0.0005,  ...,  0.2514,  0.0019, -0.2221],\n",
       "          ...,\n",
       "          [-0.0690, -0.0700,  0.1170,  ...,  0.0450, -0.1179,  0.0319],\n",
       "          [ 0.0572,  0.0030, -0.2040,  ...,  0.0598, -0.0445, -0.1742],\n",
       "          [-0.1444, -0.0960,  0.0838,  ...,  0.1032,  0.0384,  0.1200]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0915,  0.1405,  0.1347, -0.1555, -0.0026, -0.0781,  0.0267, -0.1639,\n",
       "           0.0976,  0.1655,  0.0194, -0.0345,  0.1145,  0.1681, -0.1147, -0.0330,\n",
       "          -0.1461, -0.1269,  0.0074,  0.1516, -0.0998, -0.1573, -0.0951, -0.0589,\n",
       "          -0.0008, -0.0357, -0.0396,  0.1200, -0.1729,  0.0810,  0.1209, -0.0474],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2745, -0.0443, -0.1447,  ..., -0.1249, -0.1986, -0.0239],\n",
       "          [ 0.2478, -0.1264,  0.0131,  ...,  0.2817,  0.0388,  0.2998],\n",
       "          [ 0.0439, -0.2164,  0.2252,  ...,  0.1268,  0.0739, -0.0014],\n",
       "          ...,\n",
       "          [-0.1321, -0.0019, -0.2908,  ...,  0.0811, -0.1082, -0.0246],\n",
       "          [ 0.1098,  0.2334, -0.0105,  ...,  0.0879,  0.0560,  0.0673],\n",
       "          [-0.2236,  0.0904,  0.0264,  ..., -0.2824, -0.1501, -0.1007]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0845,  0.0598, -0.1752, -0.1587, -0.1192, -0.0881, -0.0198, -0.0853,\n",
       "           0.0774, -0.1648,  0.0509, -0.0236, -0.0195, -0.0604,  0.1005, -0.1502,\n",
       "          -0.1108, -0.1109, -0.1212, -0.0714,  0.0831, -0.0272,  0.0931,  0.0558,\n",
       "          -0.0966,  0.0450,  0.0819, -0.1134,  0.1367,  0.1047, -0.0322,  0.0492],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1454],\n",
       "          [-0.3432],\n",
       "          [-0.2456],\n",
       "          [ 0.1311],\n",
       "          [ 0.0914],\n",
       "          [-0.1409],\n",
       "          [ 0.3143],\n",
       "          [ 0.1318],\n",
       "          [-0.2029],\n",
       "          [ 0.0553],\n",
       "          [-0.3779],\n",
       "          [-0.1802],\n",
       "          [ 0.0605],\n",
       "          [-0.0973],\n",
       "          [ 0.1022],\n",
       "          [-0.1177],\n",
       "          [-0.1838],\n",
       "          [-0.3371],\n",
       "          [ 0.4188],\n",
       "          [ 0.1443],\n",
       "          [-0.3729],\n",
       "          [ 0.0549],\n",
       "          [-0.0099],\n",
       "          [ 0.2397],\n",
       "          [ 0.0209],\n",
       "          [ 0.3462],\n",
       "          [-0.1753],\n",
       "          [ 0.1855],\n",
       "          [-0.1330],\n",
       "          [-0.3270],\n",
       "          [ 0.4260],\n",
       "          [-0.3855]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0077, -0.0623, -0.0893, -0.1038, -0.1334, -0.0158, -0.0715,\n",
       "             0.1652,  0.1785, -0.2213, -0.0163, -0.0238,  0.3060, -0.2602,\n",
       "             0.0319, -0.2000,  0.1233, -0.0747,  0.3905, -0.2493,  0.1966,\n",
       "             0.3012, -0.0112, -0.3482,  0.2676,  0.0263,  0.3369, -0.4007,\n",
       "            -0.3823,  0.3028, -0.3353, -0.2562]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2434, -0.1241,  0.0835,  ...,  0.1330,  0.1645, -0.2511],\n",
       "          [ 0.0510,  0.0523, -0.1917,  ..., -0.1374, -0.2160, -0.2538],\n",
       "          [ 0.0793, -0.2923, -0.0401,  ..., -0.1004,  0.0123,  0.2299],\n",
       "          ...,\n",
       "          [-0.1013, -0.2714,  0.1223,  ...,  0.2745, -0.0081,  0.0653],\n",
       "          [ 0.2143,  0.1636, -0.2980,  ...,  0.0685,  0.1791,  0.0881],\n",
       "          [ 0.1418,  0.0471,  0.1261,  ...,  0.0592,  0.1030, -0.1336]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0972,  0.0681,  0.0231,  0.0607, -0.1531,  0.0141,  0.1678, -0.0818,\n",
       "           0.0199, -0.1677, -0.1639, -0.1476, -0.1084, -0.0608,  0.0582,  0.1560,\n",
       "          -0.1623,  0.1629, -0.0694,  0.0365, -0.1704,  0.1428,  0.0935,  0.0509,\n",
       "          -0.0633, -0.0872,  0.0579, -0.1076, -0.1673,  0.0560,  0.0499,  0.0094],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2418,  0.1747, -0.0101,  ...,  0.0071,  0.0049, -0.2453],\n",
       "          [ 0.0797, -0.2419, -0.2146,  ...,  0.1395, -0.1862,  0.0587],\n",
       "          [-0.1255, -0.1274, -0.0469,  ...,  0.1384, -0.1120, -0.0705],\n",
       "          ...,\n",
       "          [ 0.2567,  0.1228, -0.1890,  ..., -0.2855,  0.0843, -0.2868],\n",
       "          [ 0.1678,  0.2396,  0.0883,  ..., -0.1277, -0.1656,  0.1565],\n",
       "          [-0.0092,  0.0431,  0.1771,  ..., -0.1520,  0.1210, -0.0114]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1519,  0.0210,  0.0773, -0.1249,  0.0468,  0.0107, -0.1237, -0.1610,\n",
       "           0.1384, -0.1447, -0.0281, -0.1088,  0.0252,  0.1490, -0.1469, -0.0268,\n",
       "           0.0009,  0.0461, -0.0229, -0.0341,  0.0039,  0.0544,  0.1222, -0.1491,\n",
       "          -0.1755, -0.0634, -0.0517,  0.1123,  0.0781, -0.1688,  0.0556, -0.0643],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0216],\n",
       "          [ 0.1518],\n",
       "          [-0.3283],\n",
       "          [-0.3216],\n",
       "          [-0.3452],\n",
       "          [ 0.0063],\n",
       "          [-0.1943],\n",
       "          [ 0.0557],\n",
       "          [ 0.3539],\n",
       "          [-0.1397],\n",
       "          [ 0.3921],\n",
       "          [-0.0215],\n",
       "          [-0.0501],\n",
       "          [ 0.0277],\n",
       "          [-0.1401],\n",
       "          [-0.4032],\n",
       "          [-0.1630],\n",
       "          [-0.1900],\n",
       "          [-0.0109],\n",
       "          [ 0.3773],\n",
       "          [-0.3253],\n",
       "          [ 0.1710],\n",
       "          [ 0.0729],\n",
       "          [-0.3398],\n",
       "          [ 0.1057],\n",
       "          [ 0.0455],\n",
       "          [ 0.2277],\n",
       "          [ 0.1006],\n",
       "          [-0.0128],\n",
       "          [ 0.3808],\n",
       "          [-0.0697],\n",
       "          [-0.0175]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.1571, -0.2048,  0.1557, -0.2799, -0.0699, -0.4080, -0.0503,\n",
       "             0.0321, -0.3203, -0.2811,  0.4041, -0.1939,  0.2228,  0.4056,\n",
       "             0.1191,  0.2572,  0.2701,  0.0423,  0.2636, -0.1177, -0.2856,\n",
       "             0.2691, -0.2283,  0.1514, -0.2545,  0.1811,  0.0537,  0.1970,\n",
       "            -0.2696,  0.1085, -0.0190, -0.2397]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.7211e-01, -1.1772e-01,  2.6444e-01,  ..., -1.1321e-01,\n",
       "            3.8639e-02, -1.7924e-01],\n",
       "          [-2.6087e-01,  1.7128e-01, -2.7384e-01,  ...,  2.3648e-01,\n",
       "            1.4116e-02,  1.9759e-05],\n",
       "          [-1.2278e-01,  2.8812e-01, -1.7441e-01,  ...,  1.0292e-01,\n",
       "            2.5749e-02, -1.0646e-01],\n",
       "          ...,\n",
       "          [-1.1504e-01, -8.7088e-04, -2.6372e-01,  ...,  3.0373e-01,\n",
       "            8.5738e-02,  1.1585e-01],\n",
       "          [-7.6787e-03,  2.9624e-01, -2.8862e-01,  ...,  1.1278e-02,\n",
       "           -2.5875e-01, -1.5363e-01],\n",
       "          [ 2.6799e-01, -1.7903e-01,  1.2547e-02,  ..., -1.4061e-01,\n",
       "            2.6419e-01,  2.5792e-01]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1080,  0.1495, -0.1692, -0.0203, -0.0645,  0.0751, -0.1111,  0.0851,\n",
       "           0.0223, -0.0064, -0.1217, -0.0920,  0.1018, -0.0547,  0.0685, -0.1253,\n",
       "          -0.0691, -0.0986,  0.0587,  0.0721,  0.1125,  0.0402,  0.0614, -0.1162,\n",
       "          -0.1290,  0.0328, -0.1683, -0.0181,  0.1286,  0.1493, -0.0572, -0.1013],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2008, -0.1594, -0.2536,  ...,  0.0276, -0.1331,  0.2041],\n",
       "          [ 0.1338, -0.0995, -0.2364,  ...,  0.1121, -0.2473,  0.0160],\n",
       "          [-0.0827, -0.0225, -0.0010,  ..., -0.1417, -0.1674, -0.1509],\n",
       "          ...,\n",
       "          [-0.2227,  0.2246,  0.2417,  ..., -0.0382, -0.1411, -0.2532],\n",
       "          [ 0.1213, -0.2700, -0.1443,  ...,  0.1188, -0.2067,  0.0719],\n",
       "          [-0.2714, -0.0747,  0.0365,  ...,  0.2917, -0.0630,  0.1102]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0854, -0.0858, -0.0035, -0.1187,  0.0004, -0.1179,  0.0929,  0.0689,\n",
       "          -0.0641,  0.1714, -0.1467,  0.1653,  0.1635, -0.1634,  0.0076, -0.0820,\n",
       "           0.0308,  0.1105, -0.1082,  0.0641, -0.1068, -0.0290,  0.0155,  0.0969,\n",
       "          -0.0238,  0.0664,  0.0300, -0.1178, -0.0385, -0.0852,  0.1619, -0.1694],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2269],\n",
       "          [ 0.0308],\n",
       "          [ 0.2621],\n",
       "          [ 0.1999],\n",
       "          [-0.4201],\n",
       "          [ 0.1058],\n",
       "          [-0.2145],\n",
       "          [ 0.1145],\n",
       "          [ 0.2604],\n",
       "          [ 0.1254],\n",
       "          [ 0.0976],\n",
       "          [-0.4204],\n",
       "          [-0.3658],\n",
       "          [-0.1256],\n",
       "          [ 0.3167],\n",
       "          [ 0.1282],\n",
       "          [-0.3791],\n",
       "          [ 0.3925],\n",
       "          [-0.3921],\n",
       "          [-0.2475],\n",
       "          [ 0.0550],\n",
       "          [-0.1193],\n",
       "          [-0.1748],\n",
       "          [ 0.3928],\n",
       "          [-0.0128],\n",
       "          [ 0.2232],\n",
       "          [ 0.0828],\n",
       "          [-0.3581],\n",
       "          [-0.0640],\n",
       "          [ 0.0900],\n",
       "          [ 0.2468],\n",
       "          [ 0.2274]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.4171,  0.3166, -0.2643,  0.4023, -0.2637,  0.4244, -0.0177,\n",
       "             0.2808,  0.4242,  0.3162,  0.1281,  0.4134,  0.1163, -0.2308,\n",
       "             0.2457, -0.0225, -0.3864,  0.2549,  0.0013, -0.1130, -0.2720,\n",
       "             0.0451, -0.0754,  0.1300, -0.1314, -0.3682,  0.2406,  0.2053,\n",
       "             0.3449,  0.3907,  0.3028, -0.1976]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1845,  0.0157, -0.0358,  ..., -0.2664, -0.2547,  0.0698],\n",
       "          [-0.0749, -0.2701,  0.1238,  ..., -0.1705, -0.0216, -0.1035],\n",
       "          [-0.2506, -0.2393,  0.1903,  ..., -0.0462, -0.0805,  0.0050],\n",
       "          ...,\n",
       "          [ 0.2972, -0.2229,  0.1991,  ..., -0.2327, -0.2091, -0.0761],\n",
       "          [ 0.0423,  0.0618, -0.0071,  ..., -0.1352, -0.0988,  0.2487],\n",
       "          [-0.0592, -0.1881, -0.1584,  ...,  0.1806, -0.1244, -0.2917]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0699,  0.1678,  0.0363,  0.0902, -0.1065, -0.1176, -0.1678,  0.0929,\n",
       "          -0.1265, -0.1561,  0.0309, -0.0547,  0.0532,  0.1551,  0.0397,  0.0687,\n",
       "          -0.0872,  0.0729, -0.0516,  0.0441, -0.0268,  0.1183, -0.1615,  0.1681,\n",
       "           0.0411, -0.1170,  0.0381,  0.0323,  0.0191, -0.0101,  0.1434, -0.1747],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2854,  0.0582,  0.2675,  ...,  0.1599,  0.0824,  0.0466],\n",
       "          [ 0.2657,  0.2292, -0.0237,  ..., -0.2433,  0.2562, -0.2289],\n",
       "          [-0.2342, -0.0640,  0.1056,  ..., -0.0048, -0.0574,  0.1330],\n",
       "          ...,\n",
       "          [ 0.1543, -0.2308,  0.2146,  ..., -0.2141,  0.1242,  0.1664],\n",
       "          [ 0.1759,  0.0084,  0.2644,  ..., -0.2529,  0.0628,  0.2657],\n",
       "          [-0.2364,  0.2191, -0.1446,  ...,  0.1355,  0.1901,  0.0411]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1377, -0.0438, -0.0294,  0.0767, -0.0459,  0.0518,  0.0626, -0.1688,\n",
       "           0.0724,  0.1073,  0.0906,  0.0453,  0.1532, -0.1385,  0.1767,  0.0267,\n",
       "           0.1212, -0.1691,  0.0733, -0.1121,  0.0695, -0.1389, -0.1385, -0.0896,\n",
       "          -0.0343, -0.0562, -0.1073, -0.1152, -0.1358, -0.1399,  0.0849,  0.1528],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2249],\n",
       "          [-0.2654],\n",
       "          [-0.3973],\n",
       "          [-0.0960],\n",
       "          [ 0.4073],\n",
       "          [-0.1976],\n",
       "          [-0.1571],\n",
       "          [ 0.0286],\n",
       "          [ 0.1863],\n",
       "          [-0.2845],\n",
       "          [ 0.0473],\n",
       "          [-0.1182],\n",
       "          [-0.0815],\n",
       "          [ 0.1984],\n",
       "          [ 0.3355],\n",
       "          [ 0.3830],\n",
       "          [ 0.2169],\n",
       "          [ 0.0020],\n",
       "          [ 0.1175],\n",
       "          [-0.2755],\n",
       "          [-0.1767],\n",
       "          [ 0.1788],\n",
       "          [-0.1336],\n",
       "          [ 0.1484],\n",
       "          [-0.0267],\n",
       "          [ 0.0961],\n",
       "          [ 0.1906],\n",
       "          [ 0.2818],\n",
       "          [ 0.2918],\n",
       "          [ 0.3748],\n",
       "          [ 0.2966],\n",
       "          [-0.0400]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3260, -0.1998,  0.0929,  0.4243, -0.4105,  0.1684, -0.2256,\n",
       "            -0.0850,  0.3391, -0.4141, -0.1374,  0.3897,  0.1901,  0.0748,\n",
       "             0.1018,  0.3775,  0.3099, -0.2710, -0.4229,  0.1982,  0.1300,\n",
       "             0.3890, -0.1390, -0.1956, -0.0284,  0.0946, -0.3285, -0.1847,\n",
       "             0.3488,  0.1719, -0.3641,  0.0447]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1454, -0.2002,  0.0934,  ...,  0.0492,  0.1674,  0.2861],\n",
       "          [ 0.2392,  0.2147, -0.2440,  ...,  0.0506, -0.2793, -0.2809],\n",
       "          [-0.0406, -0.1222, -0.2187,  ..., -0.0201,  0.0405, -0.2598],\n",
       "          ...,\n",
       "          [ 0.1902,  0.1466,  0.1405,  ...,  0.0973,  0.2839, -0.1504],\n",
       "          [-0.0065, -0.2489, -0.0914,  ...,  0.2246, -0.1064, -0.2542],\n",
       "          [-0.1514, -0.2075, -0.3057,  ..., -0.0326, -0.0004,  0.2439]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1627,  0.0454,  0.0625,  0.0151,  0.0085,  0.0554, -0.1531, -0.1330,\n",
       "          -0.1282, -0.1390, -0.0960, -0.0413, -0.0691,  0.0993, -0.1067,  0.0073,\n",
       "          -0.1663,  0.1253,  0.0032, -0.0838, -0.0427,  0.0286,  0.0892,  0.1472,\n",
       "           0.0681, -0.1575,  0.1141,  0.1308,  0.0783,  0.0289,  0.1636, -0.0508],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.1214e-01, -2.7203e-02,  3.6118e-02,  ...,  3.4266e-03,\n",
       "            8.9197e-02, -1.0156e-01],\n",
       "          [ 8.6926e-02, -6.6029e-02, -1.4377e-01,  ...,  2.3326e-04,\n",
       "           -7.9531e-03, -2.0759e-01],\n",
       "          [-3.1791e-02, -1.7049e-01, -8.7779e-02,  ..., -1.7660e-01,\n",
       "            1.7112e-01, -5.8193e-02],\n",
       "          ...,\n",
       "          [ 1.0539e-01, -8.0097e-02,  2.6308e-01,  ..., -8.2745e-02,\n",
       "            2.5292e-01,  4.7874e-02],\n",
       "          [ 1.2080e-01, -8.0158e-02,  2.2662e-01,  ..., -1.0933e-01,\n",
       "            2.6007e-01,  2.5593e-01],\n",
       "          [ 1.2307e-01,  2.3917e-02,  1.2403e-01,  ...,  5.6463e-02,\n",
       "            2.9420e-01,  5.2454e-02]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0284,  0.0402, -0.1009,  0.1208,  0.1443,  0.0388, -0.1009,  0.0531,\n",
       "           0.0330, -0.1701, -0.0645,  0.1468, -0.1704, -0.1041,  0.1225,  0.1583,\n",
       "           0.1080, -0.0709, -0.0233,  0.0790, -0.1008,  0.1287, -0.0354,  0.0969,\n",
       "           0.0378, -0.1460,  0.0706, -0.0234, -0.1669, -0.0145,  0.0783,  0.0549],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2365],\n",
       "          [ 0.2616],\n",
       "          [-0.3807],\n",
       "          [ 0.1268],\n",
       "          [-0.2793],\n",
       "          [ 0.1557],\n",
       "          [-0.0339],\n",
       "          [ 0.1632],\n",
       "          [ 0.2672],\n",
       "          [ 0.0242],\n",
       "          [-0.2353],\n",
       "          [-0.0231],\n",
       "          [ 0.2781],\n",
       "          [-0.3366],\n",
       "          [ 0.2738],\n",
       "          [ 0.3119],\n",
       "          [-0.3778],\n",
       "          [ 0.1608],\n",
       "          [ 0.2652],\n",
       "          [-0.2709],\n",
       "          [ 0.3132],\n",
       "          [ 0.1410],\n",
       "          [-0.1965],\n",
       "          [ 0.1663],\n",
       "          [ 0.2742],\n",
       "          [-0.0727],\n",
       "          [ 0.1957],\n",
       "          [ 0.2209],\n",
       "          [-0.2207],\n",
       "          [-0.4026],\n",
       "          [-0.3595],\n",
       "          [ 0.1632]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.0091,  0.0152,  0.0809, -0.0704, -0.1793,  0.1532, -0.2919,\n",
       "             0.3738, -0.1789,  0.0818,  0.3216,  0.3898, -0.2799, -0.0194,\n",
       "             0.1867, -0.1473,  0.3888, -0.3075, -0.3640,  0.4113, -0.1131,\n",
       "             0.3619,  0.2722, -0.1870,  0.0677,  0.1253, -0.2781, -0.3808,\n",
       "            -0.0744,  0.0599, -0.3779,  0.3340]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1852, -0.1101,  0.1104,  ..., -0.0673, -0.1639, -0.0174],\n",
       "          [-0.1903, -0.2238, -0.1406,  ...,  0.2923, -0.2264,  0.0133],\n",
       "          [-0.0566,  0.2088, -0.1563,  ...,  0.1742,  0.2696, -0.0254],\n",
       "          ...,\n",
       "          [ 0.0254,  0.0714, -0.0735,  ..., -0.0072,  0.0911, -0.2942],\n",
       "          [-0.1935, -0.2101,  0.2285,  ..., -0.2822, -0.0672,  0.1066],\n",
       "          [ 0.2603,  0.2398,  0.1699,  ...,  0.2295, -0.0526, -0.0180]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1544,  0.1681, -0.1439,  0.0070,  0.1545,  0.0921,  0.0530, -0.1503,\n",
       "          -0.0558, -0.1126,  0.0866, -0.1704,  0.0693,  0.0064,  0.1435, -0.0581,\n",
       "          -0.1034, -0.0838,  0.0032,  0.0480,  0.0366, -0.0699, -0.0817,  0.1508,\n",
       "          -0.0897, -0.1756,  0.0245, -0.0578, -0.0761,  0.1703,  0.1491,  0.0733],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0226,  0.1641, -0.1355,  ...,  0.0438,  0.2973,  0.2768],\n",
       "          [ 0.0670,  0.0902,  0.0730,  ...,  0.1703, -0.2659,  0.1479],\n",
       "          [ 0.0672, -0.0019, -0.0715,  ..., -0.0868, -0.1859,  0.1738],\n",
       "          ...,\n",
       "          [ 0.1926,  0.2669, -0.1961,  ..., -0.0973,  0.2477, -0.1617],\n",
       "          [-0.2816,  0.0004,  0.0211,  ...,  0.3060,  0.0028,  0.1521],\n",
       "          [-0.2247, -0.1865,  0.1564,  ...,  0.1614, -0.1019,  0.0393]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0278,  0.0483, -0.0647, -0.1670,  0.1090,  0.0330, -0.0785,  0.1209,\n",
       "          -0.1650,  0.1639, -0.0153, -0.1141,  0.0069, -0.0226,  0.1496, -0.0464,\n",
       "           0.1062,  0.0280, -0.0595, -0.0046,  0.0628, -0.0297, -0.0986, -0.0806,\n",
       "           0.0192,  0.1091, -0.0853,  0.1583, -0.1216,  0.0418,  0.0629,  0.0436],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2769],\n",
       "          [-0.2491],\n",
       "          [-0.2420],\n",
       "          [-0.1372],\n",
       "          [-0.3890],\n",
       "          [-0.2638],\n",
       "          [-0.1066],\n",
       "          [ 0.3547],\n",
       "          [-0.1647],\n",
       "          [ 0.2577],\n",
       "          [-0.2476],\n",
       "          [ 0.0367],\n",
       "          [-0.0636],\n",
       "          [-0.0046],\n",
       "          [ 0.2193],\n",
       "          [-0.0664],\n",
       "          [-0.3142],\n",
       "          [ 0.1955],\n",
       "          [ 0.3175],\n",
       "          [-0.2396],\n",
       "          [ 0.2435],\n",
       "          [-0.3985],\n",
       "          [ 0.2050],\n",
       "          [-0.2870],\n",
       "          [ 0.2761],\n",
       "          [-0.0938],\n",
       "          [-0.1778],\n",
       "          [ 0.1642],\n",
       "          [-0.3000],\n",
       "          [-0.2339],\n",
       "          [ 0.2982],\n",
       "          [ 0.0202]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-0.1603,  0.1036, -0.0579, -0.2262,  0.3630,  0.1993, -0.2206,\n",
       "            -0.2846, -0.0958, -0.1208, -0.2155, -0.2952, -0.4010, -0.0098,\n",
       "             0.0015,  0.3488, -0.3202, -0.2088, -0.1500, -0.1013,  0.2577,\n",
       "             0.1787,  0.3442,  0.1528,  0.1104, -0.0669,  0.1969,  0.2410,\n",
       "             0.1189, -0.3917, -0.3072,  0.3708]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0020,  0.1426,  0.1153,  ...,  0.0762,  0.0274, -0.1484],\n",
       "          [ 0.2401,  0.1542,  0.2337,  ...,  0.1550, -0.0394, -0.1608],\n",
       "          [-0.0211,  0.2413, -0.2519,  ..., -0.0956,  0.1666, -0.2508],\n",
       "          ...,\n",
       "          [-0.1113, -0.1771,  0.2217,  ..., -0.0792, -0.0047,  0.1175],\n",
       "          [ 0.1416,  0.2448, -0.2120,  ...,  0.1497, -0.0066, -0.0780],\n",
       "          [ 0.1416, -0.1672,  0.3019,  ..., -0.2813, -0.1823, -0.1642]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1539,  0.1414,  0.1380,  0.1003,  0.0910,  0.0122, -0.0162, -0.0815,\n",
       "           0.1549, -0.1129,  0.0054,  0.1650,  0.0965, -0.0347, -0.1376,  0.0905,\n",
       "           0.0554, -0.1573, -0.0850,  0.1248, -0.1696,  0.1755,  0.0257, -0.0565,\n",
       "          -0.1650, -0.0216,  0.0953, -0.1045, -0.1602,  0.1328, -0.1348, -0.1721],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0334,  0.2065, -0.1255,  ...,  0.1635, -0.1982,  0.1629],\n",
       "          [-0.2971,  0.2633, -0.0005,  ..., -0.2182, -0.1679,  0.2955],\n",
       "          [ 0.2928,  0.2819, -0.2249,  ..., -0.2882, -0.1162, -0.2110],\n",
       "          ...,\n",
       "          [ 0.1711, -0.1292,  0.0102,  ...,  0.0270,  0.0467, -0.1756],\n",
       "          [ 0.2617, -0.2309,  0.0020,  ..., -0.2576, -0.2197,  0.0076],\n",
       "          [ 0.2836,  0.1379, -0.2454,  ..., -0.2546, -0.1920,  0.2517]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1146, -0.0843, -0.1245, -0.0486,  0.0924,  0.1762,  0.0451,  0.1286,\n",
       "          -0.0915, -0.0103, -0.0184, -0.0777,  0.0508,  0.1032,  0.1557, -0.1448,\n",
       "          -0.1137,  0.0144, -0.1747, -0.0899,  0.0705, -0.0646,  0.1297, -0.0546,\n",
       "           0.0938,  0.1055,  0.0721,  0.0477, -0.0041,  0.1307, -0.0731,  0.0333],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1412],\n",
       "          [-0.2866],\n",
       "          [ 0.1093],\n",
       "          [-0.0697],\n",
       "          [ 0.1773],\n",
       "          [ 0.0745],\n",
       "          [-0.0286],\n",
       "          [-0.2555],\n",
       "          [-0.2202],\n",
       "          [ 0.1557],\n",
       "          [-0.0141],\n",
       "          [ 0.2425],\n",
       "          [-0.3009],\n",
       "          [ 0.4039],\n",
       "          [-0.2115],\n",
       "          [-0.1829],\n",
       "          [ 0.1167],\n",
       "          [ 0.2735],\n",
       "          [ 0.2136],\n",
       "          [ 0.2820],\n",
       "          [-0.0418],\n",
       "          [-0.2651],\n",
       "          [ 0.2884],\n",
       "          [ 0.0920],\n",
       "          [-0.1887],\n",
       "          [-0.2346],\n",
       "          [ 0.3677],\n",
       "          [-0.3385],\n",
       "          [ 0.0224],\n",
       "          [ 0.2586],\n",
       "          [ 0.2549],\n",
       "          [ 0.1462]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.0936,  0.1406,  0.0693, -0.1696,  0.2489, -0.3377,  0.1822,\n",
       "             0.2821, -0.2046, -0.1267, -0.0454,  0.1538, -0.1819, -0.3685,\n",
       "             0.2575, -0.0129, -0.3427, -0.2564, -0.3029,  0.3833,  0.1449,\n",
       "            -0.2894,  0.1840,  0.1137, -0.0919, -0.4113, -0.0394, -0.0552,\n",
       "            -0.1713,  0.0539,  0.0336,  0.1260]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0242,  0.1378,  0.1727,  ...,  0.2511,  0.1984,  0.2978],\n",
       "          [-0.0037, -0.1657,  0.2421,  ...,  0.2419, -0.0221,  0.1337],\n",
       "          [ 0.0270,  0.2732, -0.2815,  ...,  0.2329,  0.0645,  0.0965],\n",
       "          ...,\n",
       "          [-0.0536,  0.1570, -0.1986,  ...,  0.0103, -0.2365,  0.0061],\n",
       "          [ 0.1849,  0.2766, -0.2844,  ..., -0.2534,  0.1473, -0.2809],\n",
       "          [ 0.2960,  0.0009,  0.2238,  ...,  0.2190,  0.2076, -0.1224]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0875, -0.1720, -0.1122,  0.0598, -0.0203,  0.1475,  0.1380,  0.0086,\n",
       "           0.1183,  0.0727,  0.0453,  0.0168, -0.1341, -0.0591, -0.1640, -0.0985,\n",
       "          -0.0421,  0.1673,  0.0299,  0.0988,  0.0660,  0.1666, -0.0799, -0.0514,\n",
       "           0.1355,  0.0873,  0.1564,  0.1044, -0.0471,  0.0344,  0.1045, -0.1485],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1116, -0.1549, -0.0320,  ..., -0.2784,  0.1916, -0.1654],\n",
       "          [-0.0940,  0.0443, -0.0126,  ...,  0.1341, -0.0644, -0.0246],\n",
       "          [ 0.2837,  0.0183,  0.0277,  ...,  0.0837, -0.0073, -0.0022],\n",
       "          ...,\n",
       "          [ 0.1126, -0.2147,  0.0843,  ..., -0.2636, -0.3024,  0.0366],\n",
       "          [-0.2674,  0.0350, -0.0292,  ...,  0.0637, -0.0712,  0.1524],\n",
       "          [-0.1222, -0.0980,  0.2838,  ..., -0.0348, -0.2246, -0.0306]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1081,  0.0203,  0.0334,  0.1441,  0.0685,  0.1580, -0.0729, -0.1520,\n",
       "          -0.1015, -0.1639, -0.0826, -0.0561, -0.1742,  0.1240,  0.0190, -0.1232,\n",
       "           0.0166,  0.0336,  0.1085,  0.0608, -0.0514,  0.1644, -0.1139, -0.1567,\n",
       "          -0.1419,  0.1463, -0.0302,  0.0076, -0.0667, -0.0587, -0.1297, -0.0610],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3122],\n",
       "          [-0.2233],\n",
       "          [-0.0322],\n",
       "          [-0.2346],\n",
       "          [-0.3292],\n",
       "          [ 0.1214],\n",
       "          [ 0.4160],\n",
       "          [-0.1302],\n",
       "          [ 0.4109],\n",
       "          [-0.3787],\n",
       "          [ 0.3827],\n",
       "          [ 0.4241],\n",
       "          [-0.0194],\n",
       "          [-0.1177],\n",
       "          [ 0.1615],\n",
       "          [-0.0195],\n",
       "          [ 0.2137],\n",
       "          [-0.1656],\n",
       "          [-0.2758],\n",
       "          [ 0.2247],\n",
       "          [-0.1361],\n",
       "          [-0.0105],\n",
       "          [-0.2051],\n",
       "          [-0.3672],\n",
       "          [-0.3871],\n",
       "          [ 0.0529],\n",
       "          [ 0.0923],\n",
       "          [ 0.0956],\n",
       "          [ 0.1437],\n",
       "          [-0.2206],\n",
       "          [-0.0312],\n",
       "          [-0.2136]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.2158,  0.1597, -0.2968,  0.1973,  0.0816,  0.0967,  0.3862,\n",
       "             0.2934,  0.0687, -0.2210, -0.1432, -0.3390, -0.2223,  0.0343,\n",
       "            -0.1680, -0.0346,  0.2957, -0.1737, -0.0578,  0.0355, -0.1372,\n",
       "            -0.2229,  0.3563, -0.0671, -0.1580, -0.4181,  0.1551,  0.3417,\n",
       "            -0.4189,  0.2894, -0.3606, -0.0440]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1936, -0.1986, -0.3042,  ...,  0.2758, -0.0451,  0.2161],\n",
       "          [ 0.0507, -0.2121,  0.2575,  ..., -0.1137, -0.3046, -0.1699],\n",
       "          [ 0.0771, -0.1755,  0.0932,  ...,  0.2816, -0.0766, -0.0350],\n",
       "          ...,\n",
       "          [ 0.2716, -0.2241,  0.1096,  ...,  0.1009, -0.0551, -0.0458],\n",
       "          [ 0.1883, -0.2166,  0.2648,  ..., -0.2842, -0.1189,  0.2848],\n",
       "          [-0.1876, -0.0045,  0.0953,  ...,  0.0919,  0.2661,  0.0526]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1485, -0.0416, -0.0771, -0.0320,  0.1007, -0.0759,  0.1554,  0.0958,\n",
       "           0.1623,  0.0798, -0.0922,  0.0859,  0.1265,  0.0246, -0.1348,  0.1213,\n",
       "          -0.0834, -0.0700, -0.0104, -0.0138, -0.0315, -0.0106, -0.1028, -0.1531,\n",
       "          -0.1653,  0.0179, -0.1288, -0.0953,  0.0417, -0.1672, -0.0946,  0.1603],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1035,  0.1513, -0.1880,  ...,  0.2703,  0.1626,  0.1067],\n",
       "          [ 0.2015,  0.2133,  0.0118,  ...,  0.0188, -0.2877,  0.0164],\n",
       "          [ 0.1892,  0.1697, -0.1114,  ...,  0.2268, -0.0666,  0.0128],\n",
       "          ...,\n",
       "          [-0.1366, -0.2227, -0.1017,  ...,  0.2328,  0.0422,  0.0995],\n",
       "          [ 0.1559, -0.2364, -0.2673,  ...,  0.2002,  0.1915,  0.0378],\n",
       "          [ 0.1438,  0.0384,  0.1834,  ...,  0.1511, -0.0925,  0.0713]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1420,  0.1443,  0.1011,  0.0684,  0.0944,  0.0351,  0.0621, -0.1098,\n",
       "           0.1609, -0.1699, -0.0918,  0.0243, -0.1001, -0.0779,  0.1588, -0.0500,\n",
       "           0.1016,  0.0710, -0.0057, -0.0671,  0.1419,  0.0012,  0.1641,  0.0117,\n",
       "          -0.1717, -0.1704, -0.1012,  0.0296, -0.0796, -0.1360, -0.0430,  0.1031],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3411],\n",
       "          [-0.1522],\n",
       "          [-0.3532],\n",
       "          [-0.0908],\n",
       "          [ 0.0507],\n",
       "          [ 0.3094],\n",
       "          [-0.3625],\n",
       "          [-0.2449],\n",
       "          [ 0.2189],\n",
       "          [-0.0016],\n",
       "          [-0.1061],\n",
       "          [-0.2734],\n",
       "          [ 0.1068],\n",
       "          [ 0.2569],\n",
       "          [-0.2015],\n",
       "          [ 0.1819],\n",
       "          [-0.2920],\n",
       "          [-0.1257],\n",
       "          [ 0.2098],\n",
       "          [-0.2226],\n",
       "          [-0.4191],\n",
       "          [-0.0600],\n",
       "          [-0.3502],\n",
       "          [-0.1165],\n",
       "          [ 0.0648],\n",
       "          [ 0.1177],\n",
       "          [ 0.0359],\n",
       "          [-0.1730],\n",
       "          [-0.3923],\n",
       "          [ 0.0256],\n",
       "          [ 0.2732],\n",
       "          [-0.2907]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.3411,  0.3787,  0.3279, -0.3069,  0.0399,  0.0408, -0.1790,\n",
       "             0.1013, -0.3707, -0.2346, -0.2525, -0.0254, -0.2059, -0.1064,\n",
       "            -0.4233, -0.3824, -0.2588,  0.0753,  0.1032,  0.2436, -0.3039,\n",
       "            -0.3330, -0.1856,  0.1411,  0.4025, -0.1733, -0.1530,  0.1409,\n",
       "            -0.3518,  0.4103,  0.3455, -0.3165]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0253,  0.1185,  0.0795,  ..., -0.1661,  0.2232, -0.2182],\n",
       "          [-0.2673,  0.1286, -0.2066,  ...,  0.0405,  0.0505, -0.2781],\n",
       "          [-0.0607, -0.1856,  0.0015,  ...,  0.2342,  0.1831, -0.0331],\n",
       "          ...,\n",
       "          [ 0.0778, -0.2852,  0.0782,  ..., -0.1374,  0.1229,  0.2812],\n",
       "          [ 0.1804,  0.1531, -0.0066,  ...,  0.0825, -0.1465,  0.2741],\n",
       "          [ 0.1643, -0.2660,  0.1056,  ...,  0.1402,  0.0451, -0.0118]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1087,  0.0607,  0.0960,  0.0100, -0.0084, -0.1498, -0.0782, -0.0570,\n",
       "          -0.1062,  0.0330, -0.0260, -0.0274,  0.0240,  0.0589, -0.0025, -0.1632,\n",
       "          -0.1456, -0.1707, -0.0372, -0.1561,  0.0104,  0.0140, -0.1212, -0.0730,\n",
       "           0.0908,  0.0503, -0.0200,  0.1598,  0.0339,  0.1246, -0.1490, -0.0140],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2794,  0.0417, -0.1149,  ..., -0.2977, -0.2344,  0.2635],\n",
       "          [-0.2512, -0.3015,  0.0495,  ..., -0.2198,  0.1141, -0.0575],\n",
       "          [ 0.1425, -0.1550, -0.2845,  ...,  0.2297,  0.0659,  0.1861],\n",
       "          ...,\n",
       "          [ 0.0253,  0.1886,  0.0698,  ...,  0.0032, -0.1315, -0.0803],\n",
       "          [-0.1131, -0.2297,  0.1972,  ...,  0.1007, -0.2180, -0.3002],\n",
       "          [ 0.0007, -0.1692,  0.1100,  ..., -0.0440, -0.0609, -0.0518]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1689,  0.0219, -0.0607, -0.0473, -0.1549, -0.0406,  0.1030, -0.0489,\n",
       "          -0.1687,  0.1629, -0.0745, -0.1731,  0.0797,  0.0943,  0.1716, -0.0018,\n",
       "          -0.0545, -0.0171,  0.1511, -0.1457,  0.0610, -0.1737, -0.1298, -0.0504,\n",
       "           0.1495,  0.1227,  0.0203, -0.0767,  0.1150, -0.1211, -0.1572, -0.1416],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2121],\n",
       "          [-0.1713],\n",
       "          [ 0.1397],\n",
       "          [-0.2528],\n",
       "          [ 0.2382],\n",
       "          [ 0.2388],\n",
       "          [ 0.3937],\n",
       "          [ 0.1337],\n",
       "          [ 0.2728],\n",
       "          [-0.2412],\n",
       "          [-0.0616],\n",
       "          [ 0.3457],\n",
       "          [-0.2139],\n",
       "          [-0.1473],\n",
       "          [ 0.0605],\n",
       "          [-0.0150],\n",
       "          [ 0.2665],\n",
       "          [-0.0444],\n",
       "          [-0.2604],\n",
       "          [-0.0607],\n",
       "          [-0.3726],\n",
       "          [ 0.1801],\n",
       "          [ 0.2557],\n",
       "          [-0.1419],\n",
       "          [ 0.2832],\n",
       "          [ 0.3759],\n",
       "          [ 0.2535],\n",
       "          [-0.2003],\n",
       "          [-0.0342],\n",
       "          [-0.1722],\n",
       "          [ 0.2591],\n",
       "          [-0.1408]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-3.1278e-01,  1.7844e-01, -1.1652e-01, -3.0944e-01, -4.0135e-01,\n",
       "            -3.3196e-01, -3.5349e-01, -3.1976e-01, -3.4860e-01, -3.7839e-02,\n",
       "            -2.7642e-01, -3.8305e-01, -3.3134e-01,  3.0620e-01,  6.7978e-03,\n",
       "            -3.2356e-01, -1.7736e-01, -3.4600e-01,  2.3537e-01,  2.6530e-01,\n",
       "            -1.5598e-01,  3.2821e-04,  2.3619e-01,  2.9938e-01,  3.0306e-01,\n",
       "             3.2505e-01,  3.0836e-01, -3.4294e-01,  4.6873e-02, -2.3408e-01,\n",
       "             7.1298e-03, -2.3199e-01]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0514, -0.2816, -0.2639,  ...,  0.0083,  0.1016,  0.0139],\n",
       "          [ 0.0185,  0.0358,  0.1018,  ..., -0.1643, -0.2088, -0.1501],\n",
       "          [-0.0358,  0.2426,  0.2713,  ...,  0.2885,  0.2969, -0.1294],\n",
       "          ...,\n",
       "          [-0.0769, -0.1687, -0.2002,  ...,  0.2663, -0.0466,  0.2549],\n",
       "          [ 0.2978, -0.0949,  0.1972,  ..., -0.2950,  0.1283, -0.1481],\n",
       "          [-0.1450,  0.1198, -0.3035,  ..., -0.0876,  0.2053,  0.2084]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.0706,  0.0826,  0.0444,  0.1486,  0.1214,  0.1010, -0.0063,  0.0030,\n",
       "           0.0887, -0.0019,  0.0885, -0.0243,  0.0384, -0.0259, -0.1325, -0.1027,\n",
       "          -0.1064,  0.0459, -0.0469,  0.1017,  0.0745, -0.0119, -0.1750,  0.0907,\n",
       "          -0.0402,  0.0933,  0.0473,  0.0137, -0.0528, -0.1513,  0.1326,  0.0400],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1668,  0.2844, -0.2308,  ..., -0.2701, -0.1639,  0.1379],\n",
       "          [-0.2974,  0.2508, -0.2588,  ..., -0.2431, -0.2762, -0.2974],\n",
       "          [ 0.2139,  0.0848, -0.1012,  ..., -0.1479, -0.2623, -0.1894],\n",
       "          ...,\n",
       "          [ 0.2736,  0.2068, -0.0951,  ...,  0.1560, -0.0722,  0.0430],\n",
       "          [-0.0957,  0.2300, -0.0306,  ...,  0.2366,  0.1679, -0.1378],\n",
       "          [ 0.0699, -0.0052,  0.0711,  ..., -0.1217,  0.1823,  0.2922]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1371, -0.0643, -0.1351,  0.1136, -0.1274, -0.0067,  0.0235, -0.0735,\n",
       "           0.0905,  0.1591,  0.1749,  0.1347, -0.0285,  0.1319,  0.1408, -0.1717,\n",
       "          -0.0093, -0.0579,  0.1644, -0.0707,  0.0206, -0.1284, -0.1623, -0.1504,\n",
       "           0.1339,  0.0754, -0.0247, -0.1081, -0.1356, -0.1086, -0.0977,  0.1314],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1483],\n",
       "          [-0.2655],\n",
       "          [ 0.1409],\n",
       "          [ 0.2301],\n",
       "          [ 0.1359],\n",
       "          [ 0.3194],\n",
       "          [-0.0033],\n",
       "          [ 0.3240],\n",
       "          [ 0.1735],\n",
       "          [ 0.2781],\n",
       "          [-0.4132],\n",
       "          [-0.1700],\n",
       "          [ 0.3804],\n",
       "          [ 0.3417],\n",
       "          [-0.1656],\n",
       "          [-0.1318],\n",
       "          [ 0.1876],\n",
       "          [-0.1858],\n",
       "          [ 0.1126],\n",
       "          [ 0.0774],\n",
       "          [ 0.4214],\n",
       "          [-0.0250],\n",
       "          [-0.1456],\n",
       "          [ 0.1189],\n",
       "          [ 0.1767],\n",
       "          [ 0.3651],\n",
       "          [-0.2560],\n",
       "          [-0.2224],\n",
       "          [-0.0750],\n",
       "          [ 0.0509],\n",
       "          [-0.0279],\n",
       "          [ 0.2223]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 0.9310, -0.4203,  0.8324,  0.9844,  0.2977,  0.8979,  0.5413,\n",
       "            -0.2152, -0.7964,  0.7929,  0.5858,  0.7146, -0.3480, -0.7545,\n",
       "             0.4573, -0.4383,  0.7453, -0.5494, -0.1395, -0.9801, -0.5232,\n",
       "             0.8242, -0.0039,  0.3582,  0.6315,  0.0433,  0.6213,  0.3394,\n",
       "            -0.1590,  0.0385,  0.9977,  0.8776],\n",
       "           [-0.5278,  0.6508,  0.4678,  0.1787,  0.8124, -0.1735, -0.9747,\n",
       "             0.2240, -0.8208, -0.8486, -0.4956, -0.8451, -0.7479, -0.1448,\n",
       "             0.4280, -0.3692, -0.3346, -0.9619, -0.5580,  0.9198,  0.3631,\n",
       "            -0.4175, -0.9872, -0.4615,  0.6478, -0.0502,  0.8460, -0.7686,\n",
       "            -0.0477, -0.0361, -0.2239,  0.4212],\n",
       "           [-0.1493, -0.5128, -0.8393,  0.3426, -0.3236, -0.5069, -0.5300,\n",
       "             0.8132,  0.7032, -0.6155, -0.7683, -0.8510,  0.2846,  0.6921,\n",
       "             0.4729, -0.8367, -0.1529,  0.1710, -0.2171, -0.5885,  0.3749,\n",
       "             0.3792,  0.4959, -0.7905,  0.2953, -0.7471, -0.9554,  0.4038,\n",
       "            -0.8813,  0.5338, -0.0950, -0.1955],\n",
       "           [ 0.6042,  0.0355,  0.6878,  0.1065, -0.6491,  0.6650,  0.0272,\n",
       "            -0.5985, -0.9453,  0.0220,  0.6565, -0.2014,  0.5019,  0.2882,\n",
       "            -0.5355, -0.8571, -0.5245, -0.2560,  0.7458,  0.5365,  0.5010,\n",
       "            -0.1290, -0.6197, -0.1097, -0.6159,  0.0981, -0.1385, -0.9998,\n",
       "             0.2439, -0.3524, -0.1904,  0.2771],\n",
       "           [-0.5605, -0.7267,  0.3331, -0.6505, -0.3048, -0.7510,  0.1357,\n",
       "             0.5804,  0.0135, -0.7341,  0.9920, -0.3914,  0.0732, -0.4787,\n",
       "             0.3646,  0.5079,  0.9822,  0.2773, -0.6018,  0.9317, -0.9225,\n",
       "            -0.8072, -0.9316,  0.1673, -0.6605,  0.6141, -0.3060, -0.5243,\n",
       "            -0.8410,  0.9010, -0.0711, -0.0114],\n",
       "           [-0.8222,  0.3158, -0.8645, -0.4933,  0.2483,  0.3266,  0.3987,\n",
       "             0.1633,  0.7367,  0.3994, -0.1917,  0.1165, -0.0521, -0.7512,\n",
       "             0.8212, -0.2081,  0.8636,  0.7712, -0.9410,  0.6470, -0.4506,\n",
       "             0.7349, -0.4075,  0.5138,  0.4827, -0.2461,  0.8395,  0.1830,\n",
       "             0.8232, -0.5184, -0.6212, -0.8489],\n",
       "           [-0.0927,  0.6666,  0.2577,  0.2157,  0.6388,  0.7426, -0.3432,\n",
       "            -0.5010,  0.8998,  0.3073,  0.7862,  0.3806, -0.6362,  0.5928,\n",
       "             0.3056,  0.4212, -0.6180, -0.2669,  0.3826, -0.0534, -0.5262,\n",
       "            -0.7796, -0.7624,  0.1052, -0.3655,  0.7426,  0.3756,  0.8086,\n",
       "             0.2309, -0.7740, -0.1824, -0.6649],\n",
       "           [-0.5992, -0.5601,  0.2166, -0.9749, -0.5545,  0.6658,  0.0217,\n",
       "             0.3589, -0.1415, -0.9284, -0.6953,  0.5781,  0.0230,  0.8862,\n",
       "             0.0968,  0.1918,  0.3838,  0.3201, -0.6260, -0.3248, -0.1985,\n",
       "            -0.9998, -0.2701, -0.2100,  0.8349, -0.7638,  0.4030,  0.7938,\n",
       "             0.5984,  0.9452,  0.1860, -0.1076]],\n",
       "  \n",
       "          [[ 0.4765, -0.0812,  0.5337, -0.7402,  0.1690,  0.5925, -0.9255,\n",
       "            -0.7853,  0.7728,  0.7901, -0.8640,  0.8090,  0.9287, -0.5102,\n",
       "            -0.3628, -0.4791, -0.1528, -0.7652,  0.5214, -0.4591, -0.4932,\n",
       "             0.3939, -0.7550, -0.5314, -0.7254, -0.2509,  0.7520,  0.1277,\n",
       "             0.7096, -0.6977, -0.2695,  0.2587],\n",
       "           [-0.6273,  0.1169,  0.5683, -0.0567,  0.9648, -0.7746,  0.3791,\n",
       "            -0.0165,  0.6762,  0.0917,  0.2222, -0.8571,  0.1956, -0.0056,\n",
       "             0.7920,  0.3025,  0.4328, -0.2398,  0.5822,  0.9798,  0.6678,\n",
       "            -0.9046,  0.7678, -0.2108, -0.7777, -0.7936,  0.0742, -0.1311,\n",
       "            -0.0812,  0.9490, -0.9085,  0.8743],\n",
       "           [ 0.6078, -0.3525, -0.9110, -0.6898, -0.0839, -0.5058, -0.7446,\n",
       "             0.7785,  0.6042, -0.4491,  0.2265, -0.0686, -0.8571,  0.9123,\n",
       "             0.0915, -0.8799,  0.5406, -0.1148,  0.6129, -0.8846, -0.4944,\n",
       "            -0.7602,  0.4932,  0.8647,  0.9264, -0.2324, -0.4081,  0.3857,\n",
       "             0.6361, -0.9171,  0.2975,  0.6104],\n",
       "           [ 0.6475, -0.4193, -0.6483, -0.2443, -0.4967,  0.3112, -0.1840,\n",
       "             0.9421, -0.9259,  0.8466,  0.4930,  0.2168, -0.9422, -0.6881,\n",
       "             0.5864, -0.4299, -0.0431, -0.6746, -0.5836, -0.6829, -0.7617,\n",
       "            -0.4550,  0.3687,  0.8535,  0.9734,  0.6208, -0.1172, -0.4623,\n",
       "            -0.7513,  0.5665,  0.5648,  0.1987],\n",
       "           [ 0.2164,  0.5854, -0.9423, -0.9556, -0.3139,  0.8747, -0.6669,\n",
       "            -0.7430, -0.5025,  0.5254,  0.6868,  0.8468, -0.9814, -0.4923,\n",
       "             0.3335,  0.8213,  0.2149, -0.5456,  0.9482,  0.1264, -0.6619,\n",
       "            -0.5458,  0.1748, -0.9725,  0.3877,  0.3041,  0.4904,  0.7347,\n",
       "            -0.4824,  0.9518,  0.9491, -0.3511],\n",
       "           [ 0.5506,  0.5760,  0.3759, -0.7877, -0.0210,  0.0072,  0.3102,\n",
       "             0.0622, -0.8429,  0.2546,  0.1424, -0.9584, -0.7868, -0.8338,\n",
       "            -0.2816,  0.6332,  0.1405,  0.0184,  0.3687,  0.4612,  0.4626,\n",
       "            -0.6305,  0.1305,  0.1037, -0.4496,  0.2438, -0.7210,  0.2566,\n",
       "             0.2547,  0.3316, -0.7292,  0.2742],\n",
       "           [-0.1436, -0.2035, -0.1636, -0.2043, -0.5756,  0.8958, -0.7660,\n",
       "             0.5928, -0.5999, -0.2068, -0.0807,  0.8079,  0.2458,  0.2023,\n",
       "             0.3523, -0.3356, -0.7989, -0.0422, -0.0470, -0.0074, -0.0552,\n",
       "             0.8282,  0.9169, -0.2459, -0.2136,  0.6715,  0.8570,  0.0122,\n",
       "             0.5440,  0.8456,  0.8998, -0.3687],\n",
       "           [-0.5150,  0.9380,  0.2626,  0.4410,  0.0218, -0.9624, -0.1767,\n",
       "            -0.8292,  0.5053, -0.3890, -0.3341,  0.3868, -0.3462, -0.0511,\n",
       "            -0.8146,  0.8814,  0.3575, -0.8414,  0.7217,  0.2694,  0.0057,\n",
       "             0.5287, -0.5125, -0.6361, -0.6396,  0.6981, -0.9961,  0.9566,\n",
       "             0.2038,  0.5270,  0.9601, -0.3916]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.3905]],\n",
       "  \n",
       "           [[-0.0569]]]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1153, -0.0669, -0.1280,  ..., -0.0988, -0.1074,  0.0126],\n",
       "          [-0.1144,  0.1428, -0.1728,  ..., -0.0927, -0.1371, -0.0239],\n",
       "          [ 0.0444, -0.1018,  0.1735,  ..., -0.1249, -0.0434,  0.1346],\n",
       "          ...,\n",
       "          [-0.1123,  0.0345,  0.1289,  ..., -0.1682, -0.1203,  0.0498],\n",
       "          [-0.1288, -0.1248, -0.0661,  ..., -0.0607, -0.1699,  0.0010],\n",
       "          [-0.0812, -0.0507,  0.1258,  ...,  0.1280,  0.1122,  0.1087]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0225,  0.0253,  0.0016,  0.0342, -0.0468,  0.0248, -0.0428,  0.0550,\n",
       "            0.0584,  0.0588,  0.0108,  0.0012, -0.0212,  0.0275,  0.0244, -0.0356,\n",
       "            0.0472,  0.0224,  0.0598, -0.0355, -0.0026,  0.0117,  0.0305,  0.0363,\n",
       "            0.0625,  0.0176,  0.0268, -0.0556, -0.0561, -0.0166,  0.0401, -0.0176,\n",
       "           -0.0599, -0.0180,  0.0081,  0.0317,  0.0099,  0.0581,  0.0542, -0.0317,\n",
       "            0.0080, -0.0005, -0.0004,  0.0251,  0.0480, -0.0318, -0.0075,  0.0129,\n",
       "           -0.0563,  0.0119, -0.0493,  0.0392,  0.0432, -0.0045,  0.0275,  0.0346,\n",
       "            0.0559, -0.0470, -0.0375, -0.0543, -0.0274, -0.0044, -0.0360, -0.0099,\n",
       "            0.0337,  0.0093,  0.0043, -0.0612,  0.0354,  0.0466,  0.0127, -0.0341,\n",
       "            0.0151,  0.0319, -0.0175, -0.0336, -0.0317,  0.0088,  0.0044, -0.0445,\n",
       "           -0.0051,  0.0355,  0.0422, -0.0591,  0.0578,  0.0220, -0.0493,  0.0090,\n",
       "           -0.0460, -0.0487,  0.0466,  0.0289, -0.0365, -0.0085,  0.0235, -0.0071,\n",
       "           -0.0146,  0.0479, -0.0512, -0.0360,  0.0007, -0.0414, -0.0558, -0.0377,\n",
       "            0.0058, -0.0615,  0.0582,  0.0085, -0.0342, -0.0433,  0.0581,  0.0413,\n",
       "           -0.0100, -0.0408,  0.0427, -0.0269, -0.0076, -0.0547,  0.0286,  0.0130,\n",
       "           -0.0329,  0.0131,  0.0404,  0.0163,  0.0016,  0.0230,  0.0357,  0.0177,\n",
       "            0.0503, -0.0412, -0.0205, -0.0175,  0.0609,  0.0178,  0.0285,  0.0348,\n",
       "            0.0554,  0.0492,  0.0374,  0.0043,  0.0205,  0.0215, -0.0351, -0.0542,\n",
       "            0.0201,  0.0578, -0.0092,  0.0339, -0.0571,  0.0352,  0.0311, -0.0455,\n",
       "            0.0081,  0.0038, -0.0367,  0.0070, -0.0156,  0.0257,  0.0455,  0.0269,\n",
       "           -0.0216, -0.0104, -0.0096,  0.0467, -0.0064, -0.0410, -0.0505,  0.0159,\n",
       "            0.0614, -0.0465, -0.0213, -0.0539, -0.0237, -0.0085,  0.0163,  0.0114,\n",
       "           -0.0621, -0.0144, -0.0159, -0.0443, -0.0430,  0.0216, -0.0134,  0.0280,\n",
       "            0.0612,  0.0171, -0.0166,  0.0372,  0.0239,  0.0481,  0.0498, -0.0195,\n",
       "            0.0064,  0.0556,  0.0563,  0.0079, -0.0536,  0.0472,  0.0558,  0.0094,\n",
       "           -0.0567,  0.0620, -0.0265, -0.0488,  0.0118,  0.0500, -0.0522,  0.0378,\n",
       "           -0.0290,  0.0114, -0.0619,  0.0400,  0.0389, -0.0107, -0.0295,  0.0196,\n",
       "            0.0449,  0.0405, -0.0097,  0.0586,  0.0386,  0.0002,  0.0187, -0.0424,\n",
       "            0.0583,  0.0206, -0.0355, -0.0510,  0.0413, -0.0462,  0.0485, -0.0212,\n",
       "            0.0292,  0.0410,  0.0335, -0.0616,  0.0607,  0.0468, -0.0160, -0.0595,\n",
       "            0.0519,  0.0054, -0.0029, -0.0134, -0.0439,  0.0552,  0.0134, -0.0063,\n",
       "            0.0084,  0.0472,  0.0407, -0.0167, -0.0608, -0.0395, -0.0472,  0.0342]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.0369], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.7954,  0.6717,  0.3755,  ...,  0.2511, -0.0095, -0.4542],\n",
       "          [-0.0700, -0.1492, -0.0271,  ...,  0.0890, -0.1194, -0.1057],\n",
       "          [-1.0399, -0.5144,  0.3637,  ...,  0.6505, -0.0661, -0.5454],\n",
       "          ...,\n",
       "          [ 0.0496, -0.0059,  1.4255,  ..., -0.6402,  0.9795,  1.4849],\n",
       "          [ 1.4437,  0.0136,  0.3438,  ...,  0.9699, -0.6781, -0.8837],\n",
       "          [-1.0839,  0.5644, -0.3034,  ..., -0.2851,  2.9708, -0.2952]],\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.6761, -0.3424, -0.8475,  ...,  0.0735, -1.4540, -0.0297],\n",
       "          [ 2.7434, -1.6208, -0.6274,  ...,  0.9051, -0.1285, -0.7418],\n",
       "          [-0.2100, -0.5439, -0.2950,  ...,  2.7955,  2.5029, -1.2350],\n",
       "          ...,\n",
       "          [-0.5396, -1.4107,  1.9083,  ..., -0.6017,  0.0597, -0.0111],\n",
       "          [ 0.5127, -1.0575,  0.0893,  ...,  0.2109,  1.0535, -0.7887],\n",
       "          [-0.0538,  0.4492,  0.8469,  ..., -1.9734, -1.5246,  0.3950]],\n",
       "         requires_grad=True)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model_manager.lightning_model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "            callbacks=callbacks,\n",
    "            max_epochs=500,\n",
    "            accelerator='gpu',\n",
    "            logger=CSVLogger(save_dir='logs/', name='hetero_gnn_1'),\n",
    "            num_sanity_val_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs/hetero_gnn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca454acf333413596da08a2b2098f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.05754399373371567\n",
      "Restoring states from the checkpoint path at c:\\Users\\fardin\\Projects\\ColorIntelligence\\.lr_find_3639a14d-95d8-405f-bf29-6fc55c15dcab.ckpt\n",
      "Restored all states from the checkpoint at c:\\Users\\fardin\\Projects\\ColorIntelligence\\.lr_find_3639a14d-95d8-405f-bf29-6fc55c15dcab.ckpt\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(trainer)\n",
    "results = tuner.lr_find(lightning_model, datamodule=data_manager, min_lr=0.0000001,max_lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = results.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(trainer.model.optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | HeteroGcnGatModel1 | 1.8 M \n",
      "1 | loss_func | BCEWithLogitsLoss  | 0     \n",
      "2 | train_acc | BinaryAccuracy     | 0     \n",
      "3 | val_acc   | BinaryAccuracy     | 0     \n",
      "4 | test_acc  | BinaryAccuracy     | 0     \n",
      "-------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.281     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Missing folder: logs/HeteroGat1\\version_17.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 47\u001b[0m train_fn_result \u001b[39m=\u001b[39m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m train_fn_result\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    575\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    577\u001b[0m     ckpt_path,\n\u001b[0;32m    578\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m )\n\u001b[1;32m--> 581\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    583\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:973\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    971\u001b[0m     call\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 973\u001b[0m _log_hyperparams(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    975\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loggers\\utilities.py:95\u001b[0m, in \u001b[0;36m_log_hyperparams\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     94\u001b[0m logger\u001b[39m.\u001b[39mlog_graph(pl_module)\n\u001b[1;32m---> 95\u001b[0m logger\u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\fabric\\loggers\\csv_logs.py:149\u001b[0m, in \u001b[0;36mCSVLogger.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 149\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loggers\\csv_logs.py:64\u001b[0m, in \u001b[0;36mExperimentWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m hparams_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNAME_HPARAMS_FILE)\n\u001b[1;32m---> 64\u001b[0m save_hparams_to_yaml(hparams_file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams)\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\core\\saving.py:311\u001b[0m, in \u001b[0;36msave_hparams_to_yaml\u001b[1;34m(config_yaml, hparams, use_omegaconf)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_dir(fs, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(config_yaml)):\n\u001b[1;32m--> 311\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing folder: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(config_yaml)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    313\u001b[0m \u001b[39m# convert Namespace or AD to dict\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Missing folder: logs/HeteroGat1\\version_17.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\TestHeterogeneousGraphClassifier2.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/HeterogeneousGraphs/TestHeterogeneousGraphClassifier2.ipynb#Y212sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mlightning_model, datamodule\u001b[39m=\u001b[39;49mdata_manager)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    544\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    546\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    547\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:71\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mon_exception(exception)\n\u001b[0;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m logger \u001b[39min\u001b[39;00m trainer\u001b[39m.\u001b[39mloggers:\n\u001b[1;32m---> 71\u001b[0m     logger\u001b[39m.\u001b[39;49mfinalize(\u001b[39m\"\u001b[39;49m\u001b[39mfailed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     72\u001b[0m trainer\u001b[39m.\u001b[39m_teardown()\n\u001b[0;32m     73\u001b[0m \u001b[39m# teardown might access the stage so we reset it after\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\fabric\\loggers\\csv_logs.py:157\u001b[0m, in \u001b[0;36mCSVLogger.finalize\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experiment \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[39m# When using multiprocessing, finalize() should be a no-op on the main process, as no experiment has been\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     \u001b[39m# initialized there\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\fabric\\loggers\\csv_logs.py:149\u001b[0m, in \u001b[0;36mCSVLogger.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@rank_zero_only\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loggers\\csv_logs.py:64\u001b[0m, in \u001b[0;36mExperimentWriter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Save recorded hparams and metrics into files.\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m hparams_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNAME_HPARAMS_FILE)\n\u001b[1;32m---> 64\u001b[0m save_hparams_to_yaml(hparams_file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams)\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\core\\saving.py:311\u001b[0m, in \u001b[0;36msave_hparams_to_yaml\u001b[1;34m(config_yaml, hparams, use_omegaconf)\u001b[0m\n\u001b[0;32m    309\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(config_yaml)\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_dir(fs, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(config_yaml)):\n\u001b[1;32m--> 311\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing folder: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(config_yaml)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    313\u001b[0m \u001b[39m# convert Namespace or AD to dict\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(hparams, Namespace):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Missing folder: logs/HeteroGat1\\version_17."
     ]
    }
   ],
   "source": [
    "trainer.fit(model=lightning_model, datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/HeteroGat1\\\\version_17\\\\checkpoints\\\\epoch=10-step=2827.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os import path\n",
    "def plot_csv_logger(csv_path, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "    metrics = pd.read_csv(csv_path)\n",
    "\n",
    "    aggregation_metrics = []\n",
    "    agg_col = 'epoch'\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggregation_metrics.append(agg)\n",
    "\n",
    "    df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "    df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "    df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_csv_logger(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\logs\\HeteroGat1\\version_17\\metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
