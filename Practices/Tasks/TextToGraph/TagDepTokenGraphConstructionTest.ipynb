{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from Scripts.DataManager.GraphConstructor.TagDepTokenGraphConstructor import TagDepTokenGraphConstructor\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence')\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\Amazon-Review\\train_sm.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\Amazon-Review\\test_sm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['Polarity', 'Title', 'Review']\n",
    "test_df.columns = ['Polarity', 'Title', 'Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['Polarity', 'Review']]\n",
    "test_df = test_df[['Polarity', 'Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\TagDepTokenGraphConstructor.py:104: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  data['sentence'].x = torch.tensor(sentence_embeddings, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph_const = TagDepTokenGraphConstructor(train_df['Review'][:10], r'data\\GraphData\\Full-WSentence-WGeneral', config, lazy_construction=False, naming_prepend='graph', load_preprocessed_data=False, use_sentence_nodes=True, use_general_node=True , use_compression=True)\n",
    "graph_const.setup(load_preprocessed_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\GraphData\\Full-WSentence-WGeneral\\graph_var.txt\n",
      "data loading 0\n"
     ]
    }
   ],
   "source": [
    "graph_const.save_all_data_compressed()\n",
    "graph_const.load_all_data_comppressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66, 300])\n",
      "torch.Size([5, 300])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(graph_const.get_graph(8)['word'].x.shape)\n",
    "print(graph_const.get_graph(8)['sentence'].x.shape)\n",
    "print(graph_const.get_graph(8)['word', 'word_sentence', 'sentence'].edge_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
