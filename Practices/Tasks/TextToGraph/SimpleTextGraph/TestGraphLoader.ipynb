{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split, T_co\n",
    "from torch_geometric.data.lightning import LightningDataset\n",
    "import pdb\n",
    "import lightning as L\n",
    "import time\n",
    "from Scripts.DataManager.GraphConstructor.CoOccurrenceGraphConstructor import CoOccurrenceGraphConstructor\n",
    "from Scripts.DataManager.GraphLoader.GLabeledGraphLoader import GLabeledGraphLoader\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\Configs\\Config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\Amazon-Review\\train_sm.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\Amazon-Review\\test_sm.csv')\n",
    "train_df.columns = ['Polarity', 'Title', 'Review']\n",
    "test_df.columns = ['Polarity', 'Title', 'Review']\n",
    "train_df = train_df[['Polarity', 'Review']]\n",
    "test_df = test_df[['Polarity', 'Review']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\Configs\\Config.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time in second: 0.008000612258911133\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "graph_const = CoOccurrenceGraphConstructor(train_df['Review'], 'AmazonReview', config, lazy_construction=True,  load_preprocessed_data=True, naming_prepend='graph')\n",
    "print(f'execution time in second: {time.time() - start_time}')\n",
    "# graph_const = CoOccurrenceGraphConstructor(train_df['Review'][:10], 'AmazonReview', config, lazy_construction=False, naming_prepend='graph', load_preprocessed_data=False)\n",
    "# graph = graph_const.to_graph(train_df['Review'][0])\n",
    "# graph_const.draw_graph(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "labels = torch.tensor(test_df['Polarity'].apply(lambda p: 0 if p==1 else 1), dtype=torch.float32).view(-1,1)\n",
    "graph_loader = GLabeledGraphLoader(graph_const, labels[:10],2, 'cpu', val_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler, STEP_OUTPUT\n",
    "\n",
    "from torch_geometric.nn import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Scripts.Models.ModelsManager.ModelManager import ModelManager\n",
    "from Scripts.Models.ClassifierModels.GATGCNClassifierSimple import GNNClassifier\n",
    "from Scripts.DataManager.GraphLoader.NLabeledGraphLoader import NLabeledGraphLoader\n",
    "from Scripts.Utils.enums import Optimizer, LossType\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv, GCN2Conv, DenseGCNConv\n",
    "from torch_geometric.nn.dense.diff_pool import dense_diff_pool\n",
    "from torch_geometric.nn import Sequential as GSequential\n",
    "from torch import nn\n",
    "from torch_geometric.nn.dense.diff_pool import dense_diff_pool\n",
    "from torch_geometric.data import batch\n",
    "from torch_geometric.utils import to_dense_adj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import Linear\n",
    "\n",
    "\n",
    "class GraphAutoEncoderModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_feature: int, out_features: int, dropout=0.1, *args, **kwargs):\n",
    "        super(GraphAutoEncoderModel, self).__init__(*args, **kwargs)\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.encoder = GSequential('x, edge_index, edge_weights', [\n",
    "            (GCNConv(input_feature, 256), 'x, edge_index, edge_weights ->x1'),\n",
    "            (nn.ReLU(), 'x1->x1'),\n",
    "            (GCNConv(256, 128), 'x1, edge_index, edge_weights -> x2'),\n",
    "            (nn.ReLU(), 'x2->x2'),\n",
    "            (GCNConv(128, 64), 'x2, edge_index, edge_weights -> x3'),\n",
    "            (nn.ReLU(), 'x3->x3'),\n",
    "            (GCNConv(64, 32), 'x3, edge_index, edge_weights -> x3'),\n",
    "            (nn.ReLU(), 'x3->x3'),\n",
    "            (GATv2Conv(32, 32, 4, dropout=dropout), 'x3, edge_index ->x3'),\n",
    "            # (GATv2Conv(128, 64, 2, dropout=dropout), 'x2, edge_index->x2'),\n",
    "            (nn.ReLU(), 'x3->x3'),\n",
    "            (GCN2Conv(128, 0.5, 0.1, 2), 'x3, x2, edge_index, edge_weights->x3'),\n",
    "            (nn.ReLU(), 'x3->x3'),\n",
    "            (GCNConv(128, 256), 'x3, edge_index->x3'),\n",
    "            (nn.ReLU(), 'x3->x3'),\n",
    "            (GCN2Conv(256, 0.5, 0.1, 2), 'x3, x1, edge_index, edge_weights->x3'),\n",
    "            (nn.ReLU(), 'x3->x3')\n",
    "        ])\n",
    "\n",
    "        self.pooling_layer1 = GCNConv(256, 5)\n",
    "        self.pooling_layer2 = DenseGCNConv(256, 1)\n",
    "\n",
    "        # self.output_layer = GCNConv(256, self.num_out_features)\n",
    "        self.output_layer = Linear(256, self.num_out_features)\n",
    "\n",
    "    def forward(self, X):\n",
    "        ci = torch.tensor([X[i].x.shape[0] for i in range(len(X))], dtype=torch.int).cumsum(0, dtype=torch.int)\n",
    "        x1 = self.encoder(X.x, X.edge_index, X.edge_attr)\n",
    "        x2 = [x1[0 if i==0 else ci[i - 1]:ci[i]] for i in range(len(ci))]\n",
    "        x3 = torch.zeros((len(x2), 256), dtype = x1.dtype, device = x1.device)\n",
    "        for i in range(len(ci)):\n",
    "            s = self.pooling_layer1(x2[i], X[i].edge_index, X[i].edge_attr)\n",
    "            # adj = to_dense_adj(edge_index=data_batch[i].edge_index, edge_attr=data_batch[i].edge_attr)\n",
    "            adj = torch.sparse_coo_tensor(X[i].edge_index, X[i].edge_attr).to_dense()\n",
    "            nodes, adj, _, _ = dense_diff_pool(x2[i], adj, s=s)\n",
    "            s = self.pooling_layer2(nodes, adj)\n",
    "            nodes, _, _, _ = dense_diff_pool(nodes, adj, s=s)\n",
    "            x3[i] = torch.squeeze(nodes)\n",
    "\n",
    "        return self.output_layer(x3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_data_loader = graph_loader.get_train_data()\n",
    "X, y = next(iter(train_data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x000001E2199755A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 132, in __del__\n",
      "    self._close()\n",
      "  File \"C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 277, in _close\n",
      "    _CloseHandle(self._handle)\n",
      "OSError: [WinError 6] The handle is invalid\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 5.6575],\n        [13.2368]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_model = GraphAutoEncoderModel(300, 1)\n",
    "autoencoder_model(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "class LightningModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self, model, optimizer, loss_func):\n",
    "        super(LightningModel, self).__init__()\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        if model.num_out_features > 2:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "            self.test_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "        else:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "            self.test_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "\n",
    "\n",
    "    def forward(self, data_batch, *args, **kwargs):\n",
    "        return self.model(data_batch)\n",
    "\n",
    "    def training_step(self, data_batch, *args, **kwargs) :\n",
    "        data, labels = data_batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_func(logits, labels.view(logits.shape))\n",
    "        self.log('training_loss', loss)\n",
    "\n",
    "        predicted_labels = logits if logits.shape[1] < 2 else torch.argmax(logits, dim=1)\n",
    "        self.train_acc(predicted_labels, labels.view(predicted_labels.shape))\n",
    "        self.log('training_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, data_batch, *args, **kwargs):\n",
    "        data, labels = data_batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_func(logits, labels.view(logits.shape))\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        predicted_labels = logits if logits.shape[1] < 2 else torch.argmax(logits, dim=1)\n",
    "        self.val_acc(predicted_labels, labels.view(predicted_labels.shape))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "\n",
    "    # def test_step(self, data_batch, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "    #     data, labels = data_batch\n",
    "    #     pred_labels = self(data)\n",
    "    #     loss = self.loss_func(pred_labels, labels)\n",
    "    #     self.log('test_loss', loss)\n",
    "\n",
    "    def predict_step(self, data_batch, *args: Any, **kwargs: Any) -> Any:\n",
    "        data, labels = data_batch\n",
    "        return self(data)\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return self.optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "autoencoder_model = GraphAutoEncoderModel(300, 1)\n",
    "lightning_model = LightningModel(autoencoder_model,\n",
    "                                 torch.optim.Adam(autoencoder_model.parameters(), lr=0.001, weight_decay=0.005), nn.BCEWithLogitsLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | model     | GraphAutoEncoderModel | 245 K \n",
      "1 | loss_func | BCEWithLogitsLoss     | 0     \n",
      "2 | train_acc | BinaryAccuracy        | 0     \n",
      "3 | val_acc   | BinaryAccuracy        | 0     \n",
      "4 | test_acc  | BinaryAccuracy        | 0     \n",
      "----------------------------------------------------\n",
      "245 K     Trainable params\n",
      "0         Non-trainable params\n",
      "245 K     Total params\n",
      "0.983     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1de1b7e4cae4c38ae3ca276206c0685"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be278de2ca4a49aa88d8fb34f307b282"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85ab257ec90640118fd51e5b2fa7669c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21be0244ecc246dc936e0c30c61eb848"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e513d1d0774b1eb54d6fd983c7f702"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab36ef25b55448958f8ac55a0ff1cb58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b91b76e71ff4911ba694944b168e5a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d3efd9a4ce140f5b21ce00edf57ca34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99dfc95bf4df458b91c76f4849f313af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14bb062a571e4750acf2168dcc19aa0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6186f79fe9224e8ba2d94b21c0f8d8d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, num_sanity_val_steps=0)\n",
    "trainer.fit(lightning_model, graph_loader.get_train_data(), graph_loader.get_val_data())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "train_data = graph_loader.get_train_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "X, y = next(iter(train_data))\n",
    "module_0 = GCNConv(300, 256)\n",
    "output = module_0(X.x, X.edge_index, X.edge_attr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "output2 = [output[:X[0].x.shape[0]], output[X[0].x.shape[0]:X[1].x.shape[0]], output[X[1].x.shape[0]:X[2].x.shape[0]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "import torch_geometric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X is torch_geometric.data.batch.Batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "gcn_conv = GCNConv(256, 64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# s = gcn_conv(output2[0], X[0].edge_index)\n",
    "# adj = torch.sparse_coo_tensor(X[0].edge_index, X[0].edge_attr).to_dense()\n",
    "# output3 = dense_diff_pool(output2[0], adj, s=s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}