{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.AGGraphDataModule import AGGraphDataModule\n",
    "import time\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "# config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence')\n",
    "config = Config(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Creating Graphs :   0%|          | 0/127598 [00:00<?, ?it/s]e:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\TagDepTokenGraphConstructor.py:68: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  data['sentence'].x = torch.tensor(sentence_embeddings, dtype=torch.float32)\n",
      " Creating Graphs : 100%|██████████| 127598/127598 [2:50:17<00:00, 12.49it/s]   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph_type = TextGraphType.SENTIMENT\n",
    "removals = ['sentiment'] # Enter node types to remove here\n",
    "# removals = ['general'] # Without General Nodes\n",
    "# removals = ['dep'] # Without Dependency Nodes\n",
    "# removals = ['tag'] # Without Tag Nodes\n",
    "# removals = ['sentiment'] # Without Sentiment Nodes\n",
    "# removals = ['sentiment' , 'general'] # Without Sentiment and General Nodes\n",
    "data_manager = AGGraphDataModule(config, True, True, shuffle=False, start_data_load=0 , end_data_load = -1 , device='cpu', batch_size=batch_size, graph_type=graph_type, load_preprocessed_data = False)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_manager.update_batch_size(128)\n",
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.BaseModels.HeteroGat import HeteroGat\n",
    "from Scripts.Models.BaseModels.HeteroLinear import HeteroLinear\n",
    "from Scripts.Models.GraphNodeEmbedding.HeteroDeepGraphNodeEmbedding1 import HeteroDeepGraphNodeEmbedding1\n",
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding1 import HeteroDeepGraphEmbedding1\n",
    "from Scripts.Models.GraphEmbedding.HeteroMempool1 import HeteroMempool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import HeteroBinaryLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import HeteroLossArgs, HeteroLoss1, HeteroLoss2\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "graph_embedding = HeteroDeepGraphEmbedding1(300, 1, X1.metadata(), 128, dropout=0.2, edge_type_count=11)\n",
    "graph_embedding = graph_embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# lightning_model = HeteroBinaryLightningModel.load_from_checkpoint(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\logs\\hetero_model_5\\version_0\\checkpoints\\epoch=7-step=2056.ckpt', model=)\n",
    "\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True),\n",
    "#     EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "# ]\n",
    "lightning_model = HeteroBinaryLightningModel(graph_embedding,\n",
    "                                 torch.optim.Adam(graph_embedding.parameters(), lr=0.004, weight_decay=0.001),\n",
    "                                       loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.05),\n",
    "                                       learning_rate=0.004,\n",
    "                                       batch_size=batch_size,\n",
    "                                       user_lr_scheduler=True,\n",
    "                                       min_lr=0.00005\n",
    "                                       ).to(device)\n",
    "model_manager = ClassifierModelManager(graph_embedding, lightning_model, log_name='hetero_model_6', model_save_dir=r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\hetero_model_3',device=device, num_train_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_manager.tune(data_manager=data_manager, min_lr=1e-7, max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | model     | HeteroDeepGraphEmbedding1 | 2.2 M \n",
      "1 | loss_func | HeteroLoss1               | 0     \n",
      "2 | train_acc | BinaryAccuracy            | 0     \n",
      "3 | val_acc   | BinaryAccuracy            | 0     \n",
      "4 | test_acc  | BinaryAccuracy            | 0     \n",
      "--------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.829     Total estimated model params size (MB)\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (37) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 37/37 [00:17<00:00,  2.06it/s, v_num=15, train_acc_step=0.750, val_acc_step=1.000, val_acc_epoch=0.840, train_acc_epoch=0.764]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "model_manager.fit(datamodule=data_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "def evaluate(eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        model_manager.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            print(f\"ii: {X.edge_index_dict[('word', 'word_sentiment', 'sentiment')]}\")\n",
    "            y_p, _ = model_manager.torch_model(X.to(device))\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        print(f\"ii: {y_true.shape} : {y_pred.shape}\")\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3, y3 = next(iter(data_manager.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(data_manager.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.trainer.save_checkpoint(r'C:\\Users\\fardin\\Desktop\\Learning Parts 2\\part1\\deep_graph_embedding_1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = HeteroBinaryLightningModel.load_from_checkpoint(r'C:\\Users\\fardin\\Desktop\\Learning Parts 2\\part1\\deep_graph_embedding_1.ckpt', model=graph_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_manager.test_dataloader()\n",
    "x_t, y_t = next(iter(test_dataloader))\n",
    "len(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.eval()\n",
    "y_pred = custom_model(x_t.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = (y_pred[0]>0).to(torch.int)\n",
    "y_pred2 = y_pred2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_t, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_t, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
