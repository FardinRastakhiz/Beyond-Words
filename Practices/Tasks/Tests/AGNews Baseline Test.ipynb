{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omid Davar @2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "C:\\Users\\Omid\\AppData\\Local\\Temp\\ipykernel_3164\\3467580989.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  self.embeddings_tensor =  torch.tensor(torch.load(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\data\\AG\\embeddings.pt'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from spacy.lang.en import English\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "class MulticlassTextDataset(Dataset):\n",
    "        \n",
    "    def __init__(self , load_embeddings = True):\n",
    "        self.load_embeddings = load_embeddings\n",
    "        self.end_data_load = -1\n",
    "        self.start_data_load = 0\n",
    "        self.train_df = pd.read_csv(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\data\\AG\\train.csv')\n",
    "        self.test_df = pd.read_csv(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\data\\AG\\test.csv')\n",
    "        self.train_df.columns = ['Class', 'Title', 'Description']\n",
    "        self.test_df.columns = ['Class', 'Title', 'Description']\n",
    "        self.train_df['Description'] = self.train_df['Title'].astype(str) + ' ' +  self.train_df['Description'].astype(str)\n",
    "        self.test_df['Description'] = self.test_df['Title'].astype(str) + ' ' +  self.test_df['Description'].astype(str)\n",
    "        self.train_df = self.train_df[['Class', 'Description']]\n",
    "        self.test_df = self.test_df[['Class', 'Description']]\n",
    "        self.data = pd.concat([self.train_df, self.test_df])\n",
    "        self.end_data_load = self.end_data_load if self.end_data_load>0 else self.data.shape[0]\n",
    "        self.end_data_load = self.end_data_load if self.end_data_load < self.data.shape[0] else self.data.shape[0] \n",
    "        self.data = self.data.iloc[:self.end_data_load]\n",
    "        self.data.index = np.arange(0, self.end_data_load)\n",
    "        # activate one line below\n",
    "        self.data['Class'] -= 1\n",
    "        labels = self.data['Class'][self.start_data_load:self.end_data_load]\n",
    "        labels = labels.to_numpy()\n",
    "        labels = torch.from_numpy(labels)\n",
    "        \n",
    "        self.labels = torch.squeeze(labels.to(torch.float32).view(-1, 1).to('cpu') , 1)\n",
    "        if self.load_embeddings:\n",
    "            self.embeddings_tensor =  torch.tensor(torch.load(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\data\\AG\\embeddings.pt'))\n",
    "        else:\n",
    "            embeddings = []\n",
    "            for text in tqdm(self.data['Description'] , 'Creating Embeddings ...'):\n",
    "                doc = nlp(text)\n",
    "                embedding = doc.vector\n",
    "                embeddings.append(embedding)\n",
    "            torch.save(embeddings , r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\data\\AG\\embeddings.pt')\n",
    "            self.data['embedding'] = embeddings\n",
    "            self.embeddings_tensor = embeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.embeddings_tensor[idx], self.labels[idx]]\n",
    "\n",
    "\n",
    "class MulticlassSpacyClassifierModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MulticlassSpacyClassifierModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MulticlassSpacyTextClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim , batch_size=256):\n",
    "        super(MulticlassSpacyTextClassifier, self).__init__()\n",
    "        self.model = MulticlassSpacyClassifierModel(input_dim, hidden_dim, output_dim)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\" , num_classes=output_dim)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_dim)\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = self.model(x)\n",
    "        \n",
    "        y_pred = y_pred.float()\n",
    "        y = y.long()\n",
    "\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        self.train_acc(torch.squeeze(torch.argmax(y_pred, dim=1)), y)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = self.model(x)\n",
    "        # Cast the model outputs and target labels to the appropriate data types\n",
    "        y_pred = y_pred.float()  # Ensure y_pred is of type torch.float\n",
    "        y = y.long()  # Ensure y is of type torch.long\n",
    "        self.val_acc(torch.squeeze(torch.argmax(y_pred, dim=1)), y)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=True, batch_size=self.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "input_dim = 300  # SpaCy embeddings dimension\n",
    "hidden_dim = 100\n",
    "output_dim = 4 \n",
    "trainer = pl.Trainer(max_epochs=70)\n",
    "\n",
    "\n",
    "multiclass_dataset = MulticlassTextDataset()\n",
    "\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(multiclass_dataset))\n",
    "val_size = int(0.15 * len(multiclass_dataset))\n",
    "test_size = len(multiclass_dataset) - (train_size + val_size)\n",
    "train_dataset, val_dataset , test_dataset = torch.utils.data.random_split(multiclass_dataset, [train_size, val_size,test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256 , shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256 , shuffle=False)\n",
    "\n",
    "\n",
    "multiclass_model = MulticlassSpacyTextClassifier(input_dim, hidden_dim, output_dim , batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Scripts.Models.LightningModels.LightningModels import BaseLightningModel\n",
    "from Scripts.Models.ModelsManager.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model: BaseLightningModel,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        # df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        # loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        # plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.torch_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                    give_confusion_matrix: bool=True, \n",
    "                    give_report: bool=True, \n",
    "                    give_f1_score: bool=False, \n",
    "                    give_accuracy_score: bool=False, \n",
    "                    give_precision_score: bool=False, \n",
    "                    give_recall_score: bool=False, \n",
    "                    give_hinge_loss: bool=False,\n",
    "                    multi_class: bool=True\n",
    "                    ):\n",
    "            \n",
    "            test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "            \n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            self.lightning_model.eval()\n",
    "            self.lightning_model.model.eval()\n",
    "            self.torch_model.eval()\n",
    "            for X, y in eval_dataloader:\n",
    "                self.trainer.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_p = self.trainer.model(X.to(self.device))\n",
    "                if type(y_p) is tuple:\n",
    "                    y_p = y_p[0]\n",
    "                \n",
    "                if multi_class:\n",
    "                    y_pred.append(y_p.detach().to(y.device))\n",
    "                    y_true.append(y)\n",
    "                else:\n",
    "                    y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                    y_true.append(y.to(torch.int32))\n",
    "            y_true = torch.concat(y_true)\n",
    "            y_pred = torch.concat(y_pred)\n",
    "            if multi_class:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "            else:\n",
    "                y_true_num = y_true\n",
    "                y_pred_num = y_pred\n",
    "            with open(test_metrics_path, 'at+') as f:\n",
    "                if(give_confusion_matrix):\n",
    "                    print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_report):\n",
    "                    print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "                if(give_f1_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_accuracy_score):\n",
    "                    print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_precision_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_recall_score):\n",
    "                    if multi_class:\n",
    "                        print(f'f1_score: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                    else:\n",
    "                        print(f'f1_score: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "                if(give_hinge_loss):\n",
    "                    print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Restoring states from the checkpoint path at E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\logs\\hetero_model_11\\version_0\\checkpoints\\epoch=20-step=8379.ckpt\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:345: The dirpath has changed from 'logs/hetero_model_11\\\\version_0\\\\checkpoints' to 'logs/hetero_model_11\\\\version_1\\\\checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "\n",
      "  | Name      | Type                           | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model     | MulticlassSpacyClassifierModel | 30.5 K\n",
      "1 | loss_fn   | CrossEntropyLoss               | 0     \n",
      "2 | train_acc | MulticlassAccuracy             | 0     \n",
      "3 | val_acc   | MulticlassAccuracy             | 0     \n",
      "-------------------------------------------------------------\n",
      "30.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 K    Total params\n",
      "0.122     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\logs\\hetero_model_11\\version_0\\checkpoints\\epoch=20-step=8379.ckpt\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "model_manager = ClassifierModelManager(multiclass_model.model, multiclass_model, log_name='hetero_model_11', model_save_dir=r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\hetero_model_7',device='cpu', num_train_epoch=20)\n",
    "model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, ckpt_path=\"E:\\\\Darsi\\\\Payan Name Arshad\\\\Second Work\\\\ColorIntelligence2\\\\ColorIntelligence\\\\logs\\\\hetero_model_11\\\\version_0\\\\checkpoints\\\\epoch=20-step=8379.ckpt\")\n",
    "# model_manager.fit(train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.save_plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend='tests_baseline')\n",
    "model_manager.torch_model = model_manager.torch_model.to('cpu')\n",
    "model_manager.save_evaluation(test_dataloader, 'baseline',True, True, True, True, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6381"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
