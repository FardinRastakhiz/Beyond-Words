{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fardin Rastakhiz @2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.AmazonReviewGraphDataModule import AmazonReviewGraphDataModule\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: C:\\Users\\fardin\\Projects\\ColorIntelligence\\data/GraphData/AmazonReview\\sentiment\\graph_var.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Loding Graphs From File : 100%|██████████| 12/12 [02:07<00:00, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.shuffle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag_dep_seq_sent = TextGraphType.TAGS | TextGraphType.DEPENDENCY | TextGraphType.SEQUENTIAL | TextGraphType.SENTENCE | TextGraphType.SENTIMENT\n",
    "tag_dep_seq_sent = TextGraphType.SENTIMENT\n",
    "data_manager = AmazonReviewGraphDataModule(config, True, True, shuffle=False, start_data_load=0 , end_data_load = 12000, device='cpu', batch_size=batch_size, graph_type=tag_dep_seq_sent, load_preprocessed_data = True)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_manager.update_batch_size(128)\n",
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))\n",
    "# X1.metadata()\n",
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word'),\n",
       "  ('word', 'word_sentiment', 'sentiment'),\n",
       "  ('sentiment', 'sentiment_word', 'word')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, k: dep\n",
      "i: 1, k: tag\n",
      "i: 2, k: word\n",
      "i: 3, k: sentence\n",
      "i: 4, k: general\n",
      "i: 5, k: sentiment\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(X1.metadata()[0]):\n",
    "    print(f'i: {i}, k: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding3 import HeteroDeepGraphEmbedding3\n",
    "from Scripts.Models.LightningModels.LightningModels import HeteroBinaryLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import HeteroLossArgs, HeteroLoss1, HeteroLoss2\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import BatchNorm, MemPooling, to_hetero, PairNorm\n",
    "from torch_geometric.data import HeteroData\n",
    "from Scripts.Models.BaseModels.HeteroGat import HeteroGat\n",
    "from Scripts.Models.BaseModels.HeteroLinear import HeteroLinear\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class HeteroDeepGraphEmbedding3(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_feature: int, out_features: int,\n",
    "                 metadata,\n",
    "                 hidden_feature: int=256,\n",
    "                 device = 'cpu',\n",
    "                 dropout=0.1,\n",
    "                 edge_type_count=9,\n",
    "                 edge_type_weights=-1,\n",
    "                 pivot_node='word'\n",
    "                 ):\n",
    "\n",
    "        super(HeteroDeepGraphEmbedding3, self).__init__()\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.bsh: int = hidden_feature\n",
    "        self.edge_type_count = edge_type_count\n",
    "        self.metadata = metadata\n",
    "        self.pivot_node = pivot_node\n",
    "        self.edge_type_weights = [1] * self.edge_type_count if edge_type_weights==-1 else edge_type_weights\n",
    "\n",
    "        self.part_weight_norm = torch.nn.LayerNorm((self.edge_type_count,))\n",
    "        self.norm = PairNorm()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        self.hetero_linear_1 = to_hetero(HeteroLinear(input_feature, self.bsh, dropout), self.metadata)\n",
    "        \n",
    "        self.hetero_gat_1 = to_hetero(HeteroGat(self.bsh, self.bsh, dropout, num_heads=2), self.metadata)\n",
    "        self.hetero_gat_2 = to_hetero(HeteroGat(self.bsh, self.bsh, dropout, num_heads=2), self.metadata)\n",
    "        self.hetero_gat_3 = to_hetero(HeteroGat(self.bsh, self.bsh, dropout, num_heads=2), self.metadata)\n",
    "        \n",
    "        self.hetero_linear_2 = to_hetero(HeteroLinear(self.bsh, input_feature, dropout, use_batch_norm=True), self.metadata)\n",
    "        self.hetero_linear_3 = to_hetero(HeteroLinear(input_feature, input_feature, dropout, use_dropout=False), self.metadata)\n",
    "        \n",
    "        self.mem_pools = []\n",
    "        for i in range(len(self.metadata[0])):\n",
    "            self.mem_pools.append(MemPooling(self.bsh, self.bsh, 2, 1))\n",
    "        self.mem_pools = torch.nn.ModuleList(self.mem_pools)\n",
    "        \n",
    "        self.conv1 = GCNConv(self.bsh, self.bsh)\n",
    "        \n",
    "        self.mem_pool_2 = MemPooling(self.bsh, self.bsh, 2, 1)\n",
    "        \n",
    "        # self.linear_1_list = []\n",
    "        # for i in range(len(self.metadata[0])):\n",
    "        #     self.linear_1_list.append(Linear(self.num_out_features * self.bsh, self.bsh))\n",
    "        # self.linear_1_list = torch.nn.ModuleList(self.linear_1_list)\n",
    "        \n",
    "        \n",
    "        # self.type_aggregation = torch.nn.GRU()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linear_1 = Linear(self.bsh, self.bsh)\n",
    "        self.linear_2 = Linear(self.bsh, self.bsh)\n",
    "        self.linear_3 = Linear(self.bsh, 64)\n",
    "        self.batch_norm_1 = BatchNorm(64)\n",
    "        \n",
    "        self.output_layer = Linear(64, self.num_out_features)\n",
    "\n",
    "        self.dep_embedding = torch.nn.Embedding(45, self.input_features)\n",
    "        self.tag_embedding = torch.nn.Embedding(50, self.input_features)\n",
    "        self.dep_unembedding = torch.nn.Linear(self.input_features, 45)\n",
    "        self.tag_unembedding = torch.nn.Linear(self.input_features, 50)\n",
    "        \n",
    "        self.pw1 = torch.nn.Parameter(torch.tensor(self.edge_type_weights, dtype=torch.float32), requires_grad=False)\n",
    "        self.pw2 = torch.nn.Parameter(torch.tensor(self.edge_type_weights, dtype=torch.float32), requires_grad=False)\n",
    "        \n",
    "        self.node_types = {n for i, e in enumerate(metadata[1]) for n in {e[0], e[2]} if self.edge_type_weights[i]!=0}\n",
    "\n",
    "    def forward(self, x: HeteroData) -> Tensor:\n",
    "        x_dict, edge_attr_dict, edge_index_dict = self.preprocess_data(x)\n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw1)\n",
    "        \n",
    "        x_dict = self.hetero_linear_1(x_dict)\n",
    "        \n",
    "        x_dict = self.hetero_gat_1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "        \n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw2)\n",
    "        \n",
    "        x_dict = self.hetero_gat_2(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = self.normalize(x_dict, x)\n",
    "\n",
    "        x_dict = self.hetero_gat_3(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_pools = []\n",
    "        pivot_index=0\n",
    "        j = 0\n",
    "        for i, k in enumerate(self.metadata[0]):\n",
    "            if k in self.node_types:\n",
    "                x_pooled, S = self.mem_pools[i](x_dict[k], x[k].batch)\n",
    "                x_pooled = torch.unsqueeze(x_pooled.view(x_pooled.shape[0], -1), dim=1)\n",
    "                x_pools.append(x_pooled)\n",
    "                if k==self.pivot_node:\n",
    "                    pivot_index=j\n",
    "                j += 1\n",
    "        if len(x_pools) > 1:\n",
    "            x_pools = torch.concat(x_pools, dim=1) * (len(self.metadata[0]) * 1.0 / len(self.node_types))\n",
    "            aggr_graph = self.create_aggregated_graph(x_pools, pivot_index, self.pw1.device)\n",
    "            x_out = self.conv1(aggr_graph.x, aggr_graph.edge_index)\n",
    "            x_pooled, S = self.mem_pool_2(x_out, aggr_graph.batch)\n",
    "        else:\n",
    "            x_pooled = x_pools[0]\n",
    "            \n",
    "        x_pooled = x_pooled.view(x_pooled.shape[0], -1)\n",
    "                    \n",
    "        x_pooled = F.relu(self.linear_1(x_pooled))\n",
    "        x_pooled = F.relu(self.linear_2(x_pooled))\n",
    "        x_pooled = F.relu(self.linear_3(x_pooled))\n",
    "        x_pooled = F.relu(self.batch_norm_1(x_pooled))\n",
    "        out = self.output_layer(x_pooled)\n",
    "        x_dict = self.hetero_linear_2(x_dict)\n",
    "        x_dict = self.hetero_linear_3(x_dict)\n",
    "        x_dict['dep'] = self.dep_unembedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_unembedding(x_dict['tag'])\n",
    "        return out, x_dict\n",
    "\n",
    "    def preprocess_data(self, x):\n",
    "        x_dict = {key: x.x_dict[key] for key in x.x_dict}\n",
    "        x_dict['dep'] = self.dep_embedding(x_dict['dep'])\n",
    "        x_dict['tag'] = self.tag_embedding(x_dict['tag'])\n",
    "\n",
    "        edge_attr_dict = x.edge_attr_dict\n",
    "        edge_index_dict = x.edge_index_dict\n",
    "\n",
    "        shape1 = edge_index_dict[('sentence', 'sentence_word', 'word')].shape[1]\n",
    "        shape2 = edge_attr_dict[('word', 'word_sentence', 'sentence')].shape[0]\n",
    "        if shape1 != shape2:\n",
    "            edge_attr_dict[('sentence', 'sentence_word', 'word')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][shape1:shape2]\n",
    "            edge_attr_dict[('word', 'word_sentence', 'sentence')] = edge_attr_dict[('word', 'word_sentence', 'sentence')][:shape1]\n",
    "\n",
    "        # for key in x.edge_attr_dict:\n",
    "        #     edge_attr_dict[key] = self.get_scale_same(1.0, edge_attr_dict[key])\n",
    "\n",
    "        return x_dict, edge_attr_dict, edge_index_dict\n",
    "\n",
    "    def normalize(self, x_dict, x):\n",
    "        # for key in x_dict:\n",
    "        #     x_dict[key] = self.norm(x_dict[key], x[key].batch)\n",
    "        return x_dict\n",
    "\n",
    "    def update_weights(self, edge_attr_dict, part_weights):\n",
    "        # part_weights = 0.9 * self.part_weight_norm(part_weights) + 0.05\n",
    "        # part_weights = 0.9 * F.sigmoid(part_weights) + 0.05\n",
    "        for i, key in enumerate(edge_attr_dict):\n",
    "            edge_attr = edge_attr_dict[key]\n",
    "            if edge_attr is None or edge_attr == ('word', 'seq', 'word'):\n",
    "                continue\n",
    "            edge_attr_dict[key]= edge_attr * part_weights[i]\n",
    "        return edge_attr_dict\n",
    "\n",
    "    def get_scale_same(self, scale:float, attributes: Tensor):\n",
    "        if attributes is None or len(attributes) == 0:\n",
    "            return\n",
    "        attributes = scale * torch.ones_like(attributes)\n",
    "        return attributes\n",
    "    \n",
    "    def create_aggregated_graph(self, new_nodes: Tensor, pivot_index=0, device= 'cpu'):\n",
    "        edge_index = torch.tensor([[pivot_index, i] for i in range(new_nodes.shape[1]) if i!=pivot_index], device=device).T\n",
    "        data_list = []\n",
    "        for i in range(new_nodes.shape[0]):\n",
    "            data_graph = Data(x=new_nodes[i], edge_index=edge_index, device=device)\n",
    "            data_list.append(data_graph)\n",
    "        batch_graph = Batch.from_data_list(data_list)\n",
    "        return batch_graph\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.9664e-01],\n",
       "         [ 8.5578e-01],\n",
       "         [-1.7825e+00],\n",
       "         [-3.0153e-01],\n",
       "         [-5.8905e-01],\n",
       "         [ 6.2493e-01],\n",
       "         [ 2.8201e-01],\n",
       "         [ 8.3939e-01],\n",
       "         [-9.5669e-03],\n",
       "         [ 9.4852e-02],\n",
       "         [-5.3513e-01],\n",
       "         [ 6.1064e-03],\n",
       "         [ 9.2584e-02],\n",
       "         [ 1.1942e-01],\n",
       "         [ 8.1326e-02],\n",
       "         [ 2.1596e-01],\n",
       "         [ 2.1799e-01],\n",
       "         [-1.4275e-01],\n",
       "         [-1.4546e-01],\n",
       "         [-5.9504e-01],\n",
       "         [-8.1713e-01],\n",
       "         [ 1.7648e-01],\n",
       "         [-2.1912e-01],\n",
       "         [-5.0127e-01],\n",
       "         [-1.8200e-01],\n",
       "         [-8.9573e-02],\n",
       "         [ 1.3916e-02],\n",
       "         [ 3.5024e-01],\n",
       "         [-1.5335e+00],\n",
       "         [-8.4542e-02],\n",
       "         [-1.7846e-01],\n",
       "         [ 3.0782e-01],\n",
       "         [-7.2526e-01],\n",
       "         [-6.7935e-01],\n",
       "         [-6.4869e-01],\n",
       "         [-4.3277e-01],\n",
       "         [-3.4739e-02],\n",
       "         [-3.8318e-02],\n",
       "         [-1.4576e-01],\n",
       "         [-3.6043e-02],\n",
       "         [-1.0770e-02],\n",
       "         [ 1.3541e-01],\n",
       "         [-1.2356e-01],\n",
       "         [ 1.4111e-01],\n",
       "         [-1.5936e-02],\n",
       "         [ 4.8689e-02],\n",
       "         [ 3.7665e-03],\n",
       "         [ 3.7218e-01],\n",
       "         [-7.0073e-01],\n",
       "         [-1.1346e-01],\n",
       "         [-1.0936e+00],\n",
       "         [-1.7737e-01],\n",
       "         [-1.9216e-02],\n",
       "         [-3.5345e-01],\n",
       "         [-4.1455e-01],\n",
       "         [ 1.7029e-02],\n",
       "         [ 1.5751e-01],\n",
       "         [ 2.2202e-01],\n",
       "         [ 9.4840e-03],\n",
       "         [ 2.1041e-01],\n",
       "         [ 2.1406e-02],\n",
       "         [-1.3827e-01],\n",
       "         [ 8.9597e-02],\n",
       "         [-1.1739e-02],\n",
       "         [-3.9173e-01],\n",
       "         [-1.0636e-01],\n",
       "         [-7.0546e-02],\n",
       "         [-1.2928e-01],\n",
       "         [ 9.7392e-02],\n",
       "         [ 1.8404e-03],\n",
       "         [ 5.2166e-02],\n",
       "         [-5.3252e-02],\n",
       "         [-2.8443e-01],\n",
       "         [ 2.3199e-01],\n",
       "         [-1.1632e-01],\n",
       "         [-6.7745e-01],\n",
       "         [-1.0040e-02],\n",
       "         [-3.8374e-02],\n",
       "         [-2.1092e-02],\n",
       "         [-1.8583e-01],\n",
       "         [ 9.9259e-02],\n",
       "         [-1.7236e-01],\n",
       "         [ 2.7292e-01],\n",
       "         [-1.4902e-01],\n",
       "         [-2.1234e-01],\n",
       "         [ 4.4837e-02],\n",
       "         [-1.9648e-03],\n",
       "         [-1.3156e-01],\n",
       "         [ 1.4847e-01],\n",
       "         [ 6.2468e-02],\n",
       "         [-5.7839e-01],\n",
       "         [ 7.4541e-01],\n",
       "         [ 2.6403e-01],\n",
       "         [ 2.8034e-03],\n",
       "         [ 2.8592e-02],\n",
       "         [-5.2418e-01],\n",
       "         [ 3.9294e-02],\n",
       "         [-2.3293e-01],\n",
       "         [ 3.5821e-03],\n",
       "         [ 1.8946e-02],\n",
       "         [-2.5250e-01],\n",
       "         [ 1.8934e-02],\n",
       "         [ 5.5784e-02],\n",
       "         [ 2.1654e-01],\n",
       "         [ 1.6985e-01],\n",
       "         [-1.9599e-01],\n",
       "         [-3.1092e-02],\n",
       "         [ 2.7695e-01],\n",
       "         [ 5.5474e-04],\n",
       "         [-5.0604e-01],\n",
       "         [ 1.4009e-02],\n",
       "         [-8.6989e-02],\n",
       "         [-2.4179e-02],\n",
       "         [ 2.1194e-02],\n",
       "         [ 7.4832e-03],\n",
       "         [ 2.3560e-01],\n",
       "         [-1.5904e+00],\n",
       "         [-1.6145e-01],\n",
       "         [-1.4993e-01],\n",
       "         [-2.0812e-01],\n",
       "         [ 1.2301e-01],\n",
       "         [ 2.0475e-01],\n",
       "         [-3.8368e-01],\n",
       "         [-4.6446e-02],\n",
       "         [-2.7562e-01],\n",
       "         [ 5.1715e-01],\n",
       "         [ 1.4734e-01],\n",
       "         [-3.1704e-01],\n",
       "         [ 1.5397e-01],\n",
       "         [-1.4492e-01],\n",
       "         [ 4.2901e-02],\n",
       "         [-1.1387e+00],\n",
       "         [-2.2244e-01],\n",
       "         [-3.4602e-01],\n",
       "         [ 6.8285e-03],\n",
       "         [ 3.5371e-02],\n",
       "         [-1.0351e+00],\n",
       "         [-1.7141e-01],\n",
       "         [ 1.7653e-01],\n",
       "         [ 2.3766e-01],\n",
       "         [ 5.5516e-02],\n",
       "         [-3.8369e-01],\n",
       "         [ 1.1493e-01],\n",
       "         [-3.9132e-01],\n",
       "         [-9.3435e-02],\n",
       "         [-1.9384e-01],\n",
       "         [ 5.7921e-02],\n",
       "         [ 2.1674e-02],\n",
       "         [-4.1643e-02],\n",
       "         [ 1.8970e-02],\n",
       "         [-3.2013e-01],\n",
       "         [-8.5076e-02],\n",
       "         [-1.5762e-01],\n",
       "         [-2.2011e-01],\n",
       "         [ 1.3521e-02],\n",
       "         [ 3.5194e-01],\n",
       "         [-1.5782e-01],\n",
       "         [ 4.5853e-01],\n",
       "         [-1.7666e-01],\n",
       "         [-2.1894e-01],\n",
       "         [-2.0849e-01],\n",
       "         [ 6.9856e-02],\n",
       "         [-6.6545e-02],\n",
       "         [-7.7548e-02],\n",
       "         [ 6.0265e-01],\n",
       "         [ 4.3925e-02],\n",
       "         [ 2.0158e-02],\n",
       "         [ 2.7119e-03],\n",
       "         [ 1.8654e-01],\n",
       "         [-1.4061e-01],\n",
       "         [-2.6344e-03],\n",
       "         [-5.0162e-01],\n",
       "         [ 3.2680e-01],\n",
       "         [ 4.8591e-02],\n",
       "         [-1.3220e-01],\n",
       "         [ 7.6253e-02],\n",
       "         [-1.4898e-01],\n",
       "         [-1.4613e-01],\n",
       "         [ 5.0526e-02],\n",
       "         [-2.6556e-01],\n",
       "         [-5.5892e-02],\n",
       "         [-7.7290e-02],\n",
       "         [ 2.0030e-01],\n",
       "         [-5.8446e-01],\n",
       "         [-3.3892e-01],\n",
       "         [-6.2985e-01],\n",
       "         [ 9.7711e-03],\n",
       "         [-2.6935e-03],\n",
       "         [ 4.5702e-01],\n",
       "         [-1.5576e-01],\n",
       "         [-4.0921e-01],\n",
       "         [-6.5207e-01],\n",
       "         [-4.4535e-01],\n",
       "         [-1.0032e-01],\n",
       "         [-7.6221e-04],\n",
       "         [-4.1329e-01],\n",
       "         [-4.3166e-01],\n",
       "         [-1.6244e-01],\n",
       "         [-1.5654e-01],\n",
       "         [-8.4894e-02],\n",
       "         [-7.6611e-02],\n",
       "         [-7.1965e-02],\n",
       "         [-3.8044e-02],\n",
       "         [ 1.9492e-02],\n",
       "         [-5.9273e-02],\n",
       "         [ 4.9568e-02],\n",
       "         [-3.4349e-01],\n",
       "         [ 2.7505e-01],\n",
       "         [-4.3726e-03],\n",
       "         [ 1.4601e-01],\n",
       "         [ 3.8512e-02],\n",
       "         [ 2.6717e-02],\n",
       "         [ 2.8499e-01],\n",
       "         [-2.8165e-01],\n",
       "         [-2.2710e-02],\n",
       "         [ 2.5705e-01],\n",
       "         [ 2.3065e-02],\n",
       "         [ 1.3974e-01],\n",
       "         [-8.0583e-01],\n",
       "         [ 1.7505e-01],\n",
       "         [-4.1091e-01],\n",
       "         [-3.9813e-02],\n",
       "         [-1.9812e-01],\n",
       "         [ 4.6468e-02],\n",
       "         [-1.5289e-01],\n",
       "         [-5.2968e-03],\n",
       "         [-1.1865e+00],\n",
       "         [-4.0032e-02],\n",
       "         [-1.3296e+00],\n",
       "         [-9.9515e-03],\n",
       "         [ 1.5207e-01],\n",
       "         [-2.8853e-01],\n",
       "         [ 2.1858e-01],\n",
       "         [-2.8454e-01],\n",
       "         [ 2.6268e-01],\n",
       "         [-9.2109e-02],\n",
       "         [-5.0311e-02],\n",
       "         [ 3.0471e-01],\n",
       "         [-1.4155e+00],\n",
       "         [ 1.9662e-01],\n",
       "         [-3.9548e-01],\n",
       "         [ 2.9922e-01],\n",
       "         [-5.1857e-02],\n",
       "         [-7.2962e-01],\n",
       "         [-3.0637e-01],\n",
       "         [-8.5439e-02],\n",
       "         [-8.3862e-01],\n",
       "         [ 1.0351e-01],\n",
       "         [-3.8799e+00],\n",
       "         [-1.0737e-02],\n",
       "         [-1.9485e-02],\n",
       "         [-8.2552e-03],\n",
       "         [-5.7781e-01],\n",
       "         [ 4.2979e-02],\n",
       "         [-5.2966e-01],\n",
       "         [-7.0169e-01]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " {'dep': tensor([[ 0.1405, -0.0886,  0.1670,  ...,  0.1041,  0.1722,  0.0587],\n",
       "          [ 0.0425,  0.0194,  0.1145,  ...,  0.2315,  0.2228, -0.0155],\n",
       "          [ 0.1688, -0.2137,  0.3037,  ...,  0.0404,  0.2234, -0.0374],\n",
       "          ...,\n",
       "          [ 0.0328, -0.1134,  0.1315,  ...,  0.1191,  0.1254, -0.0258],\n",
       "          [ 0.0666, -0.0461,  0.1101,  ...,  0.1084,  0.0941,  0.0397],\n",
       "          [ 0.1029, -0.0865,  0.1014,  ...,  0.0801,  0.0973,  0.0533]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       "  'tag': tensor([[-0.0411,  0.1769,  0.1012,  ...,  0.0107,  0.0139,  0.0640],\n",
       "          [ 0.6265,  0.5355,  0.3978,  ...,  0.1893, -0.1830,  0.6107],\n",
       "          [ 0.5103,  0.3197,  0.0328,  ...,  0.1307,  0.3874,  0.1940],\n",
       "          ...,\n",
       "          [ 0.0544,  0.1108,  0.1142,  ..., -0.0401,  0.0588,  0.0852],\n",
       "          [ 0.0097,  0.1077,  0.0431,  ..., -0.0081, -0.0131,  0.1553],\n",
       "          [ 0.0398,  0.0740,  0.0110,  ..., -0.0466,  0.0892,  0.1004]],\n",
       "         device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       "  'word': tensor([[-2.3582e-03,  1.8048e-01, -3.3969e-03,  ...,  6.5171e-01,\n",
       "           -8.2822e-03,  4.6295e-01],\n",
       "          [ 1.6076e-01, -4.8907e-03,  3.7190e-01,  ...,  3.2247e-01,\n",
       "           -1.1771e-02, -3.0664e-03],\n",
       "          [ 2.3382e-02,  2.8477e-01, -3.0225e-03,  ..., -1.4473e-03,\n",
       "            1.4443e-01, -1.0445e-03],\n",
       "          ...,\n",
       "          [-1.9589e-03,  2.6028e-01,  1.0335e-01,  ...,  5.9052e-01,\n",
       "           -4.3640e-03, -6.9500e-03],\n",
       "          [-2.0919e-04,  3.7973e-01, -1.6137e-03,  ...,  8.0048e-01,\n",
       "           -1.1641e-02,  7.2179e-01],\n",
       "          [ 3.2420e-01, -1.1717e-03, -3.6783e-03,  ...,  5.4834e-01,\n",
       "           -3.4083e-03, -5.4498e-03]], device='cuda:0',\n",
       "         grad_fn=<LeakyReluBackward0>),\n",
       "  'sentence': tensor([[-6.5653e-03, -2.4195e-03, -1.2421e-03,  ...,  8.3655e-01,\n",
       "           -6.9747e-03, -3.2724e-03],\n",
       "          [-5.5636e-04, -3.0748e-03, -4.1202e-03,  ...,  2.1636e-01,\n",
       "           -2.7732e-03,  1.7386e-01],\n",
       "          [-2.8675e-03, -3.5754e-03, -4.0700e-03,  ...,  2.5092e-01,\n",
       "           -6.9397e-03, -4.2752e-04],\n",
       "          ...,\n",
       "          [-6.8989e-03,  1.0460e+00, -3.1725e-03,  ...,  1.1232e+00,\n",
       "           -9.2190e-03,  9.3686e-01],\n",
       "          [ 1.3751e-03,  4.1023e-01,  1.5838e-01,  ...,  6.1098e-01,\n",
       "           -1.0170e-03,  4.0677e-01],\n",
       "          [ 7.2843e-02,  7.9442e-01, -6.0849e-03,  ...,  9.3227e-01,\n",
       "           -1.1006e-02,  8.1607e-01]], device='cuda:0',\n",
       "         grad_fn=<LeakyReluBackward0>),\n",
       "  'general': tensor([[ 3.2218e-01,  1.0012e-02,  3.5981e-01,  ..., -1.1487e-03,\n",
       "           -1.0981e-03,  3.2776e-01],\n",
       "          [-2.6188e-03, -5.5680e-03, -9.1288e-04,  ...,  3.1314e-01,\n",
       "            4.9791e-01,  2.5611e-01],\n",
       "          [ 1.6464e-01, -1.4265e-03, -6.0450e-03,  ..., -6.0795e-03,\n",
       "           -3.9423e-03,  3.6292e-01],\n",
       "          ...,\n",
       "          [ 3.4662e-01, -3.7786e-03,  7.4507e-02,  ...,  3.6231e-01,\n",
       "            5.2970e-02, -9.4764e-05],\n",
       "          [ 2.2777e-02,  1.3766e-01,  8.3634e-02,  ..., -8.4768e-05,\n",
       "            1.2095e-01,  7.2772e-01],\n",
       "          [ 4.4165e-01,  1.8231e-01, -3.6840e-03,  ...,  4.0192e-01,\n",
       "           -7.0755e-03,  2.3723e-01]], device='cuda:0',\n",
       "         grad_fn=<LeakyReluBackward0>),\n",
       "  'sentiment': tensor([[ 2.7847e-01, -8.7072e-04,  1.2549e+00,  ..., -1.5988e-03,\n",
       "            9.4314e-01, -1.6170e-03],\n",
       "          [ 6.2960e-03, -4.2340e-04,  9.3364e-02,  ...,  1.2788e-01,\n",
       "           -3.2469e-04,  5.4063e-02],\n",
       "          [ 2.7197e-02,  6.0030e-01,  4.1695e-01,  ...,  9.1363e-02,\n",
       "           -3.8367e-04,  2.4688e-01],\n",
       "          ...,\n",
       "          [-2.0846e-03,  2.8089e-01, -2.9293e-03,  ...,  4.7679e-01,\n",
       "           -2.9146e-03,  1.1189e+00],\n",
       "          [ 3.7258e-02,  1.4778e-01,  8.9381e-01,  ...,  2.9599e-01,\n",
       "           -1.2299e-03,  2.8662e-01],\n",
       "          [-5.3768e-03, -1.4207e-03,  5.3062e-02,  ...,  3.7424e-02,\n",
       "            2.1184e-02,  3.8106e-01]], device='cuda:0',\n",
       "         grad_fn=<LeakyReluBackward0>)})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_embedding = HeteroDeepGraphEmbedding3(300, 1, X1.metadata(), 128, dropout=0.2, edge_type_count=11, edge_type_weights=[1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]).to(device)\n",
    "graph_embedding(X1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 128])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randn((7,256, 128))[:,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_weights = {\n",
    "    'seq': [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'full': [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "    'dep': [1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'tag': [0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'general_sentence': [0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
    "    'sentence': [0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
    "    'sentiment': [0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dep', 'general', 'sentence', 'sentiment', 'tag', 'word'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{n for i, e in enumerate(X1.metadata()[1]) for n in {e[0], e[2]} if edge_type_weights['full'][i]!=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | model     | HeteroDeepGraphEmbedding3 | 2.3 M \n",
      "1 | loss_func | HeteroLoss1               | 0     \n",
      "2 | train_acc | BinaryAccuracy            | 0     \n",
      "3 | val_acc   | BinaryAccuracy            | 0     \n",
      "4 | test_acc  | BinaryAccuracy            | 0     \n",
      "--------------------------------------------------------\n",
      "2.3 M     Trainable params\n",
      "22        Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.393     Total estimated model params size (MB)\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f1625155c64557b9b3ebbacd0b1e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:58: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/hetero_model_8\\\\version_13\\\\metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\Tests\\3_SentimentClassificationOnAmazonReview3.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/Tests/3_SentimentClassificationOnAmazonReview3.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model_manager \u001b[39m=\u001b[39m ClassifierModelManager(graph_embedding, lightning_model, log_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhetero_model_8\u001b[39m\u001b[39m'\u001b[39m, model_save_dir\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mfardin\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mProjects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mColorIntelligence\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPractices\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTasks\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mHeterogeneousGraphs\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mhetero_model_8\u001b[39m\u001b[39m'\u001b[39m,device\u001b[39m=\u001b[39mdevice, num_train_epoch\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/Tests/3_SentimentClassificationOnAmazonReview3.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model_manager\u001b[39m.\u001b[39mfit(datamodule\u001b[39m=\u001b[39mdata_manager)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/Tests/3_SentimentClassificationOnAmazonReview3.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model_manager\u001b[39m.\u001b[39;49msave_plot_csv_logger(loss_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain_loss\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m], eval_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain_acc_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mval_acc_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m], name_prepend\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtests_\u001b[39;49m\u001b[39m{\u001b[39;49;00mk\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/Tests/3_SentimentClassificationOnAmazonReview3.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model_manager\u001b[39m.\u001b[39mtorch_model \u001b[39m=\u001b[39m model_manager\u001b[39m.\u001b[39mtorch_model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fardin/Projects/ColorIntelligence/Practices/Tasks/Tests/3_SentimentClassificationOnAmazonReview3.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model_manager\u001b[39m.\u001b[39msave_evaluation(data_manager\u001b[39m.\u001b[39mtest_dataloader(), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\Models\\ModelsManager\\ClassifierModelManager.py:55\u001b[0m, in \u001b[0;36mClassifierModelManager.save_plot_csv_logger\u001b[1;34m(self, loss_names, eval_names, name_prepend)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_plot_csv_logger\u001b[39m(\u001b[39mself\u001b[39m, loss_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], eval_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m], name_prepend: \u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     54\u001b[0m     csv_path \u001b[39m=\u001b[39m path\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_name, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mversion_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mversion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmetrics.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv_path)\n\u001b[0;32m     57\u001b[0m     aggregation_metrics \u001b[39m=\u001b[39m []\n\u001b[0;32m     58\u001b[0m     agg_col \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/hetero_model_8\\\\version_13\\\\metrics.csv'"
     ]
    }
   ],
   "source": [
    "for k in edge_type_weights:\n",
    "    graph_embedding = HeteroDeepGraphEmbedding3(300, 1, X1.metadata(), 128, dropout=0.2, edge_type_count=11, edge_type_weights=edge_type_weights[k])\n",
    "    graph_embedding = graph_embedding.to(device)\n",
    "    callbacks = [\n",
    "    ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True)\n",
    "    ]\n",
    "    lightning_model = HeteroBinaryLightningModel(graph_embedding,\n",
    "                                    torch.optim.Adam(graph_embedding.parameters(), lr=0.0045, weight_decay=0.001),\n",
    "                                        loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.005),\n",
    "                                        learning_rate=0.0045,\n",
    "                                        batch_size=batch_size,\n",
    "                                        user_lr_scheduler=True,\n",
    "                                        min_lr=0.0003\n",
    "                                        ).to(device)\n",
    "    model_manager = ClassifierModelManager(graph_embedding, lightning_model, log_name='hetero_model_8', model_save_dir=r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\hetero_model_8',device=device, num_train_epoch=30)\n",
    "    model_manager.fit(datamodule=data_manager)\n",
    "    model_manager.save_plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{k}')\n",
    "    model_manager.torch_model = model_manager.torch_model.to('cuda')\n",
    "    model_manager.save_evaluation(data_manager.test_dataloader(), f'{k}',True, True, True, True, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
