{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sentiment Classification\n",
    "### On Amazon-Review, Full Heterogeneous Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.YelpGraphDataModule import YelpGraphDataModule\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = 'cuda'\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Loding Graphs From File :   0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m data_manager \u001b[38;5;241m=\u001b[39m YelpGraphDataModule(config, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, start_data_load\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m , end_data_load \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, graph_type\u001b[38;5;241m=\u001b[39mtag_dep_seq_sent, load_preprocessed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m data_manager\u001b[38;5;241m.\u001b[39mload_labels()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdata_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphLoader\\YelpGraphDataModule.py:85\u001b[0m, in \u001b[0;36mYelpGraphDataModule.load_graphs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__train_dataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__test_dataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__val_dataloader \u001b[38;5;241m=\u001b[39m {}, {}, {}\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_constructors:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_constructors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_preprocessed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# reweighting\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreweights:\n",
      "File \u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\GraphConstructor.py:72\u001b[0m, in \u001b[0;36mGraphConstructor.setup\u001b[1;34m(self, load_preprocessed_data)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_preprocessed_data:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# self.load_var()\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_data_load , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_data_load , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaving_batch_size), desc \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Loding Graphs From File \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 72\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# save the content\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     save_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_data_load\n",
      "File \u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\GraphConstructor.py:187\u001b[0m, in \u001b[0;36mGraphConstructor.load_data_range\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m    185\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_data_load] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_loaded_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\SentimentGraphConstructor.py:79\u001b[0m, in \u001b[0;36mSentimentGraphConstructor.prepare_loaded_data\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_loaded_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph):\n\u001b[1;32m---> 79\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSentimentGraphConstructor\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_loaded_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     graph[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_initial_sentiment_vector()\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39medge_types:\n",
      "File \u001b[1;32me:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Scripts\\DataManager\\GraphConstructor\\TagDepTokenGraphConstructor.py:207\u001b[0m, in \u001b[0;36mTagDepTokenGraphConstructor.prepare_loaded_data\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_loaded_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph):\n\u001b[1;32m--> 207\u001b[0m     words \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[43mgraph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mx) , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mvectors_length), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(graph[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx)):\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m graph[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx[i] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mvectors:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# tag_dep_seq_sent = TextGraphType.TAGS | TextGraphType.DEPENDENCY | TextGraphType.SEQUENTIAL | TextGraphType.SENTENCE | TextGraphType.SENTIMENT\n",
    "tag_dep_seq_sent = TextGraphType.SENTIMENT\n",
    "removals = []\n",
    "data_manager = YelpGraphDataModule(config, True, True, shuffle=False, start_data_load=0 , end_data_load = 1000, device='cpu', batch_size=batch_size, graph_type=tag_dep_seq_sent, load_preprocessed_data = True)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_manager.update_batch_size(128)\n",
    "t_dataloader = data_manager.train_dataloader()\n",
    "v_dataloader = data_manager.val_dataloader()\n",
    "X1, y1 = next(iter(t_dataloader))\n",
    "X2, y2 = next(iter(v_dataloader))\n",
    "# X1.metadata()\n",
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import HeteroBinaryLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import HeteroLossArgs, HeteroLoss1, HeteroLoss2\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word'),\n",
       "  ('word', 'word_sentiment', 'sentiment'),\n",
       "  ('sentiment', 'sentiment_word', 'word')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_weights = {\n",
    "    'full': [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "    'seq': [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'dep': [1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'tag': [0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "    'general_sentence': [0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
    "    'sentence': [0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
    "    'sentiment': [0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding2 import HeteroDeepGraphEmbedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Scripts.Models.LightningModels.LightningModels import BaseLightningModel\n",
    "from Scripts.Models.ModelsManager.ModelManager import ModelManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from torch_geometric.nn import summary\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from os import path\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "\n",
    "class ClassifierModelManager(ModelManager):\n",
    "\n",
    "    def __init__(self,\n",
    "                 torch_model: torch.nn.Module,\n",
    "                 lightning_model: BaseLightningModel,\n",
    "                 model_save_dir: str = '~/Desktop',\n",
    "                 log_dir: str = 'logs/',\n",
    "                 log_name: str = 'model_logs',\n",
    "                 device='cpu',\n",
    "                 num_train_epoch = 100):\n",
    "        super(ClassifierModelManager, self).__init__(torch_model, lightning_model, model_save_dir, log_dir, log_name, device, num_train_epoch)\n",
    "\n",
    "    def _create_callbacks(self) -> List[Callback]:\n",
    "        return [\n",
    "            ModelCheckpoint(save_top_k=2, mode='max', monitor='val_acc', save_last=True),\n",
    "            # EarlyStopping(patience=50, mode='max', monitor='val_acc')\n",
    "        ]\n",
    "\n",
    "    def draw_summary(self, dataloader):\n",
    "        X, y = next(iter(dataloader))\n",
    "        print(summary(self.torch_model, X.to(self.device)))\n",
    "\n",
    "    def plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc']):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plot_csv_logger(self, loss_names=['train_loss', 'val_loss'], eval_names=['train_acc', 'val_acc'], name_prepend: str=\"\"):\n",
    "        csv_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', 'metrics.csv')\n",
    "        metrics = pd.read_csv(csv_path)\n",
    "\n",
    "        aggregation_metrics = []\n",
    "        agg_col = 'epoch'\n",
    "        for i, dfg in metrics.groupby(agg_col):\n",
    "            agg = dict(dfg.mean())\n",
    "            agg[agg_col] = i\n",
    "            aggregation_metrics.append(agg)\n",
    "\n",
    "        df_metrics = pd.DataFrame(aggregation_metrics)\n",
    "        df_metrics[loss_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='loss')\n",
    "        \n",
    "        loss_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_loss_metric.png')\n",
    "        plt.savefig(loss_png)\n",
    "        \n",
    "        df_metrics[eval_names].plot(grid=True, legend=True, xlabel='Epoch', ylabel='accuracy')\n",
    "        \n",
    "        acc_png = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_acc_metric.png')\n",
    "        plt.savefig(acc_png)\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self, eval_dataloader,\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.torch_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        if(give_confusion_matrix):\n",
    "            print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}')\n",
    "        if(give_report):\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        if(give_f1_score):\n",
    "            print(f'f1_score: {f1_score(y_true, y_pred)}')\n",
    "        if(give_accuracy_score):\n",
    "            print(f'accuracy_score: {accuracy_score(y_true, y_pred)}')\n",
    "        if(give_precision_score):\n",
    "            print(f'precision_score: {precision_score(y_true, y_pred)}')\n",
    "        if(give_recall_score):\n",
    "            print(f'recall_score: {recall_score(y_true, y_pred)}')\n",
    "        if(give_hinge_loss):\n",
    "            print(f'hinge_loss: {hinge_loss(y_true, y_pred)}')\n",
    "                \n",
    "    def save_evaluation(self, eval_dataloader, name_prepend: str='',\n",
    "                 give_confusion_matrix: bool=True, \n",
    "                 give_report: bool=True, \n",
    "                 give_f1_score: bool=False, \n",
    "                 give_accuracy_score: bool=False, \n",
    "                 give_precision_score: bool=False, \n",
    "                 give_recall_score: bool=False, \n",
    "                 give_hinge_loss: bool=False):\n",
    "        \n",
    "        test_metrics_path = path.join(self.log_dir, self.log_name, f'version_{self.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "        \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        self.lightning_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            y_p = self.torch_model(X.to(self.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "            y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "            y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        with open(test_metrics_path, 'at+') as f:\n",
    "            if(give_confusion_matrix):\n",
    "                print(f'confusion_matrix: \\n{confusion_matrix(y_true, y_pred)}', file=f)\n",
    "            if(give_report):\n",
    "                print(classification_report(y_true, y_pred), file=f)\n",
    "            if(give_f1_score):\n",
    "                print(f'f1_score: {f1_score(y_true, y_pred)}', file=f)\n",
    "            if(give_accuracy_score):\n",
    "                print(f'accuracy_score: {accuracy_score(y_true, y_pred)}', file=f)\n",
    "            if(give_precision_score):\n",
    "                print(f'precision_score: {precision_score(y_true, y_pred)}', file=f)\n",
    "            if(give_recall_score):\n",
    "                print(f'recall_score: {recall_score(y_true, y_pred)}', file=f)\n",
    "            if(give_hinge_loss):\n",
    "                print(f'hinge_loss: {hinge_loss(y_true, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | model     | HeteroDeepGraphEmbedding2 | 2.2 M \n",
      "1 | loss_func | HeteroLoss1               | 0     \n",
      "2 | train_acc | BinaryAccuracy            | 0     \n",
      "3 | val_acc   | BinaryAccuracy            | 0     \n",
      "4 | test_acc  | BinaryAccuracy            | 0     \n",
      "--------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "22        Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.829     Total estimated model params size (MB)\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "c:\\Users\\Omid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2/2 [00:01<00:00,  1.83it/s, v_num=2, train_acc_step=0.988, val_acc_step=0.800, val_acc_epoch=0.800, train_acc_epoch=0.990]"
     ]
    }
   ],
   "source": [
    "for k in edge_type_weights:\n",
    "    if k == 'dep':\n",
    "        graph_embedding = HeteroDeepGraphEmbedding2(300, 1, X1.metadata(), 128, dropout=0.2, edge_type_count=11, edge_type_weights=edge_type_weights[k])\n",
    "        graph_embedding = graph_embedding.to(device)\n",
    "        callbacks = [\n",
    "        ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True)\n",
    "        ]\n",
    "        lightning_model = HeteroBinaryLightningModel(graph_embedding,\n",
    "                                        torch.optim.Adam(graph_embedding.parameters(), lr=0.0045, weight_decay=0.001),\n",
    "                                            loss_func=HeteroLoss1(exception_keys=['word'], enc_factor=0.005),\n",
    "                                            learning_rate=0.0045,\n",
    "                                            batch_size=batch_size,\n",
    "                                            user_lr_scheduler=True,\n",
    "                                            min_lr=0.0003\n",
    "                                            ).to(device)\n",
    "        model_manager = ClassifierModelManager(graph_embedding, lightning_model, log_name='hetero_model_10', model_save_dir=r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence\\Practices\\Tasks\\HeterogeneousGraphs\\hetero_model_7',device=device, num_train_epoch=67)\n",
    "        # model_manager.fit(datamodule=data_manager,ckpt_path=\"E:\\\\Darsi\\\\Payan Name Arshad\\\\Second Work\\\\ColorIntelligence2\\\\ColorIntelligence\\\\logs\\\\hetero_model_10\\\\version_2\\\\checkpoints\\\\epoch=67-step=17476.ckpt\")\n",
    "        model_manager.fit(datamodule=data_manager)\n",
    "        # model_manager.save_plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{k}')\n",
    "        # model_manager.torch_model = model_manager.torch_model.to('cuda')\n",
    "        # model_manager.save_evaluation(data_manager.test_dataloader(), f'{k}',True, True, True, True, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.save_plot_csv_logger(loss_names=['train_loss', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc_epoch'], name_prepend=f'tests_{k}')\n",
    "model_manager.torch_model = model_manager.torch_model.to('cuda')\n",
    "model_manager.save_evaluation(data_manager.test_dataloader(), f'{k}',True, True, True, True, True, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
